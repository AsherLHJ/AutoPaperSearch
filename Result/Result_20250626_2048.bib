Search Topic {Explore the text display design in VR multiplayer conversations scenario.}

@inproceedings{10.1145/3706598.3714078,
author = {Lee, Geonsun and Yang, Yue and Healey, Jennifer and Manocha, Dinesh},
title = {Since U Been Gone: Augmenting Context-Aware Transcriptions for Re-Engaging in Immersive VR Meetings},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714078},
doi = {10.1145/3706598.3714078},
abstract = {Maintaining engagement in immersive meetings is challenging, particularly when users must catch up on missed content after disruptions. While transcription interfaces can help, table-fixed panels have the potential to distract users from the group, diminishing social presence, while avatar-fixed captions fail to provide past context. We present EngageSync, a context-aware avatar-fixed transcription interface that adapts based on user engagement, offering live transcriptions and LLM-generated summaries to enhance catching up while preserving social presence. We implemented a live VR meeting setup for a 12-participant formative study and elicited design considerations. In two user studies with small (3 avatars) and mid-sized (7 avatars) groups, EngageSync significantly improved social presence (p &lt;.05) and time spent gazing at others in the group instead of the interface over table-fixed panels. Also, it reduced re-engagement time and increased information recall (p &lt;.05) over avatar-fixed interfaces, with stronger effects in mid-sized groups (p &lt;.01).},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {785},
numpages = {20},
keywords = {Immersive VR Meeting; Social VR; Virtual Reality; Teleconferencing; Co-presence; Re-engagement; Group Conversations; Live Transcriptions},
location = {
},
series = {CHI '25}
}

@INPROCEEDINGS{10494089,
  author={Wu, Jian and Wang, Ziteng and Wang, Lili and Duan, Yuhan and Li, Jiaheng},
  booktitle={2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)}, 
  title={FanPad: A Fan Layout Touchpad Keyboard for Text Entry in VR}, 
  year={2024},
  volume={},
  number={},
  pages={222-232},
  abstract={Text entry poses a significant challenge in the realm of virtual reality (VR). This paper introduces FanPad, a novel solution designed to facilitate dual-hand text input within head-mounted displays (HMDs). FanPad accomplishes this by ingeniously mapping and curving the 26 typing keys (T26) QWERTY keyboard onto the touchpads of both controllers. The curved key layout of FanPad is derived from the natural movement of the thumb when interacting with the touchpad, resembling an arc with a thumb-length fixed radius.To optimize the experience, we introduce a customization process for the FanPad curve to better cope with individual hand shapes and thumb movements. We also provide a version with more overlap area named FanPad-Ov for different users with different typing habits.Our first user study examined the effects of curving and different overlap areas by comparing four potential layouts. The results clearly favor the FanPad and FanPad-Ov layout compared to the nocurving version, SKPad(-Ov). Subsequently, the second user study was conducted to assess long-term performance and improvement on customized FanPads. Notably, novices achieved a typing speed of 19.73 words per minute (WPM), demonstrating a remarkable increase of 58.47% after a 60-phrase training in six days. The highest typing speed reached an impressive 24.19 WPM.},
  keywords={Training;Fans;Three-dimensional displays;Head-mounted displays;Shape;Layout;Thumb;Human-centered computing;Human computer interaction (HCI);Interaction techniques;Text input;HCI design and evaluation methods;User studies},
  doi={10.1109/VR58804.2024.00045},
  ISSN={2642-5254},
  month={March},}

@inproceedings{10.1145/3411764.3445606,
author = {Rzayev, Rufat and Ugnivenko, Polina and Graf, Sarah and Schwind, Valentin and Henze, Niels},
title = {Reading in VR: The Effect of Text Presentation Type and Location},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445606},
doi = {10.1145/3411764.3445606},
abstract = {Reading is a fundamental activity to obtain information both in the real and the digital world. Virtual reality (VR) allows novel approaches for users to view, read, and interact with a text. However, for efficient reading, it is necessary to understand how a text should be displayed in VR without impairing the VR experience. Therefore, we conducted a study with 18 participants to investigate text presentation type and location in VR. We compared world-fixed, edge-fixed, and head-fixed text locations. Texts were displayed using Rapid Serial Visual Presentation (RSVP) or as a paragraph. We found that RSVP is a promising presentation type for reading short texts displayed in edge-fixed or head-fixed location in VR. The paragraph presentation type using world-fixed or edge-fixed location is promising for reading long text if movement in the virtual environment is not required. Insights from our study inform the design of reading interfaces for VR applications.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {531},
numpages = {10},
keywords = {text in VR, reading in VR., Virtual reality, RSVP},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3313831.3376872,
author = {Baceviciute, Sarune and Mottelson, Aske and Terkildsen, Thomas and Makransky, Guido},
title = {Investigating Representation of Text and Audio in Educational VR using Learning Outcomes and EEG},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376872},
doi = {10.1145/3313831.3376872},
abstract = {This paper reports findings from a between-subjects experiment that investigates how different learning content representations in virtual environments (VE) affect the process and outcomes of learning. Seventy-eight participants were subjected to an immersive virtual reality (VR) application, where they received identical instructional information, rendered in three different formats: as text in an overlay interface, as text embedded semantically in a virtual book, or as audio. Learning outcome measures, self-reports, and an electroencephalogram (EEG) were used to compare conditions. Results show that reading was superior to listening for the learning outcomes of retention, self-efficacy, and extraneous attention. Reading text from a virtual book was reported to be less cognitively demanding, compared to reading from an overlay interface. EEG analyses show significantly lower theta and higher alpha activation in the audio condition. The findings provide important considerations for the design of educational VR environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cognitive load, educational technology, eeg, learning, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@INPROCEEDINGS{9089461,
  author={Wei, Chunxue and Yu, Difeng and Dingler, Tilman},
  booktitle={2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
  title={Reading on 3D Surfaces in Virtual Environments}, 
  year={2020},
  volume={},
  number={},
  pages={721-728},
  abstract={While text tends to lead a rather static life on paper and screens, virtual reality (VR) allows readers to interact with it in novel ways: the reading surface is no longer confined to a 2D plane. We conducted two user studies, in which we assessed text rendered on different surface shapes in VR and their effects on legibility and the reading experience. Comparing differently curved surfaces, these studies disclose the impact of warp angles and view box widths on reading comfort, speed, and distraction. Our results suggest that text should be warped around the horizontal rather than the vertical axis, and we provide recommendations for the extent of warp and view box width. In a proof-of-concept application, we used everyday 3D objects as text canvases and studied them through an information-seeking task. The studies’ implications inform VR interfaces and, more generally, the rendering of text on 3D objects.},
  keywords={Three-dimensional displays;Rendering (computer graphics);Virtual environments;Shape;Two dimensional displays;Task analysis;Human-centered computing;Human computer interaction (HCI);HCI design and evaluation methods;User studies;Interaction paradigms;Virtual reality;Interaction design;Interaction design process and methods;User interface design},
  doi={10.1109/VR46266.2020.00095},
  ISSN={2642-5254},
  month={March},}

@inproceedings{10.1145/3706598.3714186,
author = {Xie, Tianze and Zhang, Xuesong and Huang, Feiyu and Liu, Di and An, Pengcheng and Je, Seungwoo},
title = {VRCaptions: Design Captions for DHH Users in Multiplayer Communication in VR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714186},
doi = {10.1145/3706598.3714186},
abstract = {Accessing auditory information remains challenging for DHH individuals in real-world situations and multiplayer VR interactions. To improve this, we investigated caption designs that specialize in the needs of DHH users in multiplayer VR settings. First, we conducted three co-design workshops with DHH participants, social workers, and designers to gather insights into the specific needs of design directions for DHH users in the context of a room escape game in VR. We further refined our designs with 13 DHH users to determine the most preferred features. Based on this, we developed VRCaptions, a caption prototype for DHH users to better experience multiplayer conversations in VR. We lastly invited two mixed-hearing groups to participate in the VR room escape game with our VRCaptions to validate. The results demonstrate that VRCaptions can enhance the ability of DHH participants to access information and reduce the barrier to communication in VR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {757},
numpages = {18},
keywords = {Accessibility, Communication, Virtual Reality, Deaf and Hard of Hearing, Caption Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3313831.3376228,
author = {Hsieh, Ching-Yu and Chiang, Yi-Shyuan and Chiu, Hung-Yu and Chang, Yung-Ju},
title = {Bridging the Virtual and Real Worlds: A Preliminary Study of Messaging Notifications in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376228},
doi = {10.1145/3313831.3376228},
abstract = {Virtual reality (VR) platforms provide their users with immersive virtual environments, but disconnect them from real-world events. The increasing length of VR sessions can therefore be expected to boost users' needs to obtain information about external occurrences such as message arrival. Yet, how and when to present these real-world notifications to users engaged in VR activities remains underexplored. We conducted an experiment to investigate individuals' receptivity during four VR activities (Loading, 360 Video, Treasure Hunt, Rhythm Game) to message notifications delivered using three types of displays (head-mounted, controller, and movable panel). While higher engagement generally led to higher perceptions that notifications were ill-timed and/or disruptive, the suitability of notification displays to VR activities was influenced by the time-sensitiveness of VR content, overlapping use of modalities for delivering alerts, the display locations, and a requirement that the display be moved for notifications to be seen. Specific design suggestions are also provided.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {eye-tracking, interruptibility, notification systems, receptivity, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

