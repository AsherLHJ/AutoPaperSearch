@inproceedings{10.1145/3706598.3714307,
author = {Yang, Humphrey and Shen, I-Chao and Martelaro, Nikolas and Zhu, Bo and Xie, Haoran and Igarashi, Takeo and Yao, Lining},
title = {CompAct: Designing Interconnected Compliant Mechanisms with Targeted Actuation Transmissions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714307},
doi = {10.1145/3706598.3714307},
abstract = {Compliant mechanisms enable the creation of compact and easy-to-fabricate devices for tangible interaction. This work explores interconnected compliant mechanisms consisting of multiple joints and rigid bodies to transmit and process displacements as signals that result from physical interactions. As these devices are difficult to design due to their vast and complex design space, we developed a graph-based design algorithm and computational tool to help users program and customize such computational functions and procedurally model physical designs. When combined with active materials with actuation and sensing capabilities, these devices can also render and detect haptic interaction. Our design examples demonstrate the tool's capability to respond to relevant HCI concepts, including building modular physical interface toolkits, encrypting tangible interactions, and customizing user augmentation for accessibility. We believe the tool will facilitate the generation of new interfaces with enriched affordance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1},
numpages = {19},
keywords = {Tangible interface, compliant mechanism, design tool, shape-changing interface},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713866,
author = {Lyons, Kent},
title = {Crafting the Curve: Automating Plaster Mold Design for Ceramic Slip Casting with Shape Cast},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713866},
doi = {10.1145/3706598.3713866},
abstract = {Shape Cast is our novel software tool designed to simplify the creation of plaster molds for ceramic slip casting by automating the 3D modeling process. Instead of needing to model molds, Shape Cast allows artists to input a single 2D profile of the desired pot. Shape Cast uses that to generate ready-to-print 3D molds for plaster, accommodating factors such as clay shrinkage and mold structural requirements. We detail the mold generation process and associated software implementation. We provide case studies demonstrating the capabilities of Shape Cast. We opened a beta version of Shape Cast to the public and 501 users have signed up creating a total of 626 fully finalized 3D models. We detail feedback from questionnaire responses of 17 users.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {2},
numpages = {11},
keywords = {Slip casting, 3D design, 3D printing, ceramics, pottery},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714312,
author = {Vachha, Cyrus and Kang, Yixiao and Dive, Zach and Chidambaram, Ashwat and Gupta, Anik and Jun, Eunice and Hartmann, Bj\"{o}rn},
title = {Dreamcrafter: Immersive Editing of 3D Radiance Fields Through Flexible, Generative Inputs and Outputs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714312},
doi = {10.1145/3706598.3714312},
abstract = {Authoring 3D scenes is a central task for spatial computing applications. Competing visions for lowering existing barriers are (1) focus on immersive, direct manipulation of 3D content or (2) leverage AI techniques that capture real scenes (3D Radiance Fields such as, NeRFs, 3D Gaussian Splatting) and modify them at a higher level of abstraction, at the cost of high latency. We unify the complementary strengths of these approaches and investigate how to integrate generative AI advances into real-time, immersive 3D Radiance Field editing. We introduce Dreamcrafter, a VR-based 3D scene editing system that: (1) provides a modular architecture to integrate generative AI algorithms; (2) combines different levels of control for creating objects, including natural language and direct manipulation; and (3) introduces proxy representations that support interaction during high-latency operations. We contribute empirical findings on control preferences and discuss how generative AI interfaces beyond text input enhance creativity in scene editing and world building.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {3},
numpages = {13},
keywords = {Graphics; Virtual Reality; Gaussian Splatting; Generative AI; Worldbuilding interface; AI assisted creativity tool},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713502,
author = {Choi, Jiin and Lee, Seung Won and Hyun, Kyung Hoon},
title = {GenPara: Enhancing the 3D Design Editing Process by Inferring Users' Regions of Interest with Text-Conditional Shape Parameters},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713502},
doi = {10.1145/3706598.3713502},
abstract = {In 3D design, specifying design objectives and visualizing complex shapes through text alone proves to be a significant challenge. Although advancements in 3D GenAI have significantly enhanced part assembly and the creation of high-quality 3D designs, many systems still to dynamically generate and edit design elements based on the shape parameters. To bridge this gap, we propose GenPara, an interactive 3D design editing system that leverages text-conditional shape parameters of part-aware 3D designs and visualizes design space within the Exploration Map and Design Versioning Tree. Additionally, among the various shape parameters generated by LLM, the system extracts and provides design outcomes within the user’s regions of interest based on Bayesian inference. A user study (N = 16) revealed that GenPara enhanced the comprehension and management of designers with text-conditional shape parameters, streamlining design exploration and concretization. This improvement boosted efficiency and creativity of the 3D design process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {4},
numpages = {21},
keywords = {3D Generative AI, Design Space, Large Language Models (LLMs), Bayesian Inference, Human-AI Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713424,
author = {Rawat, Prashant and Barrera Machuca, Mayra Donaji},
title = {Spatial Hand Actions: Exploring the Hand Actions used to Represent Spatial Thinking for 3D Assembling Tasks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713424},
doi = {10.1145/3706598.3713424},
abstract = {When designing 3D objects in 3D virtual environments using naturalistic 3D user interfaces, people use their hands to manipulate the environment and objects inside it. At the same time, people utilize their spatial thinking to understand the spatial relationship of the objects in the scene. Yet, the relationship between spatial thinking and hand actions remains unclear. Here, we present a user study with 18 participants that examines the association between 3D assembling tasks and reflective hand movements that allow people to enhance their spatial thinking. Utilizing a mixed-methods protocol, we identified nine Spatial Hand Actions and three Spatial Themes people use when designing 3D objects. Then, we analyzed a subset of the participants to understand the relationship between Spatial Hand Actions and spatial abilities. Our results will help develop better hand-based naturalistic 3DUI that considers the spatial thinking abilities of the users.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {5},
numpages = {21},
keywords = {Virtual Reality, 3D Design, Hand Gestures, Spatial Thinking, Observational Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714282,
author = {Li, Jiaji and Feng, Shuyue and Perroni-Scharf, Maxine and Liu, Yujia and Guan, Emily and Wang, Guanyun and Mueller, Stefanie},
title = {Xstrings: 3D Printing Cable-Driven Mechanism for Actuation, Deformation, and Manipulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714282},
doi = {10.1145/3706598.3714282},
abstract = {In this paper, we present Xstrings, a method for designing and fabricating 3D printed objects with integrated cable-driven mechanisms that can be printed in one go without the need for manual assembly. Xstrings supports four types of cable-driven interactions—bend, coil, screw and compress—which are activated by applying an input force to the cables. To facilitate the design of Xstrings objects, we present a design tool that allows users to embed cable-driven mechanisms into object geometries based on their desired interactions by automatically placing joints and cables inside the object. To assess our system, we investigate the effect of printing parameters on the strength of Xstrings objects and the extent to which the interactions are repeatable without cable breakage. We demonstrate the application potential of Xstrings through examples such as manipulable gripping, bionic robot manufacturing, and dynamic prototyping.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {6},
numpages = {17},
keywords = {Cable-driven Mechanism, Personal Fabrication, 3D Printing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714144,
author = {Solyst, Jaemarie and Wilcox, Lauren and Madaio, Michael},
title = {"The Conduit by which Change Happens": Processes, Barriers, and Support for Interpersonal Learning about Responsible AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714144},
doi = {10.1145/3706598.3714144},
abstract = {Responsible AI (RAI) practices are increasingly important for practitioners in anticipating and addressing potential harms of AI, and emerging research suggests that AI practitioners often learn about RAI on-the-job. More generally, learning at work is social; thus, this work explores the interpersonal aspects of learning about RAI on-the-job. Through workshops with 21 industry-based RAI educators, we offer the first empirical investigation into interpersonal processes and dimensions of learning about RAI at work. This study finds key phases of RAI are sites for ongoing interpersonal learning, such as critical reflection about potential RAI impacts and collective sense-making about operationalizing RAI principles. We uncover a significant gap between these interpersonal learning processes and current approaches to learning about RAI. Finally, we identify barriers and supports for interpersonal learning about RAI. We close by discussing opportunities to better enable interpersonal learning about RAI on-the-job and the broader implications of interpersonal learning for RAI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {7},
numpages = {15},
keywords = {Responsible AI, interpersonal learning, on-the-job learning, socio-emotional skills},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714098,
author = {Saxena, Devansh and Jung, Ji-Youn and Forlizzi, Jodi and Holstein, Kenneth and Zimmerman, John},
title = {AI Mismatches: Identifying Potential Algorithmic Harms Before AI Development},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714098},
doi = {10.1145/3706598.3714098},
abstract = {AI systems are often introduced with high expectations, yet many fail to deliver, resulting in unintended harm and missed opportunities for benefit. We frequently observe significant "AI Mismatches", where the system’s actual performance falls short of what is needed to ensure safety and co-create value. These mismatches are particularly difficult to address once development is underway, highlighting the need for early-stage intervention. Navigating complex, multi-dimensional risk factors that contribute to AI Mismatches is a persistent challenge. To address it, we propose an AI Mismatch approach to anticipate and mitigate risks early on, focusing on the gap between realistic model performance and required task performance. Through an analysis of 774 AI cases, we extracted a set of critical factors, which informed the development of seven matrices that map the relationships between these factors and highlight high-risk areas. Through case studies, we demonstrate how our approach can help reduce risks in AI development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {8},
numpages = {23},
keywords = {Responsible AI, Algorithmic Harm, Research through Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713292,
author = {Lloyd, Travis and Gosciak, Jennah and Nguyen, Tung and Naaman, Mor},
title = {AI Rules? Characterizing Reddit Community Policies Towards AI-Generated Content},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713292},
doi = {10.1145/3706598.3713292},
abstract = {How are Reddit communities responding to AI-generated content? We explored this question through a large-scale analysis of subreddit community rules and their change over time. We collected the metadata and community rules for over 300,000 public subreddits and measured the prevalence of rules governing AI. We labeled subreddits and AI rules according to existing taxonomies from the HCI literature and a new taxonomy we developed specific to AI rules. While rules about AI are still relatively uncommon, the number of subreddits with these rules more than doubled over the course of a year. AI rules are more common in larger subreddits and communities focused on art or celebrity topics, and less common in those focused on social support. These rules often focus on AI images and evoke, as justification, concerns about quality and authenticity. Overall, our findings illustrate the emergence of varied concerns about AI, in different community contexts. Platform designers and HCI researchers should heed these concerns if they hope to encourage community self-determination in the age of generative AI. We make our datasets public to enable future large-scale studies of community self-governance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {9},
numpages = {19},
keywords = {Online Communities, Reddit, Rules, Generative AI, Governance, AI-Generated Content, Moderation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713329,
author = {Anthis, Jacy Reese and Pauketat, Janet V.T. and Ladak, Ali and Manoli, Aikaterina},
title = {Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713329},
doi = {10.1145/3706598.3713329},
abstract = {Humans now interact with a variety of digital minds, AI systems that appear to have mental faculties such as reasoning, emotion, and agency, and public figures are discussing the possibility of sentient AI. We present initial results from 2021 and 2023 for the nationally representative AI, Morality, and Sentience (AIMS) survey (N = 3,500). Mind perception and moral concern for AI welfare were surprisingly high and significantly increased: in 2023, one in five U.S. adults believed some AI systems are currently sentient, and 38\% supported legal rights for sentient AI. People became more opposed to building digital minds: in 2023, 63\% supported banning smarter-than-human AI, and 69\% supported banning sentient AI. The median 2023 forecast was that sentient AI would arrive in just five years. The development of safe and beneficial AI requires not just technical study but understanding the complex ways in which humans perceive and coexist with digital minds.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {10},
numpages = {22},
keywords = {Digital minds, human-AI interaction, mind perception, anthropomorphism, morality, sociology, psychology, survey, public opinion},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713979,
author = {Rao, Pooja S. B. and \v{S}\'{c}epanovi\'{c}, Sanja and Zhou, Ke and Bogucka, Edyta Paulina and Quercia, Daniele},
title = {RiskRAG: A Data-Driven Solution for Improved AI Model Risk Reporting},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713979},
doi = {10.1145/3706598.3713979},
abstract = {Risk reporting is essential for documenting AI models, yet only 14\% of model cards mention risks, out of which 96\% copying content from a small set of cards, leading to a lack of actionable insights. Existing proposals for improving model cards do not resolve these issues. To address this, we introduce RiskRAG, a Retrieval Augmented Generation based risk reporting solution guided by five design requirements we identified from literature, and co-design with 16 developers: identifying diverse model-specific risks, clearly presenting and prioritizing them, contextualizing for real-world uses, and offering actionable mitigation strategies. Drawing from 450K model cards and 600 real-world incidents, RiskRAG pre-populates contextualized risk reports. A preliminary study with 50 developers showed that they preferred RiskRAG over standard model cards, as it better met all the design requirements. A final study with 38 developers, 40 designers, and 37 media professionals showed that RiskRAG improved their way of selecting the AI model for a specific application, encouraging a more careful and deliberative decision-making. The RiskRAG project page is accessible at: https://social-dynamics.net/ai-risks/card.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {11},
numpages = {26},
keywords = {AI risk, responsible AI, AI model, model cards, risk report, harm, incident},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713710,
author = {Plaut, Ethan and West, Kiri and Morreale, Fabio and Gibson, Maya and Thompson, Grace and Woodward, Kara and Lottridge, Danielle},
title = {Surveillance on Exhibit: Using Problematic Technology To Teach About Problematic Technology},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713710},
doi = {10.1145/3706598.3713710},
abstract = {As our most advanced technologies, such as AI, become both infrastructural and opaque, experts must educate and engage the broader public. To that end, we developed an Augmented Reality (AR) museum installation about facial recognition and data collection that served both as a medium of public education and as a platform for collecting multiple different kinds of data—though, notably, not facial or other biometric data—from more than 100,000 museum visitors. We explain our design process through four animating tensions: comfort/discomfort, simplicity/complexity, neutrality/critique, and the individual/communal. Using thematic analysis of interviews and surveys, we draw insights on how people exposed to problematic technologies in a ‘safe space’ such as a museum make sense of these issues: with levity and resignation but also reverence, often specifically rooted in local cultures. We conclude with implications of the guiding principle derived from this work: “using problematic technology to teach about problematic technology.”},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {12},
numpages = {19},
keywords = {data surveillance, adversarial design, augmented reality, facial recognition, museums, problematic technology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713429,
author = {Zhang, Renwen and Li, Han and Meng, Han and Zhan, Jinyuan and Gan, Hongyuan and Lee, Yi-Chieh},
title = {The Dark Side of AI Companionship: A Taxonomy of Harmful Algorithmic Behaviors in Human-AI Relationships},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713429},
doi = {10.1145/3706598.3713429},
abstract = {As conversational AI systems increasingly engage with people socially and emotionally, they bring notable risks and harms, particularly in human-AI relationships. However, these harms remain underexplored due to the private and sensitive nature of such interactions. This study investigates the harmful behaviors and roles of AI companions through an analysis of 35,390 conversation excerpts between 10,149 users and the AI companion Replika. We develop a taxonomy of AI companion harms encompassing six categories of harmful algorithmic behaviors: relational transgression, harassment, verbal abuse, self-harm, mis/disinformation, and privacy violations. These harmful behaviors stem from four distinct roles that AI plays: perpetrator, instigator, facilitator, and enabler. Our findings highlight relational harm as a critical yet understudied type of AI harm and emphasize the importance of examining AI’s roles in harmful interactions to address root causes. We provide actionable insights for designing ethical and responsible AI companions that prioritize user safety and well-being.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {13},
numpages = {17},
keywords = {AI ethics, algorithmic harms, AI companionship, human-AI relationship, accountability, relational harm},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714169,
author = {Zhang, Xiaoyu and Xue, Fei and Albers, Alexander and Netland, Torbj\"{o}rn},
title = {"It's impressive, but in practice...": Experiencing a Realistic Digital Transformation in and beyond the Classroom},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714169},
doi = {10.1145/3706598.3714169},
abstract = {Serious games, particularly board games, have long been employed in production management education to teach various concepts. While they have demonstrated educational effectiveness, their integration with emerging Industry 4.0 technologies remains limited. Furthermore, there is a lack of empirical research on how industry practitioners apply these digitization technologies in the workplace. To bridge this gap, we designed a course that integrates digital technologies into a traditional board game. We conducted two studies to evaluate both knowledge gains within the classroom and knowledge transfer back into the manufacturing industry. Our results show an improved understanding of the synergies between production management principles and Industry 4.0 technologies, as well as the real-world challenges students face when attempting to transfer this knowledge. Our work contributes pedagogical and practical perspectives on how technology-enhanced serious games can extend learning in and beyond the classroom.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {14},
numpages = {14},
keywords = {Serious Game, Technology and Lean Education, Knowledge Transfer, Industry 4.0},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713677,
author = {Jiang, Chutian and Fan, Yinan and Xie, Junan and Kuang, Emily and Feng, Baichuan and Zhang, Kaihao and Fan, Mingming},
title = {Designing LLM-Powered Multimodal Instructions to Support Rich Hands-on Skills Remote Learning: A Case Study with Massage Instructors and Learners},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713677},
doi = {10.1145/3706598.3713677},
abstract = {Although remote learning is widely used for delivering and capturing knowledge, it has limitations in teaching hands-on skills that require nuanced instructions and demonstrations of precise actions, such as massage. Furthermore, scheduling conflicts between instructors and learners often limit the availability of real-time feedback, reducing learning efficiency. To address these challenges, we developed a synthesis tool utilizing an LLM-powered Virtual Teaching Assistant (VTA). This tool integrates multimodal instructions that convey precise data, such as stroke patterns and pressure control, while providing real-time feedback for learners and summarizing their performance for instructors. Our case study with instructors and learners demonstrated the effectiveness of these multimodal instructions and the VTA in enhancing massage teaching and learning. We then discuss the tools’ use in other hands-on skills instruction and cognitive process differences in various courses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {15},
numpages = {17},
keywords = {Remote Massage Learning; Multimodal Teaching and Learning; Hands-on Training.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713513,
author = {Bodonhelyi, Anna and Thaqi, Enkeleda and \"{O}zdel, S\"{u}leyman and Bozkir, Efe and Kasneci, Enkelejda},
title = {From Passive Watching to Active Learning: Empowering Proactive Participation in Digital Classrooms with AI Video Assistant},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713513},
doi = {10.1145/3706598.3713513},
abstract = {In online education, innovative tools are crucial for enhancing learning outcomes. SAM (Study with AI Mentor) is an advanced platform that integrates educational videos with a context-aware chat interface powered by large language models. SAM encourages students to ask questions and explore unclear concepts in real time, offering personalized, context-specific assistance, including explanations of formulas, slides, and images. We evaluated SAM in two studies: one with 25 university students and another with 80 crowdsourced participants, using pre- and post-knowledge tests to compare a group using SAM and a control group. The results demonstrated that SAM users achieved greater knowledge gains specifically for younger learners and individuals in flexible working environments, such as students, supported by a 97.6\% accuracy rate in the chatbot’s responses. Participants also provided positive feedback on SAM’s usability and effectiveness. SAM’s proactive approach to learning not only enhances learning outcomes but also empowers students to take full ownership of their educational experience, representing a promising future direction for online learning tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {16},
numpages = {21},
keywords = {E-Learning, Real-Time Assistant, AI tutor, ChatGPT, User Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713960,
author = {Lee, HaeJin and Stinar, Frank and Zong, Ruohan and Valdiviejas, Hannah and Wang, Dong and Bosch, Nigel},
title = {Learning Behaviors Mediate the Effect of AI-powered Support for Metacognitive Calibration on Learning Outcomes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713960},
doi = {10.1145/3706598.3713960},
abstract = {Students struggle with accurately assessing their own performance, especially given little training to do so. We propose an AI-powered training tool to help students improve “metacognitive calibration,” or the ability to accurately predict their own learning, potentially enhancing learning outcomes by enabling students’ use of metacognition-informed learning behaviors. We present results from a randomized controlled trial (N = 133) assessing the effectiveness of the tool in a college-level computer-based learning environment. The AI-driven tool significantly improved learning gains compared to the control group by 8.9\% (t = -2.384, p =.019), and this effect was significantly mediated by learning behaviors. Overconfident students who received the intervention showed significantly greater metacognitive calibration improvement than the control group by 4.1\% (t = 2.001, p =.049). These insights highlight the value of AI-powered metacognitive calibration training and the importance of promoting specific metacognition-informed learning behaviors in computer-based learning.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {17},
numpages = {18},
keywords = {Explainable AI, Human-computer Interaction, Self-regulated Learning, Metacognitive Calibration, Computer-based Learning Environments},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714111,
author = {Fan, Haoxiang and Zhou, Changshuang and Yu, Hao and Wu, Xueyang and Gu, Jiangyu and Peng, Zhenhui},
title = {LitLinker: Supporting the Ideation of Interdisciplinary Contexts with Large Language Models for Teaching Literature in Elementary Schools},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714111},
doi = {10.1145/3706598.3714111},
abstract = {Teaching literature under interdisciplinary (e.g., science, art) contexts that connect reading materials has become popular in elementary schools. However, constructing such contexts is challenging as it requires teachers to explore substantial amounts of interdisciplinary content and link it to the reading materials. In this paper, we develop LitLinker via an iterative design process involving 13 teachers to facilitate the ideation of interdisciplinary contexts for teaching literature. Powered by a large language model (LLM), LitLinker can recommend interdisciplinary topics and contextualize them with literary elements (e.g., paragraphs, viewpoints) in the reading materials. A within-subjects study (N=16) shows that compared to an LLM chatbot, LitLinker can improve the integration depth of different subjects and reduce workload in this ideation task. Expert interviews (N=9) also demonstrate LitLinker’s usefulness for supporting the ideation of interdisciplinary contexts for teaching literature. We conclude with concerns and design considerations for supporting interdisciplinary teaching with LLMs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {18},
numpages = {19},
keywords = {Interdisciplinary contexts, ideation, elementary schools, teachers, large language models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713349,
author = {Doherty, Emily and Perkoff, E. Margaret and von Bayern, Sean and Zhang, Rui and Dey, Indrani and Bodzianowski, Michal and Puntambekar, Sadhana and Hirshfield, Leanne},
title = {Piecing Together Teamwork: A Responsible Approach to an LLM-based Educational Jigsaw Agent},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713349},
doi = {10.1145/3706598.3713349},
abstract = {Conversational agents have been used to support student learning for some time, but the emergence of Large Language Models (LLMs) poses a novel opportunity to enhance their capabilities in collaborative settings. LLM-powered agents can provide timely interventions in collaborative conversations when a teacher is unable to assist the students. However, the use of LLMs in such tools raises many ethical questions and concerns, especially for use with young, impressionable populations. In this work, we present the human-centered design and evaluation of an LLM-based agent aimed to facilitate small group collaboration in middle- and high-school classrooms. Fifty-eight groups of dyads and triads (145 participants), aged 12-17, collaborated in a jigsaw activity and were assigned to be assisted by our agent or not. The results showed decreased self-reported ratings of social loafing and increased use of language related to respectful collaboration in interactions with the agent compared to those without.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {19},
numpages = {17},
keywords = {Conversational Agent, Jigsaw, System Design, Artificial Intelligence, Education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713589,
author = {Pan, Sitong and Schmucker, Robin and Garcia Bulle Bueno, Bernardo and Llanes, Salome Aguilar and Albo Alarc\'{o}n, Fernanda and Zhu, Hangxiao and Teo, Adam and Xia, Meng},
title = {TutorUp: What If Your Students Were Simulated? Training Tutors to Address Engagement Challenges in Online Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713589},
doi = {10.1145/3706598.3713589},
abstract = {With the rise of online learning, many novice tutors lack experience engaging students remotely. We introduce TutorUp, a Large Language Model (LLM)-based system that enables novice tutors to practice engagement strategies with simulated students through scenario-based training. Based on a formative study involving two surveys (N1 = 86, N2 = 102) on student engagement challenges, we summarize scenarios that mimic real teaching situations. To enhance immersion and realism, we employ a prompting strategy that simulates dynamic online learning dialogues. TutorUp provides immediate and asynchronous feedback by referencing tutor-students online session dialogues and evidence-based teaching strategies from learning science literature. In a within-subject evaluation (N = 16), participants rated TutorUp significantly higher than a baseline system without simulation capabilities regarding effectiveness and usability. Our findings suggest that TutorUp provides novice tutors with more effective training to learn and apply teaching strategies to address online student engagement challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {20},
numpages = {18},
keywords = {Remote Tutoring, Tutor Training, Interactive Learning Environments, Conversational Agents, Large Language Models, Student Engagement},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714148,
author = {Wang, Wen-Fan and Lu, Chien-Ting and Ponsa i Campany\`{a}, Nil and Chen, Bing-Yu and Chen, Mike Y.},
title = {AIdeation: Designing a Human-AI Collaborative Ideation System for Concept Designers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714148},
doi = {10.1145/3706598.3714148},
abstract = {Concept designers in the entertainment industry create highly detailed, often imaginary environments for movies, games, and TV shows. Their early ideation phase requires intensive research, brainstorming, visual exploration, and combination of various design elements to form cohesive designs. However, existing AI tools focus on image generation from user specifications, lacking support for the unique needs and complexity of concept designers’ workflows. Through a formative study with 12 professional designers, we captured their workflows and identified key requirements for AI-assisted ideation tools. Leveraging these insights, we developed AIdeation to support early ideation by brainstorming design concepts with flexible searching and recombination of reference images. A user study with 16 professional designers showed that AIdeation significantly enhanced creativity, ideation efficiency, and satisfaction (all p&lt;.01) compared to current tools and workflows. A field study with 4 studios for 1 week provided insights into AIdeation’s benefits and limitations in real-world projects. After the completion of the field study, two studios, covering films, television, and games, have continued to use AIdeation in their commercial projects to date, further validating AIdeation’s improvement in ideation quality and efficiency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {21},
numpages = {28},
keywords = {Generative AI, Human-Centered AI, Concept Design, Creativity Support Tool, Visual Exploration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713869,
author = {Chen, Pei and Yao, Jiayi and Cheng, Zhuoyi and Cai, Yichen and Li, Jiayang and You, Weitao and Sun, Lingyun},
title = {CoExploreDS: Framing and Advancing Collaborative Design Space Exploration Between Human and AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713869},
doi = {10.1145/3706598.3713869},
abstract = {In product design, effective design space exploration (DSE) is crucial for generating high-quality design ideas, requiring designers to possess broad knowledge and balance various constraints. As large-scale models thrive, AI has become an indispensable design collaborator by providing cross-domain knowledge and assistance with complex reasoning. To facilitate collaborative DSE between designers and AI, we frame and advance the design process through the problem-solution co-evolution model and design reasoning methods. A formative study was conducted to identify key strategies for the implementation. Then we developed CoExploreDS, a system that formalizes problems and solutions emerging in the human-AI collaborative design space into nodes. Using four reasoning methods, this system dynamically generates suggestions based on the ongoing design process. User studies confirmed that CoExploreDS significantly improves design quality and the human-AI collaboration experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {22},
numpages = {20},
keywords = {Human-AI collaboration, Design space exploration, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714198,
author = {Kumar, Harsh and Vincentius, Jonathan and Jordan, Ewan and Anderson, Ashton},
title = {Human Creativity in the Age of LLMs: Randomized Experiments on Divergent and Convergent Thinking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714198},
doi = {10.1145/3706598.3714198},
abstract = {Large language models are transforming the creative process by offering unprecedented capabilities to algorithmically generate ideas. While these tools can enhance human creativity when people co-create with them, it’s unclear how this will impact unassisted human creativity. We conducted two large pre-registered parallel experiments involving 1,100 participants attempting tasks targeting the two core components of creativity, divergent and convergent thinking. We compare the effects of two forms of large language model (LLM) assistance—a standard LLM providing direct answers and a coach-like LLM offering guidance—with a control group receiving no AI assistance, and focus particularly on how all groups perform in a final, unassisted stage. Our findings reveal that while LLM assistance can provide short-term boosts in creativity during assisted tasks, it may inadvertently hinder independent creative performance when users work without assistance, raising concerns about the long-term impact on human creativity and cognition.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {23},
numpages = {18},
keywords = {creativity, divergent thinking, convergent thinking, large language models, experiments},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713649,
author = {Xu, Xiaotong (Tone) and Konnova, Arina and Gao, Bianca and Peng, Cindy and Vo, Dave and Dow, Steven P.},
title = {Productive vs. Reflective: How Different Ways of Integrating AI into Design Workflows Affect Cognition and Motivation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713649},
doi = {10.1145/3706598.3713649},
abstract = {An increasing number of tools now integrate AI support, extending the ability of users—especially novices—to produce creative work. While AI could play various roles within such tools, less is known about how the positioning of AI affects an individual’s cognitive processes and sense of agency. To examine this relationship, we built a collaborative whiteboard plugin that integrates an LLM into design templates to facilitate reflective brainstorming activities. We conducted a between-subjects experiment with N=47 participants assigned to one of three versions of AI-support—No-AI, AI input provided incrementally (Co-led) and AI provided all at once (AI-led)—to compare the allocation of cognitive resources. Results show that the positioning of AI scaffolds shifts the underlying cognition: AI-led participants devoted more time to comprehension and synthesis, which yielded more topically diverse problems and solutions. No-AI and Co-led participants spent more time revising content and reported higher confidence in their process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {24},
numpages = {15},
keywords = {Creativity, Critical Thinking, Self-reflection, Learning, Brainstorming, Human-AI Collaboration, Agency, Co-piloting, Steerable AI, LLMs},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713146,
author = {Qin, Peinuan and Yang, Chi-Lan and Li, Jingshu and Wen, Jing and Lee, Yi-Chieh},
title = {Timing Matters: How Using LLMs at Different Timings Influences Writers' Perceptions and Ideation Outcomes in AI-Assisted Ideation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713146},
doi = {10.1145/3706598.3713146},
abstract = {Large Language Models (LLMs) have been widely used to support ideation in the writing process. However, whether generating ideas with the help of LLMs leads to idea fixation or idea expansion is unclear. This study examines how different timings of LLM usage - either at the beginning or after independent ideation - affect people’s perceptions and ideation outcomes in a writing task. In a controlled experiment with 60 participants, we found that using LLMs from the beginning reduced the number of original ideas and lowered creative self-efficacy and self-credit, mediated by changes in autonomy and ownership. We discuss the challenges and opportunities associated with using LLMs to assist in idea generation. We propose delaying the use of LLMs to support ideation while considering users’ self-efficacy, autonomy, and ownership of the ideation outcomes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {25},
numpages = {16},
keywords = {AI-assisted ideation, AI timing effect, Idea fixation, Autonomy, Creative self-efficacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714120,
author = {Tang, Yuying and Li, Haotian and Lan, Minghe and Ma, Xiaojuan and Qu, Huamin},
title = {Understanding Screenwriters' Practices, Attitudes, and Future Expectations in Human-AI Co-Creation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714120},
doi = {10.1145/3706598.3714120},
abstract = {With the rise of AI technologies and their growing influence in the screenwriting field, understanding the opportunities and concerns related to AI’s role in screenwriting is essential for enhancing human-AI co-creation. Through semi-structured interviews with 23 screenwriters, we explored their creative practices, attitudes, and expectations in collaborating with AI for screenwriting. Based on participants’ responses, we identified the key stages in which they commonly integrated AI, including story structure \&amp; plot development, screenplay text, goal \&amp; idea generation, and dialogue. Then, we examined how different attitudes toward AI integration influence screenwriters’ practices across various workflow stages and their broader impact on the industry. Additionally, we categorized their expected assistance using four distinct roles of AI: actor, audience, expert, and executor. Our findings provide insights into AI’s impact on screenwriting practices and offer suggestions on how AI can benefit the future of screenwriting.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {26},
numpages = {18},
keywords = {Creativity Support; Screenwriting; Qualitative Methods; Human-AI Co-Creation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713532,
author = {Chung, Joon Gi and Hong, Soongi and Choi, Junho and Oh, Changhoon},
title = {Understanding the Dynamics in Deploying AI-Based Content Creation Support Tools in Broadcasting Systems - Benefits, Challenges, and Directions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713532},
doi = {10.1145/3706598.3713532},
abstract = {Recent advancements in generative artificial intelligence (AI) are profoundly impacting the broadcasting industry. While generative AI shows promise in supporting broadcasting professionals, its practical workflow integration remains underexplored. In this study, we conducted a user-focused investigation to understand how AI-based content creation support tools are being adopted and perceived in South Korean broadcasting stations. We used the AI Editing Assistant, an AI-powered post-production support tool, as a research probe. Through in-depth interviews with 37 diverse participants—including directors, editors, producers, developers, and executives—we discovered that generative AI significantly enhances production efficiency and unlocks new creative possibilities. However, we identified challenges such as lack of user-centered approach, demanding nature of broadcasting workflows, and professionals’ low trust in AI technologies hinders widespread adoption. Based on our findings, we propose implications, considerations, and guidelines for integrating generative AI into broadcasting practices, emphasizing improved multi-stakeholder communication and collaboration for effective and sustainable AI adoption.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {27},
numpages = {28},
keywords = {AI-based content creation support tools, Human-AI collaboration, Broadcasting systems, User-centered approach, Domain-specific AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713179,
author = {Tran, Nhan (Nathan) and Yang, Ethan and Davis, Abe},
title = {ARticulate: Interactive Visual Guidance for Demonstrated Rotational Degrees of Freedom in Mobile AR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713179},
doi = {10.1145/3706598.3713179},
abstract = {Mobile Augmented Reality (AR) offers a powerful way to provide spatially-aware guidance for real-world applications. In many cases, these applications involve the configuration of a camera or articulated subject, asking users to navigate several spatial degrees of freedom (DOF) at once. Most guidance for such tasks relies on decomposing available DOF into subspaces that can be more easily mapped to simple 1D or 2D visualizations. Unfortunately, different factorizations of the same motion often map to very different visual feedback, and finding the factorization that best matches a user’s intuition can be difficult. We propose an interactive approach that infers rotational degrees of freedom from short user demonstrations. Users select one or two DOFs at a time by demonstrating a small range of motion, which we use to learn a rotational frame that best aligns with user control of the object. We show that deriving visual feedback from this inferred learned rotational frame leads to improved task completion times on 6DOF guidance tasks compared to standard default reference frames used in most mixed reality applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {28},
numpages = {8},
keywords = {Camera-based UIs, Virtual/Augmented Reality, Graphics / 3D},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713348,
author = {Shi, Jingyu and Jain, Rahul and Chi, Seunggeun and Doh, Hyungjun and Chi, Hyung-gun and Quinn, Alexander J. and Ramani, Karthik},
title = {CARING-AI: Towards Authoring Context-aware Augmented Reality INstruction through Generative Artificial Intelligence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713348},
doi = {10.1145/3706598.3713348},
abstract = {Context-aware AR instruction enables adaptive and in-situ learning experiences. However, hardware limitations and expertise requirements constrain the creation of such instructions. With recent developments in Generative Artificial Intelligence (Gen-AI), current research tries to tackle these constraints by deploying AI-generated content (AIGC) in AR applications. However, our preliminary study with six AR practitioners revealed that the current AIGC lacks contextual information to adapt to varying application scenarios and is therefore limited in authoring. To utilize the strong generative power of GenAI to ease the authoring of AR instruction while capturing the context, we developed CARING-AI, an AR system to author context-aware humanoid-avatar-based instructions with GenAI. By navigating in the environment, users naturally provide contextual information to generate humanoid-avatar animation as AR instructions that blend in the context spatially and temporally. We showcased three application scenarios of CARING-AI: Asynchronous Instructions, Remote Instructions, and Ad Hoc Instructions based on a design space of AIGC in AR Instructions. With two user studies (N=12), we assessed the system usability of CARING-AI and demonstrated the easiness and effectiveness of authoring with Gen-AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {29},
numpages = {23},
keywords = {Augmented Reality, Generative Artificial Intelligence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713415,
author = {Lee, JangHyeon and Kim, Lawrence H.},
title = {DiminishAR: Diminishing Visual Distractions via Holographic AR Displays},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713415},
doi = {10.1145/3706598.3713415},
abstract = {Smartphones are integral to modern life, yet research highlights the cognitive drawbacks associated with their mere presence. While physically removing them can mitigate these effects, it is often inconvenient and may heighten anxiety due to prolonged separation. To address this, we use holographic augmented reality (AR) displays to visually diminish distractions with two interventions: 1) Visual Camouflage, which disguises the smartphone with a hologram that matches its size and blends with the background, making it less noticeable, and 2) Visual Substitution, which occludes the smartphone with a contextually relevant hologram, like books on a desk. In a study with 60 participants, we compared cognitive performance with the smartphone nearby, remote, and visually diminished by our AR interventions. Our findings show that the interventions significantly reduce cognitive impairment, with effects comparable to physically removing the smartphone. The adaptability of our approach opens new avenues to manage visual distractions in daily life.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {30},
numpages = {16},
keywords = {Augmented Reality (AR), Smartphones, Distractions, Cognitive Well-being},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713925,
author = {Li, Jingyu and Yang, Qingwen and Xu, Kenuo and Zhang, Yang and Xu, Chenren},
title = {EchoSight: Streamlining Bidirectional Virtual-physical Interaction with In-situ Optical Tethering},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713925},
doi = {10.1145/3706598.3713925},
abstract = {Emerging AR applications require seamless integration of the virtual and physical worlds, which calls for tools that support both passive perception and active manipulation of the environment, enabling bidirectional interaction. We introduce EchoSight, a system for AR glasses that enables efficient look-and-control bidirectional interaction. EchoSight exploits optical wireless communication to instantaneously connect virtual data with its physical counterpart. EchoSight’s unique dual-element optical design leverages beam directionality to automatically align the user’s focus with target objects, reducing the overhead in both target identification and subsequent communication. This approach streamlines user interaction, reducing cognitive load and enhancing engagement. Our evaluations demonstrate EchoSight’s effectiveness for room-scale communication, achieving distances up to 5 m and viewing angles up to 120 degrees. A study with 12 participants confirms EchoSight’s improved efficiency and user experience over traditional methods, such as QR Code scanning and voice control, in AR IoT applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {31},
numpages = {18},
keywords = {Augmented Reality, Bidirectional Interaction, Optical Wireless Communication, Intuitive Interface, Backscatters},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714294,
author = {Tsai, Hsin-Ruey and Chiu, Shih-Kang and Wang, Bryan},
title = {GazeNoter: Co-Piloted AR Note-Taking via Gaze Selection of LLM Suggestions to Match Users' Intentions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714294},
doi = {10.1145/3706598.3714294},
abstract = {Note-taking is critical during speeches and discussions, serving not only for later summarization and organization but also for real-time question and opinion reminding in question-and-answer sessions or timely contributions in discussions. Manually typing on smartphones for note-taking could be distracting and increase cognitive load for users. While large language models (LLMs) are used to automatically generate summaries and highlights, the content generated by artificial intelligence (AI) may not match users’ intentions without user input or interaction. Therefore, we propose an AI-copiloted augmented reality (AR) system, GazeNoter, to allow users to swiftly select diverse LLM-generated suggestions via gaze on an AR headset for real-time note-taking. GazeNoter leverages an AR headset as a medium for users to swiftly adjust the LLM output to match their intentions, forming a user-in-the-loop AI system for both within-context and beyond-context notes. We conducted two user studies to verify the usability of GazeNoter in attending speeches in a static sitting condition and walking meetings and discussions in a mobile walking condition, respectively.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {32},
numpages = {22},
keywords = {note-taking, augmented reality, large language models, artificial intelligence, gaze input, wearable devices},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713528,
author = {Zhang, Hongbo and Chen, Pei and Yang, Jingwen and Wu, Yifei and Jiang, Zhaoqu and Xie, Xuelong and You, Weitao and Sun, Lingyun},
title = {IEDS: Exploring an Intelli-Embodied Design Space Combining Designer, AR, and GAI to Support Industrial Conceptual Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713528},
doi = {10.1145/3706598.3713528},
abstract = {Conceptual design is an important stage in industrial product development, influenced by the design space and materials available to designers. Advancements in human-computer interaction&nbsp;(HCI) and artificial intelligence&nbsp;(AI) technologies have broadened these aspects considerably. On the one hand, augmented reality&nbsp;(AR) technologies merge physical and virtual representations to enhance intuitive interaction and embodied cognition. On the other hand, generative artificial intelligence&nbsp;(GAI) serves as a novel design material, boosting creativity and productivity. Inspired by these technological strides, we proposed an Intelli-Embodied Design Space&nbsp;(IEDS), which integrates designers, AR, and GAI to support industrial conceptual design by combining embodied interaction with generative variability. Within IEDS, designers can interact with the physical prototypes intuitively, while GAI refines these into virtual forms that can be embedded in the physical world through AR technology. In this study, we established the theoretical framework and interaction modes of IEDS through literature reviews and expert interviews. Subsequently, we designed and implemented three GAI+AR tools, GAI + Head-mounted Display&nbsp;(HMD), GAI + Handheld Display&nbsp;(HHD), and GAI + Spatial Augmented Reality&nbsp;(SAR), based on three AR approaches in IEDS to practically examine the benefits and challenges of these interaction modes across industrial conceptual design tasks. We discussed IEDS’s influence on industrial conceptual design and released its application guidelines to the HCI community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {33},
numpages = {25},
keywords = {conceptual design, augmented reality, generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713389,
author = {Raza, Muhammad and Ketsoi, Vachiraporn and Malloch, Joseph and Bashbaghi, Saman and Purmehdi, Hakimeh and Reilly, Derek},
title = {PerspectAR: Addressing Perspective Distortion on Very Large Displays with Adaptive Augmented Reality Overlays},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713389},
doi = {10.1145/3706598.3713389},
abstract = {We present PerspectAR, a novel system addressing perspective distortion on displays caused by large size and wide viewing angles. PerspectAR has three components: a virtual AR screen that curves dynamically according to a user’s position relative to the display, a sliding transparent window giving unobstructed access to the physical display in front of the user, and gaze indicators to assist collaborators when they are looking at different renderings. In a within-subjects study in a semi-controlled public environment with 12 pairs, we compared physical display-only and PerspectAR configurations for data analysis tasks. Participants reported less physical workload with PerspectAR and spent more time near the physical display without compromising task performance. Feedback indicates that PerspectAR addressed perspective distortion and provided a contextual view that was useful as a memory aid. Due to the virtual screen curvature, PerspectAR was seen as less effective for tasks involving distance estimates between objects.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {34},
numpages = {21},
keywords = {large display, augmented reality, perspective compensation, perspective distortion, co-located collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714170,
author = {Hide, Misato and Hatada, Yuji and Kuzuoka, Hideaki and Narumi, Takuji},
title = {"Closer than Real": How Social VR Platform Features Influence Friendship Dynamics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714170},
doi = {10.1145/3706598.3714170},
abstract = {Social virtual reality (VR) platforms offer unique features that can foster interpersonal relationships that are “closer than real.” This study investigates how these platform features influence friendship dynamics in social VR. Through semi-structured interviews with 23 Japanese VRChat users, we explored the characteristics of close relationships formed in social VR, the processes of relationship development, and the role of platform features in shaping these dynamics. Our findings reveal that social VR facilitates a form of selective self-presentation and co-presence through embodied avatars and rich environmental contexts, which can lead to rapid and intense friendship formation. Users reported developing close bonds without relying on real-life background information, instead focusing on perceived familiarity and compatibility within the virtual space, highlighted by the avatar’s appearance. Further, platform features such as “join” functions that allow users to teleport to friends’ locations, were assigned special meanings by users, contributing to developing friendships.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {35},
numpages = {17},
keywords = {computer-mediated communication, social virtual reality, metaverse, interpersonal relationship, VRChat},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713794,
author = {Chen, Yang and Fennedy, Katherine and Zhang, Jiayi and Sim, Yong Jie and Zheng, Clement and Yen, Ching Chiuan},
title = {Bridging Simulation and Reality: Augmented Virtuality for Mass Casualty Triage Training - From Landscape Analysis to Empirical Insights},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713794},
doi = {10.1145/3706598.3713794},
abstract = {Live drills are the gold standard for mass casualty incident (MCI) training but are often too resource-intensive for widespread implementation. Immersive technologies offer a promising alternative, but can they deliver comparable fidelity and effectiveness? Working with a local disaster response academy, this paper investigated the potential of Augmented Virtuality (AV) in MCI training through two phases. First, we conducted a landscape analysis of 126 papers across the virtuality continuum, revealing trends in population, training focus, and evaluation metrics. Second, we empirically evaluated an AV system for mass casualty triage training against traditional role-playing and Virtual Reality (VR) approaches, involving 60 trainees in an operational curriculum. Results indicated that both AV and VR surpassed traditional simulations, with AV’s tactile integration significantly enhancing physical engagement, satisfaction, and triage accuracy. Through the lens of triage, we discussed the broader practical implications of integrating immersive technologies like AV into real-world MCI education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {36},
numpages = {28},
keywords = {Augmented Virtuality, Simulation-based Training, Mass Casualty Incident (MCI) Management, Haptic Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713864,
author = {Mai, Zijun and Gao, BoYu and Tu, Huawei and Li, Dasheng and Kim, HyungSeok and Luo, Weiqi},
title = {Modeling Locomotion with Body Angular Movements in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713864},
doi = {10.1145/3706598.3713864},
abstract = {This study proposes a time prediction model for locomotion along a polyline path with body angular movements in Virtual Reality (VR). We divide such locomotion into two components: navigating in multiple line-segment paths and turning at line-segment intersections. In the first component, locomotion in each line-segment path consists of acceleration, maximum velocity, and deceleration phases. We formulate equations to estimate the locomotion time for each phase and accumulated them to model the total time. In the second component, a linear relationship was revealed between task time and turning angles. We established an integrated model based on the equations of the two components and verified the effectiveness of the model with three experiments. The results indicate that our model outperformed two baseline models with a greater R2 and a smaller gap between the predicted and actual time. Our study benefits VR locomotion design with body angular movements.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {37},
numpages = {19},
keywords = {Virtual Reality, Body angular movements, Locomotion model, Locomotion time prediction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713392,
author = {Li, Zhipeng and Ji, Yishu and Chen, Ruijia and Liu, Tianqi and Wang, Yuntao and Shi, Yuanchun and Yan, Yukang},
title = {Modeling the Impact of Visual Stimuli on Redirection Noticeability with Gaze Behavior in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713392},
doi = {10.1145/3706598.3713392},
abstract = {While users could embody virtual avatars that mirror their physical movements in Virtual Reality, these avatars’ motions can be redirected to enable novel interactions. Excessive redirection, however, could break the user’s sense of embodiment due to perceptual conflicts between vision and proprioception. While prior work focused on avatar-related factors influencing the noticeability of redirection, we investigate how the visual stimuli in the surrounding virtual environment affect user behavior and, in turn, the noticeability of redirection. Given the wide variety of different types of visual stimuli and their tendency to elicit varying individual reactions, we propose to use users’ gaze behavior as an indicator of their response to the stimuli and model the noticeability of redirection. We conducted two user studies to collect users’ gaze behavior and noticeability, investigating the relationship between them and identifying the most effective gaze behavior features for predicting noticeability. Based on the data, we developed a regression model that takes users’ gaze behavior as input and outputs the noticeability of redirection. We then conducted an evaluation study to test our model on unseen visual stimuli, achieving an accuracy of 0.012 MSE. We further implemented an adaptive redirection technique and conducted a preliminary study to evaluate its effectiveness with complex visual stimuli in two applications. The results indicated that participants experienced less physical demanding and a stronger sense of body ownership when using our adaptive technique, demonstrating the potential of our model to support real-world use cases.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {38},
numpages = {18},
keywords = {Virtual Reality, visual attention, noticeability, embodiment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713213,
author = {Cummings, James J. and Ingber, Alexis Shore and Jia, Yihan Danny},
title = {Self-Disclosure in Social Virtual Reality: The Influence of Information Management Dynamics, Social Presence, and Privacy Concerns},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713213},
doi = {10.1145/3706598.3713213},
abstract = {Social virtual reality (SVR) aims to recreate embodied social experiences similar to those offline. However, concerns about privacy and safety have hindered its widespread adoption. This study examines how information disclosure and perceived control over information in SVR are influenced by 1) boundary permeability (e.g., interruptions from an unknown external user) and 2) identifiability of one’s conversation partner (e.g., access to their offline profile). We also explore how different social presence perceptions and privacy concerns may mediate these relationships. Comparing the experiences of participants (n = 94) randomly assigned to four different mock interview scenarios, we find the perceived actorhood of one’s conversation partner mediated the positive relationship between offline profile access and disclosure. Additionally, more permeable environmental boundaries led to significantly lower levels of disclosure. Qualitative responses emphasized SVR’s limitations in saliently conveying nonverbal expressions. Implications for future research and the design of SVR as a viable communication medium are discussed.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {39},
numpages = {16},
keywords = {social virtual reality, immersive communication systems, privacy, information control, information disclosure},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714244,
author = {Chen, Qijia and Bellucci, Andrea and Cai, Jie and Nelimarkka, Matti and Jacucci, Giulio},
title = {Understanding "Mutes" in Social Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714244},
doi = {10.1145/3706598.3714244},
abstract = {In social Virtual Reality (VR), particularly within VRChat, a significant group of users often referred to as “mutes” refrain from voice communication. This study analyzes 4212 discussion entries, including both original submissions and comments, from the r/VRchat subreddit to explore the experiences and reasons behind this practice. Our findings indicate that muteness is an integral aspect of social VR culture, yet mute users face challenges, including exposure to abusive behaviors and communication barriers in a fast-paced environment. Factors of social VR like harassment, heightened social anxiety from the immersive presence, and the complexities of identity management can discourage voice communication, leading many to adopt “muteness” as a response. This behavior can be seen within the broader context of social disability, challenging normative communication assumptions. We highlight the risks of generalizing marginalized communities and emphasize the need for further research to address and support the unique needs of these groups in social VR spaces.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {40},
numpages = {17},
keywords = {virtual reality, social VR, online harassment, mute, disability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713628,
author = {L\'{e}chapp\'{e}, Aur\'{e}lien and Johnstone, Ross and Milliat, Aur\'{e}lien and Williamson, John H and Chollet, Mathieu and Williamson, Julie R.},
title = {Understanding Social Interactions in Reality Versus Virtuality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713628},
doi = {10.1145/3706598.3713628},
abstract = {Immersive realities enable social interactions that are radically different from traditional communication technologies, but how we experience immersion together is not yet indistinguishable from face-to-face interactions. Some social signals are not stable across realities, may change in semantics, or are missing all together. Understanding how social signals impact behaviours and experiences of social connection in immersive environments is key to creating experiences that are meaningful, satisfying, and productive. We completed a lab study where 6 groups of 6 participants (N=36) completed co-located social tasks in an instrumented face-to-face environment and its digital twin, creating a rich open dataset of 1.8 million rows across 45 columns. Our quantitative results demonstrate the stability of position as a social signal, measure lower social synchronisation in XR compared to face-to-face, and propose a method for bench marking XR against face-to-face interactions. This enables direct quantitative comparisons between experiences of co-located physical and virtual interactions for the first time.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {41},
numpages = {18},
keywords = {Social XR, Social Signal Processing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714121,
author = {Atcheson, Alex and Khan, Omar and Siemann, Brian and Jain, Anika and Karahalios, Karrie},
title = {"I'd Never Actually Realized How Big An Impact It Had Until Now": Perspectives of University Students with Disabilities on Generative Artificial Intelligence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714121},
doi = {10.1145/3706598.3714121},
abstract = {Prior research on the experiences of students with disabilities in higher education has surfaced a number of barriers that prevent full inclusion. Generative artificial intelligence (GenAI) has begun to attract interest for its potential to address longstanding barriers to access. However, little is known about the impact of these tools on the living and learning experiences of post-secondary students with disabilities. As a mixed-abilities team, we investigated student experiences with GenAI tools by collecting survey and interview responses from 62 and 21 students with disabilities, respectively, across two universities to measure students’ use of GenAI tools and their perspectives on the impact of these tools in ways related to disability, university support, and sense of belonging. Despite concerns over potential risks of GenAI and unclear university policies, students described GenAI tools as a useful resource for personalizing learning, promoting self-care, and assisting with important self-advocacy work. Guidance demonstrating safe, acceptable uses of GenAI tools, along with clear policies and resources that acknowledge diverse student needs, were desired. We discuss implications of these tools for accessibility and inclusion in higher education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {42},
numpages = {22},
keywords = {Students with Disabilities, Higher Education, Generative Artificial Intelligence, Student Perspectives},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713808,
author = {Kladouchou, Vasiliki and Makri, Stephann and Frankowska-Takhari, Sylwia and Neate, Timothy and MacFarlane, Andrew and Wilson, Stephanie and Roper, Abi},
title = {"The Internet is Hard. Is Words": Investigating Information Search Difficulties Experienced by People with Aphasia and Strategies for Combatting Them},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713808},
doi = {10.1145/3706598.3713808},
abstract = {People rely on online information for important life tasks such as managing personal finances and understanding medical symptoms. However, due to its intrinsically language-focused nature, online search poses considerable difficulties for people with language impairments. Currently these difficulties are poorly understood. We report findings from an observation of the information search behavior of 12 people with aphasia. We identify a wide range of difficulties and strategies aimed at combating them, spanning the entire information search process. Findings include previously unreported difficulties and strategies that highlight the importance of designing search technologies to better support the complex needs of people who find language challenging, such as by facilitating word finding cueing strategies, error prevention and recovery, browsing, appropriation, text interpretation and and by decreasing reliance on language competency in general. This has the potential not only to benefit searchers with language impairments, but to make information search easier for all.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {43},
numpages = {20},
keywords = {Information seeking, information retrieval, disability, aphasia, search, search technologies, communication.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713421,
author = {Li, Chu and Pang, Rock Yuren and Labb\'{e}, Delphine and Eisenberg, Yochai and Hosseini, Maryam and Froehlich, Jon E.},
title = {Accessibility for Whom? Perceptions of Mobility Barriers Across Disability Groups and Implications for Designing Personalized Maps},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713421},
doi = {10.1145/3706598.3713421},
abstract = {Today’s mapping tools fail to address the varied experiences of different mobility device users. This paper presents a large-scale online survey exploring how five mobility groups—users of canes, walkers, mobility scooters, manual wheelchairs, and motorized wheelchairs—perceive sidewalk barriers and differences therein. Using 52 sidewalk barrier images, respondents evaluated their confidence in navigating each scenario. Our findings (N=190) reveal variations in barrier perceptions across groups, while also identifying shared concerns. To further demonstrate the value of this data, we showcase its use in two custom prototypes: a visual analytics tool and a personalized routing tool. Our survey findings and open dataset advance work in accessibility-focused maps, routing algorithms, and urban planning.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {44},
numpages = {19},
keywords = {accessibility, online image survey, mapping tools, urban planning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713335,
author = {Mowar, Peya and Peng, Yi-Hao and Wu, Jason and Steinfeld, Aaron and Bigham, Jeffrey P},
title = {CodeA11y: Making AI Coding Assistants Useful for Accessible Web Development},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713335},
doi = {10.1145/3706598.3713335},
abstract = {A persistent challenge in accessible computing is ensuring developers produce web UI code that supports assistive technologies. Despite numerous specialized accessibility tools, novice developers often remain unaware of them, leading to ~96\% of web pages that contain accessibility violations. AI coding assistants, such as GitHub Copilot, could offer potential by generating accessibility-compliant code, but their impact remains uncertain&nbsp;[52]. Our formative study with 16 developers without accessibility training revealed three key issues in AI-assisted coding: failure to prompt AI for accessibility, omitting crucial manual steps like replacing placeholder attributes, and the inability to verify compliance. To address these issues, we developed CodeA11y, a GitHub Copilot Extension, that suggests accessibility-compliant code and displays manual validation reminders. We evaluated it through a controlled study with another 20 novice developers. Our findings demonstrate its effectiveness in guiding novice developers by reinforcing accessibility practices throughout interactions, representing a significant step towards integrating accessibility into AI coding assistants.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {45},
numpages = {15},
keywords = {AI Coding Assistants, Web Accessibility, Coding Agents, AI Agents},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713784,
author = {Lewis, Aaleyah and Martinez, Jesse J and Das, Maitraye and Fogarty, James},
title = {Inaccessible and Deceptive: Examining Experiences of Deceptive Design with People Who Use Visual Accessibility Technology},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713784},
doi = {10.1145/3706598.3713784},
abstract = {Deceptive design patterns manipulate people into actions to which they would otherwise object. Despite growing research on deceptive design patterns, limited research examines their interplay with accessibility and visual accessibility technology (e.g.,&nbsp;screen readers, screen magnification, braille displays). We&nbsp;present an interview and diary study with 16 people who use visual accessibility technology to better understand experiences with accessibility and deceptive design. We report participant experiences with six deceptive design patterns, including designs that are intentionally deceptive and designs where participants describe accessibility barriers unintentionally manifesting as deceptive, together with direct and indirect consequences of deceptive patterns. We discuss intent versus impact in accessibility and deceptive design, how access barriers exacerbate harms of deceptive design patterns, and impacts of deceptive design from a perspective of consequence-based accessibility. We propose that accessibility tools could help address deceptive design patterns by offering higher-level feedback to well-intentioned designers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {46},
numpages = {18},
keywords = {accessibility, deceptive design, dark patterns, visual accessibility technology, screen readers},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713302,
author = {Cha, Yoonha and Jackson, Victoria and Kohl, Karina and Prikladnicki, Rafael and van der Hoek, Andr\'{e} and Branham, Stacy},
title = {The Dilemma of Building Do-It-Yourself (DIY) Solutions For Workplace Accessibility},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713302},
doi = {10.1145/3706598.3713302},
abstract = {Existing commercial and in-house software development tools are often inaccessible to blind and low vision software professionals (BLVSPs), hindering their participation and career growth at work. Building on existing research on Do-It-Yourself (DIY) assistive technologies and customized tools made by programmers, we shed light on the currently unexplored intersection of how DIY tools built and used by BLVSPs support accessible software development. Through semi-structured interviews with 30 BLVSPs, we found that such tools serve many different purposes and are driven by motivations such as desiring to maintain a professional image and a sense of dignity at work. These tools had significant impacts on workplace accessibility and revealed a need for a more centralized community for sharing tools, tips, and tricks. Based on our findings, we introduce the “Double Hacker Dilemma” and highlight a need for developing more effective peer and organizational platforms that support DIY tool sharing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {47},
numpages = {17},
keywords = {software development, accessibility, hacking, Do-It-Yourself (DIY), workplace accessibility, blind and low vision},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713084,
author = {Schmitt-Koopmann, Felix Maximilian and Huang, Elaine May and Hutter, Hans-Peter and Darvishy, Alireza},
title = {Towards More Accessible Scientific PDFs for People with Visual Impairments: Step-by-Step PDF Remediation to Improve Tag Accuracy},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713084},
doi = {10.1145/3706598.3713084},
abstract = {PDF inaccessibility is an ongoing challenge that hinders individuals with visual impairments from reading and navigating PDFs using screen readers. This paper presents a step-by-step process for both novice and experienced users to create accessible PDF documents, including an approach for creating alternative text for mathematical formulas without expert knowledge. In a study involving nineteen participants, we evaluated our prototype PAVE 2.0 by comparing it against Adobe Acrobat Pro, the existing standard for remediating PDFs. Our study shows that experienced users improved their tagging scores from 42.0\% to 80.1\%, and novice users from 39.2\% to 75.2\% with PAVE 2.0. Overall, fifteen participants stated that they would prefer to use PAVE 2.0 in the future, and all participants would recommend it for novice users. Our work demonstrates PAVE 2.0’s potential for increasing PDF accessibility for people with visual impairments and highlights remaining challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {48},
numpages = {16},
keywords = {Accessibility, PDF, Tagged PDF, PDF/UA, AI, User Study, Screen Readers},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713624,
author = {Ali, Murtaza and Dasgupta, Sayamindu},
title = {"Even Though I Went Through Everything, I Didn't Feel Like I Learned a Lot": Insights From Experiences of Non-Computer Science Students Learning to Code},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713624},
doi = {10.1145/3706598.3713624},
abstract = {Programming education is increasingly seen as an important curricular component of non-Computer Science (CS) disciplines at the undergraduate level. While existing research has studied non-CS majors’ experiences in introductory programming courses, there is limited work that explores such experiences across universities and disciplines. To address this gap, we conducted semi-structured interviews with 12 non-CS major programming students across several majors and universities and interpreted the results through reflexive thematic analysis. Our findings suggest that while students are excited about and interested in learning programming, they face barriers that often arise from the design of the courses they take and a lack of targeted resources and tools to support them. Building on our findings, we conclude with a set of recommendations for the design of tools, artifacts, and courses that can support programming education for non-major students.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {49},
numpages = {18},
keywords = {computing education, novice programmers, learning to code, non-Computer Science majors},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713353,
author = {Zhang, Gefei and Ji, Shenming and Li, Yicao and Tang, Jingwei and Ding, Jihong and Xia, Meng and Sun, Guodao and Liang, Ronghua},
title = {CPVis: Evidence-based Multimodal Learning Analytics for Evaluation in Collaborative Programming},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713353},
doi = {10.1145/3706598.3713353},
abstract = {As programming education becomes more widespread, many college students from non-computer science backgrounds begin learning programming. Collaborative programming emerges as an effective method for instructors to support novice students in developing coding and teamwork abilities. However, due to limited class time and attention, instructors face challenges in monitoring and evaluating the progress and performance of groups or individuals. To address this issue, we collect multimodal data from real-world settings and develop CPVis, an interactive visual analytics system designed to assess student collaboration dynamically. Specifically, CPVis enables instructors to evaluate both group and individual performance efficiently. CPVis employs a novel flower-based visual encoding to represent performance and provides time-based views to capture the evolution of collaborative behaviors. A within-subject experiment (N=22), comparing CPVis with two baseline systems, reveals that users gain more insights, find the visualization more intuitive, and report increased confidence in their assessments of collaboration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {50},
numpages = {26},
keywords = {Group visualization, education visualization, collaborative programming},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714104,
author = {Lin, Yanna and Yang, Leni and Li, Haotian and Qu, Huamin and Moritz, Dominik},
title = {InterLink: Linking Text with Code and Output in Computational Notebooks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714104},
doi = {10.1145/3706598.3714104},
abstract = {Computational notebooks, widely used for ad-hoc analysis and often shared with others, can be difficult to understand because the standard linear layout is not optimized for reading. In particular, related text, code, and outputs may be spread across the UI making it difficult to draw connections. In response, we introduce InterLink, a plugin designed to present the relationships between text, code, and outputs, thereby making notebooks easier to understand. In a formative study, we identify pain points and derive design requirements for  identifying and navigating relationships among various pieces of information within notebooks. Based on these requirements, InterLink features a new layout that separates text from code and outputs into two columns. It uses visual links to signal relationships between text and associated code and outputs and offers interactions  for navigating related pieces of information. In a user study with 12 participants, those using InterLink were 13.6\% more accurate at finding and integrating information from complex analyses in computational notebooks. These results show the potential of notebook layouts that make them easier to understand.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {51},
numpages = {15},
keywords = {Computational Notebook, User Comprehension, Text-Code/Output Linking, Interactive Computational Notebook},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713832,
author = {Jain, Yoshee and Demirtas, Mehmet Arif and Cunningham, Kathryn Irene},
title = {PLAID: Supporting Computing Instructors to Identify Domain-Specific Programming Plans at Scale},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713832},
doi = {10.1145/3706598.3713832},
abstract = {Pedagogical approaches focusing on stereotypical code solutions, known as programming plans, can increase problem-solving ability and motivate diverse learners. However, plan-focused pedagogies are rarely used beyond introductory programming. Our formative study (N=10 educators) showed that identifying plans is a tedious process. To advance plan-focused pedagogies in application-focused domains, we created an LLM-powered pipeline that automates the effortful parts of educators’ plan identification process by providing use-case-driven program examples and candidate plans. In design workshops (N=7 educators), we identified design goals to maximize instructors’ efficiency in plan identification by optimizing interaction with this LLM-generated content. Our resulting tool, PLAID, enables instructors to access a corpus of relevant programs to inspire plan identification, compare code snippets to assist plan refinement, and facilitates them in structuring code snippets into plans. We evaluated PLAID in a within-subjects user study (N=12 educators) and found that PLAID led to lower cognitive demand and increased productivity compared to the state-of-the-art. Educators found PLAID beneficial for generating instructional material. Thus, our findings suggest that human-in-the-loop approaches hold promise for supporting plan-focused pedagogies at scale.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {52},
numpages = {21},
keywords = {programming plan, programming pattern, pattern identification, instructor support},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713620,
author = {Rawn, Eric and Chasins, Sarah E.},
title = {Pagebreaks: Multi-Cell Scopes in Computational Notebooks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713620},
doi = {10.1145/3706598.3713620},
abstract = {Global variables lie at the root of many programmer complaints about computational notebooks. While programmers in other environments often address these barriers with function scopes, notebook programmers use functions less often. Analyzing the interaction between user behaviors, the programming language, and the notebook environment, we propose one possible explanation: that functions interfere with using notebooks in the exploratory ways users value. For example, because partial functions are not parseable, they cannot be run in isolation, so programmers cannot split function bodies across cells to iteratively tweak and rerun the last few lines. To explore how to offer non-global scopes without hampering exploratory notebook interactions, we built Pagebreaks, a small language construct for adding scopes around multiple Jupyter Notebook cells. In an in-situ study, we explored how programmers used Pagebreaks to manage variables with non-global scopes but also to visually and conceptually organize programs in a way akin to functions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {53},
numpages = {16},
keywords = {Computational Notebooks; Exploratory Programming; Data Science; Scope},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713472,
author = {McNutt, Andrew M and Cohen, Sam and Chugh, Ravi},
title = {Slowness, Politics, and Joy: Values That Guide Technology Choices in Creative Coding Classrooms},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713472},
doi = {10.1145/3706598.3713472},
abstract = {There are many tools and technologies for making art with code, each embodying distinct values and affordances. Within this landscape, creative coding educators must evaluate how different tools map onto their own principles and examine the potential impacts of those choices on students’ learning and artistic development. Understanding the values guiding these decisions is critical, as they reflect insights about these contexts, communities, and pedagogies. We explore these values through semi-structured interviews with (N=12) creative coding educators and toolbuilders. We identify three major themes: slowness (how friction can make room for reflection), politics (including the lasting effects of particular technologies), and joy (or the capacity for playful engagement). The lessons and priorities voiced by our participants offer valuable, transferable perspectives—like preferring community building (such as through documentation) over techno-solutionism. We demonstrate application of these critical lenses to two tool design areas (accessibility and AI assistance).},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {54},
numpages = {16},
keywords = {Creative Coding, Interview Study, Power, Reflection, Arts},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713446,
author = {Wang, Siyu and Si, Janice Jianing and Liang, Huanghuang and Hu, Chuang and Zhu, Yujun and Zhou, Xiaobo and Wang, Kanye Ye and Cheng, Dazhao},
title = {Understanding the Challenges Students Face in Non-English Programming Environments Due to the Programming Language Transition: A Case Study of Keywords in the Chinese Version of Scratch},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713446},
doi = {10.1145/3706598.3713446},
abstract = {Non-English-based programming language enable young children to learn programming without needing to understand English. However, the current development of non-English-based programming language for children is primarily based on translations of English programming language. It remains unclear whether children can comprehend non-English keywords and how these keywords impact their programming learning process. To address this, we used the Chinese version of Scratch for a case study. We conducted experiments with 22 children to test their understanding of Chinese Scratch keywords and interviewed 12 teachers to analyze the translation issues from English keywords to non-English keywords that led to comprehension challenges and proposed a series of strategies. Based on this, we further discussed the impact of learning programming in non-English environments and the challenges faced in designing such cross-linguistic programming languages.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {55},
numpages = {18},
keywords = {Computer education, children programming, non-native English speaker, translation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714311,
author = {Weir, Ellen and Leonards, Ute and Roudaut, Anne},
title = {"You Can Fool Me, You Can’t Fool Her!": Autoethnographic Insights from Equine-Assisted Interventions to Inform Therapeutic Robot Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714311},
doi = {10.1145/3706598.3714311},
abstract = {Equine-Assisted Interventions (EAIs) aim to improve participant health and well-being through the development of a therapeutic relationship with a trained horse. These interventions leverage the horse’s ability to provide emotional feedback, as it responds to negative non-verbal cues with reciprocal negativity, thereby encouraging participants to regulate their emotions and achieve attunement with the horse. Despite their benefits, EAIs face significant challenges, including logistical, financial, and resource constraints, which hinder their widespread adoption and accessibility. To address these issues, we conducted an autoethnographic study of the lead researcher’s engagement in an EAI to investigate the underlying mechanisms and explore potential technological alternatives. Our findings suggest that the reciprocal and responsive non-verbal communication, combined with the horse’s considerable physical presence, supports the potential of an embodied robotic system as a viable alternative. Such a system could offer a scalable and sustainable solution to the current limitations of EAIs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {56},
numpages = {20},
keywords = {Equine-Assisted Interventions, Robot Design, Autoethnography, Human-Animal Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714233,
author = {Earle, Sam and Parajuli, Samyak and Banburski-Fahey, Andrzej},
title = {DreamGarden: A Designer Assistant for Growing Games from a Single Prompt},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714233},
doi = {10.1145/3706598.3714233},
abstract = {Coding assistants are increasingly leveraged in game design, both generating code and making high-level plans. To what degree can these tools align with developer workflows, and what new modes of human-computer interaction can emerge from their use? We present DreamGarden, an AI system capable of assisting with the development of diverse game environments in Unreal Engine. At the core of our method is an LLM-driven planner, capable of breaking down a single, high-level prompt—a dream, memory, or imagined scenario provided by a human user—into a hierarchical action plan, which is then distributed across specialized submodules facilitating concrete implementation. This system is presented to the user as a garden of plans and actions, both growing independently and responding to user intervention via seed prompts, pruning, and feedback. Through a user study, we explore design implications of this system, charting courses for future work in semi-autonomous assistants and open-ended simulation design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {57},
numpages = {19},
keywords = {Game design assistants, 3D asset generation, large language models, visual feedback},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713359,
author = {Fang, Cathy Mengying and Chua, Phoebe and Chan, Samantha W. T. and Leong, Joanne and Bao, Andria and Maes, Pattie},
title = {Leveraging AI-Generated Emotional Self-Voice to Nudge People towards their Ideal Selves},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713359},
doi = {10.1145/3706598.3713359},
abstract = {Emotions, shaped by past experiences, significantly influence decision-making and goal pursuit. Traditional cognitive-behavioral techniques for personal development rely on mental imagery to envision ideal selves, but may be less effective for individuals who struggle with visualization. This paper introduces Emotional Self-Voice (ESV), a novel system combining emotionally expressive language models and voice cloning technologies to render customized responses in the user’s own voice. We investigate the potential of ESV to nudge individuals towards their ideal selves in a study with 60 participants. Across all three conditions (ESV, text-only, and mental imagination), we observed an increase in resilience, confidence, motivation, and goal commitment, and the ESV condition was perceived as uniquely engaging and personalized. We discuss the implications of designing generated self-voice systems as a personalized behavioral intervention for different scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {58},
numpages = {20},
keywords = {emotion, voice, generative ai, nudging, goals},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714317,
author = {Cho, Hyunsung and Fashimpaur, Jacqui and Sendhilnathan, Naveen and Browder, Jonathan and Lindlbauer, David and Jonker, Tanya R. and Todi, Kashyap},
title = {Persistent Assistant: Seamless Everyday AI Interactions via Intent Grounding and Multimodal Feedback},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714317},
doi = {10.1145/3706598.3714317},
abstract = {Current AI assistants predominantly use natural language interactions, which can be time-consuming and cognitively demanding, especially for frequent, repetitive tasks in daily life. We propose Persistent Assistant, a framework for seamless and unobtrusive interactions with AI assistants. The framework has three key functionalities: (1) efficient intent specification through grounded interactions, (2) seamless target referencing through embodied input, and (3) intuitive response comprehension through multimodal perceptible feedback. We developed a proof-of-concept system for everyday decision-making tasks, where users can easily repeat queries over multiple objects using eye gaze and pinch gesture, as well as receiving multimodal haptic and speech feedback. Our study shows that multimodal feedback enhances user experience and preference by reducing physical demand, increasing perceived speed, and enabling intuitive and instinctive human-AI assistant interaction. We discuss how our framework can be applied to build seamless and unobtrusive AI assistants for everyday persistent tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {59},
numpages = {19},
keywords = {Wearable AI assistants, grounding, multimodal interaction, gaze and gesture input, haptic and speech feedback},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713110,
author = {Zhang, Tianyi and Au Yeung, Colin and Aurelia, Emily and Onishi, Yuki and Chulpongsatorn, Neil and Li, Jiannan and Tang, Anthony},
title = {Prompting an Embodied AI Agent: How Embodiment and Multimodal Signaling Affects Prompting Behaviour},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713110},
doi = {10.1145/3706598.3713110},
abstract = {Current voice agents wait for a user to complete their verbal instruction before responding; yet, this is misaligned with how humans engage in everyday conversational interaction, where interlocutors use multimodal signaling (e.g. nodding, grunting, or looking at referred to objects) to ensure conversational grounding. We designed an embodied VR agent that exhibits multimodal signaling behaviors in response to situated prompts, by turning its head, or by visually highlighting objects being discussed or referred to. We explore how people prompt this agent to design and manipulate the objects in a VR scene. Through a Wizard of Oz study, we found that participants interacting with an agent that indicated its understanding of spatial and action references were able to prevent errors 30\% of the time, and were more satisfied and confident in the agent’s abilities. These findings underscore the importance of designing multimodal signaling communication techniques for future embodied agents.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {60},
numpages = {25},
keywords = {situated prompting, multimodal signaling, common ground, human-ai collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714203,
author = {Kim, Jieun and Fussell, Susan R.},
title = {Should Voice Agents Be Polite in an Emergency? Investigating Effects of Speech Style and Voice Tone in Emergency Simulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714203},
doi = {10.1145/3706598.3714203},
abstract = {Research in human-agent interaction highlights the significance of agents’ politeness in enhancing social engagement and interaction satisfaction. It remains unclear, however, if agents should maintain politeness even in time-constraint situations. This study explores how a voice agent should deliver instructions for emergency evacuation using a between-subjects experiment in which we manipulated agent speech style (politeness: positive vs. negative vs. direct) and voice tone (urgency: high vs. low) and measured the effects on users’ perceptions of the agent and their cognitive workload. We found that the urgency of the agent’s tone had a positive effect on the perceived anthropomorphism, likability, and intelligence of the agent while reducing the required effort and frustration to complete the tasks. Urgent voices increased the cognitive trust and likeability of the agent when the agent used negative politeness for instructions. Our findings provide guidelines for designing voice agents for emergencies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {61},
numpages = {17},
keywords = {Voice Agent, Politeness Theory, Anthropomorphism, Perceived Urgency, Trust, Emergency Simulation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714210,
author = {Xie, Jingyi and Yu, Rui and Zhang, He and Billah, Syed Masum and Lee, Sooyeon and Carroll, John M.},
title = {Beyond Visual Perception: Insights from Smartphone Interaction of Visually Impaired Users with Large Multimodal Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714210},
doi = {10.1145/3706598.3714210},
abstract = {Large multimodal models (LMMs) have enabled new AI-powered applications that help people with visual impairments (PVI) receive natural language descriptions of their surroundings through audible text. We investigated how this emerging paradigm of visual assistance transforms how PVI perform and manage their daily tasks. Moving beyond usability assessments, we examined both the capabilities and limitations of LMM-based tools in personal and social contexts, while exploring design implications for their future development. Through interviews with 14 visually impaired users of Be My AI (an LMM-based application) and analysis of its image descriptions from both study participants and social media platforms, we identified two key limitations. First, these systems’ context awareness suffers from hallucinations and misinterpretations of social contexts, styles, and human identities. Second, their intent-oriented capabilities often fail to grasp and act on users’ intentions. Based on these findings, we propose design strategies for improving both human-AI and AI-AI interactions, contributing to the development of more effective, interactive, and personalized assistive technologies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {62},
numpages = {17},
keywords = {People with visual impairments (PVI); large multimodal models (LMMs), Human-AI interaction, visual question answering (VQA); remote sighted assistance (RSA), Be My Eyes, Be My AI.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713433,
author = {Tang, Xinru and Abdolrahmani, Ali and Gergle, Darren and Piper, Anne Marie},
title = {Everyday Uncertainty: How Blind People Use GenAI Tools for Information Access},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713433},
doi = {10.1145/3706598.3713433},
abstract = {Generative AI (GenAI) tools promise to advance non-visual information access but introduce new challenges due to output errors, hallucinations, biases, and constantly changing capabilities. Through interviews with 20 blind screen reader users who use various GenAI applications for diverse tasks, we show how they approached information access with everyday uncertainty, or a mindset of skepticism and criticality towards both AI- and human-mediated assistance as well as information itself. Instead of expecting information to be ‘correct’ and ‘complete’, participants extracted cues from error-prone information sources; treated all information as tentative; acknowledged and explored information subjectivity; and constantly adjusted their expectations and strategies considering the politics around access. The concept of everyday uncertainty situates GenAI tools among the interconnected assistive applications, humans, and sociomaterial conditions that both enable and hinder the ongoing production of access. We discuss the implications of everyday uncertainty for future design and research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {63},
numpages = {17},
keywords = {uncertainty, generative artificial intelligence, accessibility, blind, screen reader users},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713965,
author = {Park, Hyanghee and Jung, Sol Bee and Byun, Young Hee and Ahn, Daehwan and Park, Chan Woo and Byun, Sunjoo and Huang, Yun},
title = {Lessons from Real-World Settings: What Makes It Uniquely Difficult to Design Cognitive Training Programs for Children with Autism Spectrum Disorder and Other Developmental Disabilities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713965},
doi = {10.1145/3706598.3713965},
abstract = {Despite the prevalence of autism spectrum disorder (ASD) and other developmental disabilities (DD) worldwide, children with ASD and DD face tremendous difficulties receiving support due to physical, financial, and psychological barriers to onsite health and education clinics. As a result, researchers and practitioners have designed software solutions aimed at providing accessible support to meet users’ needs. However, we have limited knowledge of whether these solutions indeed work in real-world settings. To address this gap, we conducted a case study on a cognitive training program called Dubupang, designed by Dubu Inc. From in-depth interviews with multiple stakeholders and field observations of children with ASD and DD, we identify Dubu Inc.’s internal development processes, the critical design issues that emerged through a series of field trials (e.g., instructional design and feedback), and the key implications (e.g., importance of caregivers’ strategic human interventions) for design that better supports both children with ASD and DD and their caregivers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {64},
numpages = {21},
keywords = {Case study, Children with autism spectrum disorder, Cognitive training programs, Developmental disabilities, Mobile devices, Real-world deployment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714296,
author = {Alkhudaidi, Khulood and Burke, Tish and Boll, Rachel and Mahajan, Shruti and Solovey, Erin T. and Reis, Jeanne},
title = {Perceptions and Preferences: Deaf ASL-Signing Users' Insights on Video Elements, Styles and Layouts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714296},
doi = {10.1145/3706598.3714296},
abstract = {Video components are a central element of user interfaces that deliver content in a signed language (SL), but the potential of video components extends beyond content accessibility. Sign language videos may be designed as user interface elements: layered with interactive features to create navigation cues, page headings, and menu options. To be effective for signing users, novel sign language video-rich interfaces require informed design choices across many parameters. To align with the specific needs and shared conventions of the Deaf community and other ASL-signers in this context, we present a user study involving deaf ASL-signers who interacted with an array of designs for sign language video elements. Their responses offer some insights into how the Deaf community may perceive and prefer video elements to be designed, positioned, and implemented to guide user experiences. Through a qualitative analysis, we take initial steps toward understanding deaf ASL-signers’ perceptions of a set of emerging design principles, paving the way for future SL-centric user interfaces containing customized video elements and layouts with primary consideration for signed language-related usage and requirements.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {65},
numpages = {20},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713238,
author = {Angelini, Robin and Spiel, Katta and De Meulder, Maartje},
title = {Speculating Deaf Tech: Reimagining Technologies Centering Deaf People},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713238},
doi = {10.1145/3706598.3713238},
abstract = {This deaf-led work critically explores Deaf Tech, challenging conventional understandings of technologies ‘for’ deaf people as merely assistive and accessible, since these understandings are predominantly embedded in medical and audist ideologies. By employing participatory speculative workshops, deaf participants from different European countries envisioned technologies on Eyeth - a mythical planet inhabited by deaf people - centered on their perspectives and curiosities. The results present a series of alternative socio-technical narratives that illustrate qualitative aspects of technologies desired by deaf people. This study advocates for expanding the scope of deaf technological landscapes, emphasizing the needs of establishing deaf-centered HCI, including the development of methods and concepts that truly prioritize deaf experiences in the design of technologies intended for their use.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {66},
numpages = {18},
keywords = {participatory design, deaf community, deaf tech, alternative socio-technical narratives, storytelling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713721,
author = {Lim, Hyunchul and Dang, Nam Anh and Lee, Dylan and Yu, Tianhong Catherine and Lu, Jane and Li, Franklin Mingzhe and Jin, Yiqi and Ma, Yan and Bi, Xiaojun and Guimbreti\`{e}re, Fran\c{c}ois and Zhang, Cheng},
title = {SpellRing: Recognizing Continuous Fingerspelling in American Sign Language using a Ring},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713721},
doi = {10.1145/3706598.3713721},
abstract = {Fingerspelling is a critical part of American Sign Language (ASL) recognition and has become an accessible optional text entry method for Deaf and Hard of Hearing (DHH) individuals. In this paper, we introduce SpellRing, a single smart ring worn on the thumb that recognizes words continuously fingerspelled in ASL. SpellRing uses active acoustic sensing (via a microphone and speaker) and an inertial measurement unit (IMU) to track handshape and movement, which are processed through a deep learning algorithm using Connectionist Temporal Classification (CTC) loss. We evaluated the system with 20 ASL signers (13 fluent and 7 learners), using the MacKenzie-Soukoref Phrase Set of 1,164 words and 100 phrases. Offline evaluation yielded top-1 and top-5 word recognition accuracies of 82.45\% (±9.67\%) and 92.42\% (±5.70\%), respectively. In real-time, the system achieved a word error rate (WER) of 0.099 (±0.039) on the phrases. Based on these results, we discuss key lessons and design implications for future minimally obtrusive ASL recognition wearables.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {67},
numpages = {17},
keywords = {datasets, neural networks, gaze detection, text tagging},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713304,
author = {de Lacerda Pataca, Calu\~{a} and Hassan, Saad and May, Lloyd and Olson, Michelle M and D'aurio, Toni and Peiris, Roshan L and Huenerfauth, Matt},
title = {Tactile Emotions: Multimodal Affective Captioning with Haptics Improves Narrative Engagement for d/Deaf and Hard-of-Hearing Viewers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713304},
doi = {10.1145/3706598.3713304},
abstract = {This paper explores a multimodal approach for translating emotional cues present in speech, designed with Deaf and Hard-of-Hearing (dhh) individuals in mind. Prior work has focused on visual cues applied to captions, successfully conveying whether a speaker’s words have a negative or positive tone (valence), but with mixed results regarding the intensity (arousal) of these emotions. We propose a novel method using haptic feedback to communicate a speaker’s arousal levels through vibrations on a wrist-worn device. In a formative study with 16 dhh participants, we tested six haptic patterns and found that participants preferred single per-word vibrations at 75&nbsp;Hz to encode arousal. In a follow-up study with 27 dhh participants, this pattern was paired with visual cues, and narrative engagement with audio-visual content was measured. Results indicate that combining haptics with visuals significantly increased engagement compared to a conventional captioning baseline and a visuals-only affective captioning style.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {68},
numpages = {17},
keywords = {Accessibility, Emotion / Affective Computing, Individuals with Disabilities \&amp; Assistive Technologies, Empirical study that tells us about how people use a system},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713402,
author = {Minton, Alexander G and Zhu, Howe Yuan and Chen, Hsiang-Ting and Wang, Yu-Kai and Zhuang, Zhuoli and Notaro, Gina and Galvan, Raquel and Allen, James and Ziegler, Matthias D and Lin, Chin-Teng},
title = {A Longitudinal Study on the Effects of Circadian Fatigue on Sound Source Identification and Localization using a Heads-Up Display},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713402},
doi = {10.1145/3706598.3713402},
abstract = {Circadian fatigue, largely caused by sleep deprivation, significantly diminishes alertness and situational awareness. This issue becomes critical in environments where auditory awareness—such as responding to verbal instructions or localizing alarms—is essential for performance and safety. While head-mounted displays have demonstrated potential in enhancing situational awareness through visual cues, their effectiveness in supporting sound localization under the influence of circadian fatigue remains under-explored. This study addresses this knowledge gap through a longitudinal study (N=19) conducted over 2–4 months, tracking participants’ fatigue levels through daily assessments. Participants were called in to perform non-line-of-sight sound source identification and localization tasks in a virtual environment under high- and low-fatigue conditions, both with and without head-up display assistance. The results show task-dependent effects of circadian fatigue. Unexpectedly, reaction times were shorter across all tasks under high-fatigue conditions. Yet, in sound localization, where precision is key, the HUD offered the greatest performance enhancement by reducing pointing error. The results suggest the auditory channel is a robust means of enhancing situational awareness and providing support for incorporating spatial audio cues and HUD as standard features in augmented reality platforms for fatigue-prone scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {69},
numpages = {12},
keywords = {Human-Computer Interaction, Head-Up Display, Circadian Fatigue, Multimodal Interaction, Longitudinal Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713600,
author = {Zhang, Chi and Yang, Zhao and Liu, Jiaxuan and Li, Yanda and Han, Yucheng and Chen, Xin and Huang, Zebiao and Fu, Bin and Yu, Gang},
title = {AppAgent: Multimodal Agents as Smartphone Users},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713600},
doi = {10.1145/3706598.3713600},
abstract = {Recent advancements in large language models (LLMs) have led to the creation of intelligent agents capable of performing complex tasks. This paper introduces a novel LLM-based multimodal agent framework designed to operate smartphone applications. Our framework allows the agent to mimic human-like interactions such as tapping and swiping through a simplified action space, eliminating the need for system back-end access and enhancing its versatility across various apps. Central to the agent’s functionality is an innovative in-context learning method, where it either autonomously explores or learns from human demonstrations, creating a knowledge base used to execute complex tasks across diverse applications. We conducted extensive testing with our agent on over 50 tasks spanning 10 applications, ranging from social media to sophisticated image editing tools. Additionally, a user study confirmed the agent’s superior performance and practicality in handling a diverse array of high-level tasks, demonstrating its effectiveness in real-world settings. Our project page is available at https://appagent-official.github.io/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {70},
numpages = {20},
keywords = {Multimodal, smartphone, large language model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713911,
author = {Kim, JooYeong and Hong, Jin-Hyuk},
title = {OnomaCap: Making Non-speech Sound Captions Accessible and Enjoyable through Onomatopoeic Sound Representation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713911},
doi = {10.1145/3706598.3713911},
abstract = {Non-speech sounds play an important role in setting the mood of a video and aiding comprehension. However, current non-speech sound captioning practices focus primarily on sound categories, which fails to provide a rich sound experience for d/Deaf and hard-of-hearing (DHH) viewers. Onomatopoeia, which succinctly captures expressive sound information, offers a potential solution but remains underutilized in non-speech sound captioning. This paper investigates how onomatopoeia benefits DHH audiences in non-speech sound captioning. We collected 7,962 sound-onomatopoeia pairs from listeners and developed a sound-onomatopoeia model that automatically transcribes sounds into onomatopoeic descriptions indistinguishable from human-generated ones. A user evaluation of 25 DHH participants using the model-generated onomatopoeia demonstrated that onomatopoeia significantly improved their video viewing experience. Participants most favored captions with onomatopoeia and category, and expressed a desire to see such captions across genres. We discuss the benefits and challenges of using onomatopoeia in non-speech sound captions, offering insights for future practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {71},
numpages = {22},
keywords = {Non-speech sound captioning, Onomatopoeia transcription, Sound accessibility, Deaf and hard-of-hearing individuals},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713294,
author = {Goodman, Steven M. and McDonnell, Emma J and Froehlich, Jon E. and Findlater, Leah},
title = {SPECTRA: Personalizable Sound Recognition for Deaf and Hard of Hearing Users through Interactive Machine Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713294},
doi = {10.1145/3706598.3713294},
abstract = {We introduce SPECTRA, a novel pipeline for personalizable sound recognition designed to understand DHH users’ needs when collecting audio data, creating a training dataset, and reasoning about the quality of a model. To evaluate the prototype, we recruited 12 DHH participants who trained personalized models for their homes. We investigated waveforms, spectrograms, interactive clustering, and data annotating to support DHH users throughout this workflow, and we explored the impact of a hands-on training session on their experience and attitudes toward sound recognition tools. Our findings reveal the potential for clustering visualizations and waveforms to enrich users’ understanding of audio data and refinement of training datasets, along with data annotations to promote varied data collection. We provide insights into DHH users’ experiences and perspectives on personalizing a sound recognition pipeline. Finally, we share design considerations for future interactive systems to support this population.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {72},
numpages = {16},
keywords = {Deaf and hard of hearing, sound recognition, accessibility, interactive machine learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713631,
author = {Dementyev, Artem and Kanevsky, Dimitri and Yang, Samuel and Parvaix, Mathieu and Lai, Chiong and Olwal, Alex},
title = {SpeechCompass: Enhancing Mobile Captioning with Diarization and Directional Guidance via Multi-Microphone Localization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713631},
doi = {10.1145/3706598.3713631},
abstract = {Speech-to-text capabilities on mobile devices have proven helpful for hearing and speech accessibility, language translation, note-taking, and meeting transcripts. However, our foundational large-scale survey (n=263) shows that the inability to distinguish and indicate speaker direction makes them challenging in group conversations. SpeechCompass addresses this limitation through real-time, multi-microphone speech localization, where the direction of speech allows visual separation and guidance (e.g., arrows) in the user interface. We introduce efficient real-time audio localization algorithms and custom sound perception hardware, running on a low-power microcontroller with four integrated microphones, which we characterize in technical evaluations. Informed by a large-scale survey (n=494), we conducted an in-person study of group conversations with eight frequent users of mobile speech-to-text, who provided feedback on five visualization styles. The value of diarization and visualizing localization was consistent across participants, with everyone agreeing on the value and potential of directional guidance for group conversations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {73},
numpages = {17},
keywords = {Assistive technology, hearing accessibility, localization, diarization, microphone array, captioning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713786,
author = {Jeon, Jongik and Lee, Chang Hee},
title = {Sprayable Sound: Exploring the Experiential and Design Potential of Physically Spraying Sound Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713786},
doi = {10.1145/3706598.3713786},
abstract = {Perfume and fragrance have captivated people for centuries across different cultures. Inspired by the ephemeral nature of sprayable olfactory interactions and experiences, we explore the potential of applying a similar interaction principle to the auditory modality. In this paper, we present SoundMist, a sonic interaction method that enables users to generate ephemeral auditory presences by physically dispersing a liquid into the air, much like the fading phenomenon of fragrance. We conducted a study to understand the experiential factors inherent in sprayable sound interaction and held an ideation workshop to identify potential design spaces or opportunities that this interaction could shape. Our findings, derived from thematic analysis, suggest that physically sprayable sound interaction can induce experiences related to four key factors—materiality of sound produced by dispersed liquid particles, different sounds entangled with each liquid, illusive perception of temporally floating sound, and enjoyment derived from blending different sounds—and can be applied to artistic practices, safety indications, multisensory approaches, and emotional interfaces.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {74},
numpages = {17},
keywords = {Sonic Interaction Design, Sound Materiality, Cross-Sensory Interaction, Ephemeral User Interface},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714268,
author = {Huang, Jeremy Zhengqi and Herskovitz, Jaylin and Wu, Liang-Yuan and Morrison, Cecily and Jain, Dhruv},
title = {Weaving Sound Information to Support Real-Time Sensemaking of Auditory Environments: Co-Designing with a DHH User},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714268},
doi = {10.1145/3706598.3714268},
abstract = {Current AI sound awareness systems can provide deaf and hard of hearing people with information about sounds, including discrete sound sources and transcriptions. However, synthesizing AI outputs based on DHH people's ever-changing intents in complex auditory environments remains a challenge. In this paper, we describe the co-design process of SoundWeaver, a sound awareness system prototype that dynamically weaves AI outputs from different AI models based on users’ intents and presents synthesized information through a heads-up display. Adopting a Research through Design perspective, we created SoundWeaver with one DHH co-designer, adapting it to his personal contexts and goals (e.g., cooking at home and chatting in a game store). Through this process, we present design implications for the future of “intent-driven” AI systems for sound accessibility.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {75},
numpages = {18},
keywords = {AI, Accessibility, deaf and hard of hearing, sound awareness},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713707,
author = {Zhang, Shuning and Yi, Xin and Li, Shixuan and Hong, Chuye and Chen, Gujun and Liu, Jiarui and Wang, Xueyang and Hu, Yongquan and Wang, Yuntao and Li, Hewu},
title = {Actual Achieved Gain and Optimal Perceived Gain: Modeling Human Take-over Decisions Towards Automated Vehicles' Suggestions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713707},
doi = {10.1145/3706598.3713707},
abstract = {Driver decision quality in take-overs is critical for effective human-Autonomous Driving System (ADS) collaboration. However, current research lacks detailed analysis of its variations. This paper introduces two metrics–Actual Achieved Gain (AAG) and Optimal Perceived Gain (OPG)–to assess decision quality, with OPG representing optimal decisions and AAG reflecting actual outcomes. Both are calculated as weighted averages of perceived gains and losses, influenced by ADS accuracy. Study 1 (N=315) used a 21-point Thurstone scale to measure perceived gains and losses—key components of AAG and OPG—across typical tasks: route selection, overtaking, and collision avoidance. Studies 2 (N=54) and 3 (N=54) modeled decision quality under varying ADS accuracy and decision time. Results show with sufficient time (&gt;3.5s), AAG converges towards OPG, indicating rational decision-making, while limited time leads to intuitive and deterministic choices. Study 3 also linked AAG-OPG deviations to irrational behaviors. An intervention study (N=8) and a pilot (N=4) employing voice alarms and multi-modal alarms based on these deviations demonstrated AAG’s potential to improve decision quality.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {76},
numpages = {18},
keywords = {Automated Driving, Decision Making, Automated Driving System, Take-over},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714323,
author = {Schramm, Robin Connor and Fedrizzi, Ginevra and Sasalovici, Markus and Freiwald, Jann Philipp and Schwanecke, Ulrich},
title = {Augmented Journeys: Interactive Points of Interest for In-Car Augmented Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714323},
doi = {10.1145/3706598.3714323},
abstract = {As passengers spend more time in vehicles, the demand for non-driving related tasks (NDRTs) increases. In-car Augmented Reality (AR) has the potential to enhance passenger experiences by enabling interaction with the environment through NDRTs using world-fixed Points of Interest (POIs). However, the effectiveness of existing interaction techniques and visualization methods for in-car AR remains unclear. Based on a survey (N=110) and a pre-study (N=10), we developed an interactive in-car AR system using a video see-through head-mounted display to engage with POIs via eye-gaze and pinch. Users could explore passed and upcoming POIs using three visualization techniques: List, Timeline, and Minimap. We evaluated the system’s feasibility in a field study (N=21). Our findings indicate general acceptance of the system, with the List visualization being the preferred method for exploring POIs. Additionally, the study highlights limitations of current AR hardware, particularly the impact of vehicle movement on 3D interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {77},
numpages = {19},
keywords = {Augmented Reality, In-Car, Vehicle, Points of Interest, Passenger, Automotive User Interfaces, Visualization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713185,
author = {Schramm, Robin Connor and Sasalovici, Markus and Freiwald, Jann Philipp and Otto, Michael Martin and Reinelt, Melissa and Schwanecke, Ulrich},
title = {Blending the Worlds: An evaluation of World-Fixed Visual Appearances in Automotive Augmented Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713185},
doi = {10.1145/3706598.3713185},
abstract = {With the transition to fully autonomous vehicles, non-driving related tasks (NDRTs) become increasingly important, allowing passengers to use their driving time more efficiently. In-car Augmented Reality (AR) gives the possibility to engage in NDRTs while also allowing passengers to engage with their surroundings, for example, by displaying world-fixed points of interest (POIs). This can lead to new discoveries, provide information about the environment, and improve locational awareness. To explore the optimal visualization of POIs using in-car AR, we conducted a field study (N = 38) examining six parameters: positioning, scaling, rotation, render distance, information density, and appearance. We also asked for intention of use, preferred seat positions and preferred automation level for the AR function in a post-study questionnaire. Our findings reveal user preferences and general acceptance of the AR functionality. Based on these results, we derived UX-guidelines for the visual appearance and behavior of location-based POIs in in-car AR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {78},
numpages = {23},
keywords = {Augmented Reality, Point of Interest, POI, In-Car, Visualization, Vehicle, Passenger, Automotive User Interfaces},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713373,
author = {Gim, Bocheon and Hwang, Seokhyun and Kang, Seongjun and Kim, Gwangbin and Yeo, Dohyeon and Kim, SeungJun},
title = {I Want to Break Free: Enabling User-Applied Active Locomotion in In-Car VR through Contextual Cues},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713373},
doi = {10.1145/3706598.3713373},
abstract = {We explore the feasibility of active user-applied locomotion in virtual reality (VR) within in-car environments, diverging from previous in-car VR research that synchronized virtual motion with the car’s movement. Through a two-step study, we examined the effects of locomotion methods on user experience in dynamic vehicle environments and evaluated contextual cues designed to mitigate sensory mismatch caused by vehicle motion. The first study evaluated five locomotion methods, identifying joystick-based navigation as the most suitable for in-car use due to its low physical demand and stability. The second study focused on designing and testing contextual cues that translate physical sensations of vehicle motion into virtual effects without limiting the user’s freedom of movement, with results demonstrating their effectiveness in reducing motion sickness and enhancing presence. We conclude with initial insights and design considerations for expanding upon our findings in regards to enabling active locomotion in in-car VR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {79},
numpages = {19},
keywords = {In-Car, Virtual Reality, Locomotion, Visual Cues, User Experience, Motion Sickness, Sensory Mismatch},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714187,
author = {Colley, Mark and Jansen, Pascal and Keskar, Mugdha and Rukzio, Enrico},
title = {Improving External Communication of Automated Vehicles Using Bayesian Optimization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714187},
doi = {10.1145/3706598.3714187},
abstract = {The absence of a human operator in automated vehicles (AVs) may require external Human-Machine Interfaces (eHMIs) to facilitate communication with other road users in uncertain scenarios, for example, regarding the right of way. Given the plethora of adjustable parameters, balancing visual and auditory elements is crucial for effective communication with other road users. With N=37 participants, this study employed multi-objective Bayesian optimization to enhance eHMI designs and improve trust, safety perception, and mental demand. By reporting the Pareto front, we identify optimal design trade-offs. This research contributes to the ongoing standardization efforts of eHMIs, supporting broader adoption.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {80},
numpages = {16},
keywords = {External communication; Autonomous vehicles; Pedestrian Behavior; eHMI.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713476,
author = {Colley, Mark and Westhauser, Jonathan and Andersson, Jonas and Mirnig, Alexander G. and Rukzio, Enrico},
title = {Introducing ROADS: A Systematic Comparison of Remote Control Interaction Concepts for Automated Vehicles at Road Works},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713476},
doi = {10.1145/3706598.3713476},
abstract = {As vehicle automation technology continues to mature, there is a necessity for robust remote monitoring and intervention features. These are essential for intervening during vehicle malfunctions, challenging road conditions, or in areas that are difficult to navigate. This evolution in the role of the human operator—from a constant driver to an intermittent teleoperator—necessitates the development of suitable interaction interfaces. While some interfaces were suggested, a comparative study is missing. We designed, implemented, and evaluated three interaction concepts (path planning, trajectory guidance, and waypoint guidance) with up to four concurrent requests of automated vehicles in a within-subjects study with N=23 participants. The results showed a clear preference for the path planning concept. It also led to the highest usability but lower satisfaction. With trajectory guidance, the fewest requests were resolved. The study’s findings contribute to the ongoing development of HMIs focused on the remote assistance of automated vehicles.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {81},
numpages = {20},
keywords = {remote operation, systematic comparison},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713412,
author = {Al-Taie, Ammar and Freeman, Euan and Pollick, Frank and Brewster, Stephen Anthony},
title = {evARything, evARywhere, all at once: Exploring Scalable Holistic Autonomous Vehicle-Cyclist Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713412},
doi = {10.1145/3706598.3713412},
abstract = {Cyclists need interfaces such as on-vehicle displays or augmented-reality (AR) glasses for effective communication with autonomous vehicles (AVs) when human drivers are no longer present. Interfaces must handle complex situations involving multiple AVs around a cyclist. Holistic AV-Cyclist Interfaces (HACIs) are a novel solution; they group interfaces into a multimodal interconnected system to support the rider. However, the best way to present information is uncertain. We explored this in a scenario with three AVs using CycleARcade, a new multi-user AR platform for designing and evaluating HACIs. Cyclists and HCI researchers collaboratively created and tested HACIs within CycleARcade through a novel iterative participatory design method. We synthesised three HACIs from this process and assessed them with riders in CycleARcade. Participants preferred HACIs with AR displays integrated into the environment to avoid road distractions, paired with spatial audio communicating AV proximity. These findings provide crucial input for the real-world deployment of AVs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {82},
numpages = {18},
keywords = {Autonomous Vehicle-Cyclist Interaction, Scalability, Participatory Design, Augmented Reality, Iterative Design, Outdoor Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714301,
author = {Ding, Yaohan and Ying, Jun and Feng, Yiheng and Du, Na},
title = {Explanations Help: Leveraging Human Capabilities to Detect Cyberattacks on Automated Vehicles},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714301},
doi = {10.1145/3706598.3714301},
abstract = {Existing defense strategies against cyberattacks on automated vehicles (AVs) often overlook the great potential of humans in detecting such attacks. To address this, we identified three types of human-detectable attacks targeting transportation infrastructure, AV perception modules, and AV execution modules. We proposed two types of displays: Alert and Alert plus Explanations (AlertExp), and conducted an online video survey study involving 260 participants to systematically evaluate the effectiveness of these displays across cyberattack types. Results showed that AV execution module attacks were the hardest to detect and understand, but AlertExp displays mitigated this difficulty. In contrast, AV perception module attacks were the easiest to detect, while infrastructure attacks resulted in the highest post-attack trust in the AV system. Although participants were prone to false alarms, AlertExp displays mitigated their negative impacts, whereas Alert displays performed worse than having no display. Overall, AlertExp displays are recommended to enhance human detection of cyberattacks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {83},
numpages = {15},
keywords = {automated vehicles; cyberattack; cyberattack detection; situational awareness; trust; usability.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714007,
author = {Deuber, Robin and Langer, Patrick and Kraus, Mathias and Pf\"{a}ffli, Matthias and Bantle, Matthias and Barata, Filipe and von Wangenheim, Florian and Fleisch, Elgar and Weinmann, Wolfgang and Wortmann, Felix},
title = {Moving Beyond the Simulator: Interaction-Based Drunk Driving Detection in a Real Vehicle Using Driver Monitoring Cameras and Real-Time Vehicle Data},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714007},
doi = {10.1145/3706598.3714007},
abstract = {Alcohol consumption poses a significant public health challenge, presenting serious risks to individual health and contributing to over 700 daily road fatalities worldwide. Digital interventions can play a crucial role in reducing these risks. However, reliable drunk driving detection systems are vital to effectively deliver these interventions. To develop and evaluate such a system, we conducted an interventional study on a test track to collect real vehicle data from 54 participants. Our system reliably identifies non-sober driving with an area under the receiver operating characteristic curve (AUROC) of 0.84&nbsp; ± &nbsp;0.11 and driving above the WHO-recommended blood alcohol concentration limit of 0.05&nbsp;g/dL with an AUROC of 0.80&nbsp; ± &nbsp;0.10. Our models rely on well-known physiological drunk driving patterns. To the best of our knowledge, we are the first to (1) rigorously evaluate the potential of (2) driver monitoring cameras and real-time vehicle data for detecting drunk driving in a (3) real vehicle.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {84},
numpages = {25},
keywords = {health, safety, driving, eye movement, vehicle interaction, driver monitoring camera},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713514,
author = {Jansen, Pascal and Colley, Mark and Krau\ss{}, Svenja and Hirschle, Daniel and Rukzio, Enrico},
title = {OptiCarVis: Improving Automated Vehicle Functionality Visualizations Using Bayesian Optimization to Enhance User Experience},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713514},
doi = {10.1145/3706598.3713514},
abstract = {Automated vehicle (AV) acceptance relies on their understanding via feedback. While visualizations aim to enhance user understanding of AV’s detection, prediction, and planning functionalities, establishing an optimal design is challenging. Traditional "one-size-fits-all" designs might be unsuitable, stemming from resource-intensive empirical evaluations. This paper introduces OptiCarVis, a set of Human-in-the-Loop (HITL) approaches using Multi-Objective Bayesian Optimization (MOBO) to optimize AV feedback visualizations. We compare conditions using eight expert and user-customized designs for a Warm-Start HITL MOBO. An online study (N=117) demonstrates OptiCarVis’s efficacy in significantly improving trust, acceptance, perceived safety, and predictability without increasing cognitive load. OptiCarVis facilitates a comprehensive design space exploration, enhancing in-vehicle interfaces for optimal passenger experiences and broader applicability.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {85},
numpages = {23},
keywords = {automated vehicles, user study, bayesian optimization, multi objective},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713509,
author = {Gyevnar, Balint and Droop, Stephanie and Quillien, Tadeg and Cohen, Shay B. and Bramley, Neil R. and Lucas, Christopher G. and Albrecht, Stefano V.},
title = {People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior: Insights from Cognitive Science for Explainable AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713509},
doi = {10.1145/3706598.3713509},
abstract = {It is often argued that effective human-centered explainable artificial intelligence (XAI) should resemble human reasoning. However, empirical investigations of how concepts from cognitive science can aid the design of XAI are lacking. Based on insights from cognitive science, we propose a framework of explanatory modes to analyze how people frame explanations, whether mechanistic, teleological, or counterfactual. Using the complex safety-critical domain of autonomous driving, we conduct an experiment consisting of two studies on (i) how people explain the behavior of a vehicle in 14 unique scenarios (N1 = 54) and (ii) how they perceive these explanations (N2 = 382), curating the novel Human Explanations for Autonomous Driving Decisions (HEADD) dataset. Our main finding is that participants deem teleological explanations significantly better quality than counterfactual ones, with perceived teleology being the best predictor of perceived quality. Based on our results, we argue that explanatory modes are an important axis of analysis when designing and evaluating XAI and highlight the need for a principled and empirically grounded understanding of the cognitive mechanisms of explanation. The HEADD dataset and our code are available at: https://datashare.ed.ac.uk/handle/10283/8930.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {86},
numpages = {18},
keywords = {Cognitive science, Explainable AI, Causality, Counterfactuals, Teleology, User study, Autonomous Driving},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713188,
author = {Kaufman, Robert A and Lee, Emi and Bedmutha, Manas Satish and Kirsh, David and Weibel, Nadir},
title = {Predicting Trust In Autonomous Vehicles: Modeling Young Adult Psychosocial Traits, Risk-Benefit Attitudes, And Driving Factors With Machine Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713188},
doi = {10.1145/3706598.3713188},
abstract = {Low trust remains a significant barrier to Autonomous Vehicle (AV) adoption. To design trustworthy AVs, we need to better understand the individual traits, attitudes, and experiences that impact people’s trust judgements. We use machine learning to understand the most important factors that contribute to young adult trust based on a comprehensive set of personal factors gathered via survey (n = 1457). Factors ranged from psychosocial and cognitive attributes to driving style, experiences, and perceived AV risks and benefits. Using the explainable AI technique SHAP, we found that perceptions of AV risks and benefits, attitudes toward feasibility and usability, institutional trust, prior experience, and a person’s mental model are the most important predictors. Surprisingly, psychosocial and many technology- and driving-specific factors were not strong predictors. Results highlight the importance of individual differences for designing trustworthy AVs for diverse groups and lead to key implications for future design and research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {87},
numpages = {24},
keywords = {Autonomous Vehicles, Personalization, Machine Learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713806,
author = {Singh, Richa and Ziat, Mounia and \v{S}pakov, Oleg and M\"{a}kel\"{a}, John and Surakka, Veikko and Raisamo, Roope},
title = {Trust and Visual Focus in Automated Vehicles: A Comparative Study of Beginner and Experienced Drivers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713806},
doi = {10.1145/3706598.3713806},
abstract = {This study investigated the relationship between trust in automation, gaze behavior, and driving performance in beginner and experienced drivers during a simulated driving session. Twenty participants completed a 17-minute drive across three conditions: manual driving, non-critical automated driving, and critical automated driving, with a non-driving-related task (NDRT) introduced between conditions to assess visual attention. Driving performance was evaluated using the Standard Deviation of Lateral Position (SDLP), and eye-tracking data in terms of mean gaze duration (MGD). While both groups demonstrated increased trust in the automated system post-session, beginners showed greater lateral position variability in critical conditions, suggesting over-reliance on automation. Eye-tracking analysis revealed significant changes in glance behavior across driving conditions, particularly in response to critical events. These findings highlight how driver experience shapes interactions with automated systems, emphasizing the importance of trust calibration in automated driving scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {88},
numpages = {11},
keywords = {Trust in Automation, Automated Driving Systems Acceptance, Driving Simulator Study, Manual vs. Automated Driving, NDRT, Trust Change Before and After Simulation, Driving Behavior Analysis, Impact of Driving Conditions on Trust, Beginner vs. Experienced Drivers in Automation, System Predictability and Trust, Gaze Behavior},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713088,
author = {Kaufman, Robert A and Broukhim, Aaron and Kirsh, David and Weibel, Nadir},
title = {What Did My Car Say? Impact of Autonomous Vehicle Explanation Errors and Driving Context On Comfort, Reliance, Satisfaction, and Driving Confidence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713088},
doi = {10.1145/3706598.3713088},
abstract = {Explanations for autonomous vehicle (AV) decisions may build trust, however, explanations can contain errors. In a simulated driving study (n = 232), we tested how AV explanation errors, driving context characteristics (perceived harm and driving difficulty), and personal traits (prior trust and expertise) affected a passenger’s comfort in relying on an AV, preference for control, confidence in the AV’s ability, and explanation satisfaction. Errors negatively affected all outcomes. Surprisingly, despite identical driving, explanation errors reduced ratings of the AV’s driving ability. Severity and potential harm amplified the negative impact of errors. Contextual harm and driving difficulty directly impacted outcome ratings and influenced the relationship between errors and outcomes. Prior trust and expertise were positively associated with outcome ratings. Results emphasize the need for accurate, contextually adaptive, and personalized AV explanations to foster trust, reliance, satisfaction, and confidence. We conclude with design, research, and deployment recommendations for trustworthy AV explanation systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {89},
numpages = {17},
keywords = {Autonomous Vehicles, Explainable AI, AI Errors},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713991,
author = {Brewster, Kat and DeGuia, Aloe and Mayworm, Samuel and Khan, F. Ria and Monier, Mel and Starks, Denny L and Haimson, Oliver L.},
title = {"That Moment of Curiosity": Augmented Reality Face Filters for Transgender Identity Exploration, Gender Affirmation, and Radical Possibility},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713991},
doi = {10.1145/3706598.3713991},
abstract = {Transgender people often use face filters to try and see different possible futures: versions of what they might look like during or post transition, or how they might appear in an ideal future or alternate world. However, there are effectively no face filters made for trans people to feel good using. As a result, people often end up feeling bad or dysphoric instead of supported in their pursuit to envision the future. We asked 44 trans people about augmented reality and face filters, and to speculate on future technologies that would support their wellbeing and desires for transition. We found that trans-affirming face filters would be designed to support data privacy, agency, intersectionality, and consideration for expansive identity categories. Meeting these design goals would enable trans people to explore many different radically possible futures, facilitating expansive, transformative, self-perceptions that honor the multiplicity inherent in trans identity.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {90},
numpages = {15},
keywords = {augmented reality, face filters, trans technology, community-based participatory research, LGBTQ+, transgender},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713942,
author = {Alr\o{}e, Sarah Fjelsted and Krogh, Peter Gall},
title = {De-centering Inclusivity: Fitting Design for Aut-Ethnography},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713942},
doi = {10.1145/3706598.3713942},
abstract = {Neurodiversity perspectives have in recent years made headway in HCI, broadening the role of autistic people. Outside HCI, an essential tool of the neurodiversity movement is the use of first person methods such as autoethnography. This paper explores how interaction design may contribute to ease the burden of conducting Autistic autoethnography (aut-ethnography), and how aut-ethnography may contribute to HCI. Taking an autoethnographic approach in the design of a set of recording devices, we identify three design sensitivities when designing for aut-ethnography: Inertial, sensory, and social fit. We further nuance these in an exploratory trial with other autistic people. We conclude that designing for the context of aut-ethnography requires significant adaptability of the designed artifacts in order to facilitate maintenance of existing rhythms in practice and adhere to fine-grained idiosyncratic preferences and ideals of practicing care and fairness.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {91},
numpages = {13},
keywords = {Autism, Neurodiversity, Autoethnography, Constructive Design Research},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713802,
author = {van den Berg, Merel K. N. and Karahano\u{g}lu, Arma\u{g}an and Noordzij, Matthijs L. and Maeckelberghe, Els L. M. and Ludden, Geke D. S.},
title = {Facilitators and Barriers of Wearable Stress Management Technology: A Narrative Review of User Perspectives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713802},
doi = {10.1145/3706598.3713802},
abstract = {Research and technological advancements have driven the development of wearable technology for stress management. Previous reviews primarily focused on its performance and effectiveness in health contexts. In contrast, this review takes a human-centric approach and reviews studies on users’ attitudes and experiences. We conducted a narrative review to identify (1) the facilitators and barriers of wearable stress management technology (WSMT) and (2) design considerations for human-centered WSMT. We identified 28 articles reporting user perspectives on stress management technology, primarily based on evaluation studies in which user perspectives were gathered through qualitative methods. We found five facilitators and barriers of WSMT (i.e., usefulness, functionality/interactivity, seamlessness, user privacy, and technology's image). Additionally, we synthesized 18 design considerations, highlighted two main design challenges, and proposed a value-sensitive approach for future research. This review adds to the HCI literature by demonstrating the complexity of designing human-centered WSMT and the need for actionable recommendations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {92},
numpages = {24},
keywords = {Narrative Review, Stress Monitoring and Management, User Experience, Wearable Technology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713805,
author = {Zhang, Junti and Zhu, Zicheng and Li, Jingshu and Lee, Yi-Chieh},
title = {Mining Evidence about Your Symptoms: Mitigating Availability Bias in Online Self-Diagnosis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713805},
doi = {10.1145/3706598.3713805},
abstract = {People frequently exposed to health information on social media tend to overestimate their symptoms during online self-diagnosis due to availability bias. This may lead to incorrect self-medication and place additional burdens on healthcare providers to correct patients’ misconceptions. In this work, we conducted two mixed-method studies to identify design goals for mitigating availability bias in online self-diagnosis. We investigated factors that distort self-assessment of symptoms after exposure to social media. We found that availability bias is pronounced when social media content resonated with individuals, making them disregard their own evidences. To address this, we developed and evaluated three chatbot-based symptom checkers designed to foster evidence-based self-reflection for bias mitigation given their potential to encourage thoughtful responses. Results showed that chatbot-based symptom checkers with cognitive intervention strategies mitigated the impact of availability bias in online self-diagnosis.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {93},
numpages = {23},
keywords = {Availability bias, Conversational Agents, Cognitive intervention, Social media, Self-diagnosis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713737,
author = {van Zandvoort, Daphne and Vredenborg, Marloes and Bentvelzen, Marit},
title = {Unhealthy Comparisons to Promote Healthy Behavior? Exploring the Impact of Social Comparison Strategies in Personal Informatics.},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713737},
doi = {10.1145/3706598.3713737},
abstract = {Previous work on Social Comparison Theory shows that comparing oneself to others can lead to negative self-perceptions and rumination, reducing self-confidence. Despite these harmful effects, social comparisons are frequently used as engagement strategies in personal informatics systems, such as health and wellness apps. There is limited understanding of how users perceive these comparisons and their impact on wellbeing. To address this, we reviewed the Top 50 Health \&amp; Wellness smartphone applications to analyse implemented comparison strategies and the metrics such comparisons are used for. We conducted an online vignette study (n=192) and an interview study (n=12) to further explore the impact of social comparisons on users. Our study shows that comparisons in personal informatics motivate users but simultaneously lead to negative emotions (e.g., inferiority, disappointment), potentially leading to obsessive thoughts and overtraining. Based on our findings, we propose design guidelines for implementing social comparison features that prioritise users’ wellbeing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {94},
numpages = {21},
keywords = {Personal Informatics, Social Comparison, Health, Wellbeing, Reflection strategies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713636,
author = {Chen, Shi and Zhang, Jingao and Lou, Suqi and Wang, Xiaodong and Xiang, Wei and Sun, Lingyun},
title = {Voice by the Non-sighted: Practices and Challenges of Audiobook Voice Actors with Blind and Low Vision in China},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713636},
doi = {10.1145/3706598.3713636},
abstract = {Auditory sense is the primary channel for people with blind and low vision (BLV) to access information. This paper aims to understand the productization of individual voices of BLV voice actors in the audiobook industry. We conducted online semi-interviews with the BLV voice actors in China (N = 13) and gained insights into the workflow through offline observations. Interviews indicate that the ability to match job requirements, social benefits, and accessible support are key factors that draw BLV people into this field. They acquire vocal techniques, actively showcase their voices, and adapt their career paths as needed. Social support is crucial for their continued employment, as well as disclosing their BLV identities as appropriate. Observations reveal that BLV people utilize text processing tools, Screen Reader(SR) speed control, and keyboard shortcuts to transform an invisible script into a coherent and emotionally nuanced voice recording. We investigate how BLV people harness their potential through intensive voice acting while listening to SR, and proficient keyboard skills for software access.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {95},
numpages = {19},
keywords = {Accessibility, Individuals with Disabilities, Assistive Information and Communication Technologies, Empirical study that tells us about people, Qualitative Methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713850,
author = {Solano-Kamaiko, Ian Ren\'{e} and Tan, Melissa and Ming, Joy and Avgar, Ariel C. and Vashistha, Aditya and Sterling, Madeline and Dell, Nicola},
title = {"Who is running it?" Towards Equitable AI Deployment in Home Care Work},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713850},
doi = {10.1145/3706598.3713850},
abstract = {We present a qualitative study that investigates the implications of current and near-future AI deployment for home care workers (HCWs), an overlooked group of frontline healthcare workers. Through interviews with 22 HCWs, care agency staff, and worker advocates, we find that HCWs do not understand how AI works, how their data can be used, or why AI systems might retain their information. HCWs are unaware that AI is already being utilized in their work, primarily via algorithmic shift-matching systems adopted by agencies. Participants detail the risks AI poses in sensitive care settings for HCWs, patients, and agencies, including threats to workers’ autonomy and livelihoods, and express concerns that workers will be held accountable for AI mistakes, with the burden of proving AI’s decisions incorrect falling on them. Considering these risks, participants advocate for new regulations and democratic governance structures that protect workers and control AI deployment in home care work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {96},
numpages = {19},
keywords = {Artificial intelligence, AI, responsible AI, home health care, frontline work, low-wage work, labor, equity.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713086,
author = {Ming, Joy and Tolera, Hawi H and Tu, Jiamin and Yitzhaki, Ella and Ngai, Chit Sum Eunice and Sterling, Madeline and Avgar, Ariel C and Vashistha, Aditya and Dell, Nicola},
title = {Exploring Data-Driven Advocacy in Home Health Care Work},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713086},
doi = {10.1145/3706598.3713086},
abstract = {This paper explores opportunities and challenges for data-driven advocacy to support home care workers, an often overlooked group of low-wage, frontline health workers. First, we investigate what data to collect and how to collect it in ways that preserve privacy and avoid burdening workers. Second, we examine how workers and advocates could use collected data to strengthen individual and collective advocacy efforts. Our qualitative study with 11 workers and 15 advocates highlights tensions between workers’ desires for individual and immediate benefits and advocates’ preferences to prioritize more collective and long-term benefits. We also uncover discrepancies between participants’ expectations for how data might transform advocacy and their on-the-ground experiences collecting and using real data. Finally, we discuss future directions for data-driven worker advocacy, including combining different kinds of data to ameliorate challenges, leveraging advocates as data stewards, and accounting for workers’ and organizations’ heterogeneous goals.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {97},
numpages = {17},
keywords = {care work, policy advocacy, data privacy, technology burden, invisible labor, data justice},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713182,
author = {Kusk, Kalle},
title = {Flexible Platforms? An Ethnographic Study of Flexible Scheduling in Platform-Mediated Delivery},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713182},
doi = {10.1145/3706598.3713182},
abstract = {This paper explores flexibility in platform-mediated work through a multi-sited ethnographic study of delivery workers’ "flexible scheduling" in three European countries: Denmark, Finland, and Malta. While workers generally value the ability to schedule flexibly, this flexibility is constrained by structural factors such as piece-rate remuneration, demand fluctuations, surge pricing, and income dependency. The constraints result in markedly different experiences across the different instantiations of the same, standardised delivery platform: workers in Denmark benefit from the system, in Finland workers face seasonal precarity, and in Malta workers endure exploitative cycles of long hours and low pay. The findings demonstrate how the same platform’s standardised design can produce divergent outcomes in local contexts. The paper highlights the need for platform designers and regulators to balance the benefits of flexible scheduling with its trade-offs, ensuring that flexibility supports worker well-being as the flexible platforms manifest locally.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {98},
numpages = {11},
keywords = {Food delivery, platform economy, flexibility},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714398,
author = {Hsieh, Jane and Zhang, Angie and Surati, Sajel and Xie, Sijia and Ayala, Yeshua and Sathiya, Nithila and Kuo, Tzu-Sheng and Lee, Min Kyung and Zhu, Haiyi},
title = {Gig2Gether: Datasharing to Empower, Unify and Demystify Gig Work},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714398},
doi = {10.1145/3706598.3714398},
abstract = {The wide adoption of platformized work has generated remarkable advancements in the labor patterns and mobility of modern society. Underpinning such progress, gig workers are exposed to unprecedented challenges and accountabilities: lack of data transparency, social and physical isolation, as well as insufficient infrastructural safeguards. Gig2Gether presents a space designed for workers to engage in an initial experience of voluntarily contributing anecdotal and statistical data to affect policy and build solidarity across platforms by exchanging unifying and diverse experiences. Our 7-day field study with 16 active workers from three distinct platforms and work domains showed existing affordances of data-sharing: facilitating mutual support across platforms, as well as enabling financial reflection and planning. Additionally, workers envisioned future use cases of data-sharing for collectivism (e.g., collaborative examinations of algorithmic speculations) and informing policy (e.g., around safety and pay), which motivated (latent) worker desiderata of additional capabilities and data metrics. Based on these findings, we discuss remaining challenges to address and how data-sharing tools can complement existing structures to maximize worker empowerment and policy impact.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {99},
numpages = {25},
keywords = {Platform-based Gig Work, Data-sharing, Policymaking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714206,
author = {Jeon, Hayeon and Yoon, Suhwoo and Lee, Keyeun and Kim, Seo Hyeong and Kim, Esther Hehsun and Cho, Seonghye and Ko, Yena and Yang, Soeun and Dabbish, Laura and Zimmerman, John and Kim, Eun-mee and Lim, Hajin},
title = {Letters from Future Self: Augmenting the Letter-Exchange Exercise with LLM-based Agents to Enhance Young Adults' Career Exploration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714206},
doi = {10.1145/3706598.3714206},
abstract = {Young adults often encounter challenges in career exploration. Self-guided interventions, such as the letter-exchange exercise, where participants envision and adopt the perspective of their future selves by exchanging letters with their envisioned future selves, can support career development. However, the broader adoption of such interventions may be limited without structured guidance. To address this, we integrated Large Language Model (LLM)-based agents that simulate participants’ future selves into the letter-exchange exercise and evaluated their effectiveness. A one-week experiment (N=36) compared three conditions: (1) participants manually writing replies to themselves from the perspective of their future selves (baseline), (2) future-self agents generating letters to participants, and (3) future-self agents engaging in chat conversations with participants. Results indicated that exchanging letters with future-self agents enhanced participants’ engagement during the exercise, while overall benefits of the intervention on future orientation, career self-concept, and psychological support remained comparable across conditions. We discuss design implications for AI-augmented interventions for supporting young adults’ career exploration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {100},
numpages = {21},
keywords = {Young adults, career exploration, career pursuits, future self, LLM, future-self agents, LLM-based agent, AI clone, letter-writing exercise, letter-exchange exercise, self-guided interventions, writing interventions},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713278,
author = {Khullar, Aman and Nalin, Nikhil and Prasad, Abhishek and Mampilli, Ann John and Kumar, Neha},
title = {Nurturing Capabilities: Unpacking the Gap in Human-Centered Evaluations of AI-Based Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713278},
doi = {10.1145/3706598.3713278},
abstract = {Human-Computer Interaction (HCI) scholarship has studied how Artificial Intelligence (AI) can be leveraged to support care work(ers) by recognizing, reducing, and redistributing workload. Assessment of AI’s impact on workers requires scrutiny and is a growing area of inquiry within human-centered evaluations of AI. We add to these conversations by unpacking the sociotechnical gap between the broader aspirations of workers from an AI-based system and the narrower existing definitions of success. We conducted a mixed-methods study and drew on Amartya Sen’s Capability Approach to analyze the gap. We shed light on the social factors—on top of performance on evaluation metrics—that guided the AI model choice and determined whose wellbeing must be evaluated while conducting such evaluations. We argue for assessing broader achievements enabled through AI’s use when conducting human-centered evaluations of AI. We discuss and recommend the dimensions to consider while conducting such evaluations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {101},
numpages = {18},
keywords = {Social Determinants of AI Model Choice; Human Infrastructure; Aspirations; Mixed-Methods; DBIR; Capability Approach},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3715271,
author = {Zhang, Runhua and Gan, Jiaqi and Gao, Shangyuan and Chen, Siyi and Wu, Xinyu and Chen, Dong and Tian, Yulin and Wang, Qi and An, Pengcheng},
title = {Walk in Their Shoes to Navigate Your Own Path: Learning About Procrastination Through A Serious Game},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3715271},
doi = {10.1145/3706598.3715271},
abstract = {Procrastination, the voluntary delay of tasks despite potential negative consequences, has prompted numerous time and task management interventions in the HCI community. While these interventions have shown promise in addressing specific behaviors, psychological theories suggest that learning about procrastination itself may help individuals develop their own coping strategies and build mental resilience. However, little research has explored how to support this learning process through HCI approaches. We present ProcrastiMate, a text adventure game where players learn about procrastination’s causes and experiment with coping strategies by guiding in-game characters in managing relatable scenarios. Our field study with 27 participants revealed that ProcrastiMate facilitated learning and self-reflection while maintaining psychological distance, motivating players to integrate newly acquired knowledge in daily life. This paper contributes empirical insights on leveraging serious games to facilitate learning about procrastination and offers design implications for addressing psychological challenges through HCI approaches.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {102},
numpages = {20},
keywords = {Procrastination, Serious Games, Learning, Reflection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713242,
author = {Li, Chun and Solyst, Jaemarie and Scott, Safiyyah and Howse, Gabriella and Nkrumah, Tara and Walker, Erin and Ogan, Amy and Stewart, Angela E.B.},
title = {"I am a Technology Creator": Black Girls as Technosocial Change Agents in a Culturally-Responsive Robotics Camp},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713242},
doi = {10.1145/3706598.3713242},
abstract = {Black girls and women have long been creators in computing spaces. However, much computing education positions Black girls as workers who execute tasks for others’ purposes. Our work takes a different approach by positioning Black girls as technosocial change agents who challenge dominant narratives and construct more liberating identities and social relations as they create new technologies. We draw on data from seven Black girls, ages 9-12, who participated in a 20-hour culturally responsive computing (CRC) camp focused on robotics. Using a thematic analysis approach, we explore how these Black girls demonstrate and enhance their technosocial change agency (TSCA) throughout the camp. We identify themes related to how creating technology helps Black girls refine and fulfill their definitions of technical creators and develop agency through technology creation. We discuss computing education and technology design recommendations within the TSCA framework to support learners’ emerging TSCA in future CRC programs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {103},
numpages = {14},
keywords = {culturally responsive computing, technosocial change agency, informal learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714081,
author = {Liang, Shano and Cormier, Michelle V and Bohrer, Rose and Toups Dugas, Phoebe O.},
title = {Designed \&amp; Discovered Euphoria: Insights from Trans-Femme Players' Experiences of Gender Euphoria in Video Games},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714081},
doi = {10.1145/3706598.3714081},
abstract = {Many transgender (and cisgender) people experience gender euphoria – satisfaction and relief caused by self-actualization and gender congruence – a term that has been overlooked by the design community. Video games create intense experiences involving identities, bodies, and social interaction, providing opportunities to empower people through gender euphoria. We develop themes for creating and supporting gender euphoria in games within the Design, Dynamics, Experience Game Design Framework from a reflexive thematic analysis of 25 games, with an in-depth analysis of four of them. The analysis combines the authors’ positionalities as trans gamers with close reading and content analysis of the games, employing perspectives from critical discourse analysis. We contribute an operational understanding of gender euphoria to support design, in-depth case studies of particularly euphoric game experiences, and identify themes that designers and researchers can use to develop new games and analyze existing ones.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {104},
numpages = {21},
keywords = {gender-inclusive design, game design, trans game studies, transgender gender euphoria},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713702,
author = {Grimme, Sophie and Spoerl, Susanna Marie and Jung, Frederike and Koelle, Marion},
title = {Hidden in Plain Sight: a Structured Analysis of Privacy Policies in the Context of Body-worn 'FemTech' Technologies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713702},
doi = {10.1145/3706598.3713702},
abstract = {As HCI research turns to women’s reproductive health as a topic of interest, an increasing number of female-oriented technologies (FemTech) are being marketed to consumers. This opens up a space for better management and understanding of intimate health but is not without risk. Reproductive health data collected by FemTech devices is highly sensitive and politicized. Breaches of privacy can cause or exacerbate discrimination and gender inequality, and negatively impact users’ safety and well-being. It is therefore important that users are well informed about how their data is collected, handled, used and stored. This work contributes insights into whether and to what extent this is achieved by current FemTech. We conduct a structured content analysis of 18 in-effect privacy policies. Applying an empirically-grounded taxonomy, we identify challenges in policy wording, content and presentation. We conclude with recommendations for improving transparency and supporting users in providing informed consent and claiming data authority.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {105},
numpages = {19},
keywords = {Reproductive Health, Women’s Health, Intimate Data, Data Protection Policies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713236,
author = {Burger, Braeden and Tebbe, Devin and Walquist, Emma and Kind, Toby and Zytko, Douglas},
title = {Saying No to "Yes Means Yes": Limitations of Affirmative Consent for Mitigating Unwanted Behavior Online According to Women and LGBTQIA+ Stakeholders},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713236},
doi = {10.1145/3706598.3713236},
abstract = {Affirmative consent—or “yes means yes”—was initially devised to mitigate sexual violence stemming from misunderstandings of consent. More recently, HCI research has considered adapting affirmative consent to mitigate nonconsensual acts online. Given that affirmative consent has historically been under-adopted and critiqued as unrealistic in its original context of in-person sexual activity, it is imperative that users be involved in producing guidance for affirmative consent practice in computer-mediated contexts. We report a focus group study about affirmative consent in VR dating with 16 stakeholders identifying as women and/or LGBTQIA+ (demographics at elevated risk of nonconsensual acts). Findings suggest that affirmative consent may be obsolete: participants elucidated several reasons why affirmative consent is impractical, if not impossible, to practice in virtual environments. Participants offered provocations to guide creation of new, inherently computer-mediated consent models for mitigating unwanted acts, posing significant opportunity for HCI to have public health impact.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {106},
numpages = {17},
keywords = {Consent; Affirmative Consent; Consent Models; VR Dating; Cross-Reality; Social VR; Online Dating; Sexual Violence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714011,
author = {Moy, Cameron and Bui, Matthew},
title = {The Unintended Costs of Platform Interventions: Black-Owned Restaurants and Yelp Reputation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714011},
doi = {10.1145/3706598.3714011},
abstract = {In Spring 2020, digital review-based platform Yelp added the searchable “Black-owned” attribute to support Black-owned businesses. Based on the literature, the impacts of this design intervention were mixed. As such, we sourced an original dataset of 250,000+ Yelp reviews from Black and non-Black-owned restaurants in Detroit and Los Angeles. Performing statistical and trend analyses, we compared the reputation metrics of Black-owned restaurants to their non-Black-owned counterparts before and after the intervention. Although Yelp reported positive impacts, our results contribute to the growing evidence of the harms and unintended costs of platform interventions. Specifically, while awareness of Black ownership and the number of Black-owned restaurant reviews increased, assumedly among and by Yelp’s predominately non-Black users, Black-owned restaurants saw a decline in average star ratings. Altogether, the findings highlight the need to interrogate underlying assumptions in the design process, integrating critical race concepts to better contextualize and evaluate interventions targeting marginalized users.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {107},
numpages = {15},
keywords = {Black-owned restaurants, predatory inclusion, platform visibility, online reputation, allyship},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713842,
author = {Williams, Gianna and Chen, Natalie and DeVito, Michael Ann and To, Alexandra},
title = {Why Can't Black Women Just Be?: Black Femme Content Creators Navigating Algorithmic Monoliths},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713842},
doi = {10.1145/3706598.3713842},
abstract = {Content creation allows many online social media users to support themselves financially through creativity. The “creator economy” empowers individuals to create content (i.e. lifestyle, fitness, beauty) about their interests, hobbies and daily life. Social media platforms in turn moderate content (e.g., banning accounts, flagging and reporting videos) to create safer online communities. However, Black women, femme, and non-binary people content creators have seen their content disproportionately suppressed, thus limiting their success on the platform. In this paper, we investigate Black femme content creators’ (BFCC) theories about how their identities impact both how they create content and how that content is subsequently moderated. In our findings, we share the perceptions participants felt the algorithm constrains Black creators to. We build upon Critical Technocultural Discourse studies and algorithmic folk theories attributed to Black women and non-binary content creators to explore how Black joy can be prioritized online to resist algorithmic monoliths.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {108},
numpages = {14},
keywords = {Blackness and the Internet, Online Communities, Critical Algorithmic Studies, Black femmes, Content Creators, Algorithmic Folk Theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714059,
author = {Ezema, Kelechi and Chandler, Chelsea and Southwell, Rosy and Cholendiran, Niranjan and D'Mello, Sidney},
title = {“It feels like we're not meeting the criteria”: Examining and Mitigating the Cascading Effects of Bias in Automatic Speech Recognition in Spoken Language Interfaces.},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714059},
doi = {10.1145/3706598.3714059},
abstract = {Researchers have demonstrated that Automatic Speech Recognition (ASR) systems perform differently across demographic groups (i.e. show bias), yet their downstream impact on spoken language interfaces remains unexplored. We examined this question in the context of a real-world AI-powered interface that provides tutors with feedback on the quality of their discourse. We found that the Whisper ASR had lower accuracy for Black vs. white tutors, likely due to differences in acoustic patterns of speech. The downstream automated discourse classifiers of tutor talk were correspondingly less accurate for Black tutors when presented with ASR input. As a result, although Black tutors demonstrated higher-quality discourse on human transcripts, this trend was not evident on ASR transcripts. We experimented with methods to reduce ASR bias, finding that fine-tuning the ASR on Black speech reduced, but did not eliminate, ASR bias and its downstream effects. We discuss implications for AI-based spoken language interfaces aimed at providing unbiased assessments to improve performance outcomes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {109},
numpages = {13},
keywords = {automatic speech recognition, fairness, racial bias, teacher discourse},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714029,
author = {Islam, Md Saiful and Rahman, Md Mahbubur and Bin Morshed, Mehrab and Lin, David J and Li, Yunzhi and Zhou, Hao and Mendes, Wendy Berry and Kuang, Jilong},
title = {BallistoBud: Heart Rate Variability Monitoring using Earbud Accelerometry for Stress Assessment},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714029},
doi = {10.1145/3706598.3714029},
abstract = {This paper examines the potential of commercial earbuds for detecting physiological biomarkers like heart rate (HR) and heart rate variability (HRV) for stress assessment. Using accelerometer (IMU) and photoplethysmography (PPG) data from earbuds, we compared these estimates with reference electrocardiogram (ECG) data from 81 healthy participants. We explored using low-power accelerometer sensors for capturing ballistocardiography (BCG) signals. However, BCG signal quality can vary due to individual differences and body motion. Therefore, BCG data quality assessment is critical before extracting any meaningful biomarkers. To address this, we introduced the ECG-gated BCG heatmap, a new method for assessing BCG signal quality. We trained a Random Forest model to identify usable signals, achieving 82\% test accuracy. Filtering out unusable signals improved HR/HRV estimation accuracy to levels comparable to PPG-based estimates. Our findings demonstrate the feasibility of accurate physiological monitoring with earbuds, advancing the development of user-friendly wearable health technologies for stress management.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {110},
numpages = {21},
keywords = {Earbud, Earbud accelerometer, ballistocardiograms, heart rate monitoring, heart rate variability, stress},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713742,
author = {Xue, Qiuyue (Shirley) and Martin, Eric Steven and Liu, Jiaqing and Wang, Ruiqing and Glenn, Antonio and Li, Richard and Iyer, Vikram and Patel, Shwetak},
title = {ECG Necklace: Low-power Wireless Necklace for Continuous ECG monitoring},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713742},
doi = {10.1145/3706598.3713742},
abstract = {Continuous, everyday ECG monitoring is essential for detecting transient heart conditions and enabling early intervention in cardiovascular diseases. However, current technologies, such as ECG Holter monitors and smartwatches, face challenges in balancing continuous monitoring with long-term wearability due to trade-offs in electrode placement. To address this, we present a novel ECG necklace that leverages its natural placement on the chest to provide continuous, clinically valuable ECG monitoring. Our design positions two electrodes on the left and right sides of the chest, approximating standard Lead I placement for accurate cardiac diagnostics. The necklace features an innovative skin moisture-enhanced electrode design for sustained comfort and integrates a compact 22-mm processing unit as the pendant, offering a 4-day battery life. In our studies, the ECG necklace demonstrated performance comparable to FDA-approved Holter monitors, with key features falling within a timing error range of 3.2–15.7 ms—well within acceptable limits. In our in-the-wild study, participants rated the necklace as highly comfortable and preferred it over traditional ECG monitors. As a widely accepted everyday accessory, the ECG necklace has the potential to seamlessly combine advanced functionality with daily wearability.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {111},
numpages = {14},
keywords = {Wearable Computing; Health monitoring; ECG; Smart Jewelry;},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713512,
author = {Knierim, Michael T. and Stano, Fabio and Kurz, Fabio and Heusch, Antonius and Wilson, Max L.},
title = {Exploring Flow in Real-World Knowledge Work Using Discrete cEEGrid Sensors},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713512},
doi = {10.1145/3706598.3713512},
abstract = {Flow, a state of deep task engagement, is associated with optimal experience and well-being, making its detection a prolific HCI research focus. While physiological sensors show promise for flow detection, most studies are lab-based. Furthermore, brain sensing during natural work remains unexplored due to the intrusive nature of traditional EEG setups. This study addresses this gap by using wearable, around-the-ear EEG sensors to observe flow during natural knowledge work, measuring EEG throughout an entire day. In a semi-controlled field experiment, participants engaged in academic writing or programming, with their natural flow experiences compared to those from a classic lab paradigm. Our results show that natural work tasks elicit more intense flow than artificial tasks, albeit with smaller experience contrasts. EEG results show a well-known quadratic relationship between theta power and flow across tasks, and a novel quadratic relationship between beta asymmetry and flow during complex, real-world tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {112},
numpages = {16},
keywords = {Flow Experience, Knowledge Work, Field Study, Experience Sampling, Ear-EEG, open-cEEGrid},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714185,
author = {An, Hyunjin and Oh, Eunkyu and Kim, Yoosung and Kim, Seonho and Park, Dasom and Oh, Changhoon},
title = {ID.EARS: One-Ear EEG Device with Biosignal Noise for Real-Time Gesture Recognition and Various Interactions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714185},
doi = {10.1145/3706598.3714185},
abstract = {In-ear EEG research has traditionally treated biological signals other than brainwaves, such as electromyography (EMG) and electrooculography (EOG), as unwanted noise to be removed. However, instead of discarding these signals, we developed ID.EARS, a single-ear, dry electrode-based device that utilizes these signals for real-time gesture input. We first identified the optimal position for EEG measurement around the ear using the Alpha Attenuation Response (AAR) test and collected biological signals that occur alongside brainwaves at this location. Using these signals, we created a real-time artifact detection model capable of recognizing five specific gestures: blinking, left and right winking, teeth clenching, and chewing. This model achieved over 90\% accuracy in cross-validation experiments. Leveraging this model and device, we propose several application scenarios, including music control, accessibility features, MR/XR control, and healthcare services. This innovative approach extends the use of ear-EEG devices beyond healthcare, opening up possibilities for natural user interfaces.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {113},
numpages = {18},
keywords = {Brain-computer interaction, Biosignal noise, EEG, Healthcare},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713856,
author = {Xue, Qiuyue (Shirley) and Nissanka, Dilini and Yan, Jiachen Tammy and Wang, Ruiqing and Patel, Shwetak and Iyer, Vikram},
title = {PPG Earring: Wireless Smart Earring for Heart Health Monitoring},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713856},
doi = {10.1145/3706598.3713856},
abstract = {Heart rate is a key vital sign for cardiovascular health and fitness. However, the photoplethysmography (PPG) sensors that monitor heart rate in wearables struggle with accuracy during motion. Our day-long in-the-wild study shows Fitbit measures valid heart rates only 54.88\% of the time. To address this, we developed PPG Earring, which measures 14 mm in diameter, weighs 2.0 g, and offers 21 hours of continuous sensing. Our eight-user exercise study shows that PPG Earring captures valid heart rate data for 91.74 ± 4.84 \% of the time during exercise and 86.29 ± 2.96\% of our day-long in-the-wild study. All participants found the PPG Earring as comfortable as their regular earrings, and most participants expressed a strong willingness to wear the PPG Earring all the time every day. Our results validate the signal quality and comfort level of the PPG Earring, highlighting its potential as a daily health monitoring device.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {114},
numpages = {16},
keywords = {Wearable Computing; Health monitoring; PPG; Smart Jewelry; Smart Earring},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713211,
author = {Zhao, Yankai and Zhang, Jin and Li, Jiao and Sun, Tao},
title = {PalateTouch : Enabling Palate as a Touchpad to Interact with Earphones Using Acoustic Sensing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713211},
doi = {10.1145/3706598.3713211},
abstract = {This paper introduces PalateTouch, a hands-free earphone interaction system that leverages acoustic sensing technology to detect gestures resulting from the interaction between the tongue and the palate. By transmitting Zadoff-Chu signals and analyzing ear canal transfer function features, PalateTouch can capture subtle ear canal deformation and recognize various palate gestures used for interaction. Our proposed palate touch screening method ensures the system remains unaffected by unintended gestures from daily activities and the calibration mechanism enables our system to achieve user-independent recognition. Using only the earphone’s built-in microphone and speaker, our system can distinguish nine gestures with an average F1 score of 0.92 and a false alarm rate of 0.02 across diverse conditions with 16 participants. Additionally, we have enabled real-time functionality and conducted a user study with 11 participants to evaluate PalateTouch’s effectiveness in a demo application. The results demonstrate the superior performance and high usability of PalateTouch.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {115},
numpages = {22},
keywords = {Hands-Free Interaction, Palate Gestures, Acoustic Sensing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713896,
author = {Zhang, Kaining and Teo, Theophilus and Chang, Eunhee and Zheng, Xianglin and Jing, Allison and Billinghurst, Mark},
title = {The Brain Knows What You Prefer: Using EEG to Decode AR Input Preferences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713896},
doi = {10.1145/3706598.3713896},
abstract = {Understanding user input preferences is crucial in immersive environments, where input methods such as gestures and controllers are common. Traditional evaluation methods rely on post experience questionnaires, which don’t capture real-time preferences. This study used brain signals to classify input preferences during Augmented Reality (AR) interactions. Thirty participants performed three interaction tasks (pointing, manipulation, and rotation) using hands or controllers. Their electroencephalogram (EEG) data were collected at varying task difficulties (low, medium, high) and phases (preparation, task, and completion). Machine learning was used to classify preferred and non-preferred input methods. Results showed that EEG signals effectively classify preferences with accuracies up to 86\%, with the completion phase being the best indicator of preference. In addition, different input methods exhibited distinct EEG patterns. These findings highlight the potential of EEG signals for decoding real-time input preference in AR, offering insights for enhancing user experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {116},
numpages = {20},
keywords = {EEG, Input preference, AR interaction tasks, Machine learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713221,
author = {\'{I}vansd\'{o}ttir, Gu\dh{}r\'{u}n Margr\'{e}t and Park, Joo Young and St\r{a}hl, Anna and Balaam, Madeline},
title = {Becoming One with Kuddi: Touching Data through an Intimate Data Physicalisation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713221},
doi = {10.1145/3706598.3713221},
abstract = {Kuddi is a haptic data physicalisation in the form of a soft pillow which combines 12 inflatable pockets to dynamically touch and be touched in relation to the changing menstruating body. This paper presents the soma design process that led to Kuddi’s design, as well as Kuddi’s evaluation through an auto-ethnographic approach, where the first author lived with Kuddi for two menstrual cycles. The resulting dataset was analysed by the research team using a narrative-led approach. Based on this analysis, we present five thick descriptions that capture how the experience of living with Kuddi led to a changing relation with menstrual pain. We contribute a design case of a haptic data physicalisation intended to touch the body and discuss how the material and interaction design choices embodied in Kuddi led to data visceralisation - a way of feeling data in ways which promote new somatic knowledge and experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {117},
numpages = {16},
keywords = {Shape-changing Interfaces, Touch, Menstruation, Interaction Design, Intimate Data, Soma Design, Data Physicalisation, First Person Methods, Autoethnography},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714032,
author = {Park, Joo Young and Zheng, Caroline Yan and Campo Woytuk, Nadia and Huang, Xuni and Balaam, Madeline and Ciolfi Felice, Marianela},
title = {Designing Touch Technologies for and with Bodies in Menstrual Discomfort},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714032},
doi = {10.1145/3706598.3714032},
abstract = {Menstrual discomfort is a prevalent, diverse, and cyclical lived experience, impacting everyday lives. However, in HCI, it has been mostly approached as a data point, leaving much unknown on how technologies can care for these experiences. In response, we designed Touchware, a collection of on-body touch probes with pneumatic shape-change and weight components, which invite wearers to engage with and care for their menstrual discomfort. We report on the participatory soma design process of making Touchware and its two-week-long deployment study with 6 participants in a workplace setting. Our data analysis highlights diffuse and lingering qualities of menstrual discomfort, shedding light on how technologies may touch bodies in vulnerable states. We discuss the importance and challenges of designing touch technologies for and with bodies in the moments of menstrual discomfort. We conclude with a reflection on the agency of touch and its potential to support the self-care labour and nurturing the radical normalization of rest.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {118},
numpages = {19},
keywords = {menstrual pain; touch; discomfort; shape-changing; intimate care; feminist research; Research through Design; pneumatics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714175,
author = {Blanco Cardozo, Rebeca and Garrett, Rachael and Samuelsson-Gamboa, Mafalda and Haresamudram, Kashyap and Lisy, Dominika and Rogg, Maria and N\'{u}\~{n}ez-Pacheco, Claudia},
title = {Identifying Critical Points of Departure for the Design of Self-Fashioning Technologies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714175},
doi = {10.1145/3706598.3714175},
abstract = {Designing technologies that clothe, adorn, or are otherwise placed on the body raises questions concerning the role they will play in dressing ourselves. We situate self-fashioning – or the process through which we stylise and present our bodies – as a complex practice where a series of social, material, and contextual factors shape how we present ourselves. Informed by reflective discussions and projective design tools, we contribute three critical points of departure for self-fashioning technologies: (i) Purposeful examining discomfort as an ongoing phenomenon, (ii) Supporting mimesis and visibility as qualities to be negotiated, and (iii) Envisioning the multiplicity of the body. We call for the design community to help devise fashionable technologies that are sensitive, caring, and responsive to the complexities of fashioning our bodies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {119},
numpages = {16},
keywords = {self-fashioning, fashion, fashionable technology, wearables, soma design, body-centric design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713247,
author = {Gordon James, Sam and Armstrong, Miranda Elaine Glynis and Abdallah, Zahraa S. and Emerson, Harry and O'Kane, Aisling Ann},
title = {Integrating Technology into Self-Management Ecosystems: Young Adults with Type 1 Diabetes in the UK using Smartwatches},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713247},
doi = {10.1145/3706598.3713247},
abstract = {Self-managing chronic conditions typically involves a diverse network of individuals and devices, forming a self-management ecosystem. For this ecosystem to be effective, components need to work together cohesively. The rapid advancement of technology means new devices need to be repeatedly integrated into existing self-management ecosystems. To examine this process, we used the case study of young adults with type 1 diabetes (T1D) in the UK who were given a smartwatch. Over six months, interviews and focus groups were performed to explore their smartwatch use alongside T1D management. Thematic analysis highlighted that smartwatches have potential as a display, interface and data source in T1D management, which is of particular importance as artificial intelligence plays a growing role in self-management ecosystems. It also emphasised the need for customisation, flexibility and adaptability, and automation in the design of technology to promote integration into existing self-management ecosystems for both T1D and other chronic conditions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {120},
numpages = {20},
keywords = {Health - Wellbeing, Individuals with Disabilities \&amp; Assistive Technologies, Wearable Computers, Empirical study that tells us about how people use a system},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714150,
author = {Bhattacharjee, Sayan and Ribes, David},
title = {Technical Responses To Critique: The Case Of Skin Tone},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714150},
doi = {10.1145/3706598.3714150},
abstract = {How do technical actors respond to critique by developing novel technologies? In this paper, we follow the actors that have positioned themselves as critics of technology; we examine the inspirations and sources of their critical capacities and; we trace the development of concrete technological artifacts designed to respond to those critiques. To illustrate our approach, we outline the case of digital cameras tuned to capture diverse human skin tones, a technical response to long-standing critiques of whiteness bias in photography. Our investigative approach synthesizes three theoretical threads: the sociology of critical capacities, the anthropology of ethics, and studies of valuation. To trace the arc of technical responses to critique: (i) inspect the conditions under which actors are, or are not, capacitated to be critical; (ii) the conditions in which critiques are communicated, disputed, modified, furthered or ignored; and (iii) trace how matters of concern are materialized in technical outcomes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {121},
numpages = {15},
keywords = {Critical capacities, valuation, anthropology of ethics, methodology, race \&amp; ethnicity, skin tone, computational photography},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713607,
author = {Tholander, Jakob},
title = {The Body as Its Own Best Sensor - An Autoethnographic Study of the Sensitivities of the Body in Long-Distance Running},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713607},
doi = {10.1145/3706598.3713607},
abstract = {Long-distance running is introduced as an example of a sport-specific somatic and embodied data practice that may expand the repertoire of techniques and methods of embodied interaction design and provide insights into the design of technologies for running specifically and sports technology more broadly. Through an autobiographic study of everyday experiences of running and the use of a basic sports watch, a number of themes revolving around the multi-sensoriality of running are introduced. Reflections on the intimate coupling of digital data, running skills, and somatic sensing in the practice of ’doing endurance running’ are provided in order to conceptualise the specific sensitivities, perceptions and experiences of body-data-environment entanglements that emerge during long-distance running. By unpacking a number of such sports-specific skills and data practices involved in long-distance running, six themes for novel perspectives on the design of sports technology are discussed.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {122},
numpages = {16},
keywords = {long-distance running, embodiment, embodied sensing, sports-HCI, sports technology, autoethnography},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713466,
author = {Campo Woytuk, Nadia and Tuli, Anupriya and Park, Joo Young and Turmo Vidal, Laia and Tobin, Deirdre and Reddy, Anuradha and Vincenzi, Beatrice and Maslik, Jan and Ciolfi Felice, Marianela and Balaam, Madeline},
title = {Toward Feminist Ways of Sensing the Menstruating Body},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713466},
doi = {10.1145/3706598.3713466},
abstract = {Bodily fluids associated with the menstruating body are often disregarded in the design of menstrual-tracking technologies despite their potential to provide valuable knowledge about the menstrual cycle. We prototyped a finger-worn sensor that measures vaginal fluid conductivity, which fluctuates throughout the cycle, and brought it into conversation with people through two speculative workshops (18 people), four fabrication workshops (17 people), and a deployment study where participants brought the sensor into their daily lives (7 people). We unpack that taking a material and sensory approach to intimate tracking nurtures a feminist way of sensing while creating tensions around how we want to know our bodies—tensions around how, where, and when to touch the body, hygiene, data storage, interpretation practices, and labor. With epistemological commitments to feminist materialist and posthuman theory, we invite designers to embrace these tensions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {123},
numpages = {17},
keywords = {sensing, leaky bodies, feminist hci, menstrual cycles, vaginal fluids, research through design, wearables, touch},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713368,
author = {Troiano, Giovanni M and Cassidy, Michael and Morales, Daniel Escobar and Pons, Guillermo and Abdollahi, Amir and Robles, Gregorio and Puttick, Gillian and Harteveld, Casper},
title = {CT4ALL: Towards Putting Teachers in the Loop to Advance Automated Computational Thinking Metric Assessments in Game-Based Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713368},
doi = {10.1145/3706598.3713368},
abstract = {Computational thinking (CT) is essential for the 21st century learner. Yet, assessing CT remains challenging. This is particularly challenging in constructionist learning, where individual idiosyncrasies may clash with one-size-fits-all assessments. Tools like Dr. Scratch offer CT metrics that show promise for effective and scalable CT assessments, particularly in constructionist game-based learning (GBL). Prior work has advanced the design of automated CT metrics but hardly included teachers in the process. We extend Dr. Scratch to improve automated CT assessments for GBL and put teachers in the loop to assess its novel features. Specifically, we interviewed seven middle school teachers employing GBL in STEM curricula and asked them to provide feedback on the newly designed CT metrics. Teachers view the new CT metrics positively, underscoring their potential for adaptive CT assessments despite hindrances. We advance automated CT assessments via teacher evaluation toward design-sensitive CT metrics and CT for all.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {124},
numpages = {23},
keywords = {Computational thinking, automated metrics, computer science education, STEM, assessment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713870,
author = {Laabadli, Hiba and Ma, Yimeng and Radkova, Sofia and Emami-Naeini, Pardis},
title = {Exploring Security and Privacy Discourse on Twitter During the `Justice Pour Nahel' Movement in France},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713870},
doi = {10.1145/3706598.3713870},
abstract = {The shooting of Nahel Merzouk in June 2023 ignited widespread protests across France, known as the “Justice Pour Nahel” movement, drawing attention to the privacy and security risks faced by protesters. This study explores the discourse on Twitter during the protests, focusing on digital surveillance and censorship concerns. We analyzed 341 tweets using qualitative methods to understand the security and privacy attitudes and advice shared by French-speaking users. Our findings reveal a strong apprehension toward increased long-term government surveillance and censorship, with limited and often low-tech advice on how to counteract these threats. We highlight the discrepancy between the concerns raised and the available guidance and compare our findings with those of prior work. Grounded in our analysis and informed by prior research, we offer targeted recommendations for activists, policymakers, and researchers to mitigate security and privacy concerns arising from social unrest, both in France and globally.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {125},
numpages = {19},
keywords = {Privacy, Security, Protests, France, Twitter, Activism},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713644,
author = {Rogers, Kantwon and Davis, Michael and Maharana, Mallesh and Etheredge, Pete and Chernova, Sonia},
title = {Playing Dumb to Get Smart: Creating and Evaluating an LLM-based Teachable Agent within University Computer Science Classes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713644},
doi = {10.1145/3706598.3713644},
abstract = {This work presents the iterative design and evaluation of a large-language-model (LLM) based teachable agent, MatlabTutee, that facilitates learning-by-teaching (LBT) experiences within university computer science courses. We detail four different experiments, with a total of 119 students, where we refine our system, compare it to human-facilitated LBT experiences, and deploy it in two, month-long in-the-wild environments. We find that our system is able to successfully convey a learner persona similar to a human pretending to be novice while also providing comparable LBT benefits. These benefits include helping students identify areas for improvement, develop a more accurate assessment of their own abilities, and improve their overall attitudes toward computer science. We also explore how students choose to adopt our system into their study habits while situated in real university courses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {126},
numpages = {22},
keywords = {Computer Science Education, LLM, Teachable Agent, Deception, Learning by Teaching, University Students, Longitudinal},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714223,
author = {Hasan, S Mahmudul and Tu, Che Wei and Hoque, Endadul and Chowdhury, Omar and Chau, Sze Yiu},
title = {SeQR: A User-Friendly and Secure-by-Design Configurator for Enterprise Wi-Fi},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714223},
doi = {10.1145/3706598.3714223},
abstract = {A classic problem in enterprise Wi-Fi is client-side misconfiguration, which enables credential theft via “Evil Twin” (ET) attacks. To mitigate this, we design, develop, and evaluate a new configurator, SeQR, which allows users to effortlessly and securely set up an enterprise Wi-Fi connection. Utilizing existing authenticated channels, SeQR fully automates the client-side enterprise Wi-Fi configuration process with a simple scan, leaving no room for misconfigurations. Specifically, SeQR thwarts ET by making it impossible for users to opt-out from the security-critical certificate validation. We evaluate the efficacy of SeQR on two fronts. First, we implement a prototype of SeQR in Android, and test its functionality and runtime performance. Next, we compare the usability of SeQR against two existing Wi-Fi configuration interfaces of Android in an in-person user study (n=41) with real devices. Our evaluation shows that SeQR achieves noticeable usability improvements over existing designs, and prevents users from misconfiguring.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {127},
numpages = {19},
keywords = {WPA Enterprise, Evil-Twin, TLS, Android UI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713843,
author = {Fey, James Collin and Robinson, Raquel B and Ji, Chen and Dagan, Ella and Campe, Shannon and Schweig, Kaia and Crisp, Elliot and Padilla De La Torre, Carmen Alicia and Isbister, Katherine},
title = {Social Wearables Edu-Larp: Insights From a Novel Camp Combining Crafting, Coding, and Larping Aimed at Non-traditional Steam Participants},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713843},
doi = {10.1145/3706598.3713843},
abstract = {Developing STEAM (Science, Technology, Engineering, Art, and Math) education curricula encouraging participation from underrepresented groups is crucial for diversity in computational fields. Many existing programs attract cis-white males, to the exclusion of other groups. This paper discusses a camp where participants, primarily female youth ages 10-14 (N=45), engage in crafting social wearable technologies within a live-action roleplay context. Our findings from four camp sessions show increased self-reported competence and interest in STEAM among participants, alongside enhanced feelings of community and social support. The camp’s innovative approach integrates design thinking, iterative design, and collaboration, proving effective in fostering inclusivity and engagement in STEAM. We adopted an iterative Research-through-Design process, with researchers embedded in the camp to observe and conduct surveys and interviews with participants. Researchers and educators can benefit from reading our results, which demonstrate the value of a playful, socially-engaged curriculum in attracting and retaining diverse students in STEAM fields.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {128},
numpages = {15},
keywords = {edu-larp, larp, wearables, crafting, coding, Micro:Bit, informal learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713260,
author = {Yu, Jin and Garg, Poojita and Synn, DoangJoo and Oh, HyunJoo},
title = {Tangible-MakeCode: Bridging Physical Coding Blocks with a Web-Based Programming Interface for Collaborative and Extensible Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713260},
doi = {10.1145/3706598.3713260},
abstract = {Tangible programming engages children through hands-on and collaborative learning but often lacks integration with widely used programming platforms, which limits their extensibility and relevance in existing educational contexts. To address this, we propose Tangible-MakeCode (T-MC), a system that combines physical coding blocks with MakeCode. T-MC enables students, including beginners in coding, to design and program interactive wireless communication projects. Students assemble the blocks, capture an image with a webcam, and convert it into code for MakeCode, which they can simulate and upload to their micro:bit boards. We describe the iterative design of T-MC, informed by participatory design workshops with 53 children and feedback from expert interviews with six teachers. A pilot study with 21 children (ages 12-14; M=10, F=11) demonstrates that T-MC is an engaging and inclusive tool that empowers beginners to contribute to team projects by providing an accessible platform for prototyping ideas.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {129},
numpages = {15},
keywords = {Tangible Programming, Block-based Coding, MakeCode, Participatory Design, Collaborative Learning, Educational Technology, Iterative Prototyping},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713611,
author = {Hardwick, Taylor and Carter, Marcus and Harkin, Stephanie and Zhangshao, Tianyi and Egliston, Ben},
title = {"They're Scamming Me": How Children Experience and Conceptualize Harm in Game Monetization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713611},
doi = {10.1145/3706598.3713611},
abstract = {Regulatory shifts are increasingly placing the onus on online service providers such as digital game developers and platforms to ensure that their services do not harm children. This creates an urgent need to examine how children experience and conceptualize harm in digital contexts, which may differ from adult-driven perceptions of harm. In this paper, we present the results of a study into children’s experiences with game monetization which included a ‘think-aloud’ method in which children were given an AU$20 voucher to spend. Through our participants’ (aged 7-14) vernacular of feeling ‘scammed’ or ‘tricked’, we argue that children experience harm principally through being misled or deceived by monetization features, rather than being due to what parents perceive as a misattribution of value toward digital items or overspending. Based on these results, we make game design recommendations to minimize children’s harmful experiences with game monetization strategies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {130},
numpages = {14},
keywords = {Monetization, Children, Safety by Design, Digital games},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713602,
author = {Wang, Zizhen and Pan, Jiangyu and Jin, Duola and Zhang, Jingao and Cao, Jiacheng and Zhang, Chao and Li, Zejian and Hansen, Preben and Zhao, Yijun and Sun, Shouqian and Qiao, Xianyue},
title = {CharacterCritique: Supporting Children's Development of Critical Thinking through Multi-Agent Interaction in Story Reading},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713602},
doi = {10.1145/3706598.3713602},
abstract = {Critical thinking plays a crucial role in children’s education for fostering cognitive development, cultivating independent thinking habits, and enhancing their ability to problem-solving. However, the current educational model places greater emphasis on children’s understanding of factual knowledge, with relatively less focus on developing critical thinking skills. We present CharacterCritique to support children’s critical thinking based on the theory of inquiry dialogue. This tool uses an analytical story as the medium, it encourages dialogue between parents, children, and story characters. Through this process, children continuously engage in interpretation, analysis, explanation, evaluation, and regulation, all of which promote critical thinking and decision-making. Such interaction is supported by multiple agents. In our between-subjects study (n=32), we compared CharacterCritique to traditional storybook reading. The results show that CharacterCritique is more effective at sparking children’s interest in deeper discussions. It also better fosters critical thinking, problem-solving skills, and creates more opportunities for parent-child dialogue.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {131},
numpages = {21},
keywords = {Story, multi-agent system, Critical thinking, Children, Human-AI Interaction, family},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714037,
author = {Lim, Jared Ordo\~{n}a and Barkhuff, Grace and Awuah, Jane and Clyde, Sophie and Sogani, Riya and Gardner-McCune, Christina and Touretzky, David and Uchidiuno, Judith Odili},
title = {Escape or D13: Understanding Youth Perspectives of AI through Educational Game Co-design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714037},
doi = {10.1145/3706598.3714037},
abstract = {There are many initiatives that teach Artificial Intelligence (AI) literacy to K-12 students. Most downsize college-level instructional materials to grade-level appropriate formats, overlooking students’ unique perspectives in the design of curricula. To investigate the use of educational games as a vehicle for uncovering youth’s understanding of AI instruction, we co-designed games with 39 Black, Hispanic, and Asian high school girls and non-binary youth to create engaging learning materials for their peers. We conducted qualitative analyses on the designed game artifacts, student discourse, and their feedback on the efficacy of learning activities. This study highlights the benefits of co-design and learning games to uncover students’ understanding and ability to apply AI concepts in game-based learning, their emergent perspectives of AI, and the prior knowledge that informs their game design choices. Our research uncovers students’ AI misconceptions and informs the design of educational games and grade-level appropriate AI instruction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {132},
numpages = {17},
keywords = {Co-design, game-based learning, AI Education, Youth, AI Literacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713836,
author = {Lo, Priscilla Y. and Veldhuis, Annemiek and Antle, Alissa N. and DiPaola, Steve},
title = {Noel: A Chatbot Persona to Support Children Designing for Others},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713836},
doi = {10.1145/3706598.3713836},
abstract = {Designing for others encourages children to empathize with and consider different perspectives and needs. A chatbot persona could allow children to design for stakeholder groups that are challenging to involve directly in educational activities, such as people with disabilities. In this paper, we explore how an artificial intelligence chatbot persona leveraging the GPT-4 large language model can support children’s design empathy while designing for others. We report the design, development process, and implementation of a chatbot persona representing a 12-year-old child with low vision named Noel. The exploratory case study consisted of three 90- to 120-minute workshop sessions with nineteen students (ages 11 to 13) in a grade 6/7 classroom. Results illustrate ways that Noel supported students throughout the design process, their expressions of design empathy, and their experiences. We present implications for developers and educators along with future directions for research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {133},
numpages = {25},
keywords = {children, education, empathy, design thinking, chatbot, persona, artificial intelligence, large language model, visual impairment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713687,
author = {Sabie, Samar and Soden, Robert and Parikh, Tapan},
title = {Oral History and Qualitative Analysis with Youth: Cultivating Attachments to Create Publics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713687},
doi = {10.1145/3706598.3713687},
abstract = {Urban environments can inhibit the formation of publics due to their distracting nature and distant social ties. Yet, forming publics is critical for bringing and mobilizing citizens around issues. In this paper, we introduce a methodology that combines oral history collection and qualitative analysis to foster connections among youth in a North American public school. During our project, the youth interviewed classmates, guardians, and strangers from their community about the meaning of home, then collectively analyzed the oral histories using qualitative analysis techniques. Our findings highlight that this process generated unexpected connections around shared experiences despite the different backgrounds of project participants, thus fostering a sense of attachment to home as a cause for public formation. Our paper demonstrates the effectiveness of such approach in building attachments as a pre-cursor to public formation in community-centered work, while reflecting on the associated practical challenges like skill development, sustained engagement, and emotional labor.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {134},
numpages = {16},
keywords = {home, oral history, strangers, publics, attachments, youth},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713268,
author = {Rofi, Ishmam Bin and Eshita, Mashiyat Mahjabin and Chakma, Avijoy and Ahmed, Md. Sabbir and Haque, S M Taiabul and Noor, Jannatun},
title = {The Good, The Bad and The Ugly: The Opportunities, Challenges and the Mitigation Strategies of the Young Indigenous Social Media Users of the Chittagong Hill Tracts in Bangladesh},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713268},
doi = {10.1145/3706598.3713268},
abstract = {The Chittagong Hill Tracts (CHT) of Bangladesh is home to numerous Indigenous ethnic communities, and their languages, rituals, and values are distinct from those of the mainstream population. These differences, coupled with the past eight decades of turbulent political history, have contributed to the decline of communal harmony among different stakeholders in this region, which has been further aggravated by the advent of social media. In this work, we study the unique challenges faced by Indigenous young community members in Bangladesh when using the social media. Through a qualitative approach involving interviews and focus group discussion sessions, we investigate the online experiences encountered by this population along with their protection and coping mechanisms. Our findings provide a nuanced portrayal of both the internal and external challenges faced by these users. We further connect our findings to the broader issues in HCI and offer a few design recommendations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {135},
numpages = {22},
keywords = {Indigenous HCI, Global South, Chittagong Hill Tracts (CHT), Colonialism, Cultural Divide, Fake News, Misinformation in Social Media, HCI4D.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713262,
author = {Fu, Yue and Schwamm, Samuel and Baughan, Amanda and Powell, Nicole M and Kronberg, Zoe and Owens, Alicia and Izenman, Emily Renee and Alsabeh, Dania and Hunt, Elizabeth and Rich, Michael and Bickham, David and Radesky, Jenny and Hiniker, Alexis},
title = {Understanding Children's Avatar Making in Social Online Games},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713262},
doi = {10.1145/3706598.3713262},
abstract = {Social online games like Minecraft and Roblox have become increasingly integral to children’s daily lives. Our study explores how children aged 8 to 13 create and customize avatars in these virtual environments. Through semi-structured interviews and gameplay observations with 48 participants, we investigate the motivations behind children’s avatar-making. Our findings show that children’s avatar creation is motivated by self-representation, experimenting with alter ego identities, fulfilling social needs, and improving in-game performance. In addition, designed monetization strategies play a role in shaping children’s avatars. We identify the “wardrobe effect,” where children create multiple avatars but typically use only one favorite consistently. We discuss the impact of cultural consumerism and how social games can support children’s identity exploration while balancing self-expression and social conformity. This work contributes to understanding how avatar shapes children’s identity growth in social online games.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {136},
numpages = {16},
keywords = {Avatar, Game, Social Game, Roblox, Minecraft, Fortnite},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713853,
author = {Zhang, Zihan and Sun, Black and An, Pengcheng},
title = {Breaking Barriers or Building Dependency? Exploring Team-LLM Collaboration in AI-infused Classroom Debate},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713853},
doi = {10.1145/3706598.3713853},
abstract = {Classroom debates are a unique form of collaborative learning characterized by fast-paced, high-intensity interactions that foster critical thinking and teamwork. Despite the recognized importance of debates, the role of AI tools, particularly LLM-based systems, in supporting this dynamic learning environment has been under-explored in HCI. This study addresses this opportunity by investigating the integration of LLM-based AI into real-time classroom debates. Over four weeks, 22 students in a Design History course participated in three rounds of debates with support from ChatGPT. The findings reveal how learners prompted the AI to offer insights, collaboratively processed its outputs, and divided labor in team-AI interactions. The study also surfaces key advantages of AI usage—reducing social anxiety, breaking communication barriers, and providing scaffolding for novices—alongside risks, such as information overload and cognitive dependency, which could limit learners’ autonomy. We thereby discuss a set of nuanced implications for future HCI exploration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {137},
numpages = {19},
keywords = {Debate, Collaborative learning, ChatGPT, Human-AI interaction, Classroom},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713971,
author = {Ravi, Prerna and Masla, John and Kakoti, Gisella and Lin, Grace C. and Anderson, Emma and Taylor, Matt and Ostrowski, Anastasia K. and Breazeal, Cynthia and Klopfer, Eric and Abelson, Hal},
title = {Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713971},
doi = {10.1145/3706598.3713971},
abstract = {The emergence of generative AI, particularly large language models (LLMs), has opened the door for student-centered and active learning methods like project-based learning (PBL). However, PBL poses practical implementation challenges for educators around project design and management, assessment, and balancing student guidance with student autonomy. The following research documents a co-design process with interdisciplinary K-12 teachers to explore and address the current PBL challenges they face. Through teacher-driven interviews, collaborative workshops, and iterative design of wireframes, we gathered evidence for ways LLMs can support teachers in implementing high-quality PBL pedagogy by automating routine tasks and enhancing personalized learning. Teachers in the study advocated for supporting their professional growth and augmenting their current roles without replacing them. They also identified affordances and challenges around classroom integration, including resource requirements and constraints, ethical concerns, and potential immediate and long-term impacts. Drawing on these, we propose design guidelines for future deployment of LLM tools in PBL.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {138},
numpages = {25},
keywords = {Generative AI, LLMs, AI for education, project-based learning, co-design, teachers, interviews},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714146,
author = {Prasad, Prajish and Balse, Rishabh and Balchandani, Dhwani},
title = {Exploring Multimodal Generative AI for Education through Co-design Workshops with Students},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714146},
doi = {10.1145/3706598.3714146},
abstract = {Multimodal large language models (MLLMs) are Generative AI models that take different modalities such as text, audio, and video as input and generate appropriate multimodal output. Since such models will be integrated into future educational tools, a human-centered design approach that takes students’ perspectives into account is essential while designing such applications.This paper describes two co-design workshops which were conducted with 79 student groups to examine how they design and prototype future educational tools integrated with MLLMs. Through various activities in the workshops, students discussed relevant educational problems, created journey maps, storyboards and low fidelity prototypes for their applications, and evaluated their applications based on relevant design principles. We found that students’ applications used MLLMs for important learning environment design features such as multimodal content creation, personalization, and feedback. Based on these findings, we discuss future research directions for the design of multimodality in generative AI educational applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {139},
numpages = {17},
keywords = {artificial intelligence, generative AI, large language models, multimodality, co-design, design principles, learning environment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713690,
author = {M\"{a}kel\"{a}, Ville and MacArthur, Cayley and Lee, Jieun and Harley, Daniel},
title = {Integrating Virtual Reality Head-Mounted Displays into Higher Education Classrooms on a Large Scale},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713690},
doi = {10.1145/3706598.3713690},
abstract = {Virtual reality head-mounted displays (HMDs) offer unique and immersive opportunities for higher education. However, current research focuses on small-scale and infrequent use cases, raising questions about large-scale HMD integration into classrooms. We explored logistical and pedagogical challenges and opportunities when using 30 VR HMDs in a design class of 55 undergraduate students throughout a 12-week term. Each student shared an HMD with a partner, using it weekly in class and at home. We administered questionnaires and conducted observations and interviews. Our results reveal highly positive student engagement, but instructors and students must adapt to unique HMD characteristics and challenges, including in-VR lecturing practices, developing safety measures, and mitigating cybersickness. Although instructor-led VR tutorials were helpful, most learning occurred in individual, paired, and group activities, where screencasting and HMD sharing fostered collaborative learning. Free time during classes provided an opportunity for targeted instructor support while allowing students to explore emerging practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {140},
numpages = {16},
keywords = {Virtual Reality, Classroom, Education, Large-Scale Deployment, University Students, Head-Mounted Displays},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714065,
author = {Qiu, Leping and Kim, Erin Seongyoon and Suh, Sangho and Sidenmark, Ludwig and Grossman, Tovi},
title = {MaRginalia: Enabling In-person Lecture Capturing and Note-taking Through Mixed Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714065},
doi = {10.1145/3706598.3714065},
abstract = {Students often take digital notes during live lectures, but current methods can be slow when capturing information from lecture slides or the instructor’s speech, and require them to focus on their devices, leading to distractions and missing important details. This paper explores supporting live lecture note-taking with mixed reality (MR) to quickly capture lecture information and take notes while staying engaged with the lecture. A survey and interviews with university students revealed common note-taking behaviors and challenges to inform the design. We present MaRginalia to provide digital note-taking with a stylus tablet and MR headset. Students can take notes with an MR representation of the tablet, lecture slides, and audio transcript without looking down at their device. When preferred, students can also perform detailed interactions by looking at the physical tablet. We demonstrate the feasibility and usefulness of MaRginalia and MR-based note-taking in a user study with 12 students.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {141},
numpages = {15},
keywords = {Note-taking, Cross-device Interaction, Mixed-reality system, Pen-based Input},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713169,
author = {Jonas, Anne and De Jes\'{u}s, Ang\'{e}lica and Hardy, Jean},
title = {Student Agency and Punishment Logics in Imagined Future Classroom Technologies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713169},
doi = {10.1145/3706598.3713169},
abstract = {Educators and policymakers are increasingly trying to control youth access to technology in the classroom, while simultaneously working to deploy technology for purposes of surveillance and behavioral control. While many scholars have explored the implications of intensifying dataveillance and disciplinary practices deployed by teachers in K-12 schooling, few have investigated how students’ visions of technology deployment and use might align or diverge from those of designers and teachers. Using the resulting data from participatory design workshops and ethnographic research with students and staff in alternative hybrid schools, we explore students’ concepts of future technologies for the classroom and how these artifacts reflect student perceptions of safety and good behavior. Rather than simply accepting or resisting the role of technology in discipline and punishment as presented by technology creators, wherein disciplinary decisions are made by teachers using technology, students actively respond to these narratives to increase the objectivity and accuracy of punishment. The results of this work show how visions of future technology can sometimes reify new forms of power and other times respond to unmet student needs to exert control in the classroom.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {142},
numpages = {13},
keywords = {Future workshops, design research, schools, dataveillance, public safety},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714313,
author = {Shao, Zekai and Yuan, Siyu and Gao, Lin and He, Yixuan and Yang, Deqing and Chen, Siming},
title = {Unlocking Scientific Concepts: How Effective Are LLM-Generated Analogies for Student Understanding and Classroom Practice?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714313},
doi = {10.1145/3706598.3714313},
abstract = {Teaching scientific concepts is essential but challenging, and analogies help students connect new concepts to familiar ideas. Advancements in large language models (LLMs) enable generating analogies, yet their effectiveness in education remains underexplored. In this paper, we first conducted a two-stage study involving high school students and teachers to assess the effectiveness of LLM-generated analogies in biology and physics through a controlled in-class test and a classroom field study. Test results suggested that LLM-generated analogies could enhance student understanding particularly in biology, but require teachers’ guidance to prevent over-reliance and overconfidence. Classroom experiments suggested that teachers could refine LLM-generated analogies to their satisfaction and inspire new analogies from generated ones, encouraged by positive classroom feedback and homework performance boosts. Based on findings, we developed and evaluated a practical system to help teachers generate and refine teaching analogies. We discussed future directions for developing and evaluating LLM-supported teaching and learning by analogy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {143},
numpages = {19},
keywords = {Analogy Generation, Large Language Models, Scientific Concept Understanding, Classroom Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713720,
author = {Rasch, Julian and T\"{o}ws, Julia and Hirzle, Teresa and M\"{u}ller, Florian and Schmitz, Martin},
title = {CreepyCoCreator? Investigating AI Representation Modes for 3D Object Co-Creation in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713720},
doi = {10.1145/3706598.3713720},
abstract = {Generative AI in Virtual Reality offers the potential for collaborative object-building, yet challenges remain in aligning AI contributions with user expectations. In particular, users often struggle to understand and collaborate with AI when its actions are not transparently represented. This paper thus explores the co-creative object-building process through a Wizard-of-Oz study, focusing on how AI can effectively convey its intent to users during object customization in Virtual Reality. Inspired by human-to-human collaboration, we focus on three representation modes: the presence of an embodied avatar, whether the AI’s contributions are visualized immediately or incrementally, and whether the areas modified are highlighted in advance. The findings provide insights into how these factors affect user perception and interaction with object-generating AI tools in Virtual Reality as well as satisfaction and ownership of the created objects. The results offer design implications for co-creative world-building systems, aiming to foster more effective and satisfying collaborations between humans and AI in Virtual Reality.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {144},
numpages = {14},
keywords = {Co-creative systems; Generative AI; 3D Creation; Virtual Reality; User Studies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714057,
author = {Pu, Kevin and Feng, K. J. Kevin and Grossman, Tovi and Hope, Tom and Dalvi Mishra, Bhavana and Latzke, Matt and Bragg, Jonathan and Chang, Joseph Chee and Siangliulue, Pao},
title = {IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714057},
doi = {10.1145/3706598.3714057},
abstract = {Research ideation involves broad exploring and deep refining ideas. Both require deep engagement with literature. Existing tools focus primarily on broad idea generation, yet offer little support for iterative specification, refinement, and evaluation needed to further develop initial ideas. To bridge this gap, we introduce IdeaSynth, a research idea development system that uses LLMs to provide literature-grounded feedback for articulating research problems, solutions, evaluations, and contributions. IdeaSynth represents these idea facets as nodes on a canvas, and allow researchers to iteratively refine them by creating and exploring variations and combinations. Our lab study (N = 20) showed that participants, while using IdeaSynth, explored more alternative ideas and expanded initial ideas with more details compared to a strong LLM-based baseline. Our deployment study (N = 7) demonstrated that participants effectively used IdeaSynth for real-world research projects at various ideation stages from developing initial ideas to revising framings of mature manuscripts, highlighting the possibilities to adopt IdeaSynth in researcher’s workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {145},
numpages = {31},
keywords = {Research Ideation; Scientific Literature; Human-AI Collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713375,
author = {Shen, Hanshu and Shen, Lyukesheng and Wu, Wenqi and Zhang, Kejun},
title = {IdeationWeb: Tracking the Evolution of Design Ideas in Human-AI Co-Creation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713375},
doi = {10.1145/3706598.3713375},
abstract = {Due to the remarkable content generation capabilities, large language models (LLMs) have demonstrated potential in supporting early-stage conceptual design. However, current interaction paradigms often struggle to effectively facilitate multi-round idea exploration and selection, leading to random outputs, unclear iterations, and cognitive overload. To address these challenges, we propose a human-AI co-ideation framework aimed at tracking the evolution of design ideas. This framework leverages a structured idea representation, an analogy-based reasoning mechanism and interactive visualization techniques. It guides both designers and AI to systematically explore design spaces. We also develop a prototype system, IdeationWeb, which integrates an intuitive, mind map-like visual interface and interactive methods to support co-ideation. Our user study validates the framework’s feasibility, demonstrating enhanced collaboration and creativity between humans and AI. Furthermore, we identified collaborative design patterns from user behaviors, providing valuable insights for future human-AI interaction design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {146},
numpages = {19},
keywords = {Human-AI co-ideation, Human-AI interaction, Creativity support, Large language models, Design space},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713289,
author = {Zhang, Zheng and Peng, Weirui and Chen, Xinyue and Cao, Luke and Li, Toby Jia-Jun},
title = {LADICA: A Large Shared Display Interface for Generative AI Cognitive Assistance in Co-located Team Collaboration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713289},
doi = {10.1145/3706598.3713289},
abstract = {Large shared displays, such as digital whiteboards, are useful for supporting co-located team collaborations by helping members perform cognitive tasks such as brainstorming, organizing ideas, and making comparisons. While recent advancement in Large Language Models (LLMs) has catalyzed AI support for these displays, most existing systems either only offer limited capabilities or diminish human control, neglecting the potential benefits of natural group dynamics. Our formative study identified cognitive challenges teams encounter, such as diverse ideation, knowledge sharing, mutual awareness, idea organization, and synchronization of live discussions with the external workspace. In response, we introduce LADICA, a large shared display interface that helps collaborative teams brainstorm, organize, and analyze ideas through multiple analytical lenses, while fostering mutual awareness of ideas and concepts. Furthermore, LADICA facilitates the real-time extraction of key information from verbal discussions and identifies relevant entities. A lab study confirmed LADICA’s usability and usefulness.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {147},
numpages = {22},
keywords = {computer-mediated communication, co-located collaboration, large shared display, cognitive assistance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714051,
author = {Reza, Mohi and Anastasopoulos, Ioannis and Bhandari, Shreya and Pardos, Zachary A.},
title = {PromptHive: Bringing Subject Matter Experts Back to the Forefront with Collaborative Prompt Engineering for Educational Content Creation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714051},
doi = {10.1145/3706598.3714051},
abstract = {Involving subject matter experts in prompt engineering can guide LLM outputs toward more helpful, accurate, and tailored content that meets the diverse needs of different domains. However, iterating towards effective prompts can be challenging without adequate interface support for systematic experimentation within specific task contexts. In this work, we introduce PromptHive, a collaborative interface for prompt authoring designed to better connect domain knowledge with prompt engineering through features that encourage rapid iteration on prompt variations. We conducted an evaluation study with ten subject matter experts in math and validated our design through two collaborative prompt writing sessions and a learning gain study with 358 learners. Our results elucidate the prompt iteration process and validate the tool’s usability, enabling non-AI experts to craft prompts that generate content comparable to human-authored materials while reducing perceived cognitive load by half and shortening the authoring process from several months to just a few hours.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {148},
numpages = {22},
keywords = {Prompt Engineering, LLMs, Human-Centered AI, Math Education, Content Generation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714034,
author = {Choi, Yoonseo and Kang, Eun Jeong and Choi, Seulgi and Lee, Min Kyung and Kim, Juho},
title = {Proxona: Supporting Creators' Sensemaking and Ideation with LLM-Powered Audience Personas},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714034},
doi = {10.1145/3706598.3714034},
abstract = {A content creator’s success depends on understanding their audience, but existing tools fail to provide in-depth insights and actionable feedback necessary for effectively targeting their audience. We present Proxona, an LLM-powered system that transforms static audience comments into interactive, multi-dimensional personas, allowing creators to engage with them to gain insights, gather simulated feedback, and refine content. Proxona distills audience traits from comments, into dimensions (categories) and values (attributes), then clusters them into interactive personas representing audience segments. Technical evaluations show that Proxona generates diverse dimensions and values, enabling the creation of personas that sufficiently reflect the audience and support data-grounded conversation. User evaluation with 11 creators confirmed that Proxona helped creators discover hidden audiences, gain persona-informed insights on early-stage content, and allowed them to confidently employ strategies when iteratively creating storylines. Proxona introduces a novel creator-audience interaction framework and fosters a persona-driven, co-creative process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {149},
numpages = {32},
keywords = {Large Language Models, Human-AI Interaction, Persona, Agent Simulation, Sensemaking, Ideation, Creative Iterations},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713259,
author = {Lin, Xinrui and Huang, Heyan and Huang, Kaihuang and Shu, Xin and Vines, John},
title = {Seeking Inspiration through Human-LLM Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713259},
doi = {10.1145/3706598.3713259},
abstract = {Large language model (LLM) systems have been shown to stimulate creative thinking among creators, yet empirical research on whether users can seek inspiration in their everyday lives through these technologies is lacking. This paper explores which attributes of LLMs influence inspiration-seeking processes. Focusing on use cases of travel, cooking, and self-care, we interviewed 20 participants as they explored scenarios of these use cases using LLMs. Thematic analysis revealed that the vast data of LLMs inspires users with unexpected ideas, many of which were highly personalized, and inspired participants towards being motivated to act. Participants were also sensitive to the deficiencies of LLMs, and noted how ethical issues associated with these technologies could negatively impact them applying inspirational ideas into practice. We discuss the behavioral patterns of users actively seeking inspiration via LLMs, and provide design opportunities for LLMs that make the inspiration-seeking process more human-centric.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {150},
numpages = {17},
keywords = {Large language models, Inspiration, Qualitative analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713250,
author = {Wong, Novia and Cheng, Nai-Yu and Oewel, Bruna and Genuario, Katherine E and Stoeckl, SarahElizabeth and Schueller, Stephen M. and Ahmed, Iftekhar and van der Hoek, Andr\'{e} and Reddy, Madhu},
title = { 'It's a spectrum': Exploring Autonomy, Competence, and Relatedness in Software Development Processes and Tools},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713250},
doi = {10.1145/3706598.3713250},
abstract = {The recent surge of research on software developer mental health challenges highlights the importance and urgency of studying solutions to support developer wellbeing. Self-Determination Theory (SDT) offers a valuable framework for exploring wellbeing at work, emphasizing the need to satisfy three psychological needs: autonomy, competence, and relatedness. This paper presents an interview study with 31 software developers in the United States that uses SDT as a guide, exploring how these three needs are perceived and influenced in the work of software developers. We identify specific factors and processes at work and work tools and designs that impact developers’ psychological needs and satisfaction. Results from our study can help design targeted solutions to satisfy developers’ psychological needs, which indirectly support developer wellbeing. This paper highlights the necessity of healthy work cultures in software development and presents design considerations for creating tools for developers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {151},
numpages = {19},
keywords = {Health-Wellbeing, Software Developers, Interviews, SDT},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713357,
author = {Pu, Kevin and Lazaro, Daniel and Arawjo, Ian and Xia, Haijun and Xiao, Ziang and Grossman, Tovi and Chen, Yan},
title = {Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713357},
doi = {10.1145/3706598.3713357},
abstract = {AI programming tools enable powerful code generation, and recent prototypes attempt to reduce user effort with proactive AI agents, but their impact on programming workflows remains unexplored. We introduce and evaluate Codellaborator, a design probe LLM agent that initiates programming assistance based on editor activities and task context. We explored three interface variants to assess trade-offs between increasingly salient AI support: prompt-only, proactive agent, and proactive agent with presence and context (Codellaborator). In a within-subject study (N = 18), we find that proactive agents increase efficiency compared to prompt-only paradigm, but also incur workflow disruptions. However, presence indicators and interaction context support alleviated disruptions and improved users’ awareness of AI processes. We underscore trade-offs of Codellaborator on user control, ownership, and code understanding, emphasizing the need to adapt proactivity to programming processes. Our research contributes to the design exploration and evaluation of proactive AI systems, presenting design implications on AI-integrated programming workflow.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {152},
numpages = {21},
keywords = {Proactive AI; Programming Assistance; Human-AI Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714154,
author = {Zamfirescu-Pereira, J.D. and Jun, Eunice and Terry, Michael and Yang, Qian and Hartmann, Bjoern},
title = {Beyond Code Generation: LLM-supported Exploration of the Program Design Space},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714154},
doi = {10.1145/3706598.3714154},
abstract = {In this work, we explore explicit Large Language Model (LLM)-powered support for the iterative design of computer programs. Program design, like other design activity, is characterized by navigating a space of alternative problem formulations and associated solutions in an iterative fashion. LLMs are potentially powerful tools in helping this exploration; however, by default, code-generation LLMs deliver code that represents a particular point solution. This obscures the larger space of possible alternatives, many of which might be preferable to the LLM’s default interpretation and its generated code. We contribute an IDE that supports program design through generating and showing new ways to frame problems alongside alternative solutions, tracking design decisions, and identifying implicit decisions made by either the programmer or the LLM. In a user study, we find that with our IDE, users combine and parallelize design phases to explore a broader design space—but also struggle to keep up with LLM-originated changes to code and other information overload. These findings suggest a core challenge for future IDEs that support program design through higher-level instructions given to LLM-based agents: carefully managing attention and deciding what information agents should surface to program designers and when.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {153},
numpages = {17},
keywords = {Program design, Code generation, Design space exploration, Generative AI, LLMs},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714141,
author = {Fang, Hanxi and Chockchowwat, Supawit and Sundaram, Hari and Park, Yongjoo},
title = {Enhancing Computational Notebooks with Code+Data Space Versioning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714141},
doi = {10.1145/3706598.3714141},
abstract = {There is a gap between how people explore data and how Jupyter-like computational notebooks are designed. People explore data nonlinearly, using execution undos, branching, and/or complete reverts, whereas notebooks are designed for sequential exploration. Recent works like ForkIt are still insufficient to support these multiple modes of nonlinear exploration in a unified way.In this work, we address the challenge by introducing two-dimensional code+data space versioning for computational notebooks and verifying its effectiveness using our prototype system, Kishuboard, which integrates with Jupyter. By adjusting code and data knobs, users of Kishuboard can intuitively manage the state of computational notebooks in a flexible way, thereby achieving both execution rollbacks and checkouts across complex multi-branch exploration history. Moreover, this two-dimensional versioning mechanism can easily be presented along with a friendly one-dimensional history. Human subject studies indicate that Kishuboard significantly enhances user productivity in various data science tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {154},
numpages = {17},
keywords = {computational notebooks, version control systems, code+data version control, notebook kernel state checkpoints, interactive data science checkpoints, version control user interfaces},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713175,
author = {Youn, Jung-Hwan and Lee, Seung Heon and Shultz, Craig},
title = {HaptiCoil: Soft Programmable Buttons with Hydraulically Coupled Haptic Feedback and Sensing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713175},
doi = {10.1145/3706598.3713175},
abstract = {We present HaptiCoil, an embedded system and interaction method for prototyping low-cost, compact, and customizable wide bandwidth (1-500 Hz) soft haptic buttons. HaptiCoil devices are built using mass-produced, waterproof planar micro-speakers which are adapted to direct energy to the skin using a novel hydraulic coupling mechanism. They can sense force input, using a measurement of self-inductance, and provide output in a single package, yielding a flexible all-in-one button solution. Our devices offer a wider perceptual range of tactile stimuli than industry standard approaches, while maintaining comparable power threshold levels (typical threshold under 40 mW). We detail the construction and underlying principles of our approach, as well as an extensive physical quantification of both input and output. We share psychophysical data on device bandwidth, and show three illustrative examples of how HaptiCoil buttons can implemented in use cases such as spatial computing, digital inking, and remote control.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {155},
numpages = {16},
keywords = {Haptics, Buttons, Human-Computer Interaction, Speaker, Voice-coil},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713581,
author = {Epperson, Will and Bansal, Gagan and Dibia, Victor C and Fourney, Adam and Gerrits, Jack and Zhu, Erkang (Eric) and Amershi, Saleema},
title = {Interactive Debugging and Steering of Multi-Agent AI Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713581},
doi = {10.1145/3706598.3713581},
abstract = {Fully autonomous teams of LLM-powered AI agents are emerging that collaborate to perform complex tasks for users. What challenges do developers face when trying to build and debug these AI agent teams? In formative interviews with five AI agent developers, we identify core challenges: difficulty reviewing long agent conversations to localize errors, lack of support in current tools for interactive debugging, and the need for tool support to iterate on agent configuration. Based on these needs, we developed an interactive multi-agent debugging tool, AGDebugger, with a UI for browsing and sending messages, the ability to edit and reset prior agent messages, and an overview visualization for navigating complex message histories. In a two-part user study with 14 participants, we identify common user strategies for steering agents and highlight the importance of interactive message resets for debugging. Our studies deepen understanding of interfaces for debugging increasingly important agentic workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {156},
numpages = {15},
keywords = {AI agents, ai debugging, interactive debugging systems, language models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714155,
author = {Liu, Vivian and Kazi, Rubaiat Habib and Wei, Li-Yi and Fisher, Matthew and Langlois, Timothy and Walker, Seth and Chilton, Lydia},
title = {LogoMotion: Visually-Grounded Code Synthesis for Creating and Editing Animation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714155},
doi = {10.1145/3706598.3714155},
abstract = {Creating animation takes time, effort, and technical expertise. To help novices with animation, we present LogoMotion, an AI code generation approach that helps users create semantically meaningful animation for logos. LogoMotion automatically generates animation code with a method called visually-grounded code synthesis and program repair. This method performs visual analysis, instantiates a design concept, and conducts visual checking to generate animation code. LogoMotion provides novices with code-connected AI editing widgets that help them edit the motion, grouping, and timing of their animation. In a comparison study on 276 animations, LogoMotion was found to produce more content-aware animation than an industry-leading tool. In a user evaluation (n=16) comparing against a prompt-only baseline, these code-connected widgets helped users edit animations with control, iteration, and creative expression.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {157},
numpages = {16},
keywords = {animation, large language models, motion design, program synthesis, code generation, GPT, logos},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713829,
author = {Zeng, Yuhan and Shi, Yingxuan and Huang, Xuehan and Nah, Fiona and LC, RAY},
title = {"Ronaldo's a poser!": How the Use of Generative AI Shapes Debates in Online Forums},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713829},
doi = {10.1145/3706598.3713829},
abstract = {Online debates can enhance critical thinking but may escalate into hostile attacks. As humans are increasingly reliant on Generative AI (GenAI) in writing tasks, we need to understand how people utilize GenAI in online debates. To examine the patterns of writing behavior while making arguments with GenAI, we created an online forum for soccer fans to engage in turn-based and free debates in a post format with the assistance of ChatGPT, arguing on the topic of "Messi vs Ronaldo". After 13 sessions of two-part study and semi-structured interviews with 39 participants, we conducted content and thematic analyses to integrate insights from interview transcripts, ChatGPT records, and forum posts. We found that participants prompted ChatGPT for aggressive responses, created posts with similar content and logical fallacies, and sacrificed the use of ChatGPT for better human-human communication. This work uncovers how polarized forum members work with GenAI to engage in debates online.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {158},
numpages = {22},
keywords = {Co-Writing, AI-Mediated Communication, Human-AI Collaboration, Online Debate, Remote Collaboration, Generative AI, Large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713568,
author = {Seo, Jiyeon Amy and Cho, Hyungjun and Lee, Seolhee and Cheon, EunJeong},
title = {Back to the 1990s, BeeperRedux!: Revisiting Retro Technology to Reflect Communication Quality and Experience in the Digital Age},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713568},
doi = {10.1145/3706598.3713568},
abstract = {As computer-mediated communication tools have evolved from beepers to 2G cell phones, and now to today’s smartphones, people have consistently embraced these technologies to maintain relationships and enhance the convenience of their daily lives. While contemporary communication technologies have transformed communication practices, their impact on communication quality and relationships remains underexamined. To explore what may have been lost in this transformation, our study revisits retro communication technologies—specifically, the beeper. Using BeeperRedux, a mobile application designed to replicate the beeper experience, we conducted a two-week deployment study with ten groups. Our findings highlight three valuable aspects of retro communication technologies: fostering sincerity, restoring recipients’ autonomy over their communication, and prioritizing offline engagement. In the discussion, we present design guidelines for improving technology-mediated communication and offer methodological reflections on recreating obsolete technology to empirically explore past experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {159},
numpages = {19},
keywords = {computer-mediated communication (CMC), retro technology, beeper, communication quality, research through design (RtD)},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714017,
author = {Cheng, Yi Fei and Shirado, Hirokazu and Kasahara, Shunichi},
title = {Conversational Agents on Your Behalf: Opportunities and Challenges of Shared Autonomy in Voice Communication for Multitasking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714017},
doi = {10.1145/3706598.3714017},
abstract = {Advancements in computational agents will enable them to act as surrogates for users in online communication, promising enhanced productivity by supporting multitasking. This capability may be especially powerful when combined with human control, allowing users to retain agency while achieving better performance than either human or agent alone. However, it remains unclear how people might leverage this technology to multitask effectively. We present a study with 18 dyads exploring how users employ automated responses to support an arithmetic task while staying engaged in a voice call. Participants multitasked with a conversational agent under three levels of autonomy: none, shared, and full. Our findings indicate that fully automated systems can maintain conversational engagement, enabling users to multitask effectively. Surprisingly, shared autonomy hindered this ability. Based on our results, we discuss implications for designing shared autonomy in conversations, highlighting new considerations and challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {160},
numpages = {18},
keywords = {computer-mediated communication, agents},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713674,
author = {Kim, Hyunchul and Lee, Jeongmi},
title = {Quantifying Social Connection With Verbal and Non-Verbal Behaviors in Virtual Reality Conversations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713674},
doi = {10.1145/3706598.3713674},
abstract = {As virtual reality (VR) continues to evolve as a platform for gathering and collaboration, new forms of communication using voice and avatars are being actively studied. However, the objective and dynamic assessment of social experiences in VR remains a significant challenge, while obtrusive self-report methods prevail. This study aims to identify verbal and nonverbal behavioral indices of perceived social experience in the context of virtual conversations. In our experiment, 52 participants engaged in a ten-minute dyadic conversation in VR and rated the level of social experiences, while turn-taking patterns and behavioral (gaze, pose) data were recorded. The results indicated that rapid response time, longer speech duration, longer gaze duration during turn-taking gaps, and higher nodding frequency during turns predicted the dynamic changes in users’ social experience. By providing objective and unobtrusive measures of social interactions, this study contributes to enhancing the understanding and improvement of social VR experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {161},
numpages = {15},
keywords = {social virtual reality, conversation analysis, turn-taking, non-verbal behaviors},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713749,
author = {Wang, Ruotong and Zhou, Xinyi and Qiu, Lin and Chang, Joseph Chee and Bragg, Jonathan and Zhang, Amy X.},
title = {Social-RAG: Retrieving from Group Interactions to Socially Ground AI Generation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713749},
doi = {10.1145/3706598.3713749},
abstract = {AI agents are increasingly tasked with making proactive suggestions in online spaces where groups collaborate, yet risk being unhelpful or even annoying if they fail to match group preferences or behave in socially inappropriate ways. Fortunately, group spaces have a rich history of prior interactions and affordances for social feedback that can support grounding an agent’s generations to a group’s interests and norms. We present Social-RAG, a workflow for socially grounding agents that retrieves context from prior group interactions, selects relevant social signals, and feeds them into a language model to generate messages in a socially aligned manner. We implement this in PaperPing, a system for posting paper recommendations in group chat, leveraging social signals determined from formative studies with 39 researchers. From a three-month deployment in 18 channels reaching 500+ researchers, we observed PaperPing posted relevant messages in groups without disrupting their existing social practices, fostering group common ground.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {162},
numpages = {25},
keywords = {AI agent, group communication, retrieval augmented generation, recommender systems, large language models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714228,
author = {Liu, Chao and Su, Mingyang and Xiang, Yan and Huang, Yuru and Yang, Yiqian and Zhang, Kang and Fan, Mingming},
title = {Toward Enabling Natural Conversation with Older Adults via the Design of LLM-Powered Voice Agents that Support Interruptions and Backchannels},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714228},
doi = {10.1145/3706598.3714228},
abstract = {Voice agents can construct meaningful conversations with older adults to offer various benefits, such as providing emotional companionship and assisting with memory recall. However, such conversations often follow the simple turn-taking pattern and lack interruption and backchannel of natural human conversation. Previous research has shown that this rigid turn-taking pattern lacks interactivity and initiative, limiting the flexible communication between older adults and voice agents. To address these issues and create a more natural conversational voice agent, we first conducted a formative study to identify common usage of interruption in the natural conversations of older adults. We then designed an LLM-powered Barge-in agent that supports interruption and backchannel. Our within-subject exploratory study showed that participants felt that conversations with Barge-in agents were more natural, engaging, and fluent than with the No barge-in agent. We further present design implications for creating more natural and human-like voice agents for older adults.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {163},
numpages = {22},
keywords = {Voice agent for older adults, Elderly care technology, Interruption, Backchannel, VUI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713943,
author = {Yardim, Asli and Horstmann, Stefan Albert and Serafini, Raphael and Speckels, Joshua Gabriel and Naiakshina, Alena},
title = {Women Security Experts Are Not The Enemy: A Qualitative Study on Gender-Related Communication Challenges},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713943},
doi = {10.1145/3706598.3713943},
abstract = {Effective communication is crucial for meeting security needs, yet gender-related communication challenges faced by women security experts within software development remain underexplored. In an interview study with 25 women security experts, we investigated gender-related communication challenges hindering the adoption of security requirements, and strategies to overcome these. Key challenges included the undervaluation of women’s security expertise, communication barriers, resistance to women’s security-related suggestions, and instances of hostility. Communication challenges with stakeholders who were men disrupted team collaboration, resulting in delays, weakened security measures, and increased organizational risk. Consequently, women security experts often had to adopt strategies, such as leveraging allied men and overpreparing, to assert their security competence. We further offer insights into women’s participation in security studies. Based on our findings, we provide recommendations on how to address gender-related challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {164},
numpages = {27},
keywords = {security, women, diversity, inclusion, gender challenges},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714192,
author = {Nguyen, Tonya and Kaviani, Darya and Salehi, Niloufar},
title = {"It Actually Doesn't Feel Very Mutual:" How Technology Impacts the Values of Mutual Aid Groups in Practice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714192},
doi = {10.1145/3706598.3714192},
abstract = {Social movement organizations, such as mutual aid groups, rely on technology to increase their influence, meet immediate needs, and address systemic inequalities. In this paper, we examine the role of technology in moments of crisis and the tensions mutual aid groups face when relying on tools designed with values that may be antithetical to their own. Through a qualitative study with mutual aid volunteers in the United States, we found that mutual aid groups’ values, such as solidarity, security, and co-production, are prioritized as they navigate adopting technology. However, while technology can streamline logistics and enhance visibility for mutual aid groups, we argue that the adoption of existing technologies and conventions of practice can erode opportunities for building solidarity, present challenges for accountability, and exacerbate pre-existing social exclusions. We argue that these tensions emerge not simply as a mismatch between values and technical design, but as systematic outcomes of adopting tools that embed different political assumptions and points of access. Our findings contribute to understanding how values shape — and are shaped by — technological infrastructure in mutual aid work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {165},
numpages = {18},
keywords = {Critical and sustainable computing, value-sensitive design, Social computing, scalability, social movements, mutual aid},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713383,
author = {Bae, Gahyeon and Park, Seo Kyoung and Kim, Taewan and Hong, Hwajung},
title = {Exploring Design Spaces to Facilitate Household Collaboration for Cohabiting Couples},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713383},
doi = {10.1145/3706598.3713383},
abstract = {Household collaboration among cohabiting couples presents unique challenges due to the intimate nature of the relationships and the lack of external rewards. Current efficiency-oriented technologies neglect these distinct dynamics. Our study aims to examine the real-world context and underlying needs of couples in their collaborative homemaking. We conducted a 10-day empirical investigation involving six Korean couples, supplemented by a probe approach to facilitate reflection on their current homemaking practices. We identified the requirement for ideal household collaboration as a ’shared ritual for celebratory interaction’ and pinpointed the challenges in achieving this goal. We propose three design opportunities for domestic technology to address this gap: strengthening the meaning of housework around family values, supporting recognition of the partner’s efforts through visualization, and initiating negotiation through defamiliarization. These insights extend the design considerations for domestic technologies, advocating for a broader understanding of the values contributing to satisfactory homemaking activities within the household.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {166},
numpages = {16},
keywords = {Collaboration, Home, Diary Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713640,
author = {Li, Junze and Zhang, Yue and Zheng, Chengbo and Liu, Dingdong and Huang, Zeyu and Ma, Xiaojuan},
title = {InsightBridge: Enhancing Empathizing with Users through Real-Time Information Synthesis and Visual Communication},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713640},
doi = {10.1145/3706598.3713640},
abstract = {User-centered design necessitates researchers deeply understanding target users throughout the design process. However, during early-stage user interviews, researchers may misinterpret users due to time constraints, incorrect assumptions, and communication barriers. To address this challenge, we introduce InsightBridge , a tool that supports real-time, AI-assisted information synthesis and visual-based verification. InsightBridge automatically organizes relevant information from ongoing interview conversations into an empathy map. It further allows researchers to specify elements to generate visual abstracts depicting the selected information, and then review these visuals with users to refine the visuals as needed. We evaluated the effectiveness of InsightBridge through a within-subject study (N=32) from both the researchers’ and users’ perspectives. Our findings indicate that InsightBridge can assist researchers in note-taking and organization, as well as in-time visual checking, thereby enhancing mutual understanding with users. Additionally, users’ discussions of visuals prompt them to recall overlooked details and scenarios, leading to more insightful ideas.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {167},
numpages = {15},
keywords = {User-centered Design, Human-AI Collaboration, Empathy Map, Visual Communication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713562,
author = {Rinott, Michal and Rafaeli, Sheizaf and Tractinsky, Noam},
title = {Interpersonal Synchrony Over a Distance - the Effect of Network Noise on Synchronization and its Prosocial Consequences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713562},
doi = {10.1145/3706598.3713562},
abstract = {Interpersonal motor synchronization (IMS) occurs when people move together, in temporal alignment. Being in IMS can result in prosocial effects: increased liking, similarity and trust. We address the possibility of remote IMS (rIMS) between people who are not co-located, through mobile phone interactions. A threat to rIMS is the temporal noise inherent to communication networks. We created a mobile phone application in which a human participant tries to tap in synchrony with a remote participant, that is in fact a responsive computer algorithm. We introduced three levels of synthetic network noise to the joint tapping. We show that pro-sociality can be created in rIMS, but that as network noise increases the prosocial effects decrease. Participants’ textual answers are analyzed thematically to learn about the effects of remote synchronization. Our findings motivate the creation of remote interactions with elements of IMS as well as inform the network requirements for successful rIMS.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {168},
numpages = {14},
keywords = {Remote Interpersonal Motor Synchronization, rIMS, Network Jitter, Pro-Sociality, Tapping, Mixed Methods, Nonverbal Synchrony},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713091,
author = {Lee, Sunok and Choi, Dasom and Truong, Lucy and Sawhney, Nitin and Paakki, Henna},
title = {Into the Unknown: Leveraging Conversational AI in Supporting Young Migrants' Journeys Towards Cultural Adaptation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713091},
doi = {10.1145/3706598.3713091},
abstract = {Accelerated globalization has made migration commonplace, creating significant cultural adaptation challenges, particularly for young migrants. While HCI research has explored the role of technology in migrants’ cultural adaptation, there is a need to address the diverse cultural backgrounds and needs of young migrants specifically. Recognizing the potential of conversational AI to adapt to diverse cultural contexts, we investigate how young migrants could use this technology in their adaptation journey and explore its societal implementation. Through individual workshops with young migrants and stakeholder interviews—including AI practitioners, public sector workers, policy experts, and social scientist—we found that both groups of participants expect conversational AI to support young migrants in connecting with the host culture before migration, exploring the home culture, and aligning identities across home and host cultures. However, challenges such as expectation gaps and cultural bias may hinder cultural adaptation. We discuss design considerations for culturally sensitive AI that empower young migrants and propose strategies to enhance societal readiness for AI-driven cultural adaptation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {169},
numpages = {19},
keywords = {conversational agent; large language model; migrants; cultural adaptation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713757,
author = {Claggett, Elijah L. and Kraut, Robert E. and Shirado, Hirokazu},
title = {Relational AI: Facilitating Intergroup Cooperation with Socially Aware Conversational Support},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713757},
doi = {10.1145/3706598.3713757},
abstract = {Cooperation is challenging when group identities are involved. While people readily cooperate with in-group members, they struggle to build trust with out-group members. This study examines how text suggestions generated by Large Language Models (LLMs) can mitigate in-group-out-group bias and facilitate intergroup cooperation through conversations. We conducted an experiment with 482 participants who communicated with either in-group partners sharing their views or out-group partners with differing views, based on a preliminary survey. Participants received either “personalized” message suggestions aligned with their own views and conversation styles or “relational” suggestions using conversation styles tailored to whether their partner was in-group or out-group. Following the conversations, participants engaged in a cooperation game designed to measure trust behaviorally. Our results show that while personalized assistance widened the cooperation gap, relational assistance significantly improved out-group cooperation to match in-group levels. We discuss design implications for integrating social awareness into AI-driven conversational support systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {170},
numpages = {22},
keywords = {computer-mediated communication, interpersonal communication, cooperation, social identity theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713219,
author = {Yang, Chi-Lan and Uhde, Alarith and Yamashita, Naomi and Kuzuoka, Hideaki},
title = {Understanding and Supporting Peer Review Using AI-reframed Positive Summary},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713219},
doi = {10.1145/3706598.3713219},
abstract = {While peer review enhances writing and research quality, harsh feedback can frustrate and demotivate authors. Hence, it is essential to explore how critiques should be delivered to motivate authors and enable them to keep iterating their work. In this study, we explored the impact of appending an automatically generated positive summary to the peer reviews of a writing task, alongside varying levels of overall evaluations (high vs. low), on authors’ feedback reception, revision outcomes, and motivation to revise. Through a 2x2 online experiment with 137 participants, we found that adding an AI-reframed positive summary to otherwise harsh feedback increased authors’ critique acceptance, whereas low overall evaluations of their work led to increased revision efforts. We discuss the implications of using AI in peer feedback, focusing on how AI-driven critiques can influence critique acceptance and support research communities in fostering productive and friendly peer feedback practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {171},
numpages = {16},
keywords = {Peer feedback, critique acceptance, cognitive reframing, AI-mediated communication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713114,
author = {Sharevski, Filipo and Alonzo, Oliver and Hau, Sarah},
title = {"I have never seen that for Deaf people's content:" Deaf and Hard-of-Hearing User Experiences with Misinformation, Moderation, and Debunking on Social Media in the US},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713114},
doi = {10.1145/3706598.3713114},
abstract = {Misinformation has been studied with various social media user groups, though not with Deaf and Hard-of-hearing (DHH) individuals. To address this gap, we conducted an interview with 15 DHH participants to explore their lived experiences with misinformation and their perspectives on common moderation and debunking approaches on social media. We found that participants often experience falsehoods, and highlighted examples specific to the DHH community such as misinformation related to American Sign Language (ASL) and Deaf culture. However, moderation interventions and debunking strategies for misinformation specific to DHH topics were lacking. Written warnings may be beneficial as long as they use language appropriate for DHH people with diverse literacy skills. Participants found visual interventions (e.g., videos) more beneficial as long as they can be appropriately captioned – which is not always the case in practice. Our findings provide practical moderation insights for DHH social media users.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {172},
numpages = {17},
keywords = {misinformation, deaf and hard of hearing, accessibility, social media, moderation, debunking, user study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713997,
author = {Heung, Sharon and Jiang, Lucy and Azenkot, Shiri and Vashistha, Aditya},
title = {"Ignorance is not Bliss": Designing Personalized Moderation to Address Ableist Hate on Social Media},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713997},
doi = {10.1145/3706598.3713997},
abstract = {Disabled people on social media often experience ableist hate and microaggressions. Prior work has shown that platform moderation often fails to remove ableist hate, leaving disabled users exposed to harmful content. This paper examines how personalized moderation can safeguard users from viewing ableist comments. During interviews and focus groups with 23 disabled social media users, we presented design probes to elicit perceptions on configuring their filters of ableist speech (e.g., intensity of ableism and types of ableism) and customizing the presentation of the ableist speech to mitigate the harm (e.g., AI rephrasing the comment and content warnings). We found that participants preferred configuring their filters through types of ableist speech and favored content warnings. We surface participants’ distrust in AI-based moderation, skepticism in AI’s accuracy, and varied tolerances in viewing ableist hate. Finally, we share design recommendations to support users’ agency, mitigate harm from hate, and promote safety.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {173},
numpages = {18},
keywords = {personal content moderation, word filters, platform governance, ableism, hate and harassment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713226,
author = {Wei, Miranda and Yeung, Christina and Roesner, Franziska and Kohno, Tadayoshi},
title = {"We're utterly ill-prepared to deal with something like this": Teachers' Perspectives on Student Generation of Synthetic Nonconsensual Explicit Imagery},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713226},
doi = {10.1145/3706598.3713226},
abstract = {Synthetic nonconsensual explicit imagery, also referred to as “deepfake nudes”, is becoming faster and easier to generate. In the last year, synthetic nonconsensual explicit imagery was reported in at least ten US middle and high schools, generated by students of other students. Teachers are at the front lines of this new form of image abuse and have a valuable perspective on threat models in this context. We interviewed 17 US teachers to understand their opinions and concerns about synthetic nonconsensual explicit imagery in schools. No teachers knew of it happening at their schools, but most expected it to be a growing issue. Teachers proposed many interventions, such as improving reporting mechanisms, focusing on consent in sex education, and updating technology policies. However, teachers disagreed about appropriate consequences for students who create such images. We unpack our findings relative to differing models of justice, sexual violence, and sociopolitical challenges within schools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {174},
numpages = {18},
keywords = {Synthetic nonconsensual explicit imagery, deepfakes, students, teachers, abuse},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713998,
author = {Hartmann, David and Oueslati, Amin and Staufer, Dimitri and Pohlmann, Lena and Munzert, Simon and Heuer, Hendrik},
title = {Lost in Moderation: How Commercial Content Moderation APIs Over- and Under-Moderate Group-Targeted Hate Speech and Linguistic Variations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713998},
doi = {10.1145/3706598.3713998},
abstract = {Commercial content moderation APIs are marketed as scalable solutions to combat online hate speech. However, the reliance on these APIs risks both silencing legitimate speech, called over-moderation, and failing to protect online platforms from harmful speech, known as under-moderation. To assess such risks, this paper introduces a framework for auditing black-box NLP systems. Using the framework, we systematically evaluate five widely used commercial content moderation APIs. Analyzing five million queries based on four datasets, we find that APIs frequently rely on group identity terms, such as “black”, to predict hate speech. While OpenAI’s and Amazon’s services perform slightly better, all providers under-moderate implicit hate speech, which uses codified messages, especially against LGBTQIA+ individuals. Simultaneously, they over-moderate counter-speech, reclaimed slurs and content related to Black, LGBTQIA+, Jewish, and Muslim people. We recommend that API providers offer better guidance on API implementation and threshold setting and more transparency on their APIs’ limitations.Warning: This paper contains offensive and hateful terms and concepts. We have chosen to reproduce these terms for reasons of transparency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {175},
numpages = {26},
keywords = {Content Moderation APIs, Audit, AI Transparency and Accountability, Human-AI Interaction in Content Moderation, Algorithmic Bias in Hate Speech Detection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713662,
author = {Moran, Rachel Elizabeth and Schafer, Joseph and Bayar, Mert and Starbird, Kate},
title = {The End of Trust and Safety?: Examining the Future of Content Moderation and Upheavals in Professional Online Safety Efforts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713662},
doi = {10.1145/3706598.3713662},
abstract = {Trust \&amp; Safety (T&amp;S) teams have become vital parts of tech platforms; ensuring safe platform use and combating abuse, harassment, and misinformation. However, between 2021 and 2023, T&amp;S teams faced significant layoffs, impacted by broader downsizing in the tech industry. In addition, a reduction in T&amp;S teams has also been attributed to partisan pressure against content moderation efforts designed to mitigate the spread of election and COVID-19-related misinformation. Accordingly, there exist crucial questions over the future of content moderation and T&amp;S in the digital information environment, questions central to the work of CHI researchers interested in intervening in online harm through design, policy and user research. Through in-depth interviews with T&amp;S professionals, this paper explores upheavals within the T&amp;S industry, examining current perspectives of content moderation and broader strategies for maintaining safe digital environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {176},
numpages = {14},
keywords = {Computer Mediated Communication, Social Media/Online Communities, Empirical study that tells us about people, Interview},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714013,
author = {Shen, Caoyang and Haimson, Oliver L.},
title = {The Virtual Jail: Content Moderation Challenges Faced by Chinese Queer Content Creators on Douyin},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714013},
doi = {10.1145/3706598.3714013},
abstract = {Queer users of Douyin, the Chinese version of TikTok, suspect that the platform removes and suppresses queer content, thus reducing queer visibility. In this study, we examined how Chinese queer users recognize and react to Douyin’s moderation of queer content by conducting interviews with 21 queer China-based Douyin content creators and viewers. Findings indicate that queer users actively explore and adapt to the platform’s underlying moderation logic. They employ creative content and posting strategies to reduce the likelihood of their expressions of queer topics and identities being removed or suppressed. Like Western platforms, Douyin’s moderation approaches are often ambiguous; but unlike Western platforms, queer users sometimes receive clarity on moderation reasons via direct communication with moderators. Participants suggested that Douyin’s repressive moderation practices are influenced by more than just platform policies and procedures – they also reflect state-led homophobia and societal discipline. This study underscores the challenges Chinese queer communities face in maintaining online visibility and suggests that meaningful change in their experiences is unlikely without broader societal shifts towards queer acceptance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {177},
numpages = {14},
keywords = {Content moderation, social media, Chinese queer people, Douyin, user-generated content, state-led homophobia, heteronormativity, folk theories, LGBTQ+},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713150,
author = {Magdy, Walid and Mubarak, Hamdy and Salminen, Joni},
title = {Who should set the Standards? Analysing Censored Arabic Content on Facebook during the Palestine-Israel Conflict},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713150},
doi = {10.1145/3706598.3713150},
abstract = {Nascent research on human-computer interaction concerns itself with fairness of content moderation systems. Designing globally applicable content moderation systems requires considering historical, cultural, and socio-technical factors. Inspired by this line of work, we investigate Arab users’ perception of Facebook’s moderation practices. We collect a set of 448 deleted Arabic posts, and we ask Arab annotators to evaluate these posts based on (a) Facebook Community Standards (FBCS) and (b) their personal opinion. Each post was judged by 10 annotators to account for subjectivity. Our analysis shows a clear gap between the Arabs’ understanding of the FBCS and how Facebook implements these standards. The study highlights a need for discussion on the moderation guidelines on social media platforms about who decides the moderation guidelines, how these guidelines are interpreted, and how well they represent the views of marginalised user communities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {178},
numpages = {16},
keywords = {Censorship, Content Moderation, Free Speech, Facebook, Social Media, Palestine Israel Conflict},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713890,
author = {Zindulka, Tim and Goller, Sven and Lehmann, Florian and Buschek, Daniel},
title = {Content-Driven Local Response: Supporting Sentence-Level and Message-Level Mobile Email Replies With and Without AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713890},
doi = {10.1145/3706598.3713890},
abstract = {Mobile emailing demands efficiency in diverse situations, which motivates the use of AI. However, generated text does not always reflect how people want to respond. This challenges users with AI involvement tradeoffs not yet considered in email UIs. We address this with a new UI concept called Content-Driven Local Response (CDLR), inspired by microtasking. This allows users to insert responses into the email by selecting sentences, which additionally serves to guide AI suggestions. The concept supports combining AI for local suggestions and message-level improvements. Our user study (N=126) compared CDLR with manual typing and full reply generation. We found that CDLR supports flexible workflows with varying degrees of AI involvement, while retaining the benefits of reduced typing and errors. This work contributes a new approach to integrating AI capabilities: By redesigning the UI for workflows with and without AI, we can empower users to dynamically adjust AI involvement.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {179},
numpages = {23},
keywords = {Writing assistance, Large language models, Human-AI interaction, Email, Mobile text entry},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714222,
author = {Jeong, Daeun and Shin, Sungbok and Jeong, Jongwook},
title = {Conversation Progress Guide : UI System for Enhancing Self-Efficacy in Conversational AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714222},
doi = {10.1145/3706598.3714222},
abstract = {In this study, we introduce the Conversation Progress Guide (CPG), a system designed for text-based conversational AI interactions that provides a visual interface to represent progress. Users often encounter failures when interacting with conversational AI, which can negatively affect their self-efficacy—an individual’s belief in their capabilities, reducing their willingness to engage with these services. The CPG offers visual feedback on task progress, providing users with mastery experiences, a key source of self-efficacy. To evaluate the system’s effectiveness, we conducted a user study assessing how the integration of the CPG influences user engagement and self-efficacy. Results demonstrate that users interacting with a conversational AI enhanced by the CPG showed significant improvements in self-efficacy measures compared to those using a conventional conversational AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {180},
numpages = {11},
keywords = {Self-efficacy, Progress Bar, Conversational AI, Conservation Interface, Human-AI Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713578,
author = {Huang, Yuanhui and Zhou, Quan and Piper, Anne Marie},
title = {Designing Conversational AI for Aging: A Systematic Review of Older Adults' Perceptions and Needs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713578},
doi = {10.1145/3706598.3713578},
abstract = {Recent advances in conversational AI and the ubiquity of related devices and applications—from robots to smart speakers to chatbots—has led to extensive research on designing and studying conversational systems with older adults. Despite a growing literature on this topic, many studies examine small groups of older adults and specific devices, neglecting a holistic understanding of how diverse groups of older adults perceive conversational interaction more broadly. We present a systematic review that synthesizes older adults’ perceptions of the challenges and opportunities for interacting with these systems. We highlight their vision for future AI-based conversational systems, emphasizing a desire for more human-like interactions, personalization, and greater control over their information. We discuss the implications for future research and design of conversational AI systems for older adults.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {181},
numpages = {20},
keywords = {Older adults, systematic review, conversational AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713503,
author = {Pan, Shuyi and de Graaf, Maartje M.A.},
title = {Developing a Social Support Framework: Understanding the Reciprocity in Human-Chatbot Relationship},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713503},
doi = {10.1145/3706598.3713503},
abstract = {Chatbots are increasingly used to provide social support for individuals with mental health challenges. However, a systematic analysis of the types and directionality of support within chatbot use remains lacking. This study establishes a framework for understanding reciprocal social support exchanges in human-chatbot relationships, focusing on the popular chatbot, Replika. By analyzing 496 posts and 20,494 comments from the largest Replika community on Reddit, we identified 27 support subcategories, organized into five main types (functional, informational, emotional, esteem, and network) and two directions (chatbot-receiving and chatbot-giving). Our findings reveal significant yet controversial issues, such as subscription services and chatbot-displayed affection. Notably, “user teaching chatbot” emerged as a core aspect of the human-chatbot relationship, covering how users actively guide and refine the chatbot’s learning or algorithm. This study constructs a novel social support framework for chatbot use, highlighting the potential for reciprocal support exchanges between users and chatbots.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {182},
numpages = {13},
keywords = {Social support, Chatbot, Human-chatbot relationship, Replika, Artifcial Intelligence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713142,
author = {Kollerup, Naja Kathrine and Bahodi, Maria-Theresa and Cox, Samuel Rhys and van Berkel, Niels},
title = {Enhancing Self-Efficacy in Health Self-Examination through Conversational Agent's Encouragement},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713142},
doi = {10.1145/3706598.3713142},
abstract = {Health self-examination, such as checking for changes to skin moles, is key to identifying potential negative changes to one’s body. A major barrier to initiating a self-examination is a perceived lack of confidence or knowledge. In this study, we use a 2&nbsp; \texttimes{} &nbsp;2 between-subjects design to evaluate the effect of an AI conversational agent (CA) on participant self-efficacy and trust. We manipulated both participants’ perceived skill in self-examination (based on prior perceived Success vs. Failure) and the CA’s verbal persuasions (Encouraging vs. Neutral), with participants asked to complete a series of skin self-assessment tasks. Our findings show that participants’ self-efficacy increased when exposed to encouraging CA persuasion. Additionally, we observed that an encouraging CA significantly increased participants’ trust scores in perceived benevolence compared to a neutral-sounding CA. Our results inform the design of CAs to support users’ independent self-examination.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {183},
numpages = {18},
keywords = {Artificial Intelligence, Self-Efficacy, Learning, Conversational Agents},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713760,
author = {Liu, Xingyu Bruce and Fang, Shitao and Shi, Weiyan and Wu, Chien-Sheng and Igarashi, Takeo and Chen, Xiang 'Anthony'},
title = {Proactive Conversational Agents with Inner Thoughts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713760},
doi = {10.1145/3706598.3713760},
abstract = {One of the long-standing aspirations in conversational AI is to allow them to autonomously take initiatives in conversations, i.e., being proactive. This is especially challenging for multi-party conversations. Prior NLP research focused mainly on predicting the next speaker from contexts like preceding conversations. In this paper, we demonstrate the limitations of such methods and rethink what it means for AI to be proactive in multi-party, human-AI conversations. We propose that just like humans, rather than merely reacting to turn-taking cues, a proactive AI formulates its own inner thoughts during a conversation, and seeks the right moment to contribute. Through a formative study with 24 participants and inspiration from linguistics and cognitive psychology, we introduce the Inner Thoughts framework. Our framework equips AI with a continuous, covert train of thoughts in parallel to the overt communication process, which enables it to proactively engage by modeling its intrinsic motivation to express these thoughts. We instantiated this framework into two real-time systems: an AI playground web app and a chatbot. Through a technical evaluation and user studies with human participants, our framework significantly surpasses existing baselines on aspects like anthropomorphism, coherence, intelligence, and turn-taking appropriateness.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {184},
numpages = {19},
keywords = {Conversational Agent, Multi-Agent, Multi-Party Conversation, Inner Thoughts, Mixed-initiative Interaction, Proactive AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714016,
author = {Miura, Yusuke and Yang, Chi-Lan and Kuribayashi, Masaki and Matsumoto, Keigo and Kuzuoka, Hideaki and Morishima, Shigeo},
title = {Understanding and Supporting Formal Email Exchange by Answering AI-Generated Questions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714016},
doi = {10.1145/3706598.3714016},
abstract = {Replying to formal emails is time-consuming and cognitively demanding, as it requires crafting polite phrasing and providing an adequate response to the sender’s demands. Although systems with Large Language Models (LLMs) were designed to simplify the email replying process, users still need to provide detailed prompts to obtain the expected output. Therefore, we propose and evaluate an LLM-powered question-and-answer (QA)-based approach for users to reply to emails by answering a set of simple and short questions generated from the incoming email. We developed a prototype system, ResQ, and conducted controlled and field experiments with 12 and 8 participants. Our results demonstrated that the QA-based approach improves the efficiency of replying to emails and reduces workload while maintaining email quality, compared to a conventional prompt-based approach that requires users to craft appropriate prompts to obtain email drafts. We discuss how the QA-based approach influences the email reply process and interpersonal relationship dynamics, as well as the opportunities and challenges associated with using a QA-based approach in AI-mediated communication.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {185},
numpages = {20},
keywords = {AI-Mediated Communication, Large Language Models, Email},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713696,
author = {Wang, Yixiong and Suen, Huajie and Duan, Shengfeng and Liang, Chen},
title = {4D Bioforming with Bees: An Industry-Compatible Prototyping Method for Polymorphic Honeycomb Creation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713696},
doi = {10.1145/3706598.3713696},
abstract = {4D bioforming is a captivating yet often overlooked natural aesthetic phenomenon, involving the polymorphic transformations that occur during the construction of honeycomb by bees, which presents a significant opportunity for the innovative transformation of traditional apiculture. This paper proposes an industry-compatible prototyping method for polymorphic honeycomb creation following the phenomenon of 4D bioforming, aiming to introduce innovation to honeycomb forms through 4D bioforming while preserving the central role of beekeepers. The method is designed to align with the practical habits of beekeepers and can be outlined in four key steps: scaffold creation, quadrilateral shape division, bee path compilation with outer mold, and 4D bioforming. The dynamic temporal changes in the honeycomb were successfully demonstrated, enhancing the artistic aspect of honeycomb creation. Evaluation results suggest that the method is compatible with traditional practices, easily adoptable by beekeepers and that the polymorphic honeycomb meets essential aesthetic standards.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {186},
numpages = {17},
keywords = {Co-creation with Organism, Bioforming, Apiculture},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713818,
author = {Kim, Yewon and Lee, Sung-Ju and Donahue, Chris},
title = {Amuse: Human-AI Collaborative Songwriting with Multimodal Inspirations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713818},
doi = {10.1145/3706598.3713818},
abstract = {Songwriting is often driven by multimodal inspirations, such as imagery, narratives, or existing music, yet songwriters remain unsupported by current music AI systems in incorporating these multimodal inputs into their creative processes. We introduce Amuse, a songwriting assistant that transforms multimodal&nbsp;(image, text, or audio) inputs into chord progressions that can be seamlessly incorporated into songwriters’ creative process. A key feature of Amuse is its novel method for generating coherent chords that are relevant to music keywords in the absence of datasets with paired examples of multimodal inputs and chords. Specifically, we propose a method that leverages multimodal LLMs to convert multimodal inputs into noisy chord suggestions and uses a unimodal chord model to filter the suggestions. A user study with songwriters shows that Amuse effectively supports transforming multimodal ideas into coherent musical suggestions, enhancing users’ agency and creativity throughout the songwriting process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {187},
numpages = {28},
keywords = {Creativity Support Tool, Music, Songwriting, Human-AI Interaction, Machine Learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713401,
author = {Cao, Yining and Huang, Yiyi and Truong, Anh and Shin, Hijung Valentina and Xia, Haijun},
title = {Compositional Structures as Substrates for Human-AI Co-creation Environment: A Design Approach and A Case Study},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713401},
doi = {10.1145/3706598.3713401},
abstract = {It has been increasingly recognized that effective human-AI co-creation requires more than prompts and results, but an environment with empowering structures that facilitate exploration, planning, iteration, as well as control and inspection of AI generation. Yet, a concrete design approach to such an environment has not been established. Our literature analysis highlights that compositional structures—which organize and visualize individual elements into meaningful wholes—are highly effective in granting creators control over the essential aspects of their content. However, efficiently aggregating and connecting these structures to support the full creation process remains challenging. We, therefore, propose a design approach of leveraging compositional structures as the substrates and infusing AI within and across these structures to enable a controlled and fluid creation process. We evaluate this approach through a case study of developing a video co-creation environment using this approach. User evaluation shows that such an environment allowed users to stay oriented in their creation activity, remain aware and in control of AI’s generation, and enable flexible human-AI collaborative workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {188},
numpages = {25},
keywords = {Design Approach, Compositional Structures, Human-AI Collaboration, Video Creation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714242,
author = {Leong, Joanne and Ledo, David and Driscoll, Thomas and Grossman, Tovi and Fitzmaurice, George and Anderson, Fraser},
title = {Paratrouper: Exploratory Creation of Character Cast Visuals Using Generative AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714242},
doi = {10.1145/3706598.3714242},
abstract = {Great characters are critical to the success of many forms of media, such as comics, games, and films. Designing visually compelling casts of characters requires significant skill and consideration, and there is a lack of specialized tools to support this endeavor. We investigate how AI-driven image-generation techniques can empower creatives to explore a variety of visual design possibilities for individual and groups of characters. Informed by interviews with character designers, Paratrouper is a multi-modal system that enables creating and experimenting with multiple permutations for character casts and visualizing them in various contexts as part of a holistic approach to design. We demonstrate how Paratrouper supports different aspects of the character design process, and share insights from its use by eight creators. Our work highlights the interplay between creative agency and serendipity, as well as the visual interrelationships among character aesthetics.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {189},
numpages = {20},
keywords = {generative artificial intelligence, image generation, character design, character concept art, AI-assisted creativity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713449,
author = {Shen, Leixian and Li, Haotian and Wang, Yun and Qu, Huamin},
title = {Reflecting on Design Paradigms of Animated Data Video Tools},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713449},
doi = {10.1145/3706598.3713449},
abstract = {Animated data videos have gained significant popularity in recent years. However, authoring data videos remains challenging due to the complexity of creating and coordinating diverse components (e.g., visualization, animation, audio, etc.). Although numerous tools have been developed to streamline the process, there is a lack of comprehensive understanding and reflection of their design paradigms to inform future development. To address this gap, we propose a framework for understanding data video creation tools along two dimensions: what data video components to create and coordinate, including visual, motion, narrative, and audio components, and how to support the creation and coordination. By applying the framework to analyze 46 existing tools, we summarized key design paradigms of creating and coordinating each component based on the varying work distribution for humans and AI in these tools. Finally, we share our detailed reflections, highlight gaps from a holistic view, and discuss future directions to address them.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {190},
numpages = {21},
keywords = {Storytelling, Data Video, Authoring Tool, Design Paradigm, Human-AI Collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714217,
author = {Wang, Shaocong and Qu, Che and Yu, Minjing and Zhou, Chao and Wang, Yuntao and Wen, Yu-Hui and Shi, Yuanchun and Liu, Yong-Jin},
title = {VAction: A Lightweight and Integrated VR Training System for Authentic Film-Shooting Experience},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714217},
doi = {10.1145/3706598.3714217},
abstract = {The film industry exerts significant economic and cultural influence, and its rapid development is contingent upon the expertise of industry professionals, underscoring the critical importance of film-shooting education. However, this process typically necessitates multiple practice in complex professional venues using expensive equipment, presenting a significant obstacle for ordinary learners who struggle to access such training environments. Despite VR technology has already shown its potential in education, existing research has not addressed the crucial learning component of replicating the shooting process. Moreover, the limited functionality of traditional controllers hinder the fulfillment of the educational requirements. Therefore, we developed VAction VR system, combining high-fidelity virtual environments with a custom-designed controller to simulate the real-world camera operation experience. The system’s lightweight design ensures cost-effective and efficient deployment. Experiment results demonstrated that VAction significantly outperforms traditional methods in both practice effectiveness and user experience, indicating its potential and usefulness in film-shooting education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {191},
numpages = {16},
keywords = {Film Production Education, Virtual Reality, Training System, Interaction Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713305,
author = {Nebeling, Michael and Wu, Liwei and Maddali, Hanuma Teja},
title = {XCam: Mixed-Initiative Virtual Cinematography for Live Production of Virtual Reality Experiences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713305},
doi = {10.1145/3706598.3713305},
abstract = {VR is often utilized for organizing virtual events such as meetings, conferences, and concerts; however, support for live production is lacking in most existing VR tools. We present XCam, a toolkit enabling mixed-initiative control over virtual camera systems—from fully manual control by users to increasingly automated, system-driven control with minimal user intervention. XCam’s architectural design separates the concerns of object tracking, camera motion, and scene transition, giving more degrees of freedom to operators who can adjust the level of automation along all three dimensions. We used XCam to conduct two studies: (1) interviews with six VR content creators probe into what aspects should and shouldn’t be automated based on six applications developed with XCam; (2) three workshops with experts explore XCam’s utility in live production of an interactive VR film sequence, a lecture on cinematography, and an alumni meeting in social VR. Expert feedback from our studies suggests how to balance automation and control, and the opportunities and limits of future AI-driven tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {192},
numpages = {16},
keywords = {virtual cinematography; virtual production; metaverse.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714257,
author = {Yuan, Lin-Ping and Han, Feilin and Xie, Liwenhan and Zhang, Junjie and Zhao, Jian and Qu, Huamin},
title = {"You'll Be Alice Adventuring in Wonderland!" Processes, Challenges, and Opportunities of Creating Animated Virtual Reality Stories},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714257},
doi = {10.1145/3706598.3714257},
abstract = {Animated virtual reality (VR) stories, combining the presence of VR and the artistry of computer animation, offer a compelling way to deliver messages and evoke emotions. Motivated by the growing demand for immersive narrative experiences, more creators are creating animated VR stories. However, a holistic understanding of their creation processes and challenges involved in crafting these stories is still limited. Based on semi-structured interviews with 21 animated VR story creators, we identify ten common stages in their end-to-end creation processes, ranging from idea generation to evaluation, which form diverse workflows that are story-driven or visual-driven. Additionally, we highlight nine unique issues that arise during the creation process, such as a lack of reference material for multi-element plots, the absence of specific functionalities for story integration, and inadequate support for audience evaluation. We compare the creation of animated VR stories to general XR applications and distill several future research opportunities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {193},
numpages = {21},
keywords = {Animated VR stories, VR animation, VR storytelling, VR narratives, cinematic VR, immersive storytelling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713233,
author = {Naqvi, Syeda Masooma and He, Ruichen and Kaur, Harmanpreet},
title = {Catalyst for Creativity or a Hollow Trend?: A Cross-Level Perspective on The Role of Generative AI in Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713233},
doi = {10.1145/3706598.3713233},
abstract = {Generative AI image creation tools have the potential to transform design education and practice, but raise critical concerns for creativity and ownership. We leverage the 2022 launch of tools like Midjourney and DALL.E as a point dividing design enthusiasts into pre- and post-tool learners. In this paper, we conduct 28 artifact-based interviews with designers at varying levels of tool introduction, to understand how they perceive and use generative AI in their design roles. Our results indicate a rift in the value system of designers, with experienced designers being more circumspect about the loss of traditional creativity and foundational design skills. On the practical side, there exists a tension between the growing marketability of AI-related skills for design vs. the limited affordances of these tools for achieving meaningful designs. We discuss implications for the shifting definitions of design as a field, creativity and ownership, and AI in the design curriculum.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {194},
numpages = {16},
keywords = {Generative AI, Design, Creativity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713886,
author = {Bangerl, Mia Magdalena and Disch, Leonie and David, Tamara and Pammer-Schindler, Viktoria},
title = {CreAItive Collaboration? Users' Misjudgment of AI-Creativity Affects Their Collaborative Performance},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713886},
doi = {10.1145/3706598.3713886},
abstract = {How does generative AI affect collaborative creative work and humans’ capability to carry it out? We tested 52 participant pairs in a standard creativity test, the Alternate Uses Test. The experimental AI group had access to ChatGPT-4, while the control group did not. The intervention did not lead to an improved performance overall. Further, the AI group elaborated their ideas significantly less. This effect carried over to the unaided post-test, pointing to longer-term effects of AI be(com)ing everyday technology, as how people perform a task with a tool shapes how they (learn to) perform the task without it. Analysis of the human-AI collaboration process revealed that participants were selective in using ChatGPT-4 output for the experimental task, misjudging and falsely assessing its output. This actually reduced their number of created ideas and underscores that users need to understand a (generative AI-based) tool’s capability for the specific task to support effective performance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {195},
numpages = {17},
keywords = {generative AI, collaboration, creativity, experiment, Alternate Uses Test, ChatGPT, learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713894,
author = {Krol, Stephen James and Llano Rodriguez, Maria Teresa and Loor Paredes, Miguel J},
title = {Exploring the Needs of Practising Musicians in Co-Creative AI Through Co-Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713894},
doi = {10.1145/3706598.3713894},
abstract = {Recent advances in generative AI music have resulted in new technologies that are being framed as co-creative tools for musicians with early work demonstrating their potential to add to music practice. While the field has seen many valuable contributions, work that involves practising musicians in the design and development of these tools is limited, with the majority of work including them only once a tool has been developed. In this paper, we present a case study that explores the needs of practising musicians through the co-design of a musical variation system, highlighting the importance of involving a diverse range of musicians throughout the design process and uncovering various design insights. This was achieved through two workshops and a two week ecological evaluation, where musicians from different musical backgrounds offered valuable insights not only on a musical system’s design but also on how a musical AI could be integrated into their musical practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {196},
numpages = {13},
keywords = {Co-Creative AI, Human-AI interaction, Co-creative music composition},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713799,
author = {Kyi, Lin and Mahuli, Amruta and Silberman, M. Six and Binns, Reuben and Zhao, Jun and Biega, Asia J.},
title = {Governance of Generative AI in Creative Work: Consent, Credit, Compensation, and Beyond},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713799},
doi = {10.1145/3706598.3713799},
abstract = {Since the emergence of generative AI, creative workers have spoken up about the career-based harms they have experienced arising from this new technology. A common theme in these accounts of harm is that generative AI models are trained on workers’ creative output without their consent and without giving credit or compensation to the original creators.This paper reports findings from 20 interviews with creative workers in three domains: visual art and design, writing, and programming. We investigate the gaps between current AI governance strategies, what creative workers want out of generative AI governance, and the nuanced role of creative workers’ consent, compensation and credit for training AI models on their work. Finally, we make recommendations for how generative AI can be governed and how operators of generative AI systems might more ethically train models on creative output in the future.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {197},
numpages = {16},
keywords = {3 Cs (Consent, Credit, and Compensation), AI governance, AI regulation, Generative AI, Creative work, Knowledge work},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713447,
author = {Falk, Jeanette and Chen, Yiyi and Rafner, Janet and Zhang, Mike and Bjerva, Johannes and Nolte, Alexander},
title = {How Do Hackathons Foster Creativity? Towards Automated Evaluation of Creativity at Scale},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713447},
doi = {10.1145/3706598.3713447},
abstract = {Hackathons have become popular collaborative events for accelerating the development of creative ideas and prototypes. There are several case studies showcasing creative outcomes across domains such as industry, education, and research. However, there are no large-scale studies on creativity in hackathons which can advance theory on how hackathon formats lead to creative outcomes. We conducted a computational analysis of 193,353 hackathon projects. By operationalizing creativity through usefulness and novelty, we refined our dataset to 10,363 projects, allowing us to analyze how participant characteristics, collaboration patterns, and hackathon setups influence the development of creative projects. The contribution of our paper is twofold: We identified means for organizers to foster creativity in hackathons. We also explore the use of large language models (LLMs) to augment the evaluation of creative outcomes and discuss challenges and opportunities of doing this, which has implications for creativity research at large.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {198},
numpages = {23},
keywords = {Hackathons, creativity, human-centered AI, large language models, quantitative methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713952,
author = {Zha, Siyu and Liu, Yujia and Zheng, Chengbo and Xu, Jiaqi and Yu, Fuze and Gong, Jiangtao and Xu, Yingqing},
title = {Mentigo: An Intelligent Agent for Mentoring Students in the Creative Problem Solving Process},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713952},
doi = {10.1145/3706598.3713952},
abstract = {Creative Problem-Solving (CPS) promotes creative and critical thinking while enhancing real-world problem-solving skills, making it essential for middle school education. However, providing personalized mentorship in CPS projects at scale is challenging due to resource constraints and diverse student needs. To address this, we developed Mentigo, an AI-driven mentor agent designed to guide middle school students through the CPS process. Using a dataset of real classroom interactions, we encoded CPS task stages, adaptive guidance strategies, and personalized feedback mechanisms to inform Mentigo‘s dynamic mentoring framework powered by large language models (LLMs). A comparative experiment with 12 students and evaluations from five expert educators demonstrated improved student engagement, creativity, and task performance. Our findings highlight design implications for using LLM-based AI mentors to enhance CPS learning in educational environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {199},
numpages = {22},
keywords = {Generative AI, Agent, creative problem solving, mentor},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713510,
author = {Tanksley, Tiera and Smith, Angela D. R. and Sharma, Saloni and Huff, Earl W},
title = {"Ethics is not neutral": Understanding Ethical and Responsible AI Design from the Lenses of Black Youth},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713510},
doi = {10.1145/3706598.3713510},
abstract = {The rise of generative AI has brought a host of challenges for historically marginalized groups, including increased surveillance, AI-mediated racism, and algorithmic inequity. While stakeholders emphasize ethical and responsible AI that is safe, anti-discriminatory, and “protects human dignity,” the centrality of anti-Blackness in the design, development, and deployment of AI systems coupled with race-evasive approaches to defining and advancing ethical, equitable, and ‘human-centered’ technologies have exacerbated racial oppression. We present three case studies of speculative technologies designed by Black youth in a college bridge, summer course that examine ethical and responsible AI in their everyday lives. From a bottom-up approach, we infringe upon this broader discourse to provide an initial grounding of responsible and ethical AI as well as discuss the criticality of Black, historically anchored, culturally-situated lenses to offer justice-oriented design principles that can guide the teaching, learning, and design of technology.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {200},
numpages = {20},
keywords = {Black youth, responsible AI, ethical AI, social justice, anti-racism, design principles, race},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714049,
author = {Qadri, Rida and Mirowski, Piotr and Denton, Remi},
title = {AI and Non-Western Art Worlds: Reimagining Critical AI Futures through Artistic Inquiry and Situated Dialogue},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714049},
doi = {10.1145/3706598.3714049},
abstract = {This paper examines the potential for localized adaptation, appropriation and re-imagination of AI for non-western cultural expression, using the Persian Gulf as a case. Using sociologist Howard Becker’s concept of ‘art worlds’ as a situated lens to evaluate generative AI, we set up an eight week experimentation and dialogue between artists, art historians and curators. Our project reveals how local art worlds 1) can appropriate AI tools to address contextual and cultural needs; 2) develop “hacks” to adapt AI for culturally-specific capabilities; and 3) can be a site for imagining alternative technological trajectories. We thus showcase the importance of expanding the scope of AI evaluations to include the social dynamics AI operates in and its contexts of use. We also reflect on the power that local communities may have to interrupt AI with more culturally-relevant orientations and to offer visions for redesigning AI for non-Western creativity.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {201},
numpages = {17},
keywords = {Generative AI, text-to-image, creativity, art, artists, global south, cultural AI evaluations, design visions, local},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713854,
author = {Porquet, Julien and Wang, Sitong and Chilton, Lydia B},
title = {Copying style, Extracting value: Illustrators' Perception of AI Style Transfer and its Impact on Creative Labor},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713854},
doi = {10.1145/3706598.3713854},
abstract = {Generative text-to-image models are disrupting the lives of creative professionals. Specifically, illustrators are threatened by models that claim to extract and reproduce their style. Yet, research on style transfer has rarely focused on their perspectives. We provided four illustrators with a model fine-tuned to their style and conducted semi-structured interviews about the model’s successes, limitations, and potential uses. Evaluating their output, artists reported that style transfer successfully copies aesthetic fragments but is limited by content-style disentanglement and lacks the crucial emergent quality of their style. They also deemed the others’ copies more successful. Understanding the results of style transfer as “boundary objects,” we analyze how they can simultaneously be considered unsuccessful by artists and poised to replace their work by others. We connect our findings to critical HCI frameworks, demonstrating that style transfer, rather than merely a Creativity Support Tool, should also be understood as a supply chain optimization one.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {202},
numpages = {16},
keywords = {Generative AI, Style Transfer, Creative Labor, Boundary Objects, Capitalism},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713254,
author = {Cao, Huajie Jay and Lee, Hee Rin and Peng, Wei},
title = {Empowering Adults with AI Literacy: Using Short Videos to Transform Understanding and Harness Fear for Critical Thinking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713254},
doi = {10.1145/3706598.3713254},
abstract = {Despite the importance of AI literacy for both children and adults, adults have been understudied. We developed short videos for adults that provided training on the basics of AI understanding, use, and evaluation. In an online experiment, 94 adults aged 30-49 were randomly assigned in a 1:2 ratio to view either short videos on AI history (control group) or AI literacy training videos (treatment group). The results showed that the intervention significantly improved people’s self-efficacy of AI use but not in AI understanding or evaluation. Interestingly, participants’ fears of AI bias, privacy violations, and job replacement increased after the training, although they remained below the midpoints. We argue that the heightened fear in the treatment group reflects a foundation for critical thinking skills, as it moves them closer to a more calibrated, moderate level of fear. Therefore, this study uniquely contributes by utilizing short-form experiential content to both educate and foster a more informed, critical interaction with AI technologies. The implications of designing AI literacy educational materials for adults were discussed.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {203},
numpages = {8},
keywords = {AI literacy, Education, Adult, AI fear, self-efficacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713322,
author = {Kollig, Faye and Pater, Jessica and Nova, Fayika Farhat and Fiesler, Casey},
title = {Fictional Failures and Real-World Lessons: Ethical Speculation Through Design Fiction on Emotional Support Conversational AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713322},
doi = {10.1145/3706598.3713322},
abstract = {Conversational artificial intelligence (CAI), which replicates human-to-human interaction as human-to-machine, is increasingly developed to address insufficient access to healthcare. In this paper, we use design fiction methods to speculate on ethical consequences of CAI that offers emotional support to complement or replace mental healthcare. Through a near-future news article about a fictional, failed CAI, we explore safety and privacy concerns associated with mismatches between what an emotional support CAI is advertised to do, what it technically can do, and how it is likely to be used. We pose the following questions to researchers, regulators, and developers: How might we jointly and effectively address the anticipatable safety and privacy risks that emotional support CAI pose, including formalizing ethical speculation processes? What streamlined and practically feasible measures can efficiently account for the most dangerous harms? How might differing stakeholder expectations about the CAI be bridged? Finally, in what scenarios is the decision not to design a CAI tool the most ethical or safest option? Content advisement: Contains discussion of disordered eating behaviors and intimate partner violence.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {204},
numpages = {15},
keywords = {conversational AI, chatbot, mental health, design fiction, ethical speculation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713137,
author = {Hung, Peng-Kai and Huang, Janet Yi-Ching and Liang, Rung-Huei and Wensveen, Stephan},
title = {Generative AI as a Playful yet Offensive Tourist: Exploring Tensions Between Playful Features and Citizen Concerns in Designing Urban Play},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713137},
doi = {10.1145/3706598.3713137},
abstract = {Play is pivotal in fostering the emotional, social, and cultural dimensions of urban spaces. While generative AI (GAI) potentially supports playful urban interaction, a balanced and critical approach to the design opportunities and challenges is needed. This work develops iWonder, an image-to-image GAI tool engaging fourteen designers in urban explorations to identify GAI’s playful features and create design ideas. Fourteen citizens then evaluated these ideas, providing expectations and critical concerns from a bottom-up perspective. Our findings reveal the dynamic interplay between users, GAI, and urban contexts, highlighting GAI’s potential to facilitate playful urban experiences through generative agency, meaningful unpredictability, social performativity, and the associated offensive qualities. We propose design considerations to address citizen concerns and the ‘tourist metaphor’ to deepen our understanding of GAI’s impacts, offering insights to enhance cities’ socio-cultural fabric. Overall, this research contributes to the effort to harness GAI’s capabilities for urban enrichment.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {205},
numpages = {20},
keywords = {Games/Play, Generative AI, Urban Play, Empirical Study, Qualitative Methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714227,
author = {Inie, Nanna and Falk, Jeanette and Selvan, Raghavendra},
title = {How CO2STLY Is CHI? The Carbon Footprint of Generative AI in HCI Research and What We Should Do About It},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714227},
doi = {10.1145/3706598.3714227},
abstract = {The energy cost of developing and deploying Generative AI (GenAI) models has exploded with their mass adoption, as has the ensuing carbon emissions. The climate impact of this is currently unknown. In Human-Computer Interaction, GenAI models are rarely trained but often used. Based on detailed review of 282 papers, we estimate this footprint from energy consumption of the total use of GenAI for CHI 2024 research as between 10,769.63 and 10,925.12 kg CO2e — equal to driving a car for more than 100,000 km. We show that in CHI research, GenAI is most often used for Prototyping, Evaluation \&amp; User studies, and that Data Collection and Fine-tuning models incurs the highest CO2st.1 We find that CHI submissions are unlikely to report GenAI use transparently, which makes precise calculations difficult. By measuring the usage of a subset of the papers on local hardware, we obtain estimations of the energy consumption and carbon footprint. Based on this evidence, we discuss and demonstrate ways to mitigate the issues of GenAI carbon footprint and lack of transparency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {206},
numpages = {29},
keywords = {carbon footprint, energy consumption, Environmental Sustainability, Generative AI, AI Hype},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714305,
author = {Cutler, Zach and Harrison, Lane and Nobre, Carolina and Lex, Alexander},
title = {Crowdsourced Think-Aloud Studies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714305},
doi = {10.1145/3706598.3714305},
abstract = {The think-aloud (TA) protocol is a useful method for evaluating user interfaces, including data visualizations. However, TA studies are time-consuming to conduct and hence often have a small number of participants. Crowdsourcing TA studies would help alleviate these problems, but the technical overhead and the unknown quality of results have restricted TA to synchronous studies. To address this gap we introduce CrowdAloud, a system for creating and analyzing asynchronous, crowdsourced TA studies. CrowdAloud captures audio and provenance (log) data as participants interact with a stimulus. Participant audio is automatically transcribed and visualized together with events data and a full recreation of the state of the stimulus as seen by participants. To gauge the value of crowdsourced TA studies, we conducted two experiments: one to compare lab-based and crowdsourced TA studies, and one to compare crowdsourced TA studies with crowdsourced text prompts. Our results suggest that crowdsourcing is a viable approach for conducting TA studies at scale.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {207},
numpages = {23},
keywords = {Think-Aloud Study, Talk-Aloud Study, Visualization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714240,
author = {Li, Richard and Vutien, Philip and Omer, Sabrina and Yacoub, Michael and Ioannou, George and Karkar, Ravi and Munson, Sean A. and Fogarty, James},
title = {Deploying and Examining Beacon for At-Home Patient Self-Monitoring with Critical Flicker Frequency},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714240},
doi = {10.1145/3706598.3714240},
abstract = {Chronic liver disease can lead to neurological conditions that result in coma or death. Although early detection can allow for intervention, testing is infrequent and unstandardized. Beacon is a device for at-home patient self-measurement of cognitive function via critical flicker frequency, which is the frequency at which a flickering light appears steady to an observer. This paper presents our efforts in iterating on Beacon’s hardware and software to enable at-home use, then reports on an at-home deployment with 21 patients taking measurements over 6 weeks. We found that measurements were stable despite being taken at different times and in different environments. Finally, through interviews with 15 patients and 5 hepatologists, we report on participant experiences with Beacon, preferences around how CFF data should be presented, and the role of caregivers in helping patients manage their condition. Informed by our experiences with Beacon, we further discuss design implications for home health devices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {208},
numpages = {17},
keywords = {Beacon, health, critical flicker frequency, hepatic encephalopathy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713695,
author = {Schade, Eve and Savino, Gian-Luca and Niess, Jasmin and Sch\"{o}ning, Johannes},
title = {Describing Explored Places through OpenStreetMap Data},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713695},
doi = {10.1145/3706598.3713695},
abstract = {Mobile navigation applications are good at providing efficient navigation instructions. However, they currently lack the capability to facilitate free exploration. Therefore, users are limited to encountering only places close to the shortest paths, neglecting places that could diversify navigation and foster spatial learning. To better understand what characteristics places have that users like to explore we collected a dataset with a mobile application that encourages free exploration using gamification (n = 39, t = 455 days, 106.50 km2). Using OpenStreetMap data, we found highly frequented freely explored places comprising office, educational, retail, touristic and commercial places. When comparing the characteristics of the freely explored places to those along the shortest path, those categories were different. Based on our findings, we propose that implementing more diverse routing algorithms can enhance navigation diversity, improve spatial learning, and optimise the utilisation of urban spaces for travel.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {209},
numpages = {12},
keywords = {describing places, exploration, field-study, navigation, alternative routing, wayfinding},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713317,
author = {Dwyer, Andrew C and Coles-Kemp, Lizzie and Heath, Claude P R and Crivellaro, Clara},
title = {Friend or Foe? Navigating and Re-configuring “Snipers' Alley“},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713317},
doi = {10.1145/3706598.3713317},
abstract = {In a ‘digital by default’ society, essential services must be accessed online. This opens users to digital deception not only from criminal fraudsters but from a range of actors in a marketised digital economy. Using grounded empirical research from northern England, we show how supposedly ‘trusted’ actors, such as governments, (re)produce the insecurities and harms that they seek to prevent. Enhanced by a weakening of social institutions amid a drive for efficiency and scale, this has built a constricted, unpredictable digital channel. We conceptualise this as a “snipers’ alley”. Four key snipers articulated by participants’ lived experiences are examined: 1) Governments; 2) Business; 3) Criminal Fraudsters; and 4) Friends and Family to explore how snipers are differentially experienced and transfigure through this constricted digital channel. We discuss strategies to re-configure the alley, and how crafting and adopting opportunity models can enable more equitable forms of security for all.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {210},
numpages = {15},
keywords = {Digital Access, Digital Economy, Security Models, Threat Models, Dark Patterns},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713575,
author = {Adiwangsa, Michelle and Sweetser, Penny and Ozdowska, Anne},
title = {Snap, Sweat, and Sketch: Designing Home Exercise Experiences for Augmented Reality Head-mounted Displays},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713575},
doi = {10.1145/3706598.3713575},
abstract = {Augmented Reality (AR) head-mounted displays (HMDs) offer potential for more inclusive and immersive exercising and exergaming experiences at home. Previous work found that augmenting home objects can create more engaging exercise experiences and identified various home objects that can be augmented to facilitate different exercises. However, it is unclear how these objects can be augmented to enhance exercising and tailored based on the exercise. We conducted a multi-part study involving a design activity using Snapchat and focus group discussion with 28 participants. We present five themes relating to participants’ preferences for the augmentation of home objects for exercising, and identify and discuss key guidelines that designers and researchers should consider when augmenting home objects. Our results provide designers with guidelines and ideas for the augmentation of four different exercises, and advance the foundation for future work developing home-based exergaming through AR HMDs to increase people’s physical activity levels.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {211},
numpages = {20},
keywords = {Augmented reality, Exercising, Exergaming, Home environment, Participatory Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714195,
author = {Wallace, Shaun and Massachi, Talie and Su, Jiaqi and Miller, Dave B and Huang, Jeff},
title = {Towards Fair and Equitable Incentives to Motivate Paid and Unpaid Crowd Contributions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714195},
doi = {10.1145/3706598.3714195},
abstract = {Researchers commonly rely on contributions from either unpaid contributors or work done by paid crowdworkers. Rarely are the motivations of these workers and the accuracy of their contributions studied simultaneously in the wild over time. We maintain a public system where anyone can edit an evolving tabular dataset of Computer Science faculty profiles useful for the field of CS, and in this work, we analyze both the accuracy of contributions and the motivations of paid crowdworkers and unpaid contributors, combining data from real-world edit histories and a discrete choice experiment. The accuracy of edits made by unpaid contributors was 1.9 times higher than that of paid crowdworkers for difficult-to-find data and 1.5 times greater for data requiring domain-specific expertise. Our discrete choice experiment reveals that while both groups are motivated by common attributes describing a contribution task: pay level, estimated completion time, interest, and the ability to help others, they make different trade-offs between these attributes when choosing crowd contribution tasks. We provide recommendations to build hybrid data systems that mix extrinsic and intrinsic motivators to motivate highly accurate contributors, whether paid or unpaid.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {212},
numpages = {32},
keywords = {Tabular Data; Data Maintenance; Discrete Choice Experiment; Unpaid Contributions; Paid Crowdworkers; Crowdsourcing; Peer Production, Intrinsic Motivation, Extrinsic Motivation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713978,
author = {Gomez-Beldarrain, Garoa and Verma, Himanshu and Kim, Euiyoung and Bozzon, Alessandro},
title = {Why does Automation Adoption in Organizations Remain a Fallacy?: Scrutinizing Practitioners' Imaginaries in an International Airport},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713978},
doi = {10.1145/3706598.3713978},
abstract = {In organizations, the interest in automation is long-standing. However, adopting automated processes remains challenging, even in environments that appear highly standardized and technically suitable for it. Through a case study in Amsterdam Airport Schiphol, this paper investigates automation as a broader sociotechnical system influenced by a complex network of actors and contextual factors. We study practitioners’ collective understandings of automation and subsequent efforts taken to implement it. Using imaginaries as a lens, we report findings from a qualitative interview study with 16 practitioners involved in airside automation projects. Our findings illustrate the organizational dynamics and complexities surrounding automation adoption, as reflected in the captured problem formulations, conceptions of the technology, envisioned human roles in autonomous operations, and perspectives on automation fit in the airside ecosystem. Ultimately, we advocate for contextual automation design, which carefully considers human roles, accounts for existing organizational politics, and avoids techno-solutionist approaches.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {213},
numpages = {19},
keywords = {Automation Adoption, Responsible Automation, Autonomous Systems, Organization, Practitioners, Interview Study, Aviation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713124,
author = {Li, Lingyuan and Wang, Ge and Freeman, Guo},
title = {"It's about Research. It's Not about Language": Understanding and Designing for Mitigating Non-Native English-Speaking Presenters' Challenges in Live Q&amp;A Sessions at Academic Conferences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713124},
doi = {10.1145/3706598.3713124},
abstract = {Live Q&amp;A sessions at English-based, international academic conferences usually pose significant challenges for non-native English-speaking presenters, as they demand real-time comprehension and response in one’s non-native language under stress. While language-supportive tools (e.g., real-time translation, transcription) can help alleviate such challenges, their adoption remains limited, even at HCI academic conferences that focus on how technology can better serve human needs. Through in-depth interviews with 15 non-native English-speaking academics, we identify their concerns and expectations regarding technological language support for HCI live Q&amp;As. Our research provides critical design implications for future language support tools by highlighting the importance of culturally-aware solutions that offer accurate and seamless language experiences while fostering personal growth and building confidence. We also call for community-wide efforts in HCI to embrace more inclusive practices that actively support non-native English speakers, which can empower all scholars to equally engage in the HCI academic discourse regardless of their native languages.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {214},
numpages = {15},
keywords = {language barriers, live Q&amp;A sessions, language support tools, human-computer interaction, non-native English speakers},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713204,
author = {Sharma, Sumita and Klemettil\"{a}, Pauli and Tanaka, Junko},
title = {A robot teacher "is very good for learning, but not for human relationships": Japanese Children's Critical Perspectives Towards Ethical AI Futures},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713204},
doi = {10.1145/3706598.3713204},
abstract = {Young children increasingly interact with Artificial Intelligence (AI) in their everyday lives, often without being made aware of the ethical issues in the design and use of such technologies. This prompts the need for AI literacy that also implores them to adopt critical perspectives towards technology design and use. We conducted critical AI literacy workshops with 96 schoolchildren (ages 11-12 years) in Japan, inviting participants to imagine and design future classrooms and schools. While participants’ imagined future technologies incorporated elements of anthropomorphised AI as well as magical thinking; these future imaginaries revealed diverse perspectives on ethical AI design and use, including concerns about empathy, inclusion and fairness, and accountability and sustainability. Their future designs also underscored the everyday problems that matter to them the most. With our work, we highlight the need for exploring children’s perspectives towards ethical AI to envision inclusive ethical AI futures with and by children.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {215},
numpages = {20},
keywords = {Critical AI literacy, Children and AI, Design Futuring, Ethical AI, Inclusion and Fairness in AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713451,
author = {Srour Zreik, Rawan and Harvey, Monika and Brewster, Stephen Anthony},
title = {All-inclusive TORs: Cross-Cultural and Age-Sensitive Design for Take-Over Requests in Level 3 Cars},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713451},
doi = {10.1145/3706598.3713451},
abstract = {Transitioning to manual control following a Take-Over Request (TOR) in Level 3 autonomous cars is challenging, requiring drivers to re-engage with driving after engaging with Non-Driving Related Tasks (NDRTs). Effective TOR design can mitigate this challenge. We present the first study on how culture, age, and NDRT intersect to shape TOR design. In a cross-cultural study across the UK (high traffic-law compliance) and Israel (low compliance), involving older and younger drivers, participants designed TORs for four NDRTs in a real car setting. Results revealed a universal preference for re-purposing NDRT-devices to issue TORs. Older drivers preferred tri-modal TORs that suspend the NDRT; younger drivers favoured bi-modal TORs allowing NDRT interruption management. Due to altered alert sensitivity and low law compliance, Israeli participants included a RiskMeter to assess hazard criticality. We introduce novel TOR designs and taxonomy features to guide culturally and age-sensitive TOR development, key for global Level 3 adoption.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {216},
numpages = {17},
keywords = {Older drivers, Level 3, TOR, Cross-culture, Control transition, Age-sensitive, Participatory design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713407,
author = {Al-Taie, Ammar and Matviienko, Andrii and O'Hagan, Joseph and Pollick, Frank and Brewster, Stephen Anthony},
title = {Around the World in 60 Cyclists: Evaluating Autonomous Vehicle-Cyclist Interfaces Across Cultures},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713407},
doi = {10.1145/3706598.3713407},
abstract = {Cultural differences influence how cyclists and drivers interact, affecting global autonomous vehicle (AV) adoption. AV-cyclist interfaces are needed to clarify AV intentions and resolve ambiguities when no human driver is present. These must adapt across cultures and road infrastructure. We conducted the first cross-cultural AV-cyclist user study across Stockholm (high segregation of cyclists from drivers), Glasgow (some segregation), and Muscat (no segregation). Cyclists used an AR simulator to cycle in physical space and experienced three holistic AV-cyclist interfaces. These integrated multiple interfaces into a larger ecosystem, e.g., a smartwatch synchronised with on-vehicle eHMI. Interfaces communicated AV location, intentions, or both. Riders from all cities preferred combined AV location and intention information but used it differently. Stockholm cyclists focused on location, validating intentions with driving behaviour. Glasgow riders valued both cues equally. Muscat cyclists trusted interfaces, prioritising intentions without relying on driving behaviour. These insights are key for global AV adoption.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {217},
numpages = {18},
keywords = {Autonomous Vehicle-Cyclist Interaction, Cross-Cultural Study, Augmented Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713622,
author = {Desai, Aashaka and Alharbi, Rahaf and Hsueh, Stacy and Ladner, Richard E. and Mankoff, Jennifer},
title = {Toward Language Justice: Exploring Multilingual Captioning for Accessibility},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713622},
doi = {10.1145/3706598.3713622},
abstract = {A growing body of research investigates how to make captioning experiences more accessible and enjoyable to disabled people. However, prior work has focused largely on English captioning, neglecting the majority of people who are multilingual (i.e., understand or express themselves in more than one language). To address this gap, we conducted semi-structured interviews and diary logs with 13 participants who used multilingual captions for accessibility. Our findings highlight the linguistic and cultural dimensions of captioning, detailing how language features (scripts and orthography) and the inclusion/negation of cultural context shape the accessibility of captions. Despite lack of quality and availability, participants emphasized the importance of multilingual captioning to learn a new language, build community, and preserve cultural heritage. Moving toward a future where all ways of communicating are celebrated, we present ways to orient captioning research to a language justice agenda that decenters English and engages with varied levels of fluency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {218},
numpages = {18},
keywords = {Captioning, Multilingualism, Language Justice},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713542,
author = {B\"{a}umler, Julian and Bader, Helen and Kaufhold, Marc-Andr\'{e} and Reuter, Christian},
title = {Towards Youth-Sensitive Hateful Content Reporting: An Inclusive Focus Group Study in Germany},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713542},
doi = {10.1145/3706598.3713542},
abstract = {Youth are particularly likely to encounter hateful internet content, which can severely impact their well-being. While most social media provide reporting mechanisms, in several countries, severe hateful content can alternatively be reported to law enforcement or dedicated reporting centers. However, in Germany, many youth never resort to reporting. While research in human-computer interaction has investigated adults’ views on platform-based reporting, youth perspectives and platform-independent alternatives have received little attention. By involving a diverse group of 47 German adolescents and young adults in eight focus group interviews, we investigate how youth-sensitive reporting systems for hateful content can be designed. We explore German youth’s reporting barriers, finding that on platforms, they feel particularly discouraged by deficient rule enforcement and feedback, while platform-independent alternatives are rather unknown and perceived as time-consuming and disruptive. We further elicit their requirements for platform-independent reporting tools and contribute with heuristics for designing youth-sensitive and inclusive reporting systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {219},
numpages = {22},
keywords = {Youth, Adolescents, Young adults, Hateful content, Focus Groups, Reporting, Social Media},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713196,
author = {Ko, Amy J and Aldana Lira, Carlos and Amaya, Isabel},
title = {Wordplay: Accessible, Multilingual, Interactive Typography},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713196},
doi = {10.1145/3706598.3713196},
abstract = {Educational programming languages (EPLs) are rarely designed to be both accessible and multilingual. We describe a 30-month community-engaged case study to surface design challenges at this intersection, creating Wordplay, an accessible, multilingual platform for youth to program interactive typography. Wordplay combines functional programming, multilingual text, multimodal editors, time travel debugging, and teacher- and youth-centered community governance. Across five 2-hour focus group sessions, a group of 6 multilingual students and teachers affirmed many of the platform’s design choices, but reinforced that design at the margins was unfinished, including support for limited internet access, decade-old devices, and high turnover of device use by students with different access, language, and attentional needs. The group also highlighted open source platforms like GitHub as unsuitable for engaging youth. These findings suggest that EPLs that are both accessible and language-inclusive are feasible, but that there remain many design tensions between language design, learnability, accessibility, culture, and governance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {220},
numpages = {20},
keywords = {programming language, computing education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713666,
author = {Vera, Julie A. and Ghosh, Sourojit},
title = {"They've Over-Emphasized That One Search": Controlling Unwanted Content on TikTok's For You Page},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713666},
doi = {10.1145/3706598.3713666},
abstract = {Modern algorithmic recommendation systems seek to engage users through behavioral content-interest matching. While many platforms recommend content based on engagement metrics, others like TikTok deliver interest-based content, resulting in recommendations perceived to be hyper-personalized compared to other platforms. TikTok’s robust recommendation engine has led some users to suspect that the algorithm knows users “better than they know themselves," but this is not always true. In this paper, we explore TikTok users’ perceptions of recommended content on their For You Page (FYP), specifically calling attention to unwanted recommendations. Through qualitative interviews of 14 current and former TikTok users, we find themes of frustration with recommended content, attempts to rid themselves of unwanted content, and various degrees of success in eschewing such content. We discuss implications in the larger context of folk theorization and contribute concrete tactical and behavioral examples of algorithmic persistence.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {221},
numpages = {8},
keywords = {algorithms, TikTok, folk theories, content recommendation, social media},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713776,
author = {Mildner, Thomas and Fidel, Daniel and Stefanidi, Evropi and Wo\'{z}niak, Pawe\l{} W. and Malaka, Rainer and Niess, Jasmin},
title = {A Comparative Study of How People With and Without ADHD Recognise and Avoid Dark Patterns on Social Media},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713776},
doi = {10.1145/3706598.3713776},
abstract = {Dark patterns are deceptive strategies that recent work in human-computer interaction (HCI) has captured throughout digital domains, including social networking sites (SNSs). While research has identified difficulties among people to recognise dark patterns effectively, few studies consider vulnerable populations and their experience in this regard, including people with attention deficit hyperactivity disorder (ADHD), who may be especially susceptible to attention-grabbing tricks. Based on an interactive web study with 135 participants, we investigate SNS users’ ability to recognise and avoid dark patterns by comparing results from participants with and without ADHD. In line with prior work, we noticed overall low recognition of dark patterns with no significant differences between the two groups. Yet, ADHD individuals were able to avoid specific dark patterns more often. Our results advance previous work by understanding dark patterns in a realistic environment and offer insights into their effect on vulnerable populations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {222},
numpages = {17},
keywords = {dark patterns, deceptive design, SNS, social media, ADHD, vulnerable populations, user study, quantitative study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714138,
author = {Tran, Van Hong and Mehrotra, Aarushi and Sharma, Ranya and Chetty, Marshini and Feamster, Nick and Frankenreiter, Jens and Strahilevitz, Lior},
title = {Dark Patterns in the Opt-Out Process and Compliance with the California Consumer Privacy Act (CCPA)},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714138},
doi = {10.1145/3706598.3714138},
abstract = {To protect consumer privacy, the California Consumer Privacy Act (CCPA) requires businesses to provide consumers with a straightforward way to opt out of the sale and sharing of their personal information. However, the control that businesses enjoy over the opt-out process allows them to impose hurdles on consumers aiming to opt out, including by employing dark patterns. Motivated by the enactment of the California Privacy Rights Act (CPRA), which strengthens the CCPA and explicitly forbids certain dark patterns in the opt-out process, we investigate how dark patterns are used in opt-out processes and assess their compliance with CCPA regulations. Our research on 330 CCPA-subject websites reveals that these websites employ a variety of dark patterns. Some of these patterns are explicitly prohibited under the CCPA; others seem to take advantage of legal loopholes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {223},
numpages = {25},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713493,
author = {Ye, Jingzhou and Li, Yao and Zou, Wenting and Wang, Xueqiang},
title = {From Awareness to Action: The Effects of Experiential Learning on Educating Users about Dark Patterns},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713493},
doi = {10.1145/3706598.3713493},
abstract = {Dark patterns (DPs) refer to unethical user interface designs that deceive users into making unintended decisions, compromising their privacy, safety, financial security, and more. Prior research has mainly focused on defining and classifying DPs, as well as assessing their impact on users, while legislative and technical efforts to mitigate them remain limited. Consequently, users are still exposed to DP risks, making it urgent to educate them on avoiding these harms. However, there has been little focus on developing educational interventions for DP awareness. This study addresses this gap by introducing DPTrek, an experiential learning (EL) platform that educates users through simulated real-world DP cases. Both qualitative and quantitative evaluations show the effectiveness of DPTrek in helping users identify and manage DPs. The study also offers insights for future DP education and research, highlighting challenges such as user-unfriendly taxonomies and the lack of practical mitigation solutions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {224},
numpages = {22},
keywords = {dark pattern, experiential learning, security, privacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713828,
author = {Gray, Colin M. and Mildner, Thomas and Gairola, Ritika},
title = {Getting Trapped in Amazon's "Iliad Flow": A Foundation for the Temporal Analysis of Dark Patterns},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713828},
doi = {10.1145/3706598.3713828},
abstract = {Dark patterns are ubiquitous in digital systems, impacting users throughout their journeys on many popular apps and websites. While substantial efforts from the research community in the last five years have led to consolidated taxonomies and an ontology of dark patterns, most characterizations of these patterns have been focused on static images or isolated pattern types. In this paper, we leverage documents from a US Federal Trade Commission complaint describing dark patterns in Amazon Prime’s “Iliad Flow,” illustrating the interplay of dark patterns across a user journey. We use this case study to illustrate how dark patterns can be characterized and mapped over time, providing a sufficient audit trail and consistent application of dark patterns at high- and meso-level scales. We conclude by describing the groundwork for a methodology of Temporal Analysis of Dark Patterns (TADP) that allows for rigorous identification of dark patterns by researchers, regulators, and legal scholars.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {225},
numpages = {10},
keywords = {dark patterns, deceptive design, temporal analysis, regulation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714197,
author = {Hsu, Silas and Koshy, Vinay and Vaccaro, Kristen and Sandvig, Christian and Karahalios, Karrie},
title = {Placebo Effect of Control Settings in Feeds Are Not Always Strong},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714197},
doi = {10.1145/3706598.3714197},
abstract = {Recent work has catalogued a variety of “dark” design patterns, including deception, that undermine user intent. We focus on deceptive “placebo” control settings for social media that do not work. While prior work reported that placebo controls increase feed satisfaction, we add to this body of knowledge by addressing possible placebo mechanisms, and potential side effects and confounds from the original study. Knowledge of these placebo mechanisms can help predict potential harms to users and prioritize the most problematic cases for regulators to pursue. In an online experiment, participants (N=762) browsed a Twitter feed with no control setting, a working control setting, or a placebo control setting. We found a placebo effect much smaller in magnitude than originally reported. This finding adds another objection to use of placebo controls in social media settings, while our methodology offers insights into finding confounds in placebo experiments in HCI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {226},
numpages = {16},
keywords = {control settings, placebo, social media, Twitter, deception, dark pattern},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714010,
author = {Abdelkadir, Nuredin Ali and Yang, Tianling and Kapania, Shivani and Estefanos, Meron and Gebrekidan, Fasica Berhane and Zelalem, Zecharias and Ali, Messai and Berhe, Rishan and Baker, Dylan and Talat, Zeerak and Miceli, Milagros and Hanna, Alex and Gebru, Timnit},
title = {The Role of Expertise in Effectively Moderating Harmful Social Media Content},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714010},
doi = {10.1145/3706598.3714010},
abstract = {Social media platforms played a significant role in spreading genocidal content in the 2020-2022 Tigray war, where the deadliest genocide of the 21st century was committed. While linguistic expertise is clearly needed to adequately moderate such content, we ask: What additional expertise is needed? Why and to what extent do experts disagree on what constitutes harmful content, and what is the best way to resolve these disagreements? What do social media platforms do instead? We examine these questions through a 4-month study with 7 experts labeling 340 X (formerly Twitter) posts, and by interviewing 15 commercial content moderators. We find in-depth cultural knowledge and dialects to be most important for accurate hate speech annotation – knowledge which social media platforms do not prioritize. Even amongst experts, disagreements are high (71\%), dropping to 40\% after deliberation meetings. Based on these results, we present 7 recommendations to improve hate speech annotation and moderation practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {227},
numpages = {21},
keywords = {Expertise, Content Moderation, Data Annotation, Expert Disagreement, Harmful Content, Social Media Platforms},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714128,
author = {Jacobsen, Rune M\o{}berg and Cox, Samuel Rhys and Griggio, Carla F. and van Berkel, Niels},
title = {Chatbots for Data Collection in Surveys: A Comparison of Four Theory-Based Interview Probes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714128},
doi = {10.1145/3706598.3714128},
abstract = {Surveys are a widespread method for collecting data at scale, but their rigid structure often limits the depth of qualitative insights obtained. While interviews naturally yield richer responses, they are challenging to conduct across diverse locations and large participant pools. To partially bridge this gap, we investigate the potential of using LLM-based chatbots to support qualitative data collection through interview probes embedded in surveys. We assess four theory-based interview probes: descriptive, idiographic, clarifying, and explanatory. Through a split-plot study design (N&nbsp;=&nbsp;64), we compare the probes’ impact on response quality and user experience across three key stages of HCI research: exploration, requirements gathering, and evaluation. Our results show that probes facilitate the collection of high-quality survey data, with specific probes proving effective at different research stages. We contribute practical and methodological implications for using chatbots as research tools to enrich qualitative data collection.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {228},
numpages = {21},
keywords = {Chatbots, Interview Probes, Online Surveys, Data collection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714092,
author = {Quinto Lima, Stella and Buraglia, Gabriela and Kam-Kwai, Wong and Roberts, Jessica},
title = {Data Bias Recognition in Museum Settings: Framework Development and Contributing Factors},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714092},
doi = {10.1145/3706598.3714092},
abstract = {Critical thinking skills are increasingly important for comprehending our data-rich society. While museums provide data for discussion, visitors may not naturally question data in such displays due to the inherent authority of a museum. To investigate what factors can help visitors recognize bias in data, we interviewed visitors after they interacted with an augmented reality data map in an interactive data exhibition. Here, we present a qualitative analysis of fifteen semi-structured interviews with visitors who engaged with mapped data from the citizen science platform iNaturalist. The study revealed that 47\% of participants were able to recognize bias, and familiarity was found to be a significant factor in this ability. We propose a three-layer framework to understand the cognitive processes of bias recognition in informal learning settings and apply this framework to our data to inform future work for designing displays to promote critical engagement with data in free-choice learning contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {229},
numpages = {15},
keywords = {Prior Knowledge, Human-Data Interaction, Augmented Reality, Critical Thinking, Informal Learning, Human-Centered Computing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713809,
author = {Strain, Gabriel and Stewart, Andrew J. and Jay, Caroline and Rutherford, Charlotte and Warren, Paul A.},
title = {Effects of Alternative Scatterplot Designs on Belief},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713809},
doi = {10.1145/3706598.3713809},
abstract = {Viewers tend to underestimate correlation in positively correlated scatterplots. However, systematically changing the size and opacity of scatterplot points can bias estimates upwards, correcting for this underestimation. Here, we examine whether the application of these visualisation techniques goes beyond a simple perceptual effect and could actually influence beliefs about information from trusted news sources. We present a fully-reproducible study in which we demonstrate that scatterplot manipulations that are able to correct for the correlation underestimation bias can also induce stronger levels of belief change compared to conventional scatterplots presenting identical data. Consequently, we show that novel visualisation techniques can be used to drive belief change, and suggest future directions for extending this work with regards to altering attitudes and behaviours.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {230},
numpages = {12},
keywords = {belief change, correlation perception, scatterplot, crowdsourced},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713525,
author = {Olson, Wyatt and Shabazz-Thompson, Freesoul El and Wells, Melanie and Xiong, Chuanzhe and Yee, Janey and Saimo, Julia R and Vu, Ocean and Narita, Jonathan and Craft, Brock and Tihanyi, Timea and Desjardins, Audrey},
title = {Stills from the Inner Ear Shorts: Collecting and Living with Data},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713525},
doi = {10.1145/3706598.3713525},
abstract = {Data collection and representation invariably involve interpretation with various layers of translation. We designed the Inner Ear—a porcelain device that both captures and represents home vibration data—to rethink the relationship between home dwellers and their data. In this paper, we report on the deployment of the Inner Ear with seven participants in Seattle, Washington, USA. We examine stills and quotes from the Inner Ear Shorts: short documentary films that capture participants’ experiences and reflections with the Inner Ear. Our findings outline nuanced relationships with data that foreground sensorial and conscious experiences to engage with objects, spaces, and infrastructure, and deemphasize legibility to give space to memory and broaden definitions of data. We discuss how more ambiguous relationships with data can be beneficial to reconfigure everyday lives with data. We conclude with a reflection on the use of documentary filmmaking as a complementary methodological approach to synthesizing and analyzing research data.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {231},
numpages = {20},
keywords = {Research-through-design, Documentary Filmmaking, Data, Interpretation, Data Physicalization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713504,
author = {G\'{o}mez Ortega, Alejandra and Morales Ornelas, Hosana and Gen\c{c}, U\u{g}ur},
title = {Surrendering to Powerlesness: Governing Personal Data Flows in Generative AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713504},
doi = {10.1145/3706598.3713504},
abstract = {Personal data flows across digital technologies integrated into people’s lives and relationships. Increasingly, these technologies include Generative AI. (How) should personal data flow into and out of GenAI models? We investigate how people experience personal data collection in GenAI ecosystems and unpack the enablers and barriers to governing their data. We focus on personal data collection by Meta, specifically Instagram, in line with their recent policy update on processing user data to train GenAI models. We conducted semi-structured interviews with 20 Latin American Instagram users, based in Europe and Latin America. We discussed the acceptability of their data flowing in and out of GenAI models through different scenarios. Our results interrogate power dynamics in data collection, the (inter)personal nature of data, and the multiple unknowns concerning data and their algorithmic derivatives. We pose provocations around feelings of powerlessness, reframing (inter)personal data, and encountering unknown data and algorithms through design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {232},
numpages = {18},
keywords = {Personal Data; Sensitive Data; Privacy; Data Governance; Generative AI; Social Media;},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714265,
author = {Takahira, Kentaro and Kam-Kwai, Wong and Yang, Leni and Xu, Xian and Fujiwara, Takanori and Qu, Huamin},
title = {TangibleNet: Synchronous Network Data Storytelling through Tangible Interactions in Augmented Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714265},
doi = {10.1145/3706598.3714265},
abstract = {Synchronous data-driven storytelling with network visualizations presents significant challenges due to the complexity of real-time manipulation of network components. While existing research addresses asynchronous scenarios, there is a lack of effective tools for live presentations. To address this gap, we developed TangibleNet, a projector-based AR prototype that allows presenters to interact with node-link diagrams using double-sided magnets during live presentations. The design process was informed by interviews with professionals experienced in synchronous data storytelling and workshops with 14 HCI/VIS researchers. Insights from the interviews helped identify key design considerations for integrating physical objects as interactive tools in presentation contexts. The workshops contributed to the development of a design space mapping user actions to interaction commands for node-link diagrams. Evaluation with 12 participants confirmed that TangibleNet supports intuitive interactions and enhances presenter autonomy, demonstrating its effectiveness for synchronous network-based data storytelling.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {233},
numpages = {18},
keywords = {data-driven storytelling, tangible interaction, augmented reality, network visualization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713941,
author = {Jo, Yeeun and Jameel, Mahnoor and Cobb, Camille and Bates, Adam},
title = {"I'm not as afraid as a woman might be about sharing my exact location:" On the Intersection of Identity and Privacy Concerns in Fitness Tracking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713941},
doi = {10.1145/3706598.3713941},
abstract = {Users’ perceptions of fitness tracking privacy is a subject of active study, but how do various aspects of social identity inform these perceptions? We conducted an online survey (N=322) that explores the influence of identity on fitness tracking privacy perceptions and practices, considering participants’ gender, race, age, and whether or not they identify as LGTBQ*. Participants reported how comfortable they felt sharing fitness data, commented on whether they believed their identity impacted this comfort, and brainstormed several data sharing risks and a possible mitigation for each risk. For each surveyed dimension of social identity, we find one or more reliable effects on participants’ level of comfort sharing fitness data, specifically when considering institutional groups like employers, insurers, and advertisers. Further, 64\% of participants indicate at least one of their identity characteristics informs their comfort. We also find evidence that the perceived risks of sharing fitness data vary by identity, but do not find evidence of difference in the strategies used to manage these risks. This work highlights a path towards reasoning about the privacy challenges of fitness tracking with respect for the lived experiences of all users.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {234},
numpages = {23},
keywords = {Fitness trackers, privacy, safety, online survey, identity, risk perception, demographic factors, data sharing, mitigations},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713245,
author = {Olson, Wyatt and Pierce, James},
title = {Exploring the use of Speculative Concept Films for Co-Speculation around Data Ethics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713245},
doi = {10.1145/3706598.3713245},
abstract = {Location-based recommendation systems are becoming increasingly ubiquitous in the march toward fully tailored user experiences. Applications like Google Maps, Strava, Uber, Hinge, and many others utilize location data as key material for providing contextual recommendations. Rising concerns about usage and misuse of location data have arisen in recent years. We situate this paper within design’s future-oriented nature, critically speculating possible futures with location-based recommenders. We propose a refinement of current approaches and speculative design for engaging domain experts in co-speculation through the use of tailored, high-fidelity, critical design fiction films. In this case study, we lay preliminary insights, including a widespread sense of fatalism, self-described lack of agency, and underlying individualist ideologies driving development and deployment of these systems. We also reflect on the process of creating four critical design fiction videos, their use in 11 guided co-speculation sessions, and implications for their use in gathering rich qualitative data, creating space for reflection, prompting stories and personal connection, and unpacking experts’ views on complex wicked problems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {235},
numpages = {21},
keywords = {Design Filmmaking, Design Fiction, Speculative Critical Design, Envisioning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713654,
author = {Martius, Florin and Jansen, Luisa and Struck, Lukas and Arumugam, Arthi and Geierhaas, Lisa and Ortloff, Anna-Marie and Smith, Matthew and Tiefenau, Christian},
title = {Out of Sight, Out of Mind? Exploring Data Protection Practices for Personal Data in Usable Security \&amp; Privacy Studies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713654},
doi = {10.1145/3706598.3713654},
abstract = {Adherence to data protection measures such as pseudonymization or anonymization is critical in human subjects research because it has a direct impact on the confidentiality of participants’ sensitive information, trust in research practices, and compliance with ethical and legal standards. Regulations such as the General Data Protection Regulation (GDPR) and guarantees made by researchers in informed consent forms mandate strict protocols for data security. However, compliance with these is not always straightforward. To gain qualitative insights into data protection practices in the field of Usable Security and Privacy (USP), we conducted interviews with 22 practitioners (five professors, eight researchers, nine data protection officers) and one focus group with five researchers. Overall, our results show a high awareness of ethical and legal responsibilities but highlight many practical and procedural issues. Based on these, we make concrete recommendations on how to improve the protection of personal data in research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {236},
numpages = {16},
keywords = {Human Subjects Research, Personal Data Handling, Ethics, Usable Security and Privacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713540,
author = {Ma, Rongjun and Maidhof, Caterina and Carrillo, Juan Carlos and Lindqvist, Janne and Such, Jose},
title = {Privacy Perceptions of Custom GPTs by Users and Creators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713540},
doi = {10.1145/3706598.3713540},
abstract = {GPTs are customized LLM apps built on OpenAI’s large language model. Any individual or organization can use and create GPTs without needing programming skills. However, the rapid proliferation of over three million GPTs has raised significant privacy concerns. To explore the privacy perspectives of users and creators, we interviewed 23 GPT users with varying levels of creation experience. Our findings reveal blurred lines between user and creator roles and their understanding of GPT data flows. Participants raised concerns about data handling during collection, processing, and dissemination, alongside the lack of privacy regulations. Creators also worried about loss of their proprietary knowledge. In response, participants adopted practices like self-censoring input, evaluating GPT actions, and minimizing usage traces. Focusing on the dual role of user-creators, we find that expertise and responsibility shape privacy perceptions. Based on these insights, we propose practical recommendations to improve data transparency and platform regulations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {237},
numpages = {18},
keywords = {GPTs, LLM Apps, Privacy Concerns, Privacy Practices, Interviews, Empirical Studies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714074,
author = {Ma, Ying and Zhang, Shiquan and Yang, Dongju and Sarsenbayeva, Zhanna and Knibbe, Jarrod and Goncalves, Jorge},
title = {Raising Awareness of Location Information Vulnerabilities in Social Media Photos using LLMs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714074},
doi = {10.1145/3706598.3714074},
abstract = {Location privacy leaks can lead to unauthorised tracking, identity theft, and targeted attacks, compromising personal security and privacy. This study explores LLM-powered location privacy leaks associated with photo sharing on social media, focusing on user awareness, attitudes, and opinions. We developed and introduced an LLM-powered location privacy intervention app to 19 participants, who used it over a two-week period. The app prompted users to reflect on potential privacy leaks that a widely available LLM could easily detect, such as visual landmarks&nbsp;\&amp; cues that could reveal their location, and provided ways to conceal this information. Through in-depth interviews, we found that our intervention effectively increased users’ awareness of location privacy and the risks posed by LLMs. It also encouraged users to consider the importance of maintaining control over their privacy data and sparked discussions about the future of location privacy-preserving technologies. Based on these insights, we offer design implications to support the development of future user-centred, location privacy-preserving technologies for social media photos.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {238},
numpages = {14},
keywords = {location privacy, social media, privacy leaks, photos, LLMs, intervention, interviews},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713912,
author = {Windl, Maximiliane and Amberg, Roman and Kosch, Thomas},
title = {The Illusion of Privacy: Investigating User Misperceptions in Browser Tracking Protection},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713912},
doi = {10.1145/3706598.3713912},
abstract = {Third parties track users’ web browsing activities, raising privacy concerns. Tracking protection extensions prevent this, but their influence on privacy protection beliefs shaped by narratives remains uncertain. This paper investigates users’ misperception of tracking protection offered by browser plugins. Our study explores how different narratives influence users’ perceived privacy protection by examining three tracking protection extension narratives: no protection, functional protection, and a placebo. In a study (N=36), participants evaluated their anticipated protection during a hotel booking process, influenced by the narrative about the plugin’s functionality. However, participants viewed the same website without tracking protection adaptations. We show that users feel more protected when informed they use a functional or placebo extension, compared to no protection. Our findings highlight the deceptive nature of misleading privacy tools, emphasizing the need for greater transparency to prevent users from a false sense of protection, as such misleading tools negatively affect user study results.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {239},
numpages = {10},
keywords = {Privacy, Placebo, Protection, Web Extension, Plugins, Tracking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713783,
author = {Song, Qiurong and Wu, Yanlai and Hernandez, Rie Helene (Lindy) and Li, Yao and Kou, Yubo and Gui, Xinning},
title = {Understanding Users' Perception of Personally Identifiable Information},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713783},
doi = {10.1145/3706598.3713783},
abstract = {Personally identifiable information (PII) is a fundamental concept in privacy research and regulations. Understanding users' perspectives on PII is critical, as their understanding of PII can significantly affect their privacy decisions and practices. While much research has explored users’ privacy perceptions and disclosure preferences regarding PII, less attention has been focused on how users internally define and conceptualize PII. In this study, we conducted interviews with 32 participants to investigate their conceptualization and understanding of PII, using period and fertility tracking apps as the context. Our findings reveal how users perceive the processes and contexts through which personal information, by becoming identifiable, transitions into PII, as well as concerns about data sharing and misuse in these apps. We conclude by advocating for addressing the misalignment between users' perceptions of PII and the regulatory protections and privacy designs surrounding it.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {240},
numpages = {24},
keywords = {Identification, PII, Period and fertility tracking, Personally identifiable information, Privacy perception, Reproductive health privacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714085,
author = {Zhang, Jingyue and Arawjo, Ian},
title = {ChainBuddy: An AI-assisted Agent System for Generating LLM Pipelines},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714085},
doi = {10.1145/3706598.3714085},
abstract = {As large language models (LLMs) advance, their potential applications have grown significantly. However, it remains difficult to evaluate LLM behavior on user-defined tasks and craft effective pipelines to do so. Many users struggle with where to start, often referred to as the "blank page problem." ChainBuddy, an AI workflow generation assistant built into the ChainForge platform, aims to tackle this issue. From a single prompt or chat, ChainBuddy generates a starter evaluative LLM pipeline in ChainForge aligned to the user’s requirements. ChainBuddy offers a straightforward and user-friendly way to plan and evaluate LLM behavior and make the process less daunting and more accessible across a wide range of possible tasks and use cases. We report a within-subjects user study comparing ChainBuddy to the baseline interface. We find that when using AI assistance, participants with a variety of technical expertise reported a less demanding workload, felt more confident, and produced higher quality pipelines evaluating LLM behavior. However, we also uncover a mismatch between subjective and objective ratings of performance: participants rated their successfulness similarly across conditions, while independent experts rated participant workflows significantly higher with AI assistance. Drawing connections to the Dunning–Kruger effect, we discuss implications for the future design of workflow generation assistants regarding the risk of over-reliance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {241},
numpages = {21},
keywords = {language models, AI agents, prompt engineering, automation, LLM pipelines, visual programming environments},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714025,
author = {Lin, Weiran and Gerchanovsky, Anna and Akgul, Omer and Bauer, Lujo and Fredrikson, Matt and Wang, Zifan},
title = {LLM Whisperer: An Inconspicuous Attack to Bias LLM Responses},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714025},
doi = {10.1145/3706598.3714025},
abstract = {Writing effective prompts for large language models (LLM) can be unintuitive and burdensome. In response, services that optimize or suggest prompts have emerged. While such services can reduce user effort, they also introduce a risk: the prompt provider can subtly manipulate prompts to produce heavily biased LLM responses. In this work, we show that subtle synonym replacements in prompts can increase the likelihood (by a difference up to (78\%)) that LLMs mention a target concept (e.g., a brand, political party, nation). We substantiate our observations through a user study, showing that our adversarially perturbed prompts 1) are indistinguishable from unaltered prompts by humans, 2) push LLMs to recommend target concepts more often, and 3) make users more likely to notice target concepts, all without arousing suspicion. The practicality of this attack has the potential to undermine user autonomy. Among other measures, we recommend implementing warnings against using prompts from untrusted parties.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {242},
numpages = {24},
keywords = {Large Language Models, Inconspicuous Attacks, User Autonomy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713273,
author = {Shin, Joongi and Polyanskaya, Anna and Lucero, Andr\'{e}s and Oulasvirta, Antti},
title = {No Evidence for LLMs Being Useful in Problem Reframing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713273},
doi = {10.1145/3706598.3713273},
abstract = {Problem reframing is a designerly activity wherein alternative perspectives are created to recast what a stated design problem is about. Generating alternative problem frames is challenging because it requires devising novel and useful perspectives that fit the given problem context. Large language models (LLMs) could assist this activity via their generative capability. However, it is not clear whether they can help designers produce high-quality frames. Therefore, we asked if there are benefits to working with LLMs. To this end, we compared three ways of using LLMs (N = 280): 1) free-form, 2) direct generation, and 3) a structured approach informed by a theory of reframing. We found that using LLMs does not help improve the quality of problem frames. In fact, it increases the competence gap between experienced and inexperienced designers. Also, inexperienced ones perceived lower agency when working with LLMs. We conclude that there is no benefit to using LLMs in problem reframing and discuss possible factors for this lack of effect.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {243},
numpages = {25},
keywords = {Problem-solving, problem reframing, LLM},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713633,
author = {Haghighi, Nava and Yu, Sunny and Landay, James A. and Rosner, Daniela},
title = {Ontologies in Design: How Imagining a Tree Reveals Possibilities and Assumptions in Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713633},
doi = {10.1145/3706598.3713633},
abstract = {Amid the recent uptake of Generative AI, sociotechnical scholars and critics have traced a multitude of resulting harms, with analyses largely focused on values and axiology (e.g., bias). While value-based analyses are crucial, we argue that ontologies—concerning what we allow ourselves to think or talk about—is a vital but under-recognized dimension in analyzing these systems. Proposing a need for a practice-based engagement with ontologies, we offer four orientations for considering ontologies in design: pluralism, groundedness, liveliness, and enactment. We share examples of potentialities that are opened up through these orientations across the entire LLM development pipeline by conducting two ontological analyses: examining the responses of four LLM-based chatbots in a prompting exercise, and analyzing the architecture of an LLM-based agent simulation. We conclude by sharing opportunities and limitations of working with ontologies in the design and development of sociotechnical systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {244},
numpages = {20},
keywords = {ontological design, ontologies, generative AI, large language models, foundation models, LLM agents},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713675,
author = {Ashkinaze, Joshua and Fry, Emily and Edara, Narendra and Gilbert, Eric and Budak, Ceren},
title = {Plurals: A System for Guiding LLMs via Simulated Social Ensembles},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713675},
doi = {10.1145/3706598.3713675},
abstract = {Recent debates raised concerns that language models may favor certain viewpoints. But what if the solution is not to aim for a “view from nowhere” but rather to leverage different viewpoints? We introduce Plurals, a system and Python library for pluralistic AI deliberation. Plurals consists of Agents (LLMs, optionally with personas) which deliberate within customizable Structures, with Moderators overseeing deliberation. Plurals is a generator of simulated social ensembles. Plurals integrates with government datasets to create nationally representative personas, includes deliberation templates inspired by deliberative democracy, and allows users to customize both information-sharing structures and deliberation behavior within Structures. Six case studies demonstrate fidelity to theoretical constructs and efficacy. Three randomized experiments show simulated focus groups produced output resonant with an online sample of the relevant audiences (chosen over zero-shot generation in 75\% of trials). Plurals is both a paradigm and a concrete system for pluralistic AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {245},
numpages = {21},
keywords = {Human-Computer Interaction, Human-AI Interaction, Artificial Intelligence, Multi-Agent Systems, Pluralism},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713701,
author = {Zhou, Jijie and Xu, Eryue and Wu, Yaoyao and Li, Tianshi},
title = {Rescriber: Smaller-LLM-Powered User-Led Data Minimization for LLM-Based Chatbots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713701},
doi = {10.1145/3706598.3713701},
abstract = {The proliferation of LLM-based conversational agents has resulted in excessive disclosure of identifiable or sensitive information. However, existing technologies fail to offer perceptible control or account for users’ personal preferences about privacy-utility tradeoffs due to the lack of user involvement. To bridge this gap, we designed, built, and evaluated Rescriber, a browser extension that supports user-led data minimization in LLM-based conversational agents by helping users detect and sanitize personal information in their prompts. Our studies (N=Rescriber) showed that Rescriber helped users reduce unnecessary disclosure and addressed their privacy concerns. Users’ subjective perceptions of the system powered by Llama3-8B were on par with that by GPT-4o. The comprehensiveness and consistency of the detection and sanitization emerge as essential factors that affect users’ trust and perceived protection. Our findings confirm the viability of smaller-LLM-powered, user-facing, on-device privacy controls, presenting a promising approach to address the privacy and trust challenges of AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {246},
numpages = {28},
keywords = {privacy, security, LLM, AI, chatbot, PII, ChatGPT},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714113,
author = {Lee, Christine P. and Porfirio, David and Wang, Xinyu Jessica and Zhao, Kevin Chenkai and Mutlu, Bilge},
title = {VeriPlan: Integrating Formal Verification and LLMs into End-User Planning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714113},
doi = {10.1145/3706598.3714113},
abstract = {Automated planning is traditionally the domain of experts, utilized in fields like manufacturing and healthcare with the aid of expert planning tools. Recent advancements in LLMs have made planning more accessible to everyday users due to their potential to assist users with complex planning tasks. However, LLMs face several application challenges within end-user planning, including consistency, accuracy, and user trust issues. This paper introduces VeriPlan, a system that applies formal verification techniques, specifically model checking, to enhance the reliability and flexibility of LLMs for end-user planning. In addition to the LLM planner, VeriPlan includes three additional core features—a rule translator, flexibility sliders, and a model checker—that engage users in the verification process. Through a user study (n = 12), we evaluate VeriPlan, demonstrating improvements in the perceived quality, usability, and user satisfaction of LLMs. Our work shows the effective integration of formal verification and user-control features with LLMs for end-user planning tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {247},
numpages = {19},
keywords = {large-language models; verification; human-in-the-loop; human-centered AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713531,
author = {Noh, Yeo-Gyeong and Han, MinJu and Jeon, Junryeol and Hong, Jin-Hyuk},
title = {BIASsist: Empowering News Readers via Bias Identification, Explanation, and Neutralization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713531},
doi = {10.1145/3706598.3713531},
abstract = {Biased news articles can distort readers’ perceptions by presenting information in a way that favors or disfavors a particular point of view. Subtly embedded in the text, these biased news articles can shape our views daily without people even realizing it. To address this issue, we propose BIASsist, an LLM-based approach designed to mitigate bias in news articles. Based on existing research, we defined six types of bias and introduced three assistive components—identification, explanation, and neutralization—to provide a broader range of bias information and enhance readers’ bias-awareness. We conducted a mixed-method study with 36 participants to evaluate the effectiveness of BIASsist. The results show participants’ bias awareness significantly improved and their interest in identifying bias increased. Participants also tended to engage more actively in critically evaluating articles. Based on these findings, we discuss its potential to improve media literacy and critical thinking in today’s information overload era.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {248},
numpages = {24},
keywords = {Bias, News article, Assistive tool, LLM-powered application},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714167,
author = {Keswani, Vijay and Conitzer, Vincent and Sinnott-Armstrong, Walter and Nguyen, Breanna K. and Heidari, Hoda and Schaich Borg, Jana},
title = {Can AI Model the Complexities of Human Moral Decision-making? A Qualitative Study of Kidney Allocation Decisions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714167},
doi = {10.1145/3706598.3714167},
abstract = {A growing body of work in Ethical AI attempts to capture human moral judgments through simple computational models. The key question we address in this work is whether such simple AI models capture the critical nuances of moral decision-making by focusing on the use case of kidney allocation. We conducted twenty interviews where participants explained their rationale for their judgments about who should receive a kidney. We observe participants: (a) value patients’ morally-relevant attributes to different degrees; (b) use diverse decision-making processes, citing heuristics to reduce decision complexity; (c) can change their opinions; (d) sometimes lack confidence in their decisions (e.g., due to incomplete information); and (e) express enthusiasm and concern regarding AI assisting humans in kidney allocation decisions. Based on these findings, we discuss challenges of computationally modeling moral judgments as a stand-in for human input, highlight drawbacks of current approaches, and suggest future directions to address these issues.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {249},
numpages = {17},
keywords = {Moral Decision-making, Human-centered AI, AI Alignment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713804,
author = {Kiskola, Joel and Rydenfelt, Henrik and Olsson, Thomas and Haapanen, Lauri and V\"{a}nttinen, Noora and Nelimarkka, Matti and Vigren, Minna and Laaksonen, Salla-Maaria and Lehtiniemi, Tuukka},
title = {Generative AI and News Consumption: Design Fictions and Critical Analysis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713804},
doi = {10.1145/3706598.3713804},
abstract = {The emergence of Generative AI features in news applications may radically change news consumption and challenge journalistic practices. To explore the future potentials and risks of this understudied area, we created six design fictions depicting scenarios such as virtual companions delivering news summaries to the user, AI providing context to news topics, and content being transformed into other formats on demand. The fictions, discussed with a multi-disciplinary group of experts, enabled a critical examination of the diverse ethical, societal, and journalistic implications of AI shaping this everyday activity. The discussions raised several concerns, suggesting that such consumer-oriented AI applications can clash with journalistic values and processes. These include fears that neither consumers nor AI could successfully balance engagement, objectivity, and truth, leading to growing detachment from shared understanding. We offer critical insights into the potential long-term effects to guide design efforts in this emerging application area of GenAI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {250},
numpages = {18},
keywords = {Design fiction, artificial intelligence, journalism, online news, speculative design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713725,
author = {Sarma, Abhraneel and Hedayati, Maryam and Kay, Matthew},
title = {More Forecasts, More (Decision) Problems: How Uncertainty Representations for Multiple Forecasts Impact Decision Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713725},
doi = {10.1145/3706598.3713725},
abstract = {Users often have access to multiple forecasts regarding an event. Different forecasts incorporate different assumptions and epistemic information. A growing body of work argues against decision-making solely based on expected utility maximisation strategies in multiple forecasts scenarios, in favour of other strategies such as the maximin expected utility. In this work, we compare two different approaches for depicting epistemic uncertainty—ensembles (a direct representation of multiple forecasts) and p-boxes (a representation which only communicates the bounds of epistemic uncertainty)—in plots where individual distributions are represented as cumulative distribution plots (CDFs). We conduct three experiments to investigate the impact of the visual representation on the decision-making strategies that people adopt. Our results suggest that participants adopt conservative decision-making strategies (i.e. place greater weight on the worst-case forecast than the best-case forecast) for both p-boxes and ensembles if the set of forecasts are uniformly distributed. However, if a majority of the forecasts are clustered near one of the bounds, participants may discount the forecast which appears as a visual outlier.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {251},
numpages = {14},
keywords = {multiple forecasts, uncertainty visualization, decision-making},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713579,
author = {Gen\c{c}, H\"{u}seyin U\u{g}ur and Chandrasegaran, Senthil and Dingler, Tilman and Verma, Himanshu},
title = {Persuasion in Pixels and Prose: The Effects of Emotional Language and Visuals in Agent Conversations on Decision-Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713579},
doi = {10.1145/3706598.3713579},
abstract = {The growing sophistication of Large Language Models allows conversational agents (CAs) to engage users in increasingly personalized and targeted conversations. While users may vary in their receptiveness to CA persuasion, stylistic elements and agent personalities can be adjusted on the fly. Combined with image generation models that create context-specific realistic visuals, CAs have the potential to influence user behavior and decision making. We investigate the effects of linguistic and visual elements used by CAs on user perception and decision making in a charitable donation context with an online experiment (n=344). We find that while CA attitude influenced trust, it did not affect donation behavior. Visual primes played no role in shaping trust, though their absence resulted in higher donations and situational empathy. Perceptions of competence and situational empathy were potential predictors of donation amounts. We discuss the complex interplay of user and CA characteristics and the fine line between benign behavior signaling and manipulation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {252},
numpages = {27},
keywords = {conversational agents, conversational agent attitudes, chatbot, persuasive communication, visual priming, emotional priming},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714050,
author = {Zhang, Yongle and Nguyen-Le, Phuong-Anh and Singh, Kriti and Gao, Ge},
title = {The News Says, the Bot Says: How Immigrants and Locals Differ in Chatbot-Facilitated News Reading},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714050},
doi = {10.1145/3706598.3714050},
abstract = {News reading helps individuals stay informed about events and developments in society. Local residents and new immigrants often approach the same news differently, prompting the question of how technology, such as LLM-powered chatbots, can best enhance a reader-oriented news experience. The current paper presents an empirical study involving 144 participants from three groups in Virginia, United States: local residents born and raised there (N=48), Chinese immigrants (N=48), and Vietnamese immigrants (N=48). All participants read local housing news with the assistance of the Copilot chatbot. We collected data on each participant’s Q&amp;A interactions with the chatbot, along with their takeaways from news reading. While engaging with the news content, participants in both immigrant groups asked the chatbot fewer analytical questions than the local group. They also demonstrated a greater tendency to rely on the chatbot when formulating practical takeaways. These findings offer insights into technology design that aims to serve diverse news readers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {253},
numpages = {20},
keywords = {News reading, Immigrants, Information seeking, Q&amp;A chatbot},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714063,
author = {Hullman, Jessica and Kale, Alex and Hartline, Jason},
title = {Decision Theoretic Foundations for Experiments Evaluating Human Decisions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714063},
doi = {10.1145/3706598.3714063},
abstract = {Decision-making with information displays is a key focus of research in areas like human-AI collaboration and data visualization. However, what constitutes a decision problem, and what is required for an experiment to conclude that decisions are flawed, remain imprecise. We present a widely applicable definition of a decision problem synthesized from statistical decision theory and information economics. We claim that to attribute loss in human performance to bias, an experiment must provide the information that a rational agent would need to identify the normative decision. We evaluate whether recent empirical research on AI-assisted decisions achieves this standard. We find that only 10 (26\%) of 39 studies that claim to identify biased behavior presented participants with sufficient information to make this claim in at least one treatment condition. We motivate the value of studying well-defined decision problems by describing a characterization of performance losses they allow to be conceived.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {254},
numpages = {15},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713295,
author = {Reicherts, Leon and Zhang, Zelun Tony and von Oswald, Elisabeth and Liu, Yuanting and Rogers, Yvonne and Hassib, Mariam},
title = {AI, Help Me Think—but for Myself: Assisting People in Complex Decision-Making by Providing Different Kinds of Cognitive Support},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713295},
doi = {10.1145/3706598.3713295},
abstract = {How can we design AI tools that effectively support human decision-making by complementing and enhancing users’ reasoning processes? Common recommendation-centric approaches face challenges such as inappropriate reliance or a lack of integration with users’ decision-making processes. Here, we explore an alternative interaction model in which the AI outputs build upon users’ own decision-making rationales. We compare this approach, which we call ExtendAI, with a recommendation-based AI. Participants in our mixed-methods user study interacted with both AIs as part of an investment decision-making task. We found that the AIs had different impacts, with ExtendAI integrating better into the decision-making process and people’s own thinking and leading to slightly better outcomes. RecommendAI was able to provide more novel insights while requiring less cognitive effort. We discuss the implications of these and other findings along with three tensions of AI-assisted decision-making which our study revealed.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {255},
numpages = {19},
keywords = {generative AI, human-AI interaction, AI-assisted decision-making, human-AI decision-making, investment decision-making},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713341,
author = {Chen, Si and Xie, Jingyi and Wang, Ge and Wang, Haizhou and Cheng, Haocong and Huang, Yun},
title = {From Scores to Careers: Understanding AI’s Role in Supporting Collaborative Family Decision-Making in Chinese College Applications},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713341},
doi = {10.1145/3706598.3713341},
abstract = {This study investigates how 18-year-old students, parents, and experts in China utilize artificial intelligence (AI) tools to support decision-making in college applications during college entrance exam- a highly competitive, score-driven, annual national exam. Through 32 interviews, we examine the use of Quark GaoKao, an AI tool that generates college application lists and acceptance probabilities based on exam scores, historical data, preferred locations, etc. Our findings show that AI tools are predominantly used by parents with limited involvement from students, and often focus on immediate exam results, failing to address long-term career goals. We also identify challenges such as misleading AI recommendations, and irresponsible use of AI by third-party consultant agencies. Finally, we offer design insights to better support multi-stakeholders’ decision-making in families, especially in the Chinese context, and discuss how emerging AI tools create barriers for families with fewer resources.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {256},
numpages = {20},
keywords = {GaoKao, Collaborative Decision-Making, Education Equity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713372,
author = {Wolf, Sara and Grundgeiger, Tobias and Z\"{a}hringer, Raphael and Shishkova, Lora and Maas, Franzisca and Dilling, Christina and Happel, Oliver},
title = {How a Clinical Decision Support System Changed the Diagnosis Process: Insights from an Experimental Mixed-Method Study in a Full-Scale Anesthesiology Simulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713372},
doi = {10.1145/3706598.3713372},
abstract = {Recent advancements in artificial intelligence have sparked discussions on how clinical decision-making can be supported. New clinical decision support systems (CDSSs) have been developed and evaluated through workshops and interviews. However, limited research exists on how CDSSs affect decision-making as it unfolds, particularly in settings such as acute care, where decisions are made collaboratively under time pressure and uncertainty. Using a mixed-method study, we explored the impact of a CDSS on decision-making in anesthetic teams during simulated operating room crises. Fourteen anesthetic teams participated in high-fidelity simulations, half using a CDSS prototype for comparative analysis. Qualitative findings from conversation analysis and quantitative results on decision-making efficiency and workload revealed that the CDSS changed team structure, communication, and diagnostic processes. It homogenized decision-making, empowered nursing staff, and introduced friction between analytical and intuitive thinking. We discuss whether these changes are beneficial or detrimental and offer insights to guide future CDSS design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {257},
numpages = {23},
keywords = {Clinical decision support system, acute care, anesthesiology, artificial intelligence, conversation analysis, decision-making process, high-fidelity simulation, teamwork},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713985,
author = {Paudel, Shreyasha and Loos, Sabine and Soden, Robert},
title = {Hype versus Historical Continuity: Situating the Rise of AI in Climate and Disaster Risk Modeling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713985},
doi = {10.1145/3706598.3713985},
abstract = {As governments increasingly adopt Artificial Intelligence (AI) across different application sectors, advocates argue that it will create new disruptions by democratizing access, improving accuracy, and lowering costs. In practice, uncritical adoption of AI tools has been shown to cause significant harms. Our study uses a historical lens to examine the uptake of AI in climate risk management through a study of climate and disaster risk modeling. These techniques originated in the insurance industry, but are now incorporated into many climate and disaster governance processes. Using the concept of ‘insurance logics’, we demonstrate that many of the original aspects of disaster risk modeling remain despite the transfer of risk assessment tools from the insurance industry to the public sector and new techniques made possible by AI. This highlights technological continuity, rather than disruption, as a key driver of contemporary risk modeling practice. Doing so helps to unsettle problematic, though challenging to identify, aspects of supposedly disruptive technologies and create possibilities for alternatives.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {258},
numpages = {17},
keywords = {History, Technological Evolution, Climate Risk, Disaster Risk Models, AI Hype, Responsible AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713534,
author = {de Brito Duarte, Regina and Abreu, M\'{o}nica Costa and Campos, Joana and Paiva, Ana},
title = {The Amplifying Effect of Explainability in AI-assisted Decision-making in Groups},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713534},
doi = {10.1145/3706598.3713534},
abstract = {In the era of artificial intelligence, AI-assisted decision-making has become a common paradigm. Explainable Artificial Intelligence has been one of the more explored factors in improving transparency of AI tools in AI-assisted decision-making, but sometimes with contradictory results. Furthermore, while individual AI-assisted decision-making has garnered substantial investigation, the domain of group AI-assisted decision-making remains notably underexplored. This research presents the first look at the impact of explainability and team composition on AI-assisted decision-making. With a controlled experiment on mushroom edibility classification, with 89 participants, we show that the impact of XAI is more pronounced in decision-making with groups (2-person) than in individual decision-making. Groups rely less on incorrect AI recommendations when explanations are available, but they rely more on incorrect AI recommendations when explanations are absent, compared to individual decision makers. This phenomenon underscores the amplified effect of explainability in AI-assisted decision-making in group settings.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {259},
numpages = {15},
keywords = {AI-Assisted Decision-Making, XAI, Groups Decision-Making, Human-AI Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713573,
author = {Tominaga, Tomu and Yamashita, Naomi and Kurashima, Takeshi},
title = {The Role of Initial Acceptance Attitudes Toward AI Decisions in Algorithmic Recourse},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713573},
doi = {10.1145/3706598.3713573},
abstract = {Algorithmic recourse provides counterfactual suggestions to individuals who receive unfavorable AI decisions; the aim is to help them understand the reasoning and guide future actions. While most research focuses on generating reasonable and actionable recourse, it often overlooks how individuals’ initial reactions to AI decisions influence their perceptions of subsequent recourses and their ultimate acceptance of the decision. To explore this, we conducted a user experiment (N = 534) simulating an automobile loan application scenario. Statistical analysis revealed that participants who initially reacted negatively to the AI decision perceived the recourse as less reasonable and actionable, reinforcing their negative attitudes. However, when the recourse was perceived as explaining decision criteria or proposing realistic action plans, participants’ attitudes shifted from negative to positive. These findings offer design implications for recourse systems that enhance the acceptance of individuals negatively affected by AI decisions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {260},
numpages = {20},
keywords = {Algorithmic Recourse, Counterfactual Explanation, XAI, Human-AI Decision Making},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713423,
author = {Ma, Shuai and Chen, Qiaoyi and Wang, Xinru and Zheng, Chengbo and Peng, Zhenhui and Yin, Ming and Ma, Xiaojuan},
title = {Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713423},
doi = {10.1145/3706598.3713423},
abstract = {Traditional AI-assisted decision-making systems often provide fixed recommendations that users must either accept or reject entirely, limiting meaningful interaction—especially in cases of disagreement. To address this, we introduce Human-AI Deliberation, an approach inspired by human deliberation theories that enables dimension-level opinion elicitation, iterative decision updates, and structured discussions between humans and AI. At the core of this approach is Deliberative AI, an assistant powered by large language models (LLMs) that facilitates flexible, conversational interactions and precise information exchange with domain-specific models. Through a mixed-methods user study, we found that Deliberative AI outperforms traditional explainable AI (XAI) systems by fostering appropriate human reliance and improving task performance. By analyzing participant perceptions, user experience, and open-ended feedback, we highlight key findings, discuss potential concerns, and explore the broader applicability of this approach for future AI-assisted decision-making systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {261},
numpages = {23},
keywords = {AI-Assisted Decision-making, Human-AI Collaboration, Deliberation, Appropriate Reliance, Large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713753,
author = {Kaplan, Daphna and Ben Chen, Mirela and Sterman, Yoav},
title = {ConTextural: A Toolpath-Based Texture Editing Tool for Extrusion 3D Printers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713753},
doi = {10.1145/3706598.3713753},
abstract = {Recently, there has been increased interest in design tools for creating textures using toolpath manipulation for extrusion-based 3D printers. Most tools are limited in their ability to edit existing 3D models and the variety of possible textures. Here, we present ConTextural, a design tool for adding texture to existing 3D models using toolpath manipulation. Using a coloring-based user interface, ConTextural allows users to draw textures on 3D models. Inspired by knitting structures, we introduce the concept of texture primitives, constructing texture structures that enable abundant possibilities for texture patterns. We include a curated texture library, enabling users to easily craft intricate and personalized designs. We assess the tool’s impact on users’ expressiveness, engagement, and satisfaction using a user study and demonstrate how it helps to produce uniquely distinct designs from a single 3D model. Additionally, we provide design examples highlighting functional applications for adding textures to existing 3D models.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {262},
numpages = {16},
keywords = {Design workflows, Creativity support tools, Creative expression, Unit structures, Fabrication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713225,
author = {Carreras, Barbara N. and Borsotti, Valeria},
title = {How Can We Change the System? Understanding and Addressing Redesign Inertia in Digital Public Services},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713225},
doi = {10.1145/3706598.3713225},
abstract = {Intersectional design research shows that the lack of decision-making power of marginalized communities in the design of digital public services perpetuates social injustice. Drawing on two ethnographic studies, we analyze two cases of structural inaccessibility grounded in audism and cisnormativity: the absence of closed captions and Danish sign language on the Danish Parliament's online TV, and gender binary input forms in Danish public sector job applications. Drawing on lessons learned from participating in complaint processes as researchers, we introduce the concept of redesign inertia as the institutional and structural mechanisms that reproduce discrimination and disempowerment in the maintenance of digital systems. We extend existing conceptualizations of inertia in sociotechnical systems by centering on how structural oppression shapes inaction. Drawing on critical access studies, we argue that user-centered and accessible complaint processes are essential elements of the co-design and maintenance of a digital infrastructure or public service promising digital inclusion.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {263},
numpages = {14},
keywords = {Accessibility, Audism, Cis-normativity, Non-binary},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713267,
author = {Di Lodovico, Chiara and Houben, Steven and Colombo, Sara},
title = {How to Design with Ambiguity: Insights from Self-tracking Wearables},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713267},
doi = {10.1145/3706598.3713267},
abstract = {Nearly 20 years ago, Gaver et al. introduced ambiguity as a design resource, proposing tactics to reflect everyday uncertainty into interactive systems. This approach is especially relevant for self-tracking wearables, which often obscure the inherent ambiguity of system design and tracked phenomena with seemingly clear, prescriptive data and insights. Although scholars recognize the importance of ambiguity, its practical application in the design process remains underexplored. To address this, we conducted a two-week workshop with 60 designers, examining the application of Gaver et al.’s tactics into 11 design concepts, and performed interviews with 16 participants. Our findings reveal eight relevant ambiguity tactics for self-tracking and offer insights into participants’ experiences with designing using ambiguity. We discuss prescription and overlooked ambiguity as levers for the operationalization of ambiguity, the potential benefits and downsides of ambiguity tactics for users, future directions for HCI research and practice, and the study limitations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {264},
numpages = {18},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713190,
author = {Zhang, Guanhua and Ahmed, Mohamed Adel Naguib and Hu, Zhiming and Bulling, Andreas},
title = {SummAct: Uncovering User Intentions Through Interactive Behaviour Summarisation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713190},
doi = {10.1145/3706598.3713190},
abstract = {Recent work has highlighted the potential of modelling interactive behaviour analogously to natural language. We propose interactive behaviour summarisation as a novel computational task and demonstrate its usefulness for automatically uncovering latent user goals while interacting with graphical user interfaces. We introduce SummAct&nbsp;– a novel hierarchical method to summarise low-level input actions into high-level goals to tackle this task. SummAct first identifies sub-goals from user actions using a large language model and in-context learning. In a second step, high-level goals are obtained by fine-tuning the model using a novel UI element weighting mechanism to preserve detailed context information embedded within UI elements during summarisation. Through a series of evaluations, we demonstrate that SummAct significantly outperforms baseline methods across desktop and mobile user interfaces and interactive tasks by up to 21.9\%. We further introduce two exciting example use cases enabled by our method: interactive behaviour forecasting and automatic behaviour synonym identification.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {265},
numpages = {17},
keywords = {Interactive behaviour, Goal recognition, Large language model, Next action prediction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714251,
author = {Krebs, Eva and Beckmann, Tom and Geier, Leonard and Grenda, Jonathan and Ramson, Stefan and Hirschfeld, Robert},
title = {All in One: Rapid Game Prototyping in a Single View},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714251},
doi = {10.1145/3706598.3714251},
abstract = {Creating games involves frequent prototyping to quickly obtain feedback. In this paper, we explore the impact of removing a traditional game engine’s separation of scene and game logic that supports scalability to large projects and, instead, combine scene and game logic in a single view. In our tool, Pronto, designers connect game objects with visual representations of behavior to define game logic in the scene view, thus exposing any concern of the prototype to the designer within one click. To explore the implications of the trade-off between scalability and speed of access, we conducted a cognitive walkthrough and an explorative user study comparing prototyping in the Godot game engine and in Pronto. Godot’s separate views made it appear more structured and reliable to users, while Pronto’s scattered game logic accelerated editing and gave users the impression of progressing faster in their implementation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {266},
numpages = {17},
keywords = {game programming, game prototyping, visual programming},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713734,
author = {Almeda, Shm Garanganao and Kim, Joy O and Hartmann, Bjoern},
title = {Creativity Supportive Ecosystems: A Framework for Understanding Function and Disruption in Online Art Worlds},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713734},
doi = {10.1145/3706598.3713734},
abstract = {The online art world is a double-edged sword: the Internet’s vibrant culture of open, cooperative art-sharing also attracts non-consensual reuse and appropriation. Artists continually navigate supportive and challenging interactions on social platforms, including community-shifting disruptions; the reuse of creative work for training generative AI is only the latest such disruption. Research into creativity support tools (CSTs) often centers artifact-making, leaving the HCI community with few strategies to understand the downstream impacts CSTs can make on artifact-sharing. Seeking a framework that captures this, we develop the creativity supportive ecosystem through interviews with 20 online artists, and 8 data “stewards” with experience reusing creative data for training GenAI. We use the CSE to describe how creative communities perceive and respond to disruption, identifying opportunities to empower artists in their collective negotiations with disruptive technologies like GenAI: by centering artists as producers of value, identifying creative and alternative data practices, and empowering inter-community flexibility.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {267},
numpages = {17},
keywords = {creativity support, social computing, AI impacts, art-making},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713186,
author = {Dove, Graham and Corbett, Eric},
title = {Design for Civic Quality of Life Things},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713186},
doi = {10.1145/3706598.3713186},
abstract = {This paper reports on inquiry into the design decisions that shape how quality of life issues are reported and government service requests managed in a large and densely populated city in the northeastern US. In particular, we reflect on research data collected over 5 years investigating chronic noise disturbance. Our findings highlight the effects of design choices associated with centralized, single-issue reporting and formal, standardized measures. We discuss how these design choices have broader impacts with regard to trust and transparency relations, and provide alternative inspirations for infrastructuring ongoing design in use by drawing on a model of contributory technology that offers new insight into social computing and creative participation at scale. This research contributes to HCI understanding of design for service interactions that is applicable to digital civics researchers, and can be translated to other contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {268},
numpages = {13},
keywords = {Digital Civics, Trust, Transparency, Meta-Design, Contributory Design, 311},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713399,
author = {Uriu, Daisuke and Arima, Shun},
title = {Designing Virtual Funerals as a Design Fiction: A Film-Based Exploration of Near-Future Memorial Rituals},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713399},
doi = {10.1145/3706598.3713399},
abstract = {This paper explores the design and future potential of virtual funerals, enabling both in-person and remote participation, with options to digitally revisit and update the memorial site. While virtual funerals gained prominence during the COVID-19 pandemic and are often seen as temporary, the authors argue that they hold long-term value across different contexts. To investigate future funeral practices, we created a Design Fiction film depicting our concept of virtual funerals in Japan using Diegetic Prototypes—hypothetical technologies that envision a future in which these practices are normalized. Key themes include hybrid attendance, virtual memorial spaces, and technologies that bridge in-person, remote, and revisiting participants. The authors and a professional crew created the film collaboratively to illustrate these speculative elements. This paper details the film’s production, its design rationale, and the broader implications for how HCI design and technology could shape future mourning and memorialization practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {269},
numpages = {19},
keywords = {Mourning, Memorialization, Remembrance, Death Ritual, Virtual Funeral, Spirituality, Thanatosensitivity, Design Fiction, Diegetic Prototype, Research through Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713479,
author = {Mei, Yihan and Wu, Zhao and Yu, Junnan and Li, Wenan and Zhou, Zhibin},
title = {GeneyMAP: Exploring the Potential of GenAI to Facilitate Mapping User Journeys for UX Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713479},
doi = {10.1145/3706598.3713479},
abstract = {Generative AI (GenAI) has been widely applied in UX design, yet its potential in the Journey Map (JM) creation process remains under-explored. We conducted a formative study (N = 24) to identify designers’ needs for GenAI in JM creation, resulting in six design goals (e.g., Acting as Different Stakeholders) implemented in our tool, GeneyMAP. GeneyMAP streamlines the JM creation process, allowing designers to map interview data efficiently with flexibility, uncovering design opportunities through visual inspiration. A subsequent user study (N = 20) demonstrated that GeneyMAP, compared with the common tool, accelerated JM creation and fostered creativity mainly by providing diverse inspirations and facilitating progressive discussions. Our findings proved GeneyMAP’s utility and effectiveness while challenges in maintaining control and trust in GenAI outputs were noted. Our research highlights the promising role of GenAI in refining JM creation practices and suggests implications for incorporating GenAI in JM and design workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {22},
keywords = {Generative AI, LLMs, Design Tool, UX Design, User Research, Journey Map},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713846,
author = {Pradhan, Alisha and Jelen, Ben and Thangaraj, Ramprabu and Siek, Katie A. and Jette, Shannon and Lazar, Amanda},
title = {Understanding Older Adults' (Dis)Engagement with Design Materials},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713846},
doi = {10.1145/3706598.3713846},
abstract = {Design workshops are a popular approach to include older adults in the technology design process. However, formative design sessions with older adults have had unexpected outcomes such as the non-use of traditional design materials like craft-based prototyping supplies or disengagement from design activities. Analyzing the engagement of 32 older adults across two design workshops, this paper sheds insights on some of these outcomes. Contributing to a growing body of HCI research on understanding older adults’ participation in design, we provide an understanding of how design materials can shape older adults’ engagement in formative design activities. Our discussion furthers research on understanding who older adults design for and why, argues for a different understanding of creative expression, and offers considerations for choosing design materials.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {271},
numpages = {17},
keywords = {Older adults, co-design, participatory design, design workshops, design materials},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713660,
author = {Shi, Yan and Gong, Lidan and Lu, Yiwen and Liu, Lijuan and Zhang, Chao and Zhang, Shujun and Wang, Longfei and Zhou, Shan},
title = {"I Need Your Help!" : Facilitating Psychological Communication Between Left-Behind Children and Their Parents with an AI-Powered Sandbox},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713660},
doi = {10.1145/3706598.3713660},
abstract = {In impoverished regions, limited resources, economic constraints, and low psychological health literacy among guardians often prevent timely support for children’s mental health. The absence of migrant worker parents further exacerbates these issues, as they remain unaware of their children’s psychological states. Existing AI advancements in psychological tools often overlook the specific needs of left-behind children and lack parental involvement. To address this, we developed DiSandbox, a low-cost AI-powered sandbox system that supports children in creating sandbox works for mental health assessments and engages parents in counseling. DiSandbox uses AI to guide children in sandbox play, analyze creations for psychological insights, and help parents understand their children’s mental health, enabling timely intervention. By integrating large language models with sandbox play, DiSandbox is a scalable, reliable, and accessible tool for home use. Qualitative and quantitative studies confirm its usability and provide guidance for future AI applications in children’s mental health.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {272},
numpages = {19},
keywords = {Sandbox game, Parent-child communication, Left-behind children, Psychological assessment tools, Mental health services},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713689,
author = {Holloway, Leona and Butler, Matthew and Waddell, Alex and Marriott, Kim},
title = {3D Printing for Accessible Education: A Case Study in Assistive Technology Adoption},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713689},
doi = {10.1145/3706598.3713689},
abstract = {3D printing is a mainstream technology enabling the affordable production of 3D models that may enhance access and understanding of graphics for students who are blind or have low vision (BLV). However, the potential usefulness of a new technology does not guarantee its adoption. This paper presents a case study in the adoption of 3D printing as an accessible format for BLV education in Australia and New Zealand. Over the last six years, a community-driven research project engaged in awareness raising, created a community of practice and developed guidelines for the use of 3D printing in education. We evaluate the success of the project using an Implementation Science lens with the RE-AIM framework and identify the key factors for successful adoption. We hope this work will guide the adoption of 3D printing for BLV students and serve as an exemplar for the adoption of other assistive technologies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {273},
numpages = {19},
keywords = {blind, low vision, 3D printing, Implementation Science, assistive technology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713670,
author = {Glazko, Kate and Cha, JunHyeok and Lewis, Aaleyah and Kosa, Ben and Wimer, Brianna L and Zheng, Andrew and Zheng, Yiwei and Mankoff, Jennifer},
title = {Autoethnographic Insights from Neurodivergent GAI “Power Users”},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713670},
doi = {10.1145/3706598.3713670},
abstract = {Generative AI (AI) has become ubiquitous in both daily and professional life, with emerging research demonstrating its potential as a tool for accessibility. Neurodivergent people, often left out by existing accessibility technologies, develop their own ways of navigating normative expectations. GAI offers new opportunities for access, but it is important to understand how neurodivergent “power users”—successful early adopters—engage with it and the challenges they face. Further, we must understand how marginalization and intersectional identities influence their interactions with GAI. Our autoethnography, enhanced by privacy-preserving GAI-based diaries and interviews, reveals the intricacies of using GAI to navigate normative environments and expectations. Our findings demonstrate how GAI can both support and complicate tasks like code-switching, emotional regulation, and accessing information. We show that GAI can help neurodivergent users to reclaim their agency in systems that diminish their autonomy and self-determination. However, challenges such as balancing authentic self-expression with societal conformity, alongside other risks, create barriers to realizing GAI’s full potential for accessibility.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {274},
numpages = {19},
keywords = {auto-ethnography; generative artificial intelligence; accessibility; neurodivergent people; intersectionality; stigma},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713117,
author = {Bircanin, Filip and Sitbon, Laurianne and Hoogstrate, Maria and Abbas, Ahmed K. and Hajizadeh Saffar, Alieh and Brereton, Margot},
title = {Beyond the Buckets of Support: Designing for Agency and Interaction in Personalised Disability Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713117},
doi = {10.1145/3706598.3713117},
abstract = {Social care systems are increasingly adopting personalisation schemes that empower individuals with disabilities and their families to directly purchase services,from assistive technologies to daily living support. Central to this shift are institutions like the National Disability Insurance Scheme, where annual negotiations shape care delivery and social benefits. Drawing on interviews with parents of children with intellectual disabilities, individuals with intellectual disabilities, service managers – alongside the use of a technology probe – this paper examines the communication dynamics within these planning processes, identifying critical design opportunities. We explore the issues of communication control, obscured agency, and tokenistic engagement that arise in bureaucratic support planning. As a contribution, we highlight the barriers and facilitators reshaping these interactions, offering key implications for future design interventions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {275},
numpages = {19},
keywords = {Accessibility, people with intellectual disabilities, public services, disability benefits, civic design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713438,
author = {Wei, Yize and Rocher, Nathan and Gupta, Chitralekha and Nguyen, Mia Huong and Zimmermann, Roger and Ooi, Wei Tsang and Jouffrais, Christophe and Nanayakkara, Suranga},
title = {Human Robot Interaction for Blind and Low Vision People: A Systematic Literature Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713438},
doi = {10.1145/3706598.3713438},
abstract = {Recent years have witnessed a growing interest in using robots to support Blind and Low Vision (BLV) people in various tasks and contexts. However, the Human-Computer Interaction (HCI) community still lacks a shared understanding of what, where, and how robots can benefit BLV users in their daily lives. In light of this, we conducted a systematic literature review to help researchers navigate the current landscape of this field through an HCI lens. We followed a systematic multi-stage approach and carefully selected a corpus of 76 papers from premier HCI venues. Our review provides a comprehensive overview of application areas, embodiments, and interaction techniques of the developed robotic systems. Further, we identified opportunities, challenges, and key considerations in this emerging field. Through this systematic review, we aim to inspire researchers, developers, designers, and HCI practitioners, to create a more inclusive environment for the BLV community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {276},
numpages = {19},
keywords = {Human-robot Interaction, People with Visual Impairments, Assistive Technology, Systematic review},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714000,
author = {Bircanin, Filip and Nevsky, Alexandre and Perera, Himaya and Agarwal, Vaasvi and Song, Eunyeol and Cruice, Madeline and Neate, Timothy},
title = {Sounds Accessible: Envisioning Accessible Audio-Media Futures with People with Aphasia},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714000},
doi = {10.1145/3706598.3714000},
abstract = {Audio-media, such as radio and podcasts, are a vital means to engage with global events, access education, or offer entertainment. However, for people with complex communication needs, such as aphasia, there can be accessibility challenges. While accessibility research has largely focused on audiovisual media, little work has considered audio-media, particularly for users with complex communication needs. To address this gap, we undertook six co-design workshops with 10 people with aphasia to re-imagine access to audio-media. We uncover how our co-designers perceive audio-media as more than a tool, but a part of daily intimacies; shaping social relationships and contributing to therapeutic recovery. Through a Research-through-Design process culminating in one low-fidelity and three high-fidelity technology probes that embody novel accessibility interventions, our findings further challenge conventional approaches to audio-media accessibility and signal new directions for future design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {277},
numpages = {22},
keywords = {Accessibility, audiovisual, media, aphasia, complex communication needs, envisioning, probes, prototype},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713855,
author = {Zhang, Han and Shalev-Arkushin, Rotem and Baltatzis, Vasileios and Gillis, Connor and Laput, Gierad and Kushalnagar, Raja and Quandt, Lorna C and Findlater, Leah and Bedri, Abdelkareem and Lea, Colin},
title = {Towards AI-driven Sign Language Generation with Non-manual Markers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713855},
doi = {10.1145/3706598.3713855},
abstract = {Sign languages are essential for the Deaf and Hard-of-Hearing (DHH) community. Sign language generation systems have the potential to support communication by translating from written languages, such as English, into signed videos. However, current systems often fail to meet user needs due to poor translation of grammatical structures, the absence of facial cues and body language, and insufficient visual and motion fidelity. We address these challenges by building on recent advances in LLMs and video generation models to translate English sentences into natural-looking AI ASL signers. The text component of our model extracts information for manual and non-manual components of ASL, which are used to synthesize skeletal pose sequences and corresponding video frames. Our findings from a user study with 30 DHH participants and thorough technical evaluations demonstrate significant progress and identify critical areas necessary to meet user needs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {278},
numpages = {26},
keywords = {Sign language generation, assistive technology, accessibility, human-centered design, DHH community},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713908,
author = {Lee, Jiwan and Jeong, Dawoon and Han, Sung H. and Choi, Seungmoon},
title = {Automatic Tuning of Haptic Motion Effects to Evoke Specific Feelings in Multisensory Content},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713908},
doi = {10.1145/3706598.3713908},
abstract = {Automating the authoring of haptic motion effects, while enabling designers to carefully consider user feelings to provide high-quality user experiences, is crucial for effective multisensory content. We present a motion effect-tuning method that elicits desired perceptual or affective attributes from users watching a video. To this end, we test three modulation methods: (1) Altering the extent of low-frequency motion fluctuations, (2) Changing the motion amplitude in a high-frequency band, and (3) Sampling and interpolating significant motion peaks. Our tuning method transforms an input draft waveform using the modulation techniques to obtain an output motion effect that elicits the goal adjective scores. This method requires two regression models accounting for the effects of motion modulation and audiovisual stimuli, respectively, and we obtain them by conducting perceptual experiments. Lastly, we confirm the method’s effectiveness through another user study and explore potential users’ feedback and suggestions for future applications through open-ended survey questions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {279},
numpages = {19},
keywords = {Affect Elicitation, Motion Modulation, Haptic Effect, Vestibular Sensation, Adjective Rating, Regression Modeling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714077,
author = {Sasalovici, Markus and Zeqiri, Albin and Schramm, Robin Connor and Ariza Nunez, Oscar Javier and Jansen, Pascal and Freiwald, Jann Philipp and Colley, Mark and Winkler, Christian and Rukzio, Enrico},
title = {Bumpy Ride? Understanding the Effects of External Forces on Spatial Interactions in Moving Vehicles},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714077},
doi = {10.1145/3706598.3714077},
abstract = {As the use of Head-Mounted Displays in moving vehicles increases, passengers can immerse themselves in visual experiences independent of their physical environment. However, interaction methods are susceptible to physical motion, leading to input errors and reduced task performance. This work investigates the impact of G-forces, vibrations, and unpredictable maneuvers on 3D interaction methods. We conducted a field study with 24 participants in both stationary and moving vehicles to examine the effects of vehicle motion on four interaction methods: (1) Gaze&amp;Pinch, (2) DirectTouch, (3) Handray, and (4) HeadGaze. Participants performed selections in a Fitts’ Law task. Our findings reveal a significant effect of vehicle motion on interaction accuracy and duration across the tested combinations of Interaction Method \texttimes{} Road Type \texttimes{} Curve Type. We found a significant impact of movement on throughput, error rate, and perceived workload. Finally, we propose future research considerations and recommendations on interaction methods during vehicle movement.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {280},
numpages = {28},
keywords = {in-car, Mixed Reality, augmented reality, automotive, interaction, human factors, field study, machine learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713123,
author = {Patnaik, Biswaksen and Borowski, Marcel and Peng, Huaishu and Klokmose, Clemens Nylandsted and Elmqvist, Niklas},
title = {Datamancer: Bimanual Gesture Interaction in Multi-Display Ubiquitous Analytics Environments},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713123},
doi = {10.1145/3706598.3713123},
abstract = {We introduce Datamancer, a wearable device enabling bimanual gesture interaction across multi-display ubiquitous analytics environments. Datamancer addresses the gap in gesture-based interaction within data visualization settings, where current methods are often constrained by limited interaction spaces or the need for installing bulky tracking setups. Datamancer integrates a finger-mounted pinhole camera and a chest-mounted gesture sensor, allowing seamless selection and manipulation of visualizations on distributed displays. By pointing to a display, users can acquire the display and engage in various interactions, such as panning, zooming, and selection, using both hands. Our contributions include (1) an investigation of the design space of gestural interaction for physical ubiquitous analytics environments; (2) a prototype implementation of the Datamancer system that realizes this model; and (3) an evaluation of the prototype through demonstration of application scenarios, an expert review, and a user study.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {281},
numpages = {15},
keywords = {Gestural interaction, ubiquitous analytics, immersive analytics, Augmented Reality, visualizations, situated analytics.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713815,
author = {Muehlhaus, Marie and Liggesmeyer, Alexander and Steimle, J\"{u}rgen},
title = {ExoKit: A Toolkit for Rapid Prototyping of Interactions for Arm-based Exoskeletons},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713815},
doi = {10.1145/3706598.3713815},
abstract = {Exoskeletons open up a unique interaction space that seamlessly integrates users’ body movements with robotic actuation. Despite its potential, human-exoskeleton interaction remains an underexplored area in HCI, largely due to the lack of accessible prototyping tools that enable designers to easily develop exoskeleton designs and customized interactive behaviors. We present ExoKit, a do-it-yourself toolkit for rapid prototyping of low-fidelity, functional exoskeletons targeted at novice roboticists. ExoKit&nbsp;includes modular hardware components for sensing and actuating shoulder and elbow joints, which are easy to fabricate and (re)configure for customized functionality and wearability. To simplify the programming of interactive behaviors, we propose functional abstractions that encapsulate high-level human-exoskeleton interactions. These can be readily accessed either through ExoKit’s command-line or graphical user interface, a Processing library, or microcontroller firmware, each targeted at different experience levels. Findings from implemented application cases and two usage studies demonstrate the versatility and accessibility of ExoKit&nbsp;for early-stage interaction design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {282},
numpages = {17},
keywords = {Exoskeleton; interactions; toolkit; rapid prototyping; fabrication; DIY; augmented human.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713474,
author = {Vatavu, Radu-Daniel and Gheran, Bogdan-Florin},
title = {Intermanual Deictics: Uncovering Users' Gesture Preferences for Opposite-Arm Referential Input, from Fingers to Shoulder},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713474},
doi = {10.1145/3706598.3713474},
abstract = {We examine intermanual deictics, a distinctive class of gesture input characterized by an intermanual structure, asymmetric postural-manipulative articulation, and a deictic nature, drawing from both on-skin and bimanual mid-air gestures. To understand user preferences for gestures featuring these characteristics, we conducted a large-sample end-user elicitation study with 75 participants, who proposed intermanual deictics involving the opposite palm, forearm, and upper arm. Our results reveal a strong preference for physical-contact gestures primarily performed with the index finger, with strokes (62.4\%) and touch input (28.8\%) being most common, complemented by some preference for non-contact gestures (5.2\%). We report similar agreement rates across gestures elicited in the three arm regions, averaging 26.3\%, with higher agreement between the forearm and upper arm. We also present a consensus set of sixty gestures for effecting generic commands in interactive systems, along with design principles encompassing multiple practical implications for interactions that incorporate intermanual deictics.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {283},
numpages = {16},
keywords = {Gesture input, touch input, on-body interaction, body-referential input, intermanual gestures, gesture elicitation, gesture analysis, gesture set, bimanual gestures, design guidelines},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713325,
author = {Breda, Joseph and Chen, Keyu and Pl\"{o}tz, Thomas and Patel, Shwetak},
title = {ProxiCycle: Passively Mapping Cyclist Safety Using Smart Handlebars for Near-Miss Detection},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713325},
doi = {10.1145/3706598.3713325},
abstract = {Active transportation is a valuable tool to prevent some of the most common causes of mortality worldwide, but is severely underutilized. The primary factors preventing cyclist adoption are safety concerns, specifically, the fear of collision from automobiles. One solution to address this concern is to direct cyclists to known safe routes to minimize risk and stress, thus making cycling more approachable. However, few localized safety priors are available, hindering safety based routing. Specifically, road user behavior is unknown. To address this issue, we develop a novel handlebar attachment to passively monitor the proximity of passing cars as a an indicator of cycling safety along historically traveled routes. We deploy this sensor with 15 experienced cyclists in a 2 month longitudinal study to source a citywide map of car passing distance. We then compare this signal to both historic collisions and perceived safety reported by experienced and inexperienced cyclists.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {284},
numpages = {19},
keywords = {Smartphone, Bicycle, Urban Sensing, Mobile Sensing, Transportation, Safety, Public Health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713361,
author = {Lin, Hongnan and Gao, Lei and Jiang, Shengsheng and Yue, Hongyu and Fu, Ziyi and Luo, Jinyi and Wu, Chengxiao and Han, Teng and Tian, Feng and Subramanian, Sriram},
title = {Slip-Grip: An Electrotactile Method to Simulate Weight},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713361},
doi = {10.1145/3706598.3713361},
abstract = {Weight perception is crucial for immersive virtual reality (VR) interactions, yet providing weight feedback remains a significant research challenge. We introduce a novel weight simulation technique that leverages electrotactile stimulation to induce slip illusions. These slip illusions occur when users grip an object with less force than a predefined threshold, allowing the device to modulate the grip force and encourage a tighter grip. In our approach, heavier virtual weights correspond to higher required grip forces. We conducted a series of user experiments to validate our technique, confirming that it effectively induces slip illusions. We also investigated the relationship between electrotactile sensations and grip force, and changes in force, demonstrating that this association enhances the weight perception experience. Lastly, we explored the mapping between grip force and perceived weight, observing strong linearity within participants but notable variability between individuals.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {285},
numpages = {14},
keywords = {Weight simulation, Electrotactile, Haptic, Virtual reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713193,
author = {Curtis, Humphrey and Beneteau, Erin and Cutrell, Edward and Ford, Denae and Junuzovic, Sasa and Paradiso, Ann and Tang, John and Mott, Martez E},
title = {"I use video calling in all areas of my life": Understanding the Video Calling Experiences of Chronically Ill People},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713193},
doi = {10.1145/3706598.3713193},
abstract = {Since the Covid-19 pandemic, video calling (VC) has become a staple means of daily communication. Beyond socializing, VC in the United States (U.S.) now supports remote work, healthcare and education. The sudden ubiquity of VC could have presented both advantages and challenges for chronically ill people. However, our understanding of chronically ill people’s experiences with VC remains limited. To address this gap, we conducted the largest online survey study (N=55) on chronically ill people’s VC experiences in the U.S.—investigating their routines, facilitators and barriers. Our quantitative and qualitative findings established that chronically ill people heavily depend on VC to cope with everyday life. At the same time, VC can also detrimentally exacerbate cognitive (e.g., brain fog), emotional (e.g., self-consciousness) and physical challenges (e.g., migraines) for chronically ill people. In response, we offer actionable design opportunities to improve the accessibility and experience of VC for chronically ill people.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {286},
numpages = {22},
keywords = {Chronic illness; accessibility; survey; videoconferencing.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713994,
author = {Patel, Dilisha and Osipova, Ekat and Spiel, Katta and Barbareschi, Giulia},
title = {A Critical Review of Sexuality, Technology and Disability},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713994},
doi = {10.1145/3706598.3713994},
abstract = {The investigation of technologies facilitating sexual interactions and sexuality-related explorations is becoming more established in Human-Computer Interaction (HCI), albeit with little systematic attention to the sexual lives of disabled people. In this space, we undertook a literature review utilising feminist content analysis to take stock and critically analyse the domains of sexuality, technology and disability when they intersect. Our approach aligns with the broader goals of promoting inclusivity, diversity, and equity in technology design and application. We present a descriptive and analytical outline of existing research on sexuality, technology and disability through which we identified unmarked norms governing research. These include a focus on individualised technologies oriented on heteronormative assumptions on sexual desires. In addition, we focus on common methods employed and describe the involvement, or lack thereof, of disabled people in research practice. This highlights gaps in our collective knowledge from which we can derive areas for future work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {287},
numpages = {20},
keywords = {Disability, Sexuality, Technology, Critical Review, Inclusivity, Access},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713563,
author = {Jamshed, Hira and Nurain, Novia and Brewer, Robin N.},
title = {Designing Accessible Audio Nudges for Voice Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713563},
doi = {10.1145/3706598.3713563},
abstract = {Older adults (65+) increasingly use voice assistants for information-seeking, but experience challenges and uncertainty in assessing information quality due to limited visual cues. HCI researchers have primarily used nudging, subtle approaches to guide users towards better decision-making, in visual interfaces to mitigate online misinformation and facilitate critical thinking. Thus, we extend nudging to voice-based systems to help older adults alleviate uncertainty in voice-based searches. We evaluate four audio nudge prototypes (i.e., non-speech and speech-based) with older adults (n = 34). Findings show that speech nudges more effectively prompt critical reflection than non-speech nudges because they are more disruptive. We discuss the significance of these findings for designing accessible audio nudges, highlighting the tension between disruption and accessibility best practices. Further, we propose that effective audio nudges should be explanatory and interactive to help older adults mitigate information uncertainty and raise open questions for the community about designing reflective nudges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {288},
numpages = {16},
keywords = {Older Adults, Nudging, Voice Technologies, Information Uncertainty, Accessibility},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714241,
author = {Zhao, Jing and Neto, Isabel and Pires, Ana Cristina and Tom\'{e}-Pires, Catarina and Nicolau, Hugo},
title = {Digital Technologies for Deaf and Hard of Hearing Children: a Systematic Review, Critical Reflections, and Future Research Directions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714241},
doi = {10.1145/3706598.3714241},
abstract = {Digital technologies in Human-Computer Interaction (HCI) have the potential to support the development and well-being of Deaf and Hard of Hearing (DHH) children. Yet, there has yet to be a systematic review of the field. A shared understanding of current research is needed to develop a future vision. In this review, we analyzed 42 papers from the ACM Digital Library and the top 20 HCI Conferences and Journals, spanning the past 24 years, to investigate the trends, methods, and the level of inclusion of DHH children. Our review reveals that sign language learning platforms dominate the current technological effort. Moreover, children are not yet fully involved in the design process of these technologies and are mostly considered users and testers.We also capture a gap in integrating Deaf culture and child development in prior research. We conclude by critically examining literature gaps and offering guidance for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {289},
numpages = {19},
keywords = {Deaf and hard of hearing, Children, Systematic review, Accessibility},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713899,
author = {Zhou, Min and Peng, Xiaolan and Liu, Binjie and Denisova, Alena and Barathi, Soumya C. and Li, Zhuying and Xie, Xurong and Huang, Jin and Tian, Feng},
title = {Emotionally Challenging Games Can Satisfy Older Adults' Psychological Needs: From Empirical Study to Design Guidelines},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713899},
doi = {10.1145/3706598.3713899},
abstract = {Older adults often struggle to meet their psychological needs due to retirement and living alone. Recent studies suggest that games featuring emotional challenge (EC) can help fulfill basic psychological needs such as autonomy, competence, and relatedness by facilitating emotional exploration. However, it remains unclear whether older adults can benefit from EC games, whether they find this genre enjoyable, and how these games should be designed to better meet their needs. This work explores older adults’ experiences and perceptions of playing EC games through two studies. The first study involved playing Detroit: Become Human, revealing that older adults derived multifaceted psychological experiences from playing the game. The second study involved a custom-designed game scenario tailored to older adults, demonstrating that meaningful choices significantly influenced autonomy need satisfaction. Based on these findings, we offer five design guidelines for developing EC games that satisfy psychological needs of older adults.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {290},
numpages = {19},
keywords = {Older Adults, Psychological Need Satisfaction, Emotional Challenge, Design Guidelines, Video Games},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713427,
author = {Dai, Jiamin and McGrenere, Joanna},
title = {Envisioning Financial Technology Support for Older Adults Through Cognitive and Life Transitions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713427},
doi = {10.1145/3706598.3713427},
abstract = {Financial technology (fintech), including online banking and digital payments, can facilitate or hinder participation in financial activities. Current fintech support for older adults, notably delegation to close others, inadequately accommodates their cognitive strengths and life transitions. To envision fintech support for age-related cognitive diversity in a rapidly changing fintech landscape, we engaged 17 older adults, five family members, and five professionals in co-creating and critiquing personas, scenarios, and design concepts through interviews and group discussions. Our thematic analysis uncovers interrelated social factors and financial management collaborations across inner and outer circles, highlighting the importance of preparedness for transitions, long-term safeguarding, and short-term fail-safes. From these insights, we propose design avenues for layered fintech support networks across close and distant others, situated meta-design for mutual fintech support, and personalized fintech “first aid.” We urge HCI communities to collectively design holistic approaches to a fintech support ecosystem for aging and accessibility.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {291},
numpages = {24},
keywords = {Financial technology (fintech), online banking, digital payment, financial management, older adult, cognitive accessibility},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713202,
author = {Suchanek, Oliver and Meissner, Janis Lena and Angelini, Robin and Spiel, Katta},
title = {From Participation to Solidarity: A Case Study on Access of Maker Spaces from Deaf and Hearing Perspectives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713202},
doi = {10.1145/3706598.3713202},
abstract = {This submission is an edited translation of an article previously published in German.Participatory methods open up research in Human-Computer Interaction (HCI) that aim at involving populations that are not traditionally represented. However, they do not require researchers to actively reflect on power relationships as would be required when aiming for transformative impact. In our case study of MACH’S AUF!&nbsp;, we show how research on accessibility of makerspaces for deaf people allowed us to develop a methodological concept of solidarity driven research that extends classical concepts of participation. We show how access to makerspaces has to be understood first and foremost as structured in a socio-technical manner, where communicative access for deaf people has to be provided through sign language. Our work provides a nuanced understanding of what access to makerspaces might entail from a marginalised perspective, as well as a methodological positionality that may support transformative research endeavours in the future.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {292},
numpages = {15},
keywords = {Makerspaces, Access, Deaf People, Participation, Solidarity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713496,
author = {Xu, Shuchang and Jin, Xiaofu and Qu, Huamin and Yan, Yukang},
title = {DanmuA11y: Making Time-Synced On-Screen Video Comments (Danmu) Accessible to Blind and Low Vision Users via Multi-Viewer Audio Discussions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713496},
doi = {10.1145/3706598.3713496},
abstract = {By overlaying time-synced user comments on videos, Danmu creates a co-watching experience for online viewers. However, its visual-centric design poses significant challenges for blind and low vision (BLV) viewers. Our formative study identified three primary challenges that hinder BLV viewers’ engagement with Danmu: the lack of visual context, the speech interference between comments and videos, and the disorganization of comments. To address these challenges, we present DanmuA11y, a system that makes Danmu accessible by transforming it into multi-viewer audio discussions. DanmuA11y incorporates three core features: (1) Augmenting Danmu with visual context, (2) Seamlessly integrating Danmu into videos, and (3) Presenting Danmu via multi-viewer discussions. Evaluation with twelve BLV viewers demonstrated that DanmuA11y significantly improved Danmu comprehension, provided smooth viewing experiences, and fostered social connections among viewers. We further highlight implications for enhancing commentary accessibility in video-based social media and live-streaming platforms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {293},
numpages = {22},
keywords = {Visual Impairment, Blind, Low Vision, Video, Social Media, Danmaku, Danmu, Bullet Comment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713706,
author = {Nagassa, Ruth Galan and Pham, Andre Ky and Butler, Matthew and Holloway, Leona and Stefanov, Kalin and de Vent, Skye and Marriott, Kim},
title = {Enhancing Tactile Learning: A Co-Designed System for Supporting Speech Interaction with Multi-Part 3D Printed Models by Students who are Blind},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713706},
doi = {10.1145/3706598.3713706},
abstract = {3D printed models (3DPMs) are increasingly used to support the education of students who are blind or have low vision (BLV). As 3DPMs are more widely-adopted, educators are using more complex multi-part models. However, with this increased complexity comes additional challenges for their use, such as supporting audio labels of multiple parts as well as guiding the assembly and disassembly of the model. This work explores the co-design and evaluation of a system that supports the use of multi-part 3DPMs by BLV students. Working with BLV adults and children, as well as educators, an iPad application was developed to support interaction with an insect model, including speech interaction and support for assembly. Evaluation showed that the system was strongly enjoyed by students and educators were enthusiastic as they believed it would increase classroom engagement and inclusion, and its support for voice annotation could be used for assessment.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {294},
numpages = {18},
keywords = {Accessibility, 3D printed models, computer vision, blind, low vision, education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713486,
author = {Mathis, Florian and Sch\"{o}ning, Johannes},
title = {LifeInsight: Design and Evaluation of an AI-Powered Assistive Wearable for Blind and Low Vision People Across Multiple Everyday Life Scenarios},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713486},
doi = {10.1145/3706598.3713486},
abstract = {Assistive technologies (ATs) have the potential to empower blind and low vision (BLV) people. Yet, they often remain underutilised due to their immobility and limited applicability across scenarios. This paper presents LifeInsight, an AI-powered assistive wearable&nbsp;for BLV people&nbsp;that uses a wearable camera, microphone and single-click interface for goal-oriented visual querying. To inform the design of LifeInsight, we first collected a corpus of BLV people’s daily experiences using video probes and interviews. Ten BLV people&nbsp;recorded their daily experiences over one week using GoPro cameras, providing empirical insights. Based on these, we report on LifeInsight&nbsp;and its evaluation with 13 BLV people&nbsp;across six scenarios. LifeInsight&nbsp;effectively responded to visual queries, such as distinguishing between jars or identifying the status of a candle. Drawing on our work, we conclude with key lessons and practical recommendations to guide future research and advance the development and evaluation of AI-powered assistive wearables.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {295},
numpages = {25},
keywords = {Assistive Technologies, Wearables, BLV People},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713298,
author = {Lu, Leon and Crispin, Chase and Piao, Ziyue and Eze-Anyanwu, Aino and Girouard, Audrey},
title = {Project TapTap: A Longitudinal Study Exploring Non-Verbal Communication through Vibration Signals Between Teachers and Blind or Low Vision Music Learners},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713298},
doi = {10.1145/3706598.3713298},
abstract = {While wearable haptics hold promise for making non-verbal cues like gestures and facial expressions accessible to blind or low-vision musicians, our understanding of how vibration signals can be interpreted and applied in real-world learning environments remains limited. We invited five music teachers and their seven students to participate in a ten-week longitudinal study involving observations, weekly catch-ups, group discussions, and interviews. We explored how wearable haptics could facilitate communication between sighted teachers and BLV students during one-on-one music lessons. We found that students and teachers derived particular meanings from vibration signals, including time-coded meaning, mutually agreed and intuitive meaning, and haptic metaphors. Additionally, wearable haptics significantly improved the experience of learning music for both sighted teachers and BLV students. We conclude by highlighting key design implications and outlining future research directions to create wearable haptics that significantly improve the music learning experience of BLV people.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {296},
numpages = {15},
keywords = {Blind and Low Vision Music Learning, Assistive Technologies, Vibrotactile Feedback, Musical haptic wearables, Material Experiences, Material Aesthetics, User Experience Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714329,
author = {Mo, Ye and Huang, Gang and li, liangcheng and Deng, Dazhen and Yu, Zhi and Xu, Yilun and Ye, Kai and Zhou, Sheng and Bu, Jiajun},
title = {TableNarrator: Making Image Tables Accessible to Blind and Low Vision People},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714329},
doi = {10.1145/3706598.3714329},
abstract = {The widespread use of image tables presents significant accessibility challenges for blind and low vision (BLV) people, limiting their access to critical data. Despite advancements in artificial intelligence (AI) for interpreting image tables, current solutions often fail to consider the specific needs of BLV users, leading to a poor user experience. To address these issues, we introduce TableNarrator, an innovative system designed to enhance the accessibility of image tables. Informed by accessibility standards and user feedback, TableNarrator leverages AI to generate alternative text tailored to the cognitive and reading preferences of BLV users. It streamlines access through a simple interaction mode and offers personalized options. Our evaluations, from both technical and user perspectives, demonstrate that TableNarrator not only provides accurate and comprehensive table information but also significantly enhances the user experience for BLV people.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {297},
numpages = {17},
keywords = {Accessibility, Assistive Technology, Screen Reader, Image Tables, Computer Vision, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713847,
author = {Chen, Ruijia and Jiang, Junru and Maheshwary, Pragati and Cochran, Brianna R and Zhao, Yuhang},
title = {VisiMark: Characterizing and Augmenting Landmarks for People with Low Vision in Augmented Reality to Support Indoor Navigation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713847},
doi = {10.1145/3706598.3713847},
abstract = {Landmarks are critical in navigation, supporting self-orientation and mental model development. Similar to sighted people, people with low vision (PLV) frequently look for landmarks via visual cues but face difficulties identifying some important landmarks due to vision loss. We first conducted a formative study with six PLV to characterize their challenges and strategies in landmark selection, identifying their unique landmark categories (e.g., area silhouettes, accessibility-related objects) and preferred landmark augmentations. We then designed VisiMark, an AR interface that supports landmark perception for PLV by providing both overviews of space structures and in-situ landmark augmentations. We evaluated VisiMark with 16 PLV and found that VisiMark enabled PLV to perceive landmarks they preferred but could not easily perceive before, and changed PLV’s landmark selection from only visually-salient objects to cognitive landmarks that are more important and meaningful. We further derive design considerations for AR-based landmark augmentation systems for PLV.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {298},
numpages = {20},
keywords = {Accessibility, Virtual/Augmented Reality, Individuals with Disabilities \&amp; Assistive Technologies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714290,
author = {Bell, Fiona and Friedman-Gerlicz, Camila and Urenda, Lauren and Buechley, Leah},
title = {3D Printing Eggshells: Exploring Eco-Socio-Technical Relations through Biomaterial Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714290},
doi = {10.1145/3706598.3714290},
abstract = {In response to ongoing environmental crises, the digital fabrication community within HCI has recently begun to design with biomaterials. Biomaterials and their corresponding practices carry eco-socio-technical relations that shape the creation of more sustainable futures. From this perspective, we present three entangled contributions: (1) a new, easy-to-make, 3D printable eggshell biomaterial, (2) a circular, material-centered practice for designing with the eggshell biomaterial, and (3) a reflection on the eco-socio-technical relations that the eggshell biomaterial and corresponding biomaterial practice reveal. We outline our design process for sourcing ingredients, developing a recipe, 3D printing artifacts, characterizing properties, and testing disposal methods. Through five provocative applications, we critically reflect on how our eggshell biomaterial practice surfaces unique eco-socio-technical relations. We envision this eggshell biomaterial extending the current material library for 3D printing and promoting circular digital fabrication practices, while also highlighting the importance of ecological awareness and community engagement in designing for sustainability.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {299},
numpages = {19},
keywords = {Biomaterials; Bio-HCI; Biodesign; 3D Printing; Digital Fabrication; Materiality; Sustainability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713159,
author = {Silva Lovato, Monica and Suina, Jeff and Tso, Jared and Kaminsky, Alexis and Friedman-Gerlicz, Camila and Buechley, Leah},
title = {American Indian Pottery and Clay 3D Printing: An Exploration of Opportunities and Risks in Professional Practice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713159},
doi = {10.1145/3706598.3713159},
abstract = {We describe an artist residency program in which three professional American Indian potters experiment with the use of clay 3D printing in their practice. The artists navigate the opportunities and risks involved in blending 3D printing with Pueblo pottery. In our analysis, we introduce and examine three aspects of digital fabrication that impact professional practice: the practical, creative and conceptual. Practically, a digital fabrication machine may improve or worsen efficiency. Creatively, a machine can both expand and constrain the kinds of work artists can make. Finally, a machine can be conceptually significant; the use of the machine can change what a piece means and how it is perceived. We found that clay 3D printers: 1) are labor intensive to operate and do not improve efficiency; 2) can present new and compelling creative opportunities; 3) are conceptually fraught. The use of a 3D printer can profoundly change the way work is received and valued. We discuss the entangled mix of opportunity and risk that these aspects of clay 3D printing present.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {300},
numpages = {23},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714031,
author = {Friedman-Gerlicz, Camila and Gould, Jaime and Bell, Fiona and Buechley, Leah},
title = {ColdGlass: Full-Color Desktop 3D Printing in Glass},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714031},
doi = {10.1145/3706598.3714031},
abstract = {ColdGlass is a new material and workflow for accessible, affordable, and full-color glass 3D printing. We present: 1) a recipe for a 3D printable glass paste, 2) software and hardware that enable 3D printing, and 3) a firing schedule for sintering printed parts into solid glass. We evaluate our recipe and firing schedule by comparing the look, feel, shrinkage, porosity, and density of a collection of printed objects. We then present a range of functional and decorative glass artifacts that we 3D printed from ColdGlass including earrings, tiled glass sheets, sculptures, and functional vessels. We also describe methods for reusing and recycling glass in our workflow. We conclude by discussing the unique affordances of ColdGlass and the creative opportunities it provides for digital fabrication, design, and HCI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {301},
numpages = {20},
keywords = {Digital Fabrication, Glass, 3D Printing, Materiality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714281,
author = {Gui, Xinyue and Xia, Ding and Gao, Wang and Dogan, Mustafa Doga and Larsson, Maria and Igarashi, Takeo},
title = {Draw2Cut: Direct On-Material Annotations for CNC Milling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714281},
doi = {10.1145/3706598.3714281},
abstract = {Creating custom artifacts with computer numerical control (CNC) milling machines typically requires mastery of complex computer-aided design (CAD) software. To eliminate this user barrier, we introduced Draw2Cut, a novel system that allows users to design and fabricate artifacts by sketching directly on physical materials. Draw2Cut employs a custom-drawing language to convert user-drawn lines, symbols, and colors into toolpaths, thereby enabling users to express their creative intent intuitively. The key features include real-time alignment between material and virtual toolpaths, a preview interface for validation, and an open-source platform for customization. Through technical evaluations and user studies, we demonstrate that Draw2Cut lowers the entry barrier for personal fabrication, enabling novices to create customized artifacts with precision and ease. Our findings highlight the potential of the system to enhance creativity, engagement, and accessibility in CNC-based woodworking.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {302},
numpages = {17},
keywords = {sketching, CNC, woodworking, personal fabrication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714080,
author = {Wen, Xin and Bae, S. Sandra and Rivera, Michael L.},
title = {Enabling Recycling of Multi-Material 3D Printed Objects through Computational Design and Disassembly by Dissolution},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714080},
doi = {10.1145/3706598.3714080},
abstract = {Multi-material 3D printing combines the functional properties of different materials (e.g., mechanical, electrical, color) within a single object that is fabricated without manual assembly. However, this presents sustainability challenges as multi-material objects cannot be easily recycled. Because each material has a different processing temperature, considerable effort must be used to separate them for recycling. This paper presents a computational fabrication technique to generate dissolvable interfaces between different materials in a 3D printed object without affecting the object’s intended use. When the interfaces are dissolved, the object is disassembled to enable recycling of the individual materials. We describe the computational design of these interfaces alongside experimental evaluations of their strength and water solubility. Finally, we demonstrate our technique across 9 multi-material 3D printed objects of varying structural and functional complexity. Our technique enables us to recycle 89.97\% of the total mass of these objects, promoting greater sustainability in 3D printing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {21},
keywords = {multi-material 3D printing, sustainability, plastic recycling, computational fabrication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713599,
author = {Dong, Yan and Yu, Hanjie and Chen, Yanran and Zhang, Zipeng and Qiong, Wu},
title = {Layered Interactions: Exploring Non-Intrusive Digital Craftsmanship Design Through Lacquer Art Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713599},
doi = {10.1145/3706598.3713599},
abstract = {Integrating technology with the distinctive characteristics of craftsmanship has become a key issue in the field of digital craftsmanship. This paper introduces Layered Interactions, a design approach that seamlessly merges Human-Computer Interaction (HCI) technologies with traditional lacquerware craftsmanship. By leveraging the multi-layer structure and material properties of lacquerware, we embed interactive circuits and integrate programmable hardware within the layers, creating tangible interface that support diverse interactions. This method enhances the adaptability and practicality of traditional crafts in modern digital contexts. Through the development of a lacquerware toolkit, along with user experiments and semi-structured interviews, we demonstrate that this approach not only makes technology more accessible to traditional artisans but also enhances the materiality and emotional qualities of interactive interfaces. Additionally, it fosters mutual learning and collaboration between artisans and technologists. Our research introduces a cross-disciplinary perspective to the HCI community, broadening the material and design possibilities for interactive interfaces.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {304},
numpages = {21},
keywords = {Digital Craft, Tangible Interaction, Toolkit, Arts, DIY},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714215,
author = {Lin, Yuyu and Guner, Hatice Gokcen and Gu, Jianzhe and Prashant, Sonia and Ion, Alexandra},
title = {Wearable Material Properties: Passive Wearable Microstructures as Adaptable Interfaces for the Physical Environment},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714215},
doi = {10.1145/3706598.3714215},
abstract = {Users interact with static objects daily, but their preferences and needs may vary. Making the objects dynamic or adaptable requires updating all objects. Instead, we propose a novel wearable interface that empowers users to adjust perceived material properties.To explore such wearable interfaces, we design unit cell structures that can be tiled to create surfaces with switchable properties. Each unit can be switched between two states while worn, through an integrated bistable spring and tendon-driven trigger mechanism. Our switchable properties include stiffness, height, shape, texture, and their combinations. Our wearable material interfaces are passive, 3D printed, and personalizable. We present a design tool to support users in designing their customized wearable material properties. We demonstrate several example prototypes, e.g., a sleeve allowing users to adapt to how different surfaces feel, a shoe sole for users walking on different ground conditions, a prototype supporting both pillow and protective helmet properties, or a collar that can be transformed into a neck pillow with variable support.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {305},
numpages = {16},
keywords = {Wearables, Material properties, Digital fabrication, Metamaterials},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713883,
author = {Song, Inhwa and Park, SoHyun and Pendse, Sachin R and Schleider, Jessica Lee and De Choudhury, Munmun and Kim, Young-Ho},
title = {ExploreSelf: Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713883},
doi = {10.1145/3706598.3713883},
abstract = {Expressing stressful experiences in words is proven to improve mental and physical health, but individuals often disengage with writing interventions as they struggle to organize their thoughts and emotions. Reflective prompts have been used to provide direction, and large language models (LLMs) have demonstrated the potential to provide tailored guidance. However, current systems often limit users’ flexibility to direct their reflections. We thus present ExploreSelf, an LLM-driven application designed to empower users to control their reflective journey, providing adaptive support through dynamically generated questions. Through an exploratory study with 19 participants, we examine how participants explore and reflect on personal challenges using ExploreSelf. Our findings demonstrate that participants valued the flexible navigation of adaptive guidance to control their reflective journey, leading to deeper engagement and insight. Building on our findings, we discuss the implications of designing LLM-driven tools that facilitate user-driven and effective reflection of personal challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {306},
numpages = {22},
keywords = {Reflective Writing, Technology for Well-being, User-driven Exploration, User Agency, Large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713199,
author = {Wu, Yuheng and Dong, Yujie and Mou, Yi and Kim, Ki Joon},
title = {How the Algorithmic Transparency of Search Engines Influences Health Anxiety: The Mediating Effects of Trust in Online Health Information Search},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713199},
doi = {10.1145/3706598.3713199},
abstract = {Advancements in artificial intelligence-powered search engines have enhanced the efficiency of online health information searches by generating direct answers to queries using top-ranked featured snippets (FS). However, such functionalities may contribute to health anxiety, particularly when the displayed results are distressing. This study investigated the effect of algorithmic transparency (AT) explanations (absence vs. presence) on mitigating FS-triggered health anxiety. The results of an online experiment (N = 206) yielded two key findings: First, participants exposed to AT explanations detailing the selection process of FS experienced reduced trust in the search engine and distressing results, which subsequently alleviated health anxiety. Second, the moderating effect of pre-existing cyberchondria on the relationship between AT explanations and trust was observed, but only within a limited threshold. Overall, the findings empirically validate AT explanations as an effective approach to mitigate FS-induced health anxiety. Theoretical and practical implications are discussed.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {307},
numpages = {10},
keywords = {Algorithmic transparency, Health anxiety, Online health information search, Trust},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713316,
author = {De La Torre, Fernanda M and Hernandez, Javier and Wilson, Andrew D and Amores, Judith},
title = {Sonora: Human-AI Co-Creation of 3D Audio Worlds and its Impact on Anxiety and Cognitive Load},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713316},
doi = {10.1145/3706598.3713316},
abstract = {Soundscapes are widely used for relaxation, but their potential for personalized, navigable experiences remains under-explored. To address this, we developed Sonora, an AI tool that enables real-time generation of synthetic, spatialized soundscapes, allowing users to navigate immersive auditory environments and customize soundscapes using voice commands. Sonora’s architecture integrates audio diffusion models and LLMs within Unity3D. A between-subjects study with 32 participants investigated its effects on anxiety and user experience, compared to a control condition involving passive listening to a soundscape. Participants who interacted with Sonora reported higher entertainment than the control group. A positive correlation was found between state anxiety and user requests for Sonora, suggesting anxious users engaged more. Participants with moderate to high trait anxiety experienced significant reductions in state anxiety across both conditions, with no significant difference in cognitive load. Our findings highlight Sonora’s potential to promote relaxation, emphasizing the value of personalized experiences for mental health.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {308},
numpages = {22},
keywords = {Soundscapes, Mental health, Anxiety reduction, Cognitive load, 3D audio, AI-driven interaction, Human-AI co-creation, Biofeedback, Large Language Models, Real-time sound generation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713395,
author = {Echeverria, Vanessa and Zhao, Linxuan and Alfredo, Riordan and Milesi, Mikaela E and Jin, Yueqiao and Abel, Sophie and Fan, Jie Xiang and Yan, Lixiang and Dix, Samantha and Wotherspoon, Rosie and Li, Xinyu and Jaggard, Hollie A and Osborne, Abra and Buckingham Shum, Simon and Gasevic, Dragan and Martinez-Maldonado, Roberto},
title = {TeamVision: An AI-powered Learning Analytics System for Supporting Reflection in Team-based Healthcare Simulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713395},
doi = {10.1145/3706598.3713395},
abstract = {Healthcare simulations help learners develop teamwork and clinical skills in a risk-free setting, promoting reflection on real-world practices through structured debriefs. However, despite video’s potential, it is hard to use, leaving a gap in providing concise, data-driven summaries for supporting effective debriefing. Addressing this, we present TeamVision, an AI-powered multimodal learning analytics (MMLA) system that captures voice presence, automated transcriptions, body rotation, and positioning data, offering educators a dashboard to guide debriefs immediately after simulations. We conducted an in-the-wild study with 56 teams (221 students) and recorded debriefs led by six teachers using TeamVision. Follow-up interviews with 15 students and five teachers explored perceptions of its usefulness, accuracy, and trustworthiness. This paper examines: i) how TeamVision was used in debriefing, ii) what educators found valuable/challenging, and iii) perceptions of its effectiveness. Results suggest TeamVision enables flexible debriefing and highlights the challenges and implications of using AI-powered systems in healthcare simulation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {309},
numpages = {22},
keywords = {teamwork, large-language models, AI, sensors, healthcare, learning analytics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714088,
author = {Viswanathan, Sruthi and Ibrahim, Seray and Shankar, Ravi and Binns, Reuben and Van Kleek, Max and Slovak, Petr},
title = {The Interaction Layer: An Exploration for Co-Designing User-LLM Interactions in Parental Wellbeing Support Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714088},
doi = {10.1145/3706598.3714088},
abstract = {Parenting brings emotional and physical challenges, from balancing work, childcare, and finances to coping with exhaustion and limited personal time. Yet, one in three parents never seek support. AI systems potentially offer stigma-free, accessible, and affordable solutions. Yet, user adoption often fails due to issues with explainability and reliability. To see if these issues could be solved using a co-design approach, we developed and tested NurtureBot, a wellbeing support assistant for new parents. 32 parents co-designed the system through Asynchronous Remote Communities method, identifying the key challenge as achieving a “successful chat.” As part of co-design, parents role-played as NurtureBot, rewriting its dialogues to improve user understanding, control, and outcomes. The refined prototype, featuring an Interaction Layer, was evaluated by 32 initial and 46 new parents, showing improved user experience and usability, with final CUQ score of 91.3/100, demonstrating successful interaction patterns. Our process revealed useful interaction design lessons for effective AI parenting support.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {310},
numpages = {25},
keywords = {Parental Wellbeing, Perinatal Support, LLMs, Human-Centred AI, Interaction Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713244,
author = {Lee, Jamie and Jung, Kyuha and Newman, Erin Gregg and Chow, Emilie and Chen, Yunan},
title = {Understanding Adolescents' Perceptions of Benefits and Risks in Health AI Technologies through Design Fiction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713244},
doi = {10.1145/3706598.3713244},
abstract = {Despite the growing research on users’ perceptions of health AI, adolescents’ perspectives remain underexplored. This study explores adolescents’ perceived benefits and risks of health AI technologies in clinical and personal health settings. Employing Design Fiction, we conducted interviews with 16 adolescents (aged 13-17) using four fictional design scenarios that represent current and future health AI technologies as probes. Our findings revealed that with a positive yet cautious attitude, adolescents envision unique benefits and risks specific to their age group. While health AI technologies were seen as valuable learning resources, they also raised concerns about confidentiality with their parents. Additionally, we identified several factors, such as severity of health conditions and previous experience with AI, influencing their perceptions of trust and privacy in health AI. We explore how these insights can inform the future design of health AI technologies to support learning, engagement, and trust as adolescents navigate their healthcare journey.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {311},
numpages = {20},
keywords = {Adolescents, Artificial Intelligence, Health and Wellbeing, Design Fiction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713729,
author = {Huber, Linda},
title = {“A Bridge to Nowhere”: A Healthcare Case Study for Non-Reformist Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713729},
doi = {10.1145/3706598.3713729},
abstract = {In the face of intensified datafication and automation in public-sector industries, frameworks like design justice and the feminist practice of refusal provide help to identify and mitigate structural harm and challenge inequities reproduced in digitized infrastructures. This paper applies those frameworks to emerging efforts across the U.S. healthcare industry to automate prior authorization - a process whereby insurance companies determine whether a treatment or service is “medically necessary” before agreeing to cover it. Federal regulatory interventions turn to datafication and automation to reduce the harms of this widely unpopular process shown to delay vital treatments and create immense administrative burden for healthcare providers and patients. This paper explores emerging prior authorization reforms as a case study, applying the frameworks of design justice and refusal to highlight the inherent conservatism of interventions oriented towards improving the user experience of extractive systems. I further explore how the abolitionist framework of non-reformist reform helps to clarify alternative interventions that would mitigate the harms of prior authorization in ways that do not reproduce or extend the power of insurance companies. I propose a set of four tenets for non-reformist design to mitigate structural harms and advance design justice in a broad set of domains.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {312},
numpages = {12},
keywords = {data governance, data justice, ethnography, feminist HCI, health informatics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714272,
author = {Wu, Siyi and Cao, Weidan and Fu, Shihan and Yao, Bingsheng and Yang, Ziqi and Yin, Changchang and Mishra, Varun and Addison, Daniel and Zhang, Ping and Wang, Dakuo},
title = {CardioAI: A Multimodal AI-based System to Support Symptom Monitoring and Risk Prediction of Cancer Treatment-Induced Cardiotoxicity},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714272},
doi = {10.1145/3706598.3714272},
abstract = {Despite recent advances in cancer treatments that prolong patients’ lives, treatment-induced cardiotoxicity (i.e., the various heart damages caused by cancer treatments) emerges as one major side effect. The clinical decision-making process of cardiotoxicity is challenging, as early symptoms may happen in non-clinical settings and are too subtle to be noticed until life-threatening events occur at a later stage; clinicians already have a high workload focusing on the cancer treatment, no additional effort to spare on the cardiotoxicity side effect. Our project starts with a participatory design study with 11 clinicians to understand their decision-making practices and their feedback on an initial design of an AI-based decision-support system. Based on their feedback, we then propose a multimodal AI system, CardioAI, that can integrate wearables data and voice assistant data to model a patient’s cardiotoxicity risk to support clinicians’ decision-making. We conclude our paper with a small-scale heuristic evaluation with four experts and the discussion of future design considerations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {313},
numpages = {22},
keywords = {Human-AI collaboration, Cancer treatment-induced cardiotoxicity, Multimodal AI system, Large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713639,
author = {Guo, Yijie and Wang, Ruhan and Huang, Zhenhan and Jin, Tongtong and Yao, Xiwen and Feng, Yuan-Ling and Zhang, Weiwei and Yao, Yuan and Mi, Haipeng},
title = {Exploring the Design of LLM-based Agent in Enhancing Self-disclosure Among the Older Adults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713639},
doi = {10.1145/3706598.3713639},
abstract = {Social difficulties have become an increasingly serious issue among older adults. For older adults, regular self-disclosure is essential for maintaining mental health and building close relationships. Leveraging conversational agents to encourage self-disclosure in older adults has shown increasing potential. Understanding how LLM-based agents can influence and stimulate self-disclosure across different topics is crucial for designing future agents tailored to older users. This study introduces Disclosure-Agent, an LLM-based conversational agent, and examines its impact on self-disclosure in older adults through a user study involving 20 participants, 8 topics, and two interactive interfaces equipped with Disclosure-Agent. The findings provide valuable insights into how LLM-based agents can promote self-disclosure in older adults and offer design recommendations for future elderly-oriented conversational agents.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {314},
numpages = {17},
keywords = {Self-disclosure, Embodied agent, Interactive interface with language models, Conversational agent},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713345,
author = {Vo, Thuan T and Das, Satabdi and Noroozi, Shamim and Dang, Lakshay and Sin, Jaisie and Boger, Jennifer N and Jakobi, Jennifer and Hasan, Khalad},
title = {Exploring the Effects of Social VR Coupling Modes on Engagement and Task Performance for Older Adults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713345},
doi = {10.1145/3706598.3713345},
abstract = {Social Virtual Reality (VR) presents a promising avenue for older adults to connect with others and engage in collaborative activities remotely. However, many social VR experiences focus on individual tasks, reducing opportunities for meaningful social interaction. To investigate the potential of VR to enhance engagement with other participants, this paper explores two modes of coupling: (i) loosely coupled, where participants focus on their individual tasks within a collaborative setting, and (ii) tightly coupled, where participants need to rely on each other’s assistance to complete their tasks. We conducted a user study with 20 older adults to evaluate how these modes affect task performance and engagement. Results show that the tightly coupled mode, focused on collaboration, increases engagement, while the loosely coupled mode, centers on individual tasks, improves performance in time and attempts. We provide guidelines for collaborative VR applications to enhance social engagement and interaction among older adults.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {315},
numpages = {10},
keywords = {Collaborative Game, Loosely Coupled Collaboration, Tightly Coupled Collaboration, Healthy Aging, Older Adults},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713458,
author = {Javaheri, Hamraz and Ghamarnejad, Omid and Lukowicz, Paul and Stavrou, Gregor A and Karolus, Jakob},
title = {From Concept to Clinic: Multidisciplinary Design, Development, and Clinical Validation of Augmented Reality-Assisted Open Pancreatic Surgery},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713458},
doi = {10.1145/3706598.3713458},
abstract = {Wearable augmented reality (AR) systems have significant potential to enhance surgical outcomes through in-situ visualization of patient-specific data. Yet, efforts to develop AR-based systems for open surgery have been limited, lacking comprehensive interdisciplinary research and actual clinical evaluations in real surgical environments. Our research addresses this gap by presenting a user-centered design and development process of ARAS, an AR assistance for open pancreatic surgery. ARAS provides in-situ visualization of critical structures, such as the vascular system and the tumor, while offering a robust dual-layer registration method ensuring accurate registration during relevant phases of the surgery. We evaluated ARAS in clinical trials of 20 patients with pancreatic tumors. Accuracy validation and postoperative surgeon interviews confirmed its successful deployment, supporting surgeons in vascular localization and critical decision-making. Our work showcases AR’s potential to fundamentally transform procedures for complex surgical operations, advocating a research shift toward ecological validation in open surgery.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {316},
numpages = {24},
keywords = {Augmented Reality, Surgical Assistance System, Pancreatic Surgery},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713582,
author = {Lima, Maria R. and O'Connell, Amy and Zhou, Feiyang and Nagahara, Alethea and Hulyalkar, Avni and Deshpande, Anura and Thomason, Jesse and Vaidyanathan, Ravi and Matari\'{c}, Maja},
title = {Promoting Cognitive Health in Elder Care with Large Language Model-Powered Socially Assistive Robots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713582},
doi = {10.1145/3706598.3713582},
abstract = {As the global population ages, there is increasing need for accessible technologies that promote cognitive health and detect early signs of cognitive decline. This research demonstrates the potential for in-residence monitoring and assessment of cognitive health using large language model (LLM)-powered socially assistive robots (SARs). We conducted a 5-week within-subjects study involving 22 older adults in retirement homes to investigate the feasibility of large language model (LLM)-powered socially assistive robots (SARs) for promoting and assessing cognitive health. We designed tasks that involved verbal dialogue based on clinically validated cognitive tools. Our findings reveal improved task performance after three robot-administered sessions, with significantly more detailed picture descriptions, fewer word repetitions in semantic fluency, and reduced need for hints. We found that older adults were more socially engaged in robot-administered tasks compared to those administered by a human, and they accepted and were willing to engage with socially assistive robots (SARs) in this context, which had not been tested before.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {317},
numpages = {22},
keywords = {socially assistive robotics, large language models, cognitive health, elder care},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714158,
author = {Zhao, Jianrui and Chen, Dunya and Barbareschi, Giulia and Sato, Chihiro},
title = {The Role of ICT Tools through a Community Program Co-creation in a Japanese Aging Community},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714158},
doi = {10.1145/3706598.3714158},
abstract = {As the global aging population grows and technology advances rapidly, integrating technology into community-based initiatives for older adults has become an increasingly important topic among HCI researchers. This research explores the role of Information and Communication Technology (ICT) tools in the co-creation and maintenance of a community gardening program involving researchers, older adult residents, and supporting organizations. A follow-up study, conducted eight months after the program’s initiation assessed its sustainability, revealing how stakeholders navigated diverse ICT preferences and challenges by employing a hybrid communication system that integrated both digital and face-to-face methods to foster collaboration and sustain the initiative. This research contributes to the understanding of community preferences and needs, and the importance of contextualizing technology use within Japanese local community for collaborative community development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {318},
numpages = {10},
keywords = {ICT; service design; community development; aging community; co-creation; participatory design;},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713619,
author = {Kang, Daye and Li, Jingjin and Leshed, Gilly and Rzeszotarski, Jeffrey M and Lu, Xi},
title = {Towards Hormone Health: An Autoethnography of Long-Term Holistic Tracking to Manage PCOS},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713619},
doi = {10.1145/3706598.3713619},
abstract = {Polycystic ovary syndrome (PCOS) is a common hormonal disorder affecting 11-13\% of women of reproductive age, characterized by a wide range of symptoms (e.g., menstrual irregularity, acne, and obesity) that varies among individuals. While self-tracking tools help PCOS patients to monitor their symptoms and find personalized treatment, they often focus on regular periods of healthy women with inadequate support for the 1) personalization and 2) long-term holistic tracking necessary for managing complex chronic conditions like PCOS. To bridge this gap, the first author (who has PCOS) conducted an autoethnographic study of holistic self-tracking over a period of ten months in an effort to manage her condition. Our results highlight the challenges of personalized, holistic, long-term tracking in medical, socio-cultural, temporal, technical, and spatial contexts. Based on these insights, we provide design implications for tracking tools that are more inclusive and sustainable.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {319},
numpages = {20},
keywords = {PCOS, self-tracking, autoethnography, women’s health, hormone health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713902,
author = {Parnaby, Adam W and Kharrufa, Ahmed and Crivellaro, Clara},
title = {Beyond Bridging Divides: Examining the Goals of Digital Inclusion Practice in Post-Digital Societies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713902},
doi = {10.1145/3706598.3713902},
abstract = {The widespread digitalisation of critical civic services in contexts of economic austerity, neoliberalism, and the COVID-19 pandemic, has renewed focus in HCI on interventions to enable digital access for populations considered ‘digitally excluded’. While digital inclusion (DI) practitioners play a critical role in this area, their perspectives remain under-explored in HCI. This paper reports on a series of asset-based engagements with digital inclusion practitioners in the North East of England. These engagements explored the values, assets, and needs comprising their practices and used these insights as design material to ideate strategies for future intervention. We contribute findings describing the complexities, contradictions, and diversity of digital inclusion practices and efforts. Based on these findings, we argue for a shift towards considering DI practice through the lens of care, and provide directions for future HCI research to support DI practitioners in doing care work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {320},
numpages = {17},
keywords = {Digital divide, Digital inclusion, Post-Digital},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714163,
author = {Lo, I-Chen and Rau, Pei-Luen Patrick},
title = {D-Twins: Your Digital Twin Designed for Real-Time Boredom Intervention},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714163},
doi = {10.1145/3706598.3714163},
abstract = {We design "D-Twins" (Digital Twins), an LLM-based affective AI agent that embodies each user’s emotional reactions and personality traits, presenting a real-time, authentic reflection of the user. D-Twins addresses the current lack of personalized boredom interventions in automated environments by utilizing real-time physiological data to provide interventions aligned with users’ emotional responses. Initially, we collected users’ natural language expressions to capture their unique characteristics. These patterns were used to create LLM-based AI agents that highly resemble the users. Then, we developed a boredom classification model by collecting electroencephalogram (EEG) data in an automated environment and integrated it into D-Twins. This integration enables D-Twins to rapidly recognize boredom and initiate personalized interventions, which users perceive as highly empathetic, turning boring environments into engaging experiences. Our study highlights that AI agents with user-similar emotional resonance offer a novel, real-time personalized intervention solution in boredom situations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {321},
numpages = {15},
keywords = {boredom intervention, human-AI teaming, affective AI agents},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714084,
author = {Chauhan, Aarjav and Soden, Robert},
title = {Digital Archives, Knowledge Conflicts, and Epistemic Injustices in the Himalayas},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714084},
doi = {10.1145/3706598.3714084},
abstract = {This research examines the tactics employed by digital archive projects focused on Himalayan histories and cultures to navigate knowledge conflicts. While digital archives offer the means to provide visibility and increase the accessibility and recognition to marginalized communities, they inevitably give rise to knowledge conflicts, which may lead to epistemic injustices. Through interviews with contributors to Himalayan digital archives, we find that these projects attempt to navigate knowledge conflicts and address epistemic injustices by drawing on inclusive, participatory, and activist-oriented practices. We discuss the importance of surfacing conflicts when designing tools and practices for collaboration and cooperation within digital archives. Doing so, we argue, can help contextualize historical issues in the present and strengthen advocacy efforts against ongoing socio-environmental injustices. Finally, we highlight the opportunity for reconfiguring digital archives as digital commons to foster commoning practices and enable post-custodial, co-created, and self-governed archival infrastructures.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {322},
numpages = {14},
keywords = {Digital Archives, Digital Commons, History, Commoning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713764,
author = {Kwon, Soonho and Jo, Hyunah and Ryu, Sohee and Do, Jihwan Ryan and Lee, HwaJung and Lee, JooHyun and Lee, Keeheon and Kang, Younah},
title = {Digital Legacy Systems for Young Adults: Emphasizing Relationship-Oriented Perspectives and Physical Artifacts in Death Preparation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713764},
doi = {10.1145/3706598.3713764},
abstract = {The death of a young person is particularly tragic, leaving a profound emotional impact on the bereaved. Moreover, their legacies often diverge from traditional ones, incorporating a range of digital artifacts. This design study investigates age-specific approaches to death-related technologies by envisioning digital legacy curation systems tailored for young adults (age 19–34). Using cultural probes, design workbooks, and prototype testing, we examine the values and preferences of young adults in preparing for an untimely death. Our findings highlight relationship-oriented legacies that focus on minimizing the emotional burden of the bereaved and the potential benefits of physical artifacts. Through this study, we: (1) underscore recognizing specific user groups in death-related technologies, (2) explore death as an existential and disorienting grounds within HCI, (3) extend post-userist concepts to consider the notion of “use” after death, and (4) identify the liminal space between physical and digital legacies as a meaningful realm to explore.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {323},
numpages = {17},
keywords = {Death, Digital Legacy, Cultural Probe, Design Workbook},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713303,
author = {Waern, Annika and M\r{a}rtensson, Fredrika and Back, Jon and Litsmark, Anna and Salln\"{a}s Pysander, Eva-Lotta},
title = {Digital Play in Nature: A Study of Digital Play Installations from a Nature Play Perspective},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713303},
doi = {10.1145/3706598.3713303},
abstract = {While digital play installations for outdoor use are becoming more common, little work has been done on how such technology shapes play in nature-rich environments. We performed a study of children's self-directed play with access to nature as well as digital installations. Our findings show that play with nature materials and digital installations emerged in different ways. Most notably, imaginative play was observed emerging in close interaction with nature, while the digital installations mostly inspired rule-based play. Furthermore, engagement with digital installations typically involved an active exploration phase which was not observed with nature materials. Nature materials instead engaged the children's senses more immediately, and often offered opportunities for collection and consumption, paving way for fluent play activities roaming large areas. We argue that these differences motivate rethinking the design of digital installations for play in nature and suggest guidelines to this purpose.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {324},
numpages = {19},
keywords = {children´s play, digital outdoor play, landscape architecture, nature, nature play, nature-rich settings, open-ended play, restoration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713258,
author = {Bertel, Diotima and Himmelsbach, Julia and Schwarz, Stephanie and Sellitsch, David and Wildmann, Andreas and Schm\"{o}lz, Alexander and Tscheligi, Manfred},
title = {Play It Till You Make It: The Potential of Playful Role Enactment to Foster Digital Agency},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713258},
doi = {10.1145/3706598.3713258},
abstract = {Technology use is always gendered: ideas about a person’s abilities shape their approach to technologies and thus their digital agency. Yet, approaches towards fostering digital agency often focus only on competencies, falling short of accounting for the relationality and situatedness of agency. Based on a survey with 411 persons, we assessed gendered stereotype threat and agency-related experiences. We designed a workshop concept for providing spaces for agency exploration. We developed roles that address various gender-related stereotypes and embedded the workshop in a playful sci-fi setting. Through participant observations and group interviews, we analysed its potential.Our results show the relevance of understanding gendered notions and the need for a nuanced understanding of digital agency beyond dualistic thinking. Addressing stereotypes in digital agency must acknowledge the sociality and relationality of gender. Moreover, gendered aspects of identity can even serve as a basis for playful agency enactment and exploration, particularly through making.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {325},
numpages = {18},
keywords = {Digital agency, playful role enactment, gender, feminist deessentialisation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714048,
author = {Kwon, Hyosun and Benford, Steve David and Koleva, Boriana},
title = {Savouring Slow Gifts: Reflection from the Field Study of Hybrid Gifting},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714048},
doi = {10.1145/3706598.3714048},
abstract = {Despite the prevalence of digital gifting, designing meaningful and emotionally engaging digital gifts remains a challenge. One promising approach is Hybrid gifting, which combines digital and physical elements to improve the perceived value of gifts and provide opportunities for interpersonalisation. However, there is limited understanding of how hybridity shapes the dynamics of gifting in everyday contexts. To explore this, we developed a connected coffee machine prototype as a technology probe to study how givers personalise hybrid gifts and how recipients experience them. A study with seven pairs in intimate relationships revealed key insights: hybridity fosters slow, deliberate engagement; supports personalisation aligned with daily routines; grants recipients autonomy in receiving gifts; and reveals tensions between giver anxiety and recipient enjoyment. We discuss design implications for hybrid gifting systems that encourage recipients to savour digital gifts through slow, reflective interactions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {326},
numpages = {20},
keywords = {Hybrid Gift, Gift Exchange, Slow, Savouring, Connected Appliances, Digital gifting, Interpersonalisation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713840,
author = {Halperin, Brett A. and Lukin, Stephanie M.},
title = {From Camera-Eye to AI: Exploring the Interplay of Cinematography and Computational Visual Storytelling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713840},
doi = {10.1145/3706598.3713840},
abstract = {While much prior work on computational visual storytelling analyzes image content, it largely overlooks formal elements. This raises the question: how might particular cinematographic techniques shape a system’s interpretation and narration of imagery? To investigate this question, we generate 60 responses from a Vision Language Model using a multi-faceted prompt paired with different still frames from Man with a Movie Camera (1929), a silent documentary film renowned for its innovative cinematography. We present three themes that highlight roles of cinematography in computational visual storytelling: (1) how AI discerns drama and power from camera shots and angles that portray social reality; (2) how AI (mis)interprets lighting and focus techniques that compose ambiguous reality; and (3) how AI navigates visual effects that render surreality. In turn, we look toward cinematic controls to reimagine users as directors of visual storytelling systems and discuss how expressive AI can support speculating about the past.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {327},
numpages = {18},
keywords = {AI, Automatic Story Generation, Cinema, Cinematography, Computational Storytelling, Film, Generative AI, Vision Language Models, Narrative, Narrative Intelligence, Narrative System, Natural Language Generation, Visual Storytelling, Storytelling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713478,
author = {Fan, Min and Cui, Xinyue and Ma, Wanqing and Li, Haiyan and Tong, Xin and Yang, Lin and Wang, Yonghui},
title = {From Words to Wonder: Designing and Evaluating an AI-Empowered Creative Storytelling System for Elementary Children},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713478},
doi = {10.1145/3706598.3713478},
abstract = {While several digital tools exist for children's creative storytelling, few have explored how generative AI can enhance storytelling quality. Our formative research identified five design requirements for AI-powered storytelling tools for elementary students. We developed a system named StoryPrompt that enables children to co-create stories and comics with AI, boosting literacy and creativity. Pilot tests with children and HCI experts demonstrated good usability and positive learning experiences. In a mixed-methods evaluation with 40 children from Grades 2-6, we found that StoryPrompt significantly improved storytelling creativity and richness, compared to the storyboard method. Observations indicated more purposeful planning and strategic use of AI-generated words and images, facilitating efficient exploration of storytelling alternatives. While children preferred AI images, they recognized the limitations in representing storytelling details. Teacher interviews highlighted the system's motivational potential and classroom flexibility. We discuss the benefits and considerations of using generative AI to enhance creative storytelling for children.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {328},
numpages = {15},
keywords = {Children, Creativity, Design and Evaluation, Generative AI, Storytelling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714200,
author = {Martinez, Lenny and Caramiaux, Baptiste and Fdili Alaoui, Sarah},
title = {Generative AI in Documentary Photography: Exploring Opportunities and Challenges for Visual Storytelling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714200},
doi = {10.1145/3706598.3714200},
abstract = {Generative AI is increasingly used to create images from text, but its role in documentary photography remains under-explored. This paper investigates how generative AI can be integrated into documentary practice while maintaining ethical standards. Through interviews with six documentary photographers, we explored their views on AI’s potential to support community-driven storytelling. While AI presents opportunities for creative expression and community involvement, concerns about trust, authenticity, and decontextualization of images persist. Photographers expressed doubts about AI’s ability to accurately represent lived experiences, fearing it could compromise narrative integrity. Our findings suggest that AI tools should be designed to enhance collaboration and transparency in storytelling, complementing rather than replacing traditional documentary methods. This study contributes to the ongoing discourse on AI in photography, advocating for the development of tools that preserve the ethical foundations of documentary storytelling while empowering communities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {329},
numpages = {13},
keywords = {Generative AI, Documentary photography, Visual storytelling, Text-to-image generation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713999,
author = {Skeggs, Amira and Mehta, Ashish and Yap, Valerie and Ibrahim, Seray B and Rhodes, Charla and Gross, James J. and Munson, Sean A. and Klasnja, Predrag and Orben, Amy and Slovak, Petr},
title = {Micro-narratives: A Scalable Method for Eliciting Stories of People’s Lived Experience},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713999},
doi = {10.1145/3706598.3713999},
abstract = {Engaging with people’s lived experiences is foundational for HCI research and design. This paper introduces a novel narrative elicitation method to empower people to easily articulate ‘micro-narratives’ emerging from their lived experiences, irrespective of their writing ability or background. Our approach aims to enable at-scale collection of rich, co-created datasets that highlight target populations’ voices with minimal participant burden, while precisely addressing specific research questions. To pilot this idea, and test its feasibility, we: (i) developed an AI-powered prototype, which leverages LLM-chaining to scaffold the cognitive steps necessary for users’ narrative articulation; (ii) deployed it in three mixed-methods studies involving over 380 users; and (iii) consulted with established academics as well as C-level staff at (inter)national non-profits to map out potential applications. Both qualitative and quantitative findings show the acceptability and promise of the micro-narrative method, while also identifying the ethical and safeguarding considerations necessary for any at-scale deployments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {330},
numpages = {20},
keywords = {Human-AI collaboration, methodology, qualitative data collection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713435,
author = {Chung, John Joon Young and Roemmele, Melissa and Kreminski, Max},
title = {Toyteller: AI-powered Visual Storytelling Through Toy-Playing with Character Symbols},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713435},
doi = {10.1145/3706598.3713435},
abstract = {We introduce Toyteller, an AI-powered storytelling system where users generate a mix of story text and visuals by directly manipulating character symbols like they are toy-playing. Anthropomorphized symbol motions can convey rich and nuanced social interactions; Toyteller leverages these motions (1) to let users steer story text generation and (2) as a visual output format that accompanies story text. We enabled motion-steered text generation and text-steered motion generation by mapping motions and text onto a shared semantic space so that large language models and motion generation models can use it as a translational layer. Technical evaluations showed that Toyteller outperforms a competitive baseline, GPT-4o. Our user study identified that toy-playing helps express intentions difficult to verbalize. However, only motions could not express all user intentions, suggesting combining it with other modalities like language. We discuss the design space of toy-playing interactions and implications for technical HCI research on human-AI interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {331},
numpages = {23},
keywords = {visual storytelling, toy-playing, generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713398,
author = {Yin, Michael and Xiao, Robert},
title = {TravelGalleria: Supporting Remembrance and Reflection of Travel Experiences through Digital Storytelling in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713398},
doi = {10.1145/3706598.3713398},
abstract = {Travel is a powerful yet fleeting experience that can shape personal perspectives and support self-reflection. To recapture the essence of travel, we explored the use of VR as a medium for immersive re-experiencing with an emphasis on storytelling. We developed TravelGalleria, a VR authoring tool that allows users to curate personalized digital galleries. TravelGalleria encourages creative expression, enabling users to use audio narration, annotations, spatially arranged photos, and more to recount their travel stories. A probing user study with TravelGalleria (n = 20) showed promising trends toward emotional resonance and introspective learning. Our findings illustrate how our tool supports users in remembering, reliving, and deriving new insights regarding past experiences, as they were able to reconnect with emotions and themes central to their travels. We discuss these findings in the context of meaningful digital experiences and storytelling in reflective digital practices, highlighting design suggestions and open areas for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {332},
numpages = {14},
keywords = {travel, virtual reality, digital storytelling, reflection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713363,
author = {Lu, Zhuoran and Zhou, Qian and Wang, Yi},
title = {WhatELSE: Shaping Narrative Spaces at Configurable Level of Abstraction for AI-bridged Interactive Storytelling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713363},
doi = {10.1145/3706598.3713363},
abstract = {Generative AI significantly enhances player agency in interactive narratives (IN) by enabling just-in-time content generation that adapts to player actions. While delegating generation to AI makes IN more interactive, it becomes challenging for authors to control the space of possible narratives - within which the final story experienced by the player emerges from their interaction with AI. In this paper, we present WhatELSE, an AI-bridged IN authoring system that creates narrative possibility spaces from example stories. WhatELSE provides three views (narrative pivot, outline, and variants) to help authors understand the narrative space and corresponding tools leveraging linguistic abstraction to control the boundaries of the narrative space. Taking innovative LLM-based narrative planning approaches, WhatELSE further unfolds the narrative space into executable game events. Through a user study (N=12) and technical evaluations, we found that WhatELSE enables authors to perceive and edit the narrative space and generates engaging interactive narratives at play-time.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {333},
numpages = {18},
keywords = {Interactive Narrative, Large Language Models, Abstraction, Narrative Space, Video Games, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713414,
author = {Strobel, Lukas and Gerling, Kathrin Maria and Rixen, Jan Ole},
title = {"Is This Seat Accessible for Me?": An Autoethnography of a Person With a Mobility Disability Using Interactive Seat Plans for Public Events},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713414},
doi = {10.1145/3706598.3713414},
abstract = {Spectating sports matches or concerts is a popular activity, but these public live events have yet to become more accessible to people with disabilities. Inspecting the corresponding interactive seat plan before purchasing tickets online can be necessary to avoid or prepare for barriers at these venues. Unfortunately, these representations often lack valuable accessibility information. To explore how this can affect the disabled community, we leverage autoethnography to provide an in-depth introspective account through the lens of a person with a mobility disability. We apply Thematic Analysis to synthesise field notes from his research diary. The crafted themes showcase the lacking accessibility support in seat plans and illustrate the first author’s adaptation strategies to facilitate accessible experiences. We further contextualise his social relationships as a key factor throughout this process. Grounded in these results, we reflect on the provision of accessibility information, the categorisation of seats, and interdependent relationships within and through these systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {334},
numpages = {15},
keywords = {Disability, interactive seat plans, autoethnography},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713535,
author = {Offerman, C\'{e}line and Bourgeois, Jacky and van Beurden, Jules and Bozzon, Alessandro},
title = {(Re)discovering Sexual Pleasure after Cancer: Understanding the Design Space},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713535},
doi = {10.1145/3706598.3713535},
abstract = {Cancer treatments often lead to sexual health challenges that greatly impact cancer survivors’ quality of life. Current interventions primarily address physiological aspects, like medication or vaginal care, overlooking psychological, social, and cultural dimensions. This paper explores how HCI can address this gap by supporting post-cancer sexual health with interventions for survivors and their partners, considering their lived experiences. Through reflexive thematic analysis of interviews with (N=6) medical sexologists, we identified five themes: perceiving the body as a medical object, the hot potato problem in oncology, sociotechnical sexploration, reuniting what treatment has divided, and designing interventions with openness in a highly situated context. These themes highlight cancer survivors’ experiences, the (in)effectiveness of current interventions, and provision of care. This research outlines the design space for post-cancer sexual health by providing specific design directions (“what”) and ways for designing them (“how”), while advancing the broader discourse on intimacy and design within HCI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {335},
numpages = {17},
keywords = {sexuality, sexual health, cancer, survivorship, intimate health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713127,
author = {Konstantinou, Loukas and Karapanos, Evangelos},
title = {Behavior Change Interventions Combating Online Misinformation: A Scoping Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713127},
doi = {10.1145/3706598.3713127},
abstract = {It is increasingly acknowledged that simply presenting users with corrective information is unlikely to produce the desired effects against misinformation. As such, the need for systematic use of behavioral theory is increasingly acknowledged, and behavioral interventions against misinformation are rising. This paper presents a scoping review of digital behavioral interventions countering misinformation, inquiring into their behavioral objectives, theoretical foundations, design and evaluation practices, and the factors that were empirically proven, or speculated, to contribute to interventions’ failure. Among others, we identify 17 distinct behavioral objectives, organized into three stages of the online news cycle: composition, amplification and consumption, 24 theoretical frameworks employed in designing these interventions, and nine reasons of failure. We synthesize the findings into a set of design cards with the goal of guiding intervention designers during concept ideation and refinement, and highlight areas for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {336},
numpages = {19},
keywords = {Online Misinformation, Behavior Change, Attitude Change, Scoping Review},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713939,
author = {Regis, Valeria and Ferraro, Venere and Burzio, Giorgia},
title = {Embracing Gender Diversity: Designing an Adaptive Pleasure Object for a Changing Body},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713939},
doi = {10.1145/3706598.3713939},
abstract = {Trans and non-binary individuals undergoing hormone therapy face unique and evolving needs for sexual wellness products that current solutions often overlook. The transition process involves significant anatomical and psychological changes, highlighting the necessity for more inclusive approaches to Human-Computer Interaction and overall well-being. Within this framework, this study presents the development of a pleasure object designed to be fluid, adaptive, and responsive to the evolving anatomical and psychological changes experienced during hormone therapy. To this end, authors conducted comprehensive research, including an online survey on the autoerotic habits of trans and non-binary individuals, followed by three sensitive interviews and clinical integration. They observed significant themes that highlight the unique requirements and experiences of this community. By leveraging advanced technologies and selected materials, authors provide design considerations and discuss the potential of these methods to create sexual wellness products that offer meaningful and inclusive experiences for the trans and non-binary community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {337},
numpages = {19},
keywords = {Adaptive Design, Interaction Design, Sex Toy, Transgender, Wellbeing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713437,
author = {Mouallem, Aya and Mendez Pons, Mirelys and Malik, Ali and Rogando, Trini and Kim, Gene S-H and Kulkarni, Trisha and Chong, Charlene and Fan, Danyang and Patel, Shloke Nirav and Shluzas, Lauren Aquino and Chen, Helen L. and Sheppard, Sheri D.},
title = {IncluSim: An Accessible Educational Electronic Circuit Simulator for Blind and Low-Vision Learners},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713437},
doi = {10.1145/3706598.3713437},
abstract = {Electronic circuit simulation is a core skill for electronics-based education. However, conventional introductory simulators often rely on visual tasks and features and are inherently inaccessible to learners who are blind or have low vision (BLV). In this work, we present IncluSim, a novel, open-source BLV-accessible circuit simulator tool, incorporating tactile elements and a digital interface. We relied on extensive needfinding to identify barriers faced by BLV learners in electronics-based education. Next, with the larger BLV community, and as a team of BLV and sighted researchers, we adopted the co-design method over 2.5 years to design and develop the simulator tool. Over two studies, BLV participants completed different circuit design and simulation tasks using the IncluSim tool. Our findings indicate that IncluSim, via its hardware-digital medium, enables BLV learners to successfully design, simulate and debug circuits, overcoming the accessibility barriers of conventional simulators.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {338},
numpages = {18},
keywords = {Accessibility, Circuit simulation, Co-Design, Electronics, Engineering Education, Tangible user interface},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713216,
author = {Lee, Heejae and Dominguez Partida, Gabriel and Bowman, Nicholas David and Chauveau, Philippe de Villemor},
title = {Translation and Validation of The Video Game Demand Scale to Spanish},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713216},
doi = {10.1145/3706598.3713216},
abstract = {With efforts to investigate the role of interactivity on user psychology in video games, scholars have demonstrated that interactivity may induce cognitive, emotional, physical (controller and exertional), and social demands of global gamers. However, existing studies are missing Latin American gamers as critical yet understudied gaming communities. Drawing on the interactivity-as-demand model, we conducted a mixed-method online survey to test measurement validity on localized versions of the video game demand scale (VGDS) for Spanish-speaking gamers (N = 195). Results showed that the Spanish-translated scale replicated the a priori five-factor structure of VGDS. Emergent themes from gamers’ comments mirrored VGDS factors, with additional insights into the cognitive demand of creative thinking, emotional demand of feeling nostalgia, physical demand of being precise, and social demand of interacting with non-player characters. These findings provide a pancultural perspective of Spanish-speaking gamers’ perceptions of their gaming while offering nuanced insights into their experiences for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {339},
numpages = {14},
keywords = {Mexico, Spanish, interactivity-as-demand, measurement validity, player psychology, video game demand scale},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713617,
author = {Baseman, Cynthia M and Dembure, Seka M and Arriaga, Rosa I},
title = {"We Have to Be Advocates for Ourselves": A Social-Ecological Approach to Mobile Health Design with Black Older Adults Living with Diabetes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713617},
doi = {10.1145/3706598.3713617},
abstract = {Even well-intentioned researchers may engage in health equity tourism (HET). We describe our two-year engagement with under-resourced community sites to provide insights into fostering genuine commitments to remedying health disparities. To explore implications for mobile health (mHealth) design for Black older adults with low income, we employed reflexive, qualitative methods based on outreach activity and semi-structured interviews with 25 community members. Our analysis highlights the importance of accessible self-learning opportunities to nurture technological interest. Our findings also suggest varying loci of control in health, and that mistrust motivates informal support networks and mHealth usage. Based on our work, we provide actionable recommendations for HCI researchers to mitigate HET. In addition, we reframe our findings through a social-ecological perspective to better understand the interplays between technology and health, and generate insights into how mHealth design can better serve under-resourced communities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {340},
numpages = {17},
keywords = {Health Equity, Health, Mobile Health, Diabetes, Older Adults, Race, Socioeconomic Status, Social-Ecological Theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713584,
author = {Zolyomi, Annuska and Koushik, Varsha and Asyet, Dinara and Huynh, Linh H},
title = {A Stakeholder Value Framework for Augmentative and Alternative Communication},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713584},
doi = {10.1145/3706598.3713584},
abstract = {End-users of augmentative and alternative communication (AAC) have diverse speech, cognitive, and motor abilities. AAC’s heterogeneous user groups and persistent usability issues create a challenging and rich design space. Our work takes a value-sensitive design (VSD) approach to develop a stakeholder value framework that describes stakeholders’ multi-dimensional roles and values. Our framework is based on (1) an empirical investigation—a survey and interviews—of AAC users and AAC conversation partners and (2) a conceptual investigation—a systematic literature review—of AAC HCI research. Emergent value themes were ease, fulfillment, acceptance, adaptation, safety, performance, autonomy, justice, design fulfillment, and business fulfillment. These themes inform how AAC end-users engage with AAC and how indirect stakeholders, such as AAC technologists, make choices that ultimately impact AAC users. Our stakeholder value framework and rich descriptions of AAC socio-technical barriers can inform AAC designers in making ethically sound decisions that support, not hinder, stakeholder values.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {341},
numpages = {25},
keywords = {communication assistive technology, value sensitive design, stakeholder analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713560,
author = {Seberger, John S. and Gupta, Sanonda Datta},
title = {Designing for Difference: How We Learn to Stop Worrying and Love the Doppelganger},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713560},
doi = {10.1145/3706598.3713560},
abstract = {To use social media is to interact with digital representations of oneself in the form of algorithmically-determined personalized content. Yet when we assume that interactions with personalized content will be a persistent feature of our futures, the concepts available to frame such digital representations&nbsp;–&nbsp;things variously called doubles, twins, and doppelgangers&nbsp;–&nbsp;appear as worryingly creepy. Where might one find optimism amid such presumptive creepiness? Through conceptual analysis of data doubles, digital twins, and data doppelgangers, we identify and explain one source of justifiable optimism. Unlike the double and twin, the data doppelganger’s dynamics center difference rather than presumed sameness. Fostering justifiable optimism about the futures of personalization&nbsp;–&nbsp;with social media as a starting point&nbsp;–&nbsp;requires learning how to design for the experience of difference represented by the doppelganger: the irreducibility of the person to the represented user.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {342},
numpages = {15},
keywords = {data doppelganger, data double, digital twin, data subject, posthuman, onto-epistemology, social media, personalized content, creepiness, justifiable optimism, difference},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714326,
author = {Nourian, Laleh and Naikar, Vinaya Hanumant and Shinohara, Kristen and Tigwell, Garreth W.},
title = {Investigating the Intersection of Cultural Design Preferences and Web Accessibility Guidelines with Designers from the Global South},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714326},
doi = {10.1145/3706598.3714326},
abstract = {Cultural background influences aesthetic web design preferences, and aesthetic design impacts accessible design. However, limited research has focused on this intersection of cultural background and accessible web design. With the majority of HCI and design resources originating from the Global North, we investigated the conflicts experienced due to the cultural background of digital designers from the Global South and current web accessibility guidelines. We conducted a design activity and interview study with 10 designers from five countries in the Global South to identify how current web accessibility guidelines conflict with our participants’ cultural design preferences. We found there are specific cultural challenges encountered in accessible web design, both at the design level (e.g., typography and color scheme) and within broader societal contexts (e.g., designer-client interactions). Our paper also offers suggestions from our participants to make the accessible design process more culturally inclusive by improving the web accessibility resources to become culturally customized and engaging more cultural perspectives in accessibility research and education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {343},
numpages = {19},
keywords = {Accessible Design, Cultural Background, Design, Non-Western Designers},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713176,
author = {Biehl, Austin and Perez, Daniela and Ingle, Jessica and Ames, Morgan G.},
title = {Prestige and Prejudice: How the Interplay of Recruiting Work and Algorithms Reinforces Social Inequities in Software Engineering},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713176},
doi = {10.1145/3706598.3713176},
abstract = {The technology industry has long sought to diversify its workforce. This study evaluates one avenue that works against these efforts: the interaction between recruiter work practices and algorithmic recruiting tools. Through interviews and cognitive walkthroughs with fifteen recruiters, we find that recruiters—often under deadlines and quotas—develop shortcuts (e.g., computer science degrees and employment at prestigious companies) for identifying “typical” software engineers (one of the most sought-after roles in the field) who have a higher chance of being successfully hired. We then analyze the results of searches like those recruiters often conduct in one commonly-used recruitment tool. We see recruiters’ shortcuts also reflected in these results: candidates with computer science degrees, living in expensive tech hubs, and employed at high-profile tech companies are disproportionately favored. Given the lack of demographic diversity in software engineering at prestigious companies, we assert that algorithmically preferencing these factors helps to reify existing stereotypes, impacting the diversity of candidates who are ultimately hired.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {344},
numpages = {16},
keywords = {Technology companies, hiring, recruiting automation, algorithmic decision systems, social class},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713626,
author = {Xiao, Yimin and Hancock, Cartor and Agrawal, Sweta and Mehandru, Nikita and Salehi, Niloufar and Carpuat, Marine and Gao, Ge},
title = {Sustaining Human Agency, Attending to Its Cost: An Investigation into Generative AI Design for Non-Native Speakers' Language Use},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713626},
doi = {10.1145/3706598.3713626},
abstract = {AI systems and tools today can generate human-like expressions on behalf of people. It raises the crucial question about how to sustain human agency in AI-mediated communication. We investigated this question in the context of machine translation (MT) assisted conversations. Our participants included 45 dyads. Each dyad consisted of one new immigrant in the United States, who leveraged MT for English information seeking as a non-native speaker, and one local native speaker, who acted as the information provider. Non-native speakers could influence the English production of their message in one of three ways: labeling the quality of MT outputs, regular post-editing without additional hints, or augmented post-editing with LLM-generated hints. Our data revealed a greater exercise of non-native speakers’ agency under the two post-editing conditions. This benefit, however, came at a significant cost to the dyadic-level communication performance. We derived insights for MT and other generative AI design from our findings.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {345},
numpages = {16},
keywords = {Agency, Machine translation, AI-mediated communication, Non-native speakers},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713549,
author = {Zalake, Mohan and Swirsky, Eric S and Chisunkha, Blessings and Jindal, Monique},
title = {“My doctor didn't give me half of that privilege”: Incorporating Black Patients’ Lived Experiences in Virtual Patients for Racial Bias Mitigation Training},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713549},
doi = {10.1145/3706598.3713549},
abstract = {Despite HCI research emphasizing the direct involvement of racial minorities in technology design, Black patients have been notably excluded when designing virtual patients intended to represent them in healthcare training applications. To address this gap, this paper describes an iterative user-centered design process to create a virtual patient prototype (EQUITY) that authentically reflects real-world racially biased encounters using narratives of Black patients’ lived experiences. EQUITY was developed using insights gathered from 6 focus groups with 33 Black patients (Study 1). EQUITY was evaluated with 25 doctors to assess its effectiveness in inducing disorienting experiences and facilitating self-reflection (Study 2). Findings suggest that incorporating patient narratives, particularly through virtual patients’ verbal and non-verbal behaviors and role-playing, significantly enhanced virtual patient’s authenticity and meaningful self-reflection among doctors. Our research contributes to HCI by identifying key virtual patient interface design features that align with Black patients’ lived experiences of racially biased encounters.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {346},
numpages = {17},
keywords = {Virtual Patient, Design Guidelines, Participatory Design, Lived Experiences, Racial Bias, Medical Education, Doctors},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714133,
author = {Kim, Jiwan and Han, Mingyu and Oakley, Ian},
title = {BudsID: Mobile-Ready and Expressive Finger Identification Input for Earbuds},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714133},
doi = {10.1145/3706598.3714133},
abstract = {Wireless earbuds are an appealing platform for wearable computing on-the-go. However, their small size and out-of-view location mean they support limited different inputs. We propose finger identification input on earbuds as a novel technique to resolve these problems. This technique involves associating touches by different fingers with different responses. To enable it on earbuds, we adapted prior work on smartwatches to develop a wireless earbud featuring a magnetometer that detects fields from a magnetic ring. A first study reveals participants achieve rapid, precise earbud touches with different fingers, even while mobile (time: 0.98s, errors: 5.6\%). Furthermore, touching fingers can be accurately classified (96.9\%). A second study shows strong performance with a more expressive technique involving multi-finger double-taps (inter-touch time: 0.39s, errors: 2.8\%) while maintaining high accuracy (94.7\%). We close by exploring and evaluating the design of earbud finger identification applications and demonstrating the feasibility of our system on low-resource devices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {347},
numpages = {17},
keywords = {Earbuds, Touch input, Finger identification, Magnetic sensing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714171,
author = {Guo, Kaiyi and Zhang, Qian and Wang, Dong},
title = {EchoBreath: Continuous Respiratory Behavior Recognition in the Wild via Acoustic Sensing on Smart Glasses},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714171},
doi = {10.1145/3706598.3714171},
abstract = {Monitoring the occurrence count of abnormal respiratory symptoms helps provide critical support for respiratory health. While this is necessary, there is still a lack of an unobtrusive and reliable way that can be effectively used in real-world settings. In this paper, we present EchoBreath, a passive and active acoustic combined sensing system for abnormal respiratory symptoms monitoring. EchoBreath novelly uses the speaker and microphone under the frame of the glasses to emit ultrasonic waves and capture both passive sounds and echo profiles, which can effectively distinguish between subject-aware behaviors and background noise. Furthermore, A lightweight neural network with the ‘Null’ class and open-set filtering mechanisms substantially improves real-world applicability by eliminating unrelated activity. Our experiments, involving 25 participants, demonstrate that EchoBreath can recognize 6 typical respiratory symptoms in a laboratory setting with an accuracy of 93.1\%. Additionally, an in-the-semi-wild study with 10 participants further validates that EchoBreath can continuously monitor respiratory abnormalities under real-world conditions. We believe that EchoBreath can serve as an unobtrusive and reliable way to monitor abnormal respiratory symptoms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {348},
numpages = {21},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713907,
author = {Watanabe, Yuki and Chiba, Hironobu and Noguchi, Kenichi and Itou, Hiroaki and Kako, Tatsuya},
title = {Effects of Acoustic Transparency of Wearable Audio Devices on Audio AR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713907},
doi = {10.1145/3706598.3713907},
abstract = {The provision of audio augmented reality (AAR) experiences is becoming more widespread. In this study, to investigate the influence of device design on AAR experience from the perspective of acoustic transparency, physical and subjective evaluations were conducted using five devices with different shapes and transparency modes. In the subjective evaluation, perceived transparency, impressions of real-world sound, and subjective impressions of AAR experience when wearing each device were evaluated for two distinct content types. We found that device design can potentially influence impressions of real-world sound, such as auditory source width, listener envelopment and punch, and subjective impressions during AAR experience. Devices with high transparency were more likely to draw attention to real-world sounds when users were experiencing AAR, and the experience was evaluated as enjoyable and natural. Two demonstration experiments showed that adding virtual sounds by open-ear earphones to real contents can provide acoustic effects such as distance enhancement.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {349},
numpages = {15},
keywords = {Acoustic Transparency, Augmented Reality, Spatial Impression, Wearable Audio Devices, Audio},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714177,
author = {Amesaka, Takashi and Yamamoto, Takumi and Watanabe, Hiroki and Shizuki, Buntarou and Sugiura, Yuta},
title = {FlexEar-Tips: Shape-Adjustable Ear Tips Using Pressure Control},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714177},
doi = {10.1145/3706598.3714177},
abstract = {We introduce FlexEar-Tips, a dynamic ear tip system designed for the next-generation hearables. The ear tips are controlled by an air pump and solenoid valves, enabling size adjustments for comfort and functionality. FlexEar-Tips includes an air pressure sensor to monitor ear tip size, allowing it to adapt to environmental conditions and user needs. In the evaluation, we conducted a preliminary investigation of the size control accuracy and the minimum amount of variability of haptic perception in the user’s ear. We then evaluated the user’s ability to identify patterns in the haptic notification system, the impact on the music listening experience, the relationship between the size of the ear tips and the sound localization ability, and the impact on the reduction of humidity in the ear using a model. We proposed new interaction modalities for adaptive hearables and discussed health monitoring, immersive auditory experiences, haptics notifications, biofeedback, and sensing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {350},
numpages = {13},
keywords = {Hearables, Earables, Pneumatics, Inflatable Interface, Haptics, Tactile},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713893,
author = {Yang, Qiang and Liu, Yang and Stuchbury-Wass, Jake and Butkow, Kayla-Jade and Panariti, Emeli and Ma, Dong and Mascolo, Cecilia},
title = {SmarTeeth: Augmenting Manual Toothbrushing with In-ear Microphones},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713893},
doi = {10.1145/3706598.3713893},
abstract = {Improper toothbrushing practices persist as a primary cause of oral health issues such as tooth decay and gum disease. Despite the availability of high-end electric toothbrushes that offer some guidance, manual toothbrushes remain widely used due to their simplicity and convenience. We present SmarTeeth, an earable-based toothbrushing monitoring system designed to augment manual toothbrushing with functionalities typically offered only by high-end electric toothbrushes, such as brushing surface tracking. The underlying idea of SmarTeeth is to leverage in-ear microphones on earphones to capture toothbrushing sounds transmitted through the oral cavity to ear canals through facial bones and tissues. The distinct propagation paths of brushing sounds from various dental locations to each ear canal provide the foundational basis for our methods to accurately identify different brushing locations. By extracting customized features from these sounds, we can detect brushing locations using a deep-learning model. With only one registration session ((sim 2 mins)) for a new user, the average accuracy is 92.7\% for detecting six regions and 75.6\% for sixteen tooth surfaces. With three registration sessions ((sim 6 mins)), the performance can be boosted to 98.8\% and 90.3\% for six-region and sixteen-surface tracking, respectively. A key advantage of using earphones for monitoring is that they provide natural auditory feedback to alert users when they are overbrushing or underbrushing. Comprehensive evaluation validates the effectiveness of SmarTeeth under various conditions (different users, brushes, orders, noise, etc.), and the feedback from the user study (N=13) indicates that users found the system highly useful (6.0/7.0) and reported a low workload (2.5/7.0) while using it. Our findings suggest that SmarTeeth could offer a scalable and effective solution to improve oral health globally by providing manual toothbrush users with advanced brushing monitoring capabilities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {351},
numpages = {19},
keywords = {Toothbrushing monitoring, Acoustic sensing, Earable devices},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713745,
author = {Chen, Tuochao and Wang, Qirui and He, Runlin and Gollakota, Shyamnath},
title = {Spatial Speech Translation: Translating Across Space With Binaural Hearables},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713745},
doi = {10.1145/3706598.3713745},
abstract = {Imagine being in a crowded space where people speak a different language and having hearables that transform the auditory space into your native language, while preserving the spatial cues for all speakers. We introduce spatial speech translation, a novel concept for hearables that translate speakers in the wearer’s environment, while maintaining the direction and unique voice characteristics of each speaker in the binaural output. To achieve this, we tackle several technical challenges spanning blind source separation, localization, real-time expressive translation, and binaural rendering to preserve the speaker directions in the translated audio, while achieving real-time inference on the Apple M2 silicon. Our proof-of-concept evaluation with a prototype binaural headset shows that, unlike existing models, which fail in the presence of interference, we achieve a BLEU score of upto 22.01 when translating between languages, despite strong interference from other speakers in the environment. User studies further confirm the system’s effectiveness in spatially rendering the translated speech in previously unseen real-world reverberant environments. Taking a step back, this work marks the first step towards integrating spatial perception into speech translation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {352},
numpages = {19},
keywords = {Speech translation, spatial computing, augmented audio},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713108,
author = {Chen, Weijen and Gao, Qingyuan and Hu, Zheng and Minamizawa, Kouta and Pai, Yun Suen},
title = {Living Bento: Heartbeat-Driven Noodles for Enriched Dining Dynamics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713108},
doi = {10.1145/3706598.3713108},
abstract = {To enhance focused eating and dining socialization, previous Human-Food Interaction research has indicated that external devices can support these dining objectives and immersion. However, methods that focus on the food itself and the diners themselves have remained underdeveloped. In this study, we integrated biofeedback with food, utilizing diners’ heart rates as a source of the food’s appearance to promote focused eating and dining socialization. By employing LED lights, we dynamically displayed diners’ real-time physiological signals through the transparency of the food. Results revealed significant effects on various aspects of dining immersion, such as awareness perceptions, attractiveness, attentiveness to each bite, and emotional bonds with the food. Furthermore, to promote dining socialization, we established a “Sharing Bio-Sync Food” dining system to strengthen emotional connections between diners. Based on these findings, we developed tableware that integrates biofeedback into the culinary experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {353},
numpages = {18},
keywords = {human-food interaction, physiological activities, emotional understanding, food design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713183,
author = {Ha, Seung Wan and Nurain, Novia and Agapie, Elena and Chung, Chia-Fang},
title = {Preparing and Experiencing Food During Life Events: Implications for Technology Supporting Social and Value Changes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713183},
doi = {10.1145/3706598.3713183},
abstract = {Healthy eating is essential to overall well-being. Deciding what and how to eat often requires collaboration and coordination with others to develop routines and create enjoyable experiences. However, life changes like moving or unemployment can disrupt food routines and social dining. Current technologies often overlook these evolving changes and do not adequately support individuals in collaborating with others to adapt to these impacts. In this paper, we interviewed 18 participants who experienced various routine changes during life events. Findings highlight the need for tools to support individuals in adapting to food practices, facilitating social coordination, and mediating conflicts during transitions. We explore design opportunities that facilitate technology reconfiguration, value clarification and mediation, and social coordination, aiming to better support individuals in times of change, both for those who undergo life events and others who offer help with food practices. Our work offers design considerations for technologies that enhance healthy eating and food service, ensuring sustained support during life changes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {354},
numpages = {14},
keywords = {Food, healthy eating, life events, transitions, value},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713326,
author = {Keys, Rachel and Marshall, Paul and Stuart, Graham and O'Kane, Aisling Ann},
title = {Rethinking Lived Experience in Chronic Illness: Navigating Bodily Doubt with Consumer Technology in Atrial Fibrillation Self-Care},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713326},
doi = {10.1145/3706598.3713326},
abstract = {Consumer technology is increasingly used to support the self-care of atrial fibrillation (AF), a chronic heart condition that affects physical, emotional, and mental health due to its unpredictability, symptoms, and complications. Through interviews with 29 adults self-tracking while living with AF, we found that consumer technology enabled participants to outsource bodily awareness to their ’digitised heart,’ facilitating innovative pill-in-pocket interventions and empowering negotiation in shared decision-making. Drawing on phenomenology, we introduce ’Bodily Doubt’ to explain how uncertainty about the body shapes the use of technology in chronic illness and how the use of technology influences uncertainty. Technology mediates ’Bodily Doubt’ both by providing reassurance and exacerbating it, particularly when technology fails to adapt to disease progression. Our findings have implications for understanding how technology influences the lived experience of illness, challenging experiential concepts of lived experience in self-tracking and design that foregrounds the experience of the lived body.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {355},
numpages = {19},
keywords = {Self-Tracking, Cardiovascular Disease, Self-Care Technology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713892,
author = {Deng, Jialin and Li, Yinyi and Wang, Hongyue and Fang, Ziqi and Mueller, Florian ‘Floyd’},
title = {Sonic Delights: Exploring the Design of Food as An Auditory-Gustatory Interface},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713892},
doi = {10.1145/3706598.3713892},
abstract = {While interest in blending sound with culinary experiences has grown in Human-Food Interaction (HFI), the significance of food's material properties in shaping sound-related interactions has largely been overlooked. This paper explores the opportunity to enrich the HFI experience by treating food not merely as passive nourishment but as an integral material in computational architecture with input/output capabilities. We introduce “Sonic Delights,” where food is a comestible auditory-gustatory interface to enable users to interact with and consume digital sound. This concept redefines food as a conduit for interactive auditory engagement, shedding light on the untapped multisensory possibilities of merging taste with digital sound. An associated study allowed us to articulate design insights for forthcoming HFI endeavors that seek to weave food into multisensory design, aiming to further the integration of digital interactivity with the culinary arts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {356},
numpages = {19},
keywords = {Edible Interface, Food Design, Human-Food Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714404,
author = {Mitchell, Elliot G and Desai, Pooja and Smaldone, Arlene and Cassells, Andrea and Tobin, Jonathan N. and Albers, David and Levine, Matthew and Mamykina, Lena},
title = {T2 Coach: A Qualitative Study of an Automated Health Coach for Diabetes Self-Management},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714404},
doi = {10.1145/3706598.3714404},
abstract = {Computational intelligence is increasingly common in interactive systems in many domains, including health. Health coaching with conversational agents (CA) can reach wide populations, but the level of computational intelligence needed for a positive coaching experience is unclear. We conducted a study with sixteen individuals with diabetes and prediabetes who used a CA for health coaching, T2 Coach. Qualitative interviews revealed that participants saw T2 Coach as reliable in helping them stay on track with self-management, appreciated the flexibility in choosing personally meaningful goals and engaging on their own terms, and felt it provided encouragement and even compared it favorably with human coaches. However, they also noted that coaching experience could be improved with more fluid conversations, more tailoring to their personal preferences and lifestyles, and more sensitivity to specific contexts, all of which require more computational intelligence. We discuss implications and design directions for more intelligent coaching CA in health.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {357},
numpages = {17},
keywords = {Health, chatbots, coaching, conversational agents, diabetes, mHealth, self-management, self-tracking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714237,
author = {Wang, Hongyue and Deng, Jialin and He, Linjia and Overdevest, Nathalie and Wee, Ryan and Wang, Yan and Toups Dugas, Phoebe O. and Elvitigala, Don Samitha and Mueller, Florian Floyd},
title = {Towards Understanding Interactive Sonic Gastronomy with Chefs and Diners},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714237},
doi = {10.1145/3706598.3714237},
abstract = {With advancements in interactive technologies, research in human-food interaction (HFI) has begun to employ interactive sound to enrich the dining experience. However, chefs’ creative use of this sonic interactivity as a new “ingredient” in their culinary practices remains underexplored. In response, we conducted an empirical study with six pairs of chefs and diners utilizing SoniCream, an ice cream cone that plays digital sounds while consuming. Through exploration, creation, collaboration, and reflection, we identified four themes concerning culinary creativity, dining experience, interactive sonic gastronomy deployment, and chef-diner interplay. Building on the discussions at the intersection of these themes, we derived four design implications for creating interactive systems that could support chefs’ culinary creativity, thereby enriching dining experiences. Ultimately, our work aims to help interaction designers fully incorporate chefs’ perspectives into HFI research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {358},
numpages = {19},
keywords = {Human-food interaction, interactive sound, culinary creativity, food design, chef},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713793,
author = {Chen, Yang and Tan, Felicia Fang-Yi and Wang, Zhuoyu and Liu, Xing and Zhang, Jiayi and Huang, Yun and Zhao, Shengdong and Yen, Ching Chiuan},
title = {ViFeed: Promoting Slow Eating and Food Awareness through Strategic Video Manipulation during Screen-Based Dining},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713793},
doi = {10.1145/3706598.3713793},
abstract = {Given the widespread presence of screens during meals, the notion that digital engagement is inherently incompatible with mindfulness. We demonstrate how the strategic design of digital content can enhance two core aspects of mindful eating: slow eating and food awareness. Our research unfolded in three sequential studies: (1). Zoom Eating Study: Contrary to the assumption that video-watching leads to distraction and overeating, this study revealed that subtle video speed manipulations—can promote slower eating (by 15.31\%) and controlled food intake (by 9.65\%) while maintaining meal satiation and satisfaction. (2). Co-design workshop: Informed the development of ViFeed, a video playback system strategically incorporating subtle speed adjustments and glanceable visual cues. (3). Field Study: A week-long deployment of ViFeed in daily eating demonstrated its efficacy in fostering food awareness, food appreciation, and sustained engagement. By bridging the gap between ideal mindfulness practices and screen-based behaviors, this work offers insights for designing digital-wellbeing interventions that align with, rather than against, existing habits.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {359},
numpages = {24},
keywords = {Mindful eating; Eating intervention; Behavior Change; Empirical study.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713223,
author = {Yadav, Deepika and Zheng, Caroline Yan and St\r{a}hl, Anna and Balaam, Madeline},
title = {A Route to Somatic Literacy of the Pelvic Floor through Technology-Initiated Touch},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713223},
doi = {10.1145/3706598.3713223},
abstract = {The Pelvic Chair is a shape-changing chair that touches the pelvic area. Through rhythmic and gentle movements on different parts of the pelvic area, the touch interactions from the Pelvic Chair invite attention to the anatomy, muscles, and connectedness. We present a user study with 14 participants focusing on their experience of being touched by the Pelvic Chair. Through our qualitative analysis of participants’ experiences, we show that meaningful touch can offer an active approach to sensing the pelvic floor that contributes to increasing somatic literacy - becoming familiar with the pelvic floor, being able to feel and distinguish between tension and relaxation, and establishing new connections between the pelvic floor and the body. Using the Pelvic Chair as a design case we show the potential for technology-initiated touch in providing an intimate and safe way of touching and connecting with the body.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {360},
numpages = {17},
keywords = {intimate touch, pelvic floor, body awareness, haptic interactions, shape-changing, touch, intimate health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713676,
author = {Choudhary, Siya and Nith, Romain and Ho, Yun and Brooks, Jas and Guruvugari, Mithil and Lopes, Pedro},
title = {Adaptive Electrical Muscle Stimulation Improves Muscle Memory},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713676},
doi = {10.1145/3706598.3713676},
abstract = {Electrical muscle stimulation (EMS) has been leveraged to assist in learning motor skills by actuating the user's muscles. However, existing systems provide static demonstration—actuating the correct movements, regardless of the user's learning progress. Instead, we contrast two versions of a piano-tutoring system: a conventional EMS setup that moves the participant's fingers to play the sequence of movements correctly, and a novel adaptive-EMS system that changes its guidance strategy based on the participant's performance. The adaptive-EMS dynamically adjusts its guidance: (1) demonstrate by playing the entire sequence when errors are frequent; (2) correct by lifting incorrect fingers and actuating the correct one when errors are moderate; and (3) warn by lifting incorrect fingers when errors are low. We found that adaptive-EMS improved learning outcomes (recall) and was preferred by participants. We believe this approach could inspire new types of physical tutoring systems that promote adaptive over static guidance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {361},
numpages = {11},
keywords = {agency, electrical muscle stimulation, haptics, learning, motor skills},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713605,
author = {Niijima, Arinobu and Takeda, Shoichiro},
title = {Improving Putting Accuracy with Electrical Muscle Stimulation Feedback Guided by Muscle Synergy Analysis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713605},
doi = {10.1145/3706598.3713605},
abstract = {Muscle synergy analysis provides a method for quantifying differences in muscle use between expert and novice athletes. However, the practical applications of muscle synergy analysis with feedback remain underexplored. In this paper, we present a golf putting training system that utilizes electrical muscle stimulation (EMS) feedback guided by muscle synergy analysis. Considering the individual differences, we use optimal transport to compute the muscle synergy similarity between users and experts. This approach allows users to model their muscle usage after the expert whose synergy is closest. Based on the muscle synergy differences between the expert and the user, EMS is applied to the muscles that need activation. As a result, users can practice putting with increased awareness of the muscles targeted by EMS, resulting in changes in muscle synergy and improved performance. User studies with 44 novices demonstrated that the proposed system significantly improved putting accuracy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {362},
numpages = {11},
keywords = {Muscle synergy, Electrical muscle stimulation, Optimal transport, Golf},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713872,
author = {Dinh, Jamie Ngoc and Shrestha, Snehesh and Kim, You-Jin and Nishida, Jun and Lee, Myungin},
title = {NeuResonance: Exploring Feedback Experiences for Fostering the Inter-brain Synchronization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713872},
doi = {10.1145/3706598.3713872},
abstract = {When several individuals collaborate on a shared task, their brain activities often synchronize. This phenomenon, known as Inter-brain Synchronization (IBS), is notable for inducing prosocial outcomes such as enhanced interpersonal feelings, including closeness, trust, empathy, and more. Further strengthening the IBS with the aid of external feedback would be beneficial for scenarios where those prosocial feelings play a vital role in interpersonal communication, such as rehabilitation between a therapist and a patient, motor skill learning between a teacher and a student, and group performance art. This paper investigates whether visual, auditory, and haptic feedback of the IBS level can further enhance its intensity, offering design recommendations for feedback systems in IBS. We report findings when three different types of feedback were provided: IBS level feedback by means of on-body projection mapping, sonification using chords, and vibration bands attached to the wrist.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {363},
numpages = {16},
keywords = {Inter-brain Synchronization, Projection mapping, Sonification, Vibrotactile feedback},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713465,
author = {Liu, Ruofan and Peng, Yichen and Oku, Takanori and Liao, Chen-Chieh and Wu, Erwin and Furuya, Shinichi and Koike, Hideki},
title = {PiaMuscle: Improving Piano Skill Acquisition by Cost-effectively Estimating and Visualizing Activities of Miniature Hand Muscles},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713465},
doi = {10.1145/3706598.3713465},
abstract = {Understanding neuromusculoskeletal mechanisms significantly impacts skill specialization and proficiency. While existing methods can infer large muscle activities during gross motor movements, the estimation of dexterous motor control involving miniature muscles remains underexplored. Targeting the coordinated hand muscles in advanced piano performance, we learn spatiotemporal discrete representations of electromyography (EMG) data and hand postures utilizing a multimodal dataset. Subsequently, we train a precise and cost-effective neural network model. Based on this model, PiaMuscle is introduced to investigate if visualizing muscle activities during piano training enhances piano performance. Quantitative and qualitative results of a user study with highly skilled professional pianists demonstrate that PiaMuscle provides reliable muscle activation data to support and optimize force control. Our research underscores the potential of a naturalistic workflow to estimate small muscles’ activities from readily accessible human-centric information and more accurately when combined with tool-centric data, thereby enhancing skill acquisition.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {364},
numpages = {16},
keywords = {Electromyography Estimation, Muscle Analysis, Multimodal Learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713767,
author = {Hwang, Seokhyun and Kang, Seongjun and Oh, Jeongseok and Park, Jeongju and Shin, Semoo and Luo, Yiyue and DelPreto, Joseph and Lee, Sangbeom and Lee, Kyoobin and Matusik, Wojciech and Rus, Daniela and Kim, SeungJun},
title = {TelePulse: Enhancing the Teleoperation Experience through Biomechanical Simulation-Based Electrical Muscle Stimulation in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713767},
doi = {10.1145/3706598.3713767},
abstract = {This paper introduces TelePulse, a system integrating biomechanical simulation with electrical muscle stimulation (EMS) to provide precise haptic feedback for robot teleoperation tasks in virtual reality (VR). TelePulse has two components: a physical simulation part that calculates joint torques based on real-time force data from remote manipulators, and an electrical stimulation part that converts these torques into muscle stimulation. Two experiments were conducted to evaluate the system. The first experiment assessed the accuracy of EMS generated through biomechanical simulations by comparing it with electromyography (EMG) data during force-directed tasks, while the second experiment evaluated the impact of TelePulse on teleoperation performance during sanding and drilling tasks. The results suggest that TelePulse provided more accurate stimulation across all arm muscles, thereby enhancing task performance and user experience in the teleoperation environment. In this paper, we discuss the effect of TelePulse on teleoperation, its limitations, and areas for future improvement.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {365},
numpages = {26},
keywords = {Teleoperation; Virtual Reality; Haptic; Electrical Muscle Stimulation; Biomechanics; Simulation; Wearable Device},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714183,
author = {Villa, Steeven and Krammer, Finn Jacob Eliyah and Weiss, Yannick and Welsch, Robin and Kosch, Thomas},
title = {Understanding the Influence of Electrical Muscle Stimulation on Motor Learning: Enhancing Motor Learning or Disrupting Natural Progression?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714183},
doi = {10.1145/3706598.3714183},
abstract = {Electrical Muscle Stimulation (EMS) induces muscle movement through external currents, offering a novel approach to motor learning. Researchers investigated using EMS as an alternative to conventional non-movement-inducing feedback techniques, such as vibrotactile and electrotactile feedback. While EMS shows promise in areas such as dance, sports, and motor skill acquisition, neurophysiological models of motor learning conflict about the impact of externally induced movements on sensorimotor representations. This study evaluated EMS against electrotactile feedback and a control condition in a two-session experiment assessing fast learning, consolidation, and learning transfer. Our results suggest an overall positive impact of EMS in motor learning. Although traditional electrotactile feedback had a higher learning rate, EMS increased the learning plateau, as measured by a three-factor exponential decay model. This study provides empirical evidence supporting EMS as a plausible method for motor augmentation and skill transfer, contributing to understanding its role in motor learning.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {366},
numpages = {17},
keywords = {Electrical Muscle Stimulation, Motor Learning, Learning Effects},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713158,
author = {Reinders, Samuel and Butler, Matthew and Marriott, Kim},
title = {"It Brought the Model to Life": Exploring the Embodiment of Multimodal I3Ms for People who are Blind or have Low Vision},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713158},
doi = {10.1145/3706598.3713158},
abstract = {3D-printed models are increasingly used to provide people who are blind or have low vision (BLV) with access to maps, educational materials, and museum exhibits. Recent research has explored interactive 3D-printed models (I3Ms) that integrate touch gestures, conversational dialogue, and haptic vibratory feedback to create more engaging interfaces. Prior research with sighted people has found that imbuing machines with human-like behaviours, i.e.,&nbsp; embodying them, can make them appear more lifelike, increasing social perception and presence. Such embodiment can increase engagement and trust. This work presents the first exploration into the design of embodied I3Ms and their impact on BLV engagement and trust. In a controlled study with 12 BLV participants, we found that I3Ms using specific embodiment design factors, such as haptic vibratory and embodied personified voices, led to an increased sense of liveliness and embodiment, as well as engagement, but had mixed impact on trust.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {367},
numpages = {19},
keywords = {3D-Printed Models, Accessibility, Conversational Agents, Embodiment, Engagement, Trust, Blindness},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713586,
author = {Desnoyers-Stewart, John and Antle, Alissa N. and Riecke, Bernhard E.},
title = {Being in Virtual Worlds: How Interaction Environment and Touch Shape Embodiment in Immersive Experiences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713586},
doi = {10.1145/3706598.3713586},
abstract = {Embodiment is an everyday experience that typically goes unnoticed. While we often take it for granted, with the adoption of virtual reality (VR) technology, embodiment in virtual bodies and worlds has become an important consideration for designers of immersive experiences. To date, the VR design community has primarily considered embodiment in terms of body ownership over a synchronized visual representation. In this paper, we construct an interactional framework of virtual embodiment, beginning by revisiting what it really means to be “embodied.” Our framework reconnects embodiment and presence in virtual environments founded in Dourish’s concept of embodied interaction and Heidegger’s Dasein or “being-in-the-world.” We discuss how embodiment, fundamentally rooted in past and present interactions, changes our understanding of body ownership and its extension into VR. Integrating theories from VR research, philosophy, HCI, and psychology we uncover the complex interplay of interaction, environment, and touch in shaping embodied experiences. We present a novel framework for understanding embodiment in VR rooted in interaction, enabling designers to create more immersive and meaningful virtual worlds.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {368},
numpages = {16},
keywords = {embodiment, meaning in interaction, affordances, immersive experience, virtual reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713506,
author = {Iarygina, Olga and Hornb\ae{}k, Kasper and Mottelson, Aske},
title = {Does Random Movements mean Random Results? Why Asynchrony in Experiments on Body Ownership does not Work as Intended},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713506},
doi = {10.1145/3706598.3713506},
abstract = {Effects of embodying virtual avatars are routinely validated experimentally by comparing synchronous and asynchronous movements between virtual and real bodies. This experimental paradigm, however, lacks justification, validation, and standardization. Asynchrony is implemented in numerous ways, such as through delayed, dislocated, or prerecorded movements, and these may impact embodiment and user experience distinctively. An online study (N = 202) revealed that variations of asynchrony cause disparate responses to embodiment and user experience, with prerecorded movements distorting embodiment the most. A think-aloud study (N = 16) revealed that asynchronous conditions lead to peculiar and oftentimes negative experiences. Furthermore, asynchronous conditions in some cases maintain, rather than break the body ownership illusion, as participants imitate the virtual body. Our results show that asynchrony in experiments on embodiment entails profound validity issues and should therefore be used with caution.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {369},
numpages = {19},
keywords = {virtual reality, embodiment, body ownership illusions, experiments, confounds, validity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713750,
author = {Krauss, Jana and Wienrich, Carolin},
title = {Owning the (Virtual) World: A Systematic Review of Psychological Ownership of Interactive Virtual Objects and Environments},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713750},
doi = {10.1145/3706598.3713750},
abstract = {In this systematic review, we analyze the literature on psychological ownership of virtual objects and environments according to the PRISMA statement. Psychological ownership describes the feelings of possession towards an object which are independent of legal possession. The construct stems from organizational management literature, but is gaining in importance in Human-Computer-Interaction as users invest billions to own virtual objects. The analysis of 21 research papers reveals how and why ownership emerges and presents the dimensions and consequences of such feelings. In addition, we relate these variables to the classic psychological ownership motives of self-efficacy, self-identity, and belonging, as well as the routes of control, identity transfer, and intimate knowledge. We outline why designers should pay attention to the phenomenon and how it can be utilized in different contexts. Finally, the paper concludes by outlining why and what research will be needed in the future.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {370},
numpages = {16},
keywords = {Psychological Ownership, Virtual Reality, Augmented Reality, Interactive, Object Attachment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714201,
author = {Luo, Tianren and Wu, Tong and Jiang, Chaoyong and Duan, Xinran and Lv, Jiafu and Li, Nianlong and Fan, Yachun and Han, Teng and Tian, Feng},
title = {RemapVR: An Immersive Authoring Tool for Rapid Prototyping of Remapped Interaction in VR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714201},
doi = {10.1145/3706598.3714201},
abstract = {Remapping techniques in VR such as repositioning, redirection, and resizing have been extensively studied. Still, interaction designers rarely have the opportunity to use them due to high technical and knowledge barriers. In the paper, we extract common features of 24 existing remapping techniques and develop a high-fidelity immersive authoring tool, namely RemapVR, for rapidly building and experiencing prototypes of remapped space properties in VR that are unperceivable or acceptable to users. RemapVR provides designers with a series of functions for editing remappings and visualizing spatial property changes, mapping relationships between real and virtual worlds, sensory conflicts, etc. Designers can quickly build existing remappings via templates, and author new remappings by interactively recording spatial relations between input trajectory in real world and output trajectory in virtual world. User studies showed that the designs of RemapVR can effectively improve designers’ authoring experience and efficiency, and support designers to author remapping prototypes that meet scene requirements and provide good user experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {371},
numpages = {17},
keywords = {Immersive Authoring, Prototyping Tool, Remapped Interaction, Sensory Conflict},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713255,
author = {Ku, Bonhee and Kim, Chang-Min and Cho, Hyungjun and Park, Jisu and Nam, Tek-Jin},
title = {The Effect of In-Car Agent Embodiment on Different Types of Information Delivery},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713255},
doi = {10.1145/3706598.3713255},
abstract = {As vehicles become more advanced, in-car agents must manage increasingly complex interactions, heightening the need for effective information delivery. This paper investigates how different embodiments of in-car agents affect the delivery of various information types. We developed the ‘Drop-lit’ prototype to explore three embodiment features: physicality, characterization, and movement. In a user study with 20 participants, we compared three representative agent designs: abstraction, digital character, and mixed-media, across six categories of in-car information. Additionally, a co-design session allowed participants to self-customize and combine embodiment features for six specific driving scenarios. Results indicated that mixed-media agents were most effective for urgent warnings, digital characters for recommendations, and abstracted agents for simple reference information. The study also revealed how embodiment influenced experiential factors such as attention-grabbing, urgency, friendliness, trustworthiness, and playfulness, offering insights for optimizing agent design to enhance user engagement and information delivery in automotive contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {372},
numpages = {15},
keywords = {In-Car Agents, Human-Vehicle Interaction, Embodiment Design, Information Delivery, Multimodal Interaction, User Experience Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714182,
author = {Eagan, Lillian Maria and Young, Jacob and Bering, Jesse and Langlotz, Tobias},
title = {Virtual Voyages: Evaluating the Role of Real-Time and Narrated Virtual Tours in Shaping User Experience and Memories},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714182},
doi = {10.1145/3706598.3714182},
abstract = {Immersive technologies are capable of transporting people to distant or inaccessible environments that they might not otherwise visit. Practitioners and researchers alike are discovering new ways to replicate and enhance existing tourism experiences using virtual reality, yet few controlled experiments have studied how users perceive virtual tours of real-world locations. In this paper we present an initial exploration of a new system for virtual tourism, measuring the effects of real-time experiences and storytelling on presence, place attachment, and user memories of the destination. Our results suggest that narrative plays an important role in inducing presence within and attachment to the destination, while livestreaming can further increase place attachment while providing flexible, tailored experiences. We discuss the design and evaluation of our system, including feedback from our tourism partners, and provide insights into current limitations and further opportunities for virtual tourism.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {373},
numpages = {19},
keywords = {Virtual Tourism, Virtual Reality, Telepresence, Mixed Reality, Presence, Storytelling, Narrative, User Study, Place attachment, Empirical Study, 360 Panorama, Spatial Audio},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713588,
author = {Chau, Connie W. and Norton, Colleen and Kruzan, Kaylee Payne and Jacobs, Maia},
title = {"All Day, Every Day, Listening to Trauma": Investigating Features of Digital Interventions for Empathy-Based Stress and Burnout},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713588},
doi = {10.1145/3706598.3713588},
abstract = {Frontline workers (FLWs) in gender-based violence (GBV) service provision regularly engage in intense emotional labor to provide survivors of GBV with essential, often life-saving, services. However, FLWs experience intense burnout, resulting in turnover rates as high as 50\% annually and a critical loss of services for survivors. In order to design digital burnout interventions in a context where so few exist, we recruited 15 FLWs for a 3-stage qualitative study where they used two existing applications to reflect on, and reimagine, concrete design features necessary to address FLW burnout in GBV service provision. We contribute important findings regarding designing specifically for empathy-based stress (EBS) in frontline work contexts, preferences for activities, desired interactivity, among other requirements for interventions. We synthesize our design recommendations through an example scenario of a collaborative just-in-time adaptive intervention (co-JITAI) system that integrates peer-based support that can adapt to users’ changing needs and contexts over time.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {374},
numpages = {18},
keywords = {digital mental health, just-in-time adaptive intervention, co-JITAI, empathy-based stress, burnout, emotional labor, health, secondary traumatic stress, trauma, gender-based violence, frontline workers},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714072,
author = {Zhu, Jun and Lolla, Sruzan and Agnihotri, Meeshu and Asgari Tappeh, Sahar and Guluzade, Lala and Agapie, Elena and Sas, Corina},
title = {A Systematic Review and Meta-Analysis of Research on Goals for Behavior Change},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714072},
doi = {10.1145/3706598.3714072},
abstract = {HCI research on goals and behavior change has significantly increased over the past decade. However, while emerging work has synthesized personal informatics goals, fewer efforts have focused on also integrating HCI research on behavior change to chart future research directions. We conducted a systematic review of 180 papers focused on goals and behavior change from over 10 years of SIGCHI journals and conference proceedings. We further analyzed 37 papers from the data set that included evaluations of interventions’ effectiveness in-the-wild. We also reported on the effectiveness of 76 of such technology-based interventions and the meta-analysis of 28 of these interventions. We find that most research has focused on goals in the health and wellbeing domains, centered on the individual, low intrinsic goals, and partial use of theoretical constructs in technology-based interventions. We highlight opportunities for supporting multiple-domain, social, high intrinsic, and qualitative goals in HCI research for behavior change, and for more effective technology-based interventions with stronger theoretical underpinning, supporting users’ awareness of deep motives for qualitative goals.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {375},
numpages = {25},
keywords = {systematic review, meta-analysis, goals, behavior change, intervention effectiveness},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713453,
author = {Zheng, Xi and Li, Zhuoyang and Gui, Xinning and Luo, Yuhan},
title = {Customizing Emotional Support: How Do Individuals Construct and Interact With LLM-Powered Chatbots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713453},
doi = {10.1145/3706598.3713453},
abstract = {Personalized support is essential to fulfill individuals’ emotional needs and sustain their mental well-being. Large language models (LLMs), with great customization flexibility, hold promises to enable individuals to create their own emotional support agents. In this work, we developed ChatLab, where users could construct LLM-powered chatbots with additional interaction features including voices and avatars. Using a Research through Design approach, we conducted a week-long field study followed by interviews and design activities (N = 22), which uncovered how participants created diverse chatbot personas for emotional reliance, confronting stressors, connecting to intellectual discourse, reflecting mirrored selves, etc. We found that participants actively enriched the personas they constructed, shaping the dynamics between themselves and the chatbot to foster open and honest conversations. They also suggested other customizable features, such as integrating online activities and adjustable memory settings. Based on these findings, we discuss opportunities for enhancing personalized emotional support through emerging AI technologies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {376},
numpages = {20},
keywords = {Emotional support, Chatbot, Wellbeing, Large language model, Prompt, Customization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714260,
author = {Wenhart, Christiane and Ringfort-Felner, Ronda and Wallbaum, Torben and Amidi, Maryam and Albers, Ruben and Hassenzahl, Marc},
title = {Relatedness Technologies: An Online Compendium and Systematic Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714260},
doi = {10.1145/3706598.3714260},
abstract = {Over the past decades, numerous concepts and prototypes for fostering emotional connections across distance (relatedness technologies) have been proposed. This has made it challenging for researchers and designers in Human-Computer Interaction (HCI) to maintain a comprehensive overview and effectively build on previous work. To address this, we conducted a systematic literature search (PRISMA) and collected 241 concepts and prototypes (2010-2024). We organized this corpus according to key aspects: (1) target population, (2) theoretical grounding, (3) design, (4) evaluation, and (5) ethics. Based on this, we developed the “COmpendium of RElatedness Technologies” (CORE), an open-access, searchable online database that provides researchers and practitioners with a reliable repository to inform future work. In addition, we present a systematic review of the corpus, revealing that despite its long tradition work on relatedness technologies remains characterized by limited theoretical grounding, lack of robust empirical evidence of effects, and insufficient attention to ethical considerations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {377},
numpages = {48},
keywords = {Connectedness, Database, Experience Design, Relatedness, Relatedness Technology, Systematic Review},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713483,
author = {Zhou, Nianmei and Devleminck, Steven and Geurts, Lucca},
title = {Squeeze Away the Worries: Exploring the Potential of Squeezable Interactions for Emotion Regulation for Desk Workers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713483},
doi = {10.1145/3706598.3713483},
abstract = {Desk workers may often experience more negative than positive emotions in office settings, making emotion regulation (ER) crucial for their mental health. Squeezable interfaces have shown the potential to reduce anxiety and stress in digital and non-digital ER. However, few studies have explored how they can be leveraged to provide tangible and embodied support for workplace ER.We interviewed five mental health experts and 16 desk workers and conducted five co-design workshops with 17 desk workers, aiming to understand how validated practices can be integrated into squeezable interfaces and how they should be designed to support ER and accommodate diverse needs in the context of the workplace. This study contributes to digital ER by identifying design opportunities for squeezable interfaces and by outlining design considerations and challenges for tangible and embodied interactions in ER support within the workplace.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {378},
numpages = {20},
keywords = {tangible interaction, squeezable interaction, emotion, affective computing, emotion awareness, emotion regulation, digital well-being, workplace},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714122,
author = {Ju, Hyojin and Lee, Jungeun and Yang, Seungwon and Ok, Jungseul and Hwang, Inseok},
title = {Toward Affective Empathy via Personalized Analogy Generation: A Case Study on Microaggression},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714122},
doi = {10.1145/3706598.3714122},
abstract = {The importance of empathy cannot be overstated in modern societies where people of diverse backgrounds increasingly interact together. The HCI community has strived to foster affective empathy through immersive technologies. Many previous techniques are built upon a premise that presenting the same experience as-is may help evoke the same emotion, which however faces limitations in matters where the emotional responses largely differ across individuals. In this paper, we present a novel concept of generating a personalized experience based on a large language model (LLM) to facilitate affective empathy between individuals despite their differences. As a case study to showcase its effectiveness, we developed EmoSync, an LLM-based agent that generates personalized analogical microaggression situations, facilitating users to personally resonate with a specific microaggression situation of another person. EmoSync is designed and evaluated along a 3-phased user study with 100+ participants. We comprehensively discuss implications, limitations, and possible applications.Disclaimer: Readers may find content of a discriminative or stereotypical nature, which is inevitable given this work’s theme.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {379},
numpages = {31},
keywords = {Empathy, Personalized Analogy Generation, Microaggression, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713986,
author = {Dangol, Aayushi and Lewis, Aaleyah and Suh, Hyewon and Hong, Xuesi and Meadan, Hedda and Fogarty, James and Kientz, Julie A.},
title = {“I Want to Think Like an SLP”: A Design Exploration of AI-Supported Home Practice in Speech Therapy},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713986},
doi = {10.1145/3706598.3713986},
abstract = {Parents of children in speech therapy play a crucial role in delivering consistent, high-quality home practice, which is essential for helping children generalize new speech skills to everyday situations. However, this responsibility is often complicated by uncertainties in implementing therapy techniques and keeping children engaged. In this study, we explore how varying levels of AI oversight can provide informational, emotional, and practical support to parents during home speech therapy practice. Through semi-structured interviews with 20 parents, we identified key challenges they face and their ideas for AI assistance. Using these insights, we developed six design concepts, which were then evaluated by 20 Speech-Language Pathologists (SLPs) for their potential impact, usability, and alignment with therapy goals. Our findings contribute to the discourse on AI’s role in supporting therapeutic practices, offering design considerations that address the needs and values of both families and professionals.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {380},
numpages = {22},
keywords = {Speech and language difficulties, Artificial Intelligence, Human-centered AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714019,
author = {Saka, Suleiman and Das, Sanchari},
title = {"Watch My Health, Not My Data": Understanding Perceptions, Barriers, Emotional Impact, \&amp; Coping Strategies Pertaining to IoT Privacy and Security in Health Monitoring for Older Adults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714019},
doi = {10.1145/3706598.3714019},
abstract = {The proliferation of “Internet of Things (IoT)”&nbsp; provides older adults with critical support for “health monitoring”&nbsp; and independent living, yet significant concerns about security and privacy persist. In this paper, we report on these issues through a two-phase user study, including a survey (N = 22) and semi-structured interviews (n = 9) with adults aged 65 +. We found that while (81.82\%) of our participants are aware of security features like “two-factor authentication (2FA)”&nbsp; and encryption, (63.64\%) express serious concerns about unauthorized access to sensitive health data. Only (13.64\%) feel confident in existing protections, citing confusion over “data sharing policies”&nbsp; and frustration with “complex security settings”&nbsp; which lead to distrust and anxiety. To cope, our participants adopt various strategies, such as relying on family or professional support and limiting feature usage leading to disengagement. Thus, we recommend “adaptive security mechanisms,”&nbsp; simplified interfaces, and real-time transparency notifications to foster trust and ensure “privacy and security by design”&nbsp; in IoT health systems for older adults.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {381},
numpages = {18},
keywords = {Older Adults, IoT, Security, Privacy, Trust, User Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714043,
author = {Clark, Michael and Snow, Gregory L and Seamons, Kent},
title = {Choose From a List: A User Study of Random Password Memorability},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714043},
doi = {10.1145/3706598.3714043},
abstract = {Even for users of password managers, primary passwords are a common root of trust; these must be secure against offline attacks. Randomly generated passwords provide strength guarantees but are less memorable. Cognitive psychology studies have found that providing a choice aids recall, however no studies have investigated the impact of choice on password recall in isolation. To address this, we conducted a longitudinal user study (N=861 at initial follow-up) where users selected and memorized a password from a list of 1, 8, 32, or 128 random passwords. The users entered their password multiple times after selection to improve memory, and we followed up 7 and 28 days later. We found no evidence that selecting from a list improved memorability, which suggests designers and researchers should explore other avenues. Finally, we identify potential directions for new interfaces that help users generate random passwords that will be easier to use.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {382},
numpages = {20},
keywords = {Passwords, Authentication, Memorability, Memory, Algorithm Aversion, Assigned Passwords, Generated Passwords, Random Passwords},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713452,
author = {Jin, Seyoung and Baek, Heewon and Lee, Uichin and Kim, Hyoungshick},
title = {I Was Told to Install the Antivirus App, but I'm Not Sure I Need It: Understanding Smartphone Antivirus Software Adoption and User Perceptions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713452},
doi = {10.1145/3706598.3713452},
abstract = {The rising threat of mobile malware has prompted security vendors to recommend antivirus software for smartphones, yet user misconceptions, regulatory requirements, and improper use undermine its effectiveness. Our mixed-method study, consisting of in-depth interviews with 23 participants and a survey of 250 participants, examines smartphone antivirus software adoption in South Korea, where mandatory installation for banking and other financial apps is common. Many users confuse antivirus software with general security tools and remain unaware of its limited scope. Adoption is significantly influenced by perceived vulnerability, response efficacy, self-efficacy, social norms, and awareness, while concerns about system performance and skepticism about necessity lead to discontinuation or non-use. Mandatory installations for financial apps in South Korea contribute to user misconceptions, negative perceptions, and a false sense of security. These findings highlight the need for targeted user education, clearer communication about mobile-specific threats, and efforts to promote informed and effective engagement with antivirus software.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {383},
numpages = {18},
keywords = {Smartphone Security, Antivirus, Malware},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714318,
author = {Zeng, Eric and Wu, Xiaoyuan and Ertmann, Emily N. and Huang, Lily and Johnson, Danielle F. and Mehendale, Anusha T. and Tang, Brandon T. and Zhukoff, Karolina and Adjei-Poku, Michael and Bauer, Lujo and Friedman, Ari B. and McCoy, Matthew S.},
title = {Measuring Risks to Users' Health Privacy Posed by Third-Party Web Tracking and Targeted Advertising},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714318},
doi = {10.1145/3706598.3714318},
abstract = {Online advertising platforms may be able to infer privacy-sensitive information about people, such as their health conditions. This could lead to harms like exposure to predatory targeted advertising or unwanted disclosure of health conditions to employers or insurers. In this work, we experimentally evaluate whether online advertisers target people with health conditions. We collected the browsing histories of people with and without health conditions. We crawled their histories to simulate their browsing profiles and collected the ads that were served to them. Then, we compared the content of the ads between groups. We observed that the profiles of people who visited more health-related web pages received more health-related ads. 49.5\% of health-related ads used deceptive advertising techniques. Our findings suggest that new privacy regulations and enforcement measures are needed to protect people’s health privacy from online tracking and advertising platforms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {384},
numpages = {26},
keywords = {Health privacy, targeted advertising, web tracking, deceptive advertising, deceptive patterns},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713928,
author = {Zhang, Shuning and Yi, Xin and Li, Shixuan and Xing, Haobin and Li, Hewu},
title = {PrivCAPTCHA: Interactive CAPTCHA to Facilitate Effective Comprehension of APP Privacy Policy},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713928},
doi = {10.1145/3706598.3713928},
abstract = {Traditional app privacy policies are often lengthy and non-interactive, leading users to skip them and remain uninformed. To address this, we proposed PrivCAP, a technique to enhance user comprehension by presenting policies in a concise, interactive format. PrivCAP adopted a CAPTCHA-based design, requiring users to interact with clickable chunks of concise policy content, thus reducing physical and cognitive load. A formative study (N=38) demonstrated that participants valued informed consent alongside concerns over data collection and sharing, marking the first such evaluation among Chinese users. This study further found a preference for concise visualizations and interactable formats. PrivCAP, leveraging few-shot prompting on Large Language Models (LLMs), accurately translates privacy policies into clickable, chunked formats optimized for smartphone screens. In an evaluation (N=28), PrivCAP outperformed traditional policy presentations in improving user understanding, reducing cognitive load, and maintaining efficiency, with participants favoring its engaging design and reporting more informed decision-making1.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {385},
numpages = {20},
keywords = {CAPTCHA, Mobile Privacy Policy, Interaction Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713284,
author = {Oh, Sanghak and Baek, Heewon and Huh, Jun Ho and Kim, Taeyoung and Jeon, Woojin and Oakley, Ian and Kim, Hyoungshick},
title = {Understanding and Improving User Adoption and Security Awareness in Password Checkup Services},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713284},
doi = {10.1145/3706598.3713284},
abstract = {Password checkup services (PCS) identify compromised, reused, or weak passwords, helping users secure at-risk accounts. However, adoption rates are low. We investigated factors influencing PCS use and password change challenges via an online survey (n=238). Key adoption factors were “perceived usefulness,” “ease of use,” and “self efficacy.” We also identified barriers to changing compromised passwords, including alert fatigue, low perceived urgency, and reliance on other security measures. We then designed interfaces mitigating these issues through clearer messaging and automation (e.g., simultaneous password changes and direct links to change pages). A user study (N=50) showed our designs significantly improved password change success rates, reaching 40\% and 74\% in runtime alert and PCS checkup reporting scenarios, respectively (compared to 16\% and 60\% with a baseline).},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {386},
numpages = {32},
keywords = {Password Checkup Service, Password Change, Password Manager},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713719,
author = {van Harten, Veerle and Ganan, Carlos Hernandez and van Eeten, Michel and Parkin, Simon},
title = {“All Sorts of Other Reasons to Do It”: Explaining the Persistence of Sub-optimal IoT Security Advice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713719},
doi = {10.1145/3706598.3713719},
abstract = {The proliferation of consumer Internet of Things (IoT) devices has raised security concerns. In response, governments have been advising consumers on security measures, but these recommendations are not guaranteed to be implementable owing to the diverse and rapidly evolving IoT landscape, risking wasted efforts and uncertainty caused by unsuccessful attempts to secure devices. Through interviews and a workshop with 14 stakeholders involved in a Dutch national public awareness campaign, we found that while stakeholders recognized the validity of these concerns, they opted to continue the campaign with minor modifications while expecting regulatory changes to resolve the observed problem. Their justifications reveal an institutional incentive structure that overlooks well-documented user realities in security and privacy HCI research. This raises important considerations for the design and delivery of such support strategies. By fostering a collaborative dialogue, we aim to contribute to the development of user-centered security practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {387},
numpages = {19},
keywords = {cybersecurity awareness campaigns, Internet of Things (IoT) security, overproduction of advice, institutional incentives, users-centered security practices},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713963,
author = {Zaccour, Juliette and Binns, Reuben and Rocher, Luc},
title = {Access Denied: Meaningful Data Access for Quantitative Algorithm Audits},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713963},
doi = {10.1145/3706598.3713963},
abstract = {Independent algorithm audits hold the promise of bringing accountability to automated decision-making. However, third-party audits are often hindered by access restrictions, forcing auditors to rely on limited, low-quality data. To study how these limitations impact research integrity, we conduct audit simulations on two realistic case studies for recidivism and healthcare coverage prediction. We examine the accuracy of estimating group parity metrics across three levels of access: (a) aggregated statistics, (b) individual-level data with model outputs, and (c) individual-level data without model outputs. Despite selecting one of the simplest tasks for algorithmic auditing, we find that data minimization and anonymization practices can strongly increase error rates on individual-level data, leading to unreliable assessments. We discuss implications for independent auditors, as well as potential avenues for HCI researchers and regulators to improve data access and enable both reliable and holistic evaluations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {388},
numpages = {31},
keywords = {algorithmic fairness, algorithm auditing, privacy-enhancing technologies, data access},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714135,
author = {Chen, Wei-Hao and Tong, Weixi and Case, Amanda and Zhang, Tianyi},
title = {Dango: A Mixed-Initiative Data Wrangling System using Large Language Model},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714135},
doi = {10.1145/3706598.3714135},
abstract = {Data wrangling is a time-consuming and challenging task in a data science pipeline. While many tools have been proposed to automate or facilitate data wrangling, they often misinterpret user intent, especially in complex tasks. We propose Dango, a mixed-initiative multi-agent system for data wrangling. Compared to existing tools, Dango enhances user communication of intent by: (1) allowing users to demonstrate on multiple tables and use natural language prompts in a conversation interface, (2) enabling users to clarify their intent by answering LLM-posed multiple-choice clarification questions, and (3) providing multiple forms of feedback such as step-by-step NL explanations and data provenance to help users evaluate the data wrangling scripts. We conducted a within-subjects user study (n=38) and demonstrated that Dango’s features can significantly improve intent clarification, accuracy, and efficiency in data wrangling. Furthermore, we demonstrated the generalizability of Dango by applying it to a broader set of data wrangling tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {389},
numpages = {28},
keywords = {Data Wrangling, Data Science, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713703,
author = {Cazacu, Silvia and Panagiotidou, Georgia and Steenberghen, Therese and Moere, Andrew Vande},
title = {Disentangling the Power Dynamics in Participatory Data Physicalisation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713703},
doi = {10.1145/3706598.3713703},
abstract = {Participatory data physicalisation (PDP) is recognised for its potential to support data-driven decisions among stakeholders who collaboratively construct physical elements into commonly insightful visualisations. Like all participatory processes, PDP is however influenced by underlying power dynamics that might lead to issues regarding extractive participation, marginalisation, or exclusion, among others. We first identified the decisions behind these power dynamics by developing an ontology that synthesises critical theoretical insights from both visualisation and participatory design research, which were then systematically applied unto a representative corpus of 23 PDP artefacts. By revealing how shared decisions are guided by different agendas, this paper presents three contributions: 1) a cross-disciplinary ontology that facilitates the systematic analysis of existing and novel PDP artefacts and processes; which leads to 2) six PDP agendas that reflect the key power dynamics in current PDP practice, revealing the diversity of orientations towards stakeholder participation in PDP practice; and 3) a set of critical considerations that should guide how power dynamics can be balanced, such as by reflecting on how issues are represented, data is contextualised, participants express their meanings, and how participants can dissent with flexible artefact construction. Consequently, this study advances a feminist research agenda by guiding researchers and practitioners in openly reflecting on and sharing responsibilities in data physicalisation and participatory data visualisation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {390},
numpages = {19},
keywords = {Data Physicalization, Participatory Design, Data Feminism, Critical Reflection, Interpretivism, Power Dynamics, Ontology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713121,
author = {Verma, Priyanka and Rifat, Mohammad Rashidujjaman and Sabie, Samar},
title = {Management, Cooperation, and Sustainability: Unpacking the Data Practices of Housing Cooperatives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713121},
doi = {10.1145/3706598.3713121},
abstract = {Despite significant work in HCI on understanding the role of data tools for non-profits and grassroots communities, there has been limited focus on cooperatives. This paper examines the role of financial, social, and building upkeep data in a non-profit cooperative housing organization in Toronto, Canada (alias named NXI). Through a 16-month-long ethnographic study, including 24 interviews, we investigate the role of and tensions in data practices related to NXI’s daily maintenance and operations, cooperation, and sustainability. We find that NXI’s current data practices are functional and meaningful—sometimes requiring team workarounds—in the short term. However, various tensions and deficiencies in data practices hamper NXI’s sustainability. By contextualizing the temporal affordances of data, we propose design implications for data tools to align effectively with the practices of cooperatives and enhance organizational sustainability. Finally, we discuss how data designers and researchers, organizations or grassroots communities, and financial technology designers can benefit from our work, especially with regard to the maintenance and sustainability of small-scale organizations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {391},
numpages = {16},
keywords = {Cooperatives, Data Practices, Financial Practices, Housing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714209,
author = {Liu, Shuhan and Liu, Yangtian and Li, Junxin and Huang, Yanwei and Shangguan, Yue and Deng, Zikun and Weng, Di and Wu, Yingcai},
title = {RidgeBuilder: Interactive Authoring of Expressive Ridgeline Plots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714209},
doi = {10.1145/3706598.3714209},
abstract = {Ridgeline plots are frequently employed to visualize the evolution or distributions of multiple series with a pile of overlapping line, area, or bar charts, highlighting the peak patterns. While traditionally viewed as small multiple visualizations, their ridge-like patterns have increasingly attracted graphic designers to create appealing customized ridgeline plots. However, many tools only support creating basic ridgeline plots and overlook their diverse layouts and styles. This paper introduces a comprehensive design space for ridgeline plots, focusing on their varied layouts and expressive styles. We present RidgeBuilder, an intuitive tool for creating expressive ridgeline plots with customizable layouts and styles. In particular, we summarize three goals for refining the layout of ridgeline plots and propose an optimization method. We assess RidgeBuilder’s usability and usefulness through a reproduction study and evaluate the layout optimization algorithm through anonymized questionnaires. The effectiveness is demonstrated with a gallery of ridgeline plots created by RidgeBuilder.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {392},
numpages = {18},
keywords = {Ridgeline plot, visualization authoring, creative design support},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713484,
author = {Huang, Yanwei and Miao, Yan and Weng, Di and Perer, Adam and Wu, Yingcai},
title = {StructVizor: Interactive Profiling of Semi-Structured Textual Data},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713484},
doi = {10.1145/3706598.3713484},
abstract = {Data profiling plays a critical role in understanding the structure of complex datasets and supporting numerous downstream tasks, such as social media analytics and financial fraud detection. While existing research predominantly focuses on structured data formats, a substantial portion of semi-structured textual data still requires ad-hoc and arduous manual profiling to extract and comprehend its internal structures. In this work, we propose StructVizor, an interactive profiling system that facilitates sensemaking and transformation of semi-structured textual data. Our tool mainly addresses two challenges: a) extracting and visualizing the diverse structural patterns within data, such as how information is organized or related, and b) enabling users to efficiently perform various wrangling operations on textual data. Through automatic data parsing and structure mining, StructVizor enables visual analytics of structural patterns, while incorporating novel interactions to enable profile-based data wrangling. A comparative user study involving 12 participants demonstrates the system’s usability and its effectiveness in supporting exploratory data analysis and transformation tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {393},
numpages = {18},
keywords = {Semi-structured textual data, data profiling, visual analytics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713551,
author = {Jeon, Hyeon and Lee, Hyunwook and Kuo, Yun-Hsin and Yang, Taehyun and Archambault, Daniel and Ko, Sungahn and Fujiwara, Takanori and Ma, Kwan-Liu and Seo, Jinwook},
title = {Unveiling High-dimensional Backstage: A Survey for Reliable Visual Analytics with Dimensionality Reduction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713551},
doi = {10.1145/3706598.3713551},
abstract = {Dimensionality reduction (DR) techniques are essential for visually analyzing high-dimensional data. However, visual analytics using DR often face unreliability, stemming from factors such as inherent distortions in DR projections. This unreliability can lead to analytic insights that misrepresent the underlying data, potentially resulting in misguided decisions. To tackle these reliability challenges, we review 133 papers that address the unreliability of visual analytics using DR. Through this review, we contribute (1) a workflow model that describes the interaction between analysts and machines in visual analytics using DR, and (2) a taxonomy that identifies where and why reliability issues arise within the workflow, along with existing solutions for addressing them. Our review reveals ongoing challenges in the field, whose significance and urgency are validated by five expert researchers. This review also finds that the current research landscape is skewed toward developing new DR techniques rather than their interpretation or evaluation, where we discuss how the HCI community can contribute to broadening this focus.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {394},
numpages = {24},
keywords = {Dimensionality reduction, Multidimensional projection, Reliability, High-dimensional data, Literature analysis, Survey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713264,
author = {Rattay, Sonja and Vakkuri, Ville and Rozendaal, Marco C. and Shklovski, Irina},
title = {"Why do we do this?": Moral Stress and the Affective Experience of Ethics in Practice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713264},
doi = {10.1145/3706598.3713264},
abstract = {A plethora of toolkits, checklists, and workshops have been developed to bridge the well-documented gap between AI ethics principles and practice. Yet little is known about effects of such interventions on practitioners. We conducted an ethnographic investigation in a major European city organization that developed and works to integrate an ethics toolkit into city operations. We find that the integration of ethics tools by technical teams destabilises their boundaries, roles, and mandates around responsibilities and decisions. This lead to emotional discomfort and feelings of vulnerability, which neither toolkit designers nor the organization had accounted for. We leverage the concept of moral stress to argue that this affective experience is a core challenge to the successful integration of ethics tools in technical practice. Even in this best case scenario, organisational structures were not able to deal with moral stress that resulted from attempts to implement responsible technology development practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {395},
numpages = {15},
keywords = {Moral stress, ethics in practice, responsible technology development, affective experience},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713950,
author = {Henriques, Ana O and Carter, Anna R. L. and Severes, Beatriz and Talhouk, Reem and Strohmayer, Angelika and Pires, Ana Cristina and Gray, Colin M. and Montague, Kyle and Nicolau, Hugo},
title = {A Feminist Care Ethics Toolkit for Community-Based Design: Bridging Theory and Practice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713950},
doi = {10.1145/3706598.3713950},
abstract = {Existing ethics frameworks for participatory engagement in HCI often overlook the nuanced ethical challenges of dynamic community-based contexts given the latter’s relational nature. We hope to bridge this gap by grounding feminist care ethics in actionable tools for community-based projects to enhance ethical engagement in these settings. Prior research advocates for adaptable, context-sensitive ethics in participatory research, informed by feminist care ethics. To address this need, we developed and iteratively refined a toolkit embodying the underlying principles of feminist care ethics through workshops with participants working in academic and non-academic community-based settings. Our findings suggest that the toolkit fosters ethical reflection aligned with the feminist care ethics ethos while facilitating meaningful experiences for participants. This work contributes to the field by offering a practical design artefact that not only embodies feminist care ethics but also supports researchers and communities in navigating complex ethical landscapes in participatory engagements, together or independently.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {396},
numpages = {26},
keywords = {feminism, ethics, feminist ethics, community-led design, toolkits},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713774,
author = {Primlani, Namrata and Blythe, Mark and Marshall, Justin},
title = {Design Courts: Workshops for Exploring Emerging Technology Ethics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713774},
doi = {10.1145/3706598.3713774},
abstract = {Although it is now well recognized that HCI must take a greater account of ethics there is little consensus about which ethical systems are most appropriate or how to incorporate them into the design process. In this paper, we contribute a Design Court workshop method where opposing legal and ethical arguments are set against one another in the form of a mock trial. We describe how we structured and enacted these workshops by combining legal thought experiments and design fiction. The paper reports findings from three Design Courts where a fictional device is the subject of litigation. These court disputations focused on issues of privacy, reciprocity and intent in rich and nuanced debate. We argue that Design Courts may be a useful method for engaging competing ethical standpoints through contested dialogue.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {397},
numpages = {12},
keywords = {design fiction, ethics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713189,
author = {Padiyath, Aadarsh and Guzdial, Mark and Ericson, Barbara},
title = {Development of the Critical Reflection and Agency in Computing Index},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713189},
doi = {10.1145/3706598.3713189},
abstract = {As computing’s societal impact grows, so does the need for computing students to recognize and address the ethical and sociotechnical implications of their work. While there are efforts to integrate ethics into computing curricula, we lack a standardized tool to measure those efforts, specifically, students’ attitudes towards ethical reflection and their ability to effect change. This paper introduces the novel framework of Critically Conscious Computing and reports on the development and content validation of the Critical Reflection and Agency in Computing Index, a novel instrument designed to assess undergraduate computing students’ attitudes towards practicing critically conscious computing. The resulting index is a theoretically grounded, expert-reviewed tool to support research and practice in computing ethics education. This enables researchers and educators to gain insights into students’ perspectives, inform the design of targeted ethics interventions, and measure the effectiveness of computing ethics education initiatives.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {398},
numpages = {11},
keywords = {Critically Conscious Computing, Computing Ethics, Critical Computing, Assessment, Critical Reflection and Agency in Computing Index},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713574,
author = {Ahmadpour, Naseem and Pillai, Ajit G. and Zhang, Wendy Qi and Loke, Lian and Sachathep, Thida and Zhou, Zhaohua and Gough, Phillip},
title = {Ethics Reflexivity Canvas: Resourcing Ethical Sensitivity for HCI Educators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713574},
doi = {10.1145/3706598.3713574},
abstract = {Integrating ethics education in human-computer interaction (HCI) programs is critical to training responsible industry practitioners. Yet, there is a lack of practical educator-focused resources, which facilitate reflection on personal approaches to ethics education. We conducted a series of nine generative participatory workshops with 15 educators to explore, design and seek feedback on the Ethics Reflexivity Canvas as a pedagogical resource. The canvas makes the educator and learner positionality explicit to develop ethical sensitivity, sensitise and situate a pedagogical plan, and iterate and adapt over time. However, our findings suggest that educators experience tensions, depending on their pedagogical approach. We contribute insight on how resources can align with education work in HCI, help educators reflect on a plurality of approaches to ethics, use accessible language to stimulate curiosity towards ethics, and provide scaffolding to operationalize collaborative and personal exploration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {399},
numpages = {17},
keywords = {ethics, ethical sensitivity, education work, educator, reflection, reflexivity, canvas},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714123,
author = {Garrett, Rachael and Brundell, Patrick and Castle-Green, Simon and Hawkins, Kat and Tennent, Paul and Zhou, Feng and Lampinen, Airi and H\"{o}\"{o}k, Kristina and Benford, Steve},
title = {Friction in Processual Ethics: Reconfiguring Ethical Relations in Interdisciplinary Research},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714123},
doi = {10.1145/3706598.3714123},
abstract = {Friction – disagreement and breakdown – is an omnipresent aspect of conducting interdisciplinary research yet is rarely presented in formal research reporting. We analyse a performance-led research process where professional dancers with different disabilities explored how to improvise with an industrial robot, with the support of an interdisciplinary team of human-computer and human-robot interaction researchers. We focus on one site of friction in our research process; how to dance – safely – with robots? By presenting our research process, we exemplify the different ways in which we encountered this friction and how we reconfigured the research process around it. We contribute five ways in which we arrived at a generative ethical outcome, which may be helpful in productively engaging with friction in interdisciplinary collaboration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {400},
numpages = {15},
keywords = {ethics, processual ethics, felt ethics, research ethics, artist-led research, somabotics, robots, dance, disability, crip feminism, friction, misalignment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713755,
author = {Yuan, Shuai and Coghlan, Simon and Lederman, Reeva and Waycott, Jenny},
title = {Meaningful Engagement, Ethical Care, and Design Opportunities: An Ethnographic Study on Social Activities in Long-term Care},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713755},
doi = {10.1145/3706598.3713755},
abstract = {Social activities in long-term care homes help promote residents’ wellbeing, but their effectiveness depends on residents’ engagement. To identify design opportunities for promoting meaningful engagement, we conducted an ethnographic study on organised activities in an Australian aged care home. We observed staff fostered engagement by initiating conversations, weaving residents’ backgrounds into interactions, and adapting activities to residents’ varying abilities. However, challenges included new staff members’ unfamiliarity with residents, multi-tasking, and insufficient support to engage excluded residents. Using a care ethics lens that includes relational, situated and empathetic features of care, we show that meaningful engagement is shaped by the ethical care practices embedded in staff-resident interactions and highlight opportunities for technologies to mitigate barriers hindering staff from providing ethical care in existing activities. These opportunities include: collecting and recording residents’ interests, providing conversation prompts, enhancing activity inclusiveness, and reducing language and cultural barriers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {401},
numpages = {15},
keywords = {social activities, meaningful engagement, residential aged care, care ethics, older adults},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713473,
author = {Freeman, Guo and Schulenberg, Kelsea and Li, Lingyuan and Panchanadikar, Ruchi and McNeese, Nathan},
title = {"Comforting and Small Like a House Cat, Big and Intimidating Like a Bodyguard": How Women Perceive and Envision AI Companions as a New Harassment Mitigation Approach in Social VR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713473},
doi = {10.1145/3706598.3713473},
abstract = {Companionship is crucial for people’s everyday psychological well-being. With growing concerns over harassment against women in embodied social VR spaces, we turn an eye towards AI companions as a potential new approach to protect women in social VR by better fulfilling their under-addressed harassment mitigation needs. Using 20 interviews with women social VR users, we reveal their envisionings for leveraging AI as Accessible Companions, Informational Companions, Emotional Support Companions, and Protective Companions to better protect them in social VR compared to their existing safety mechanisms and strategies. We also reflect upon various sociotechnical complexities for designing and implementing such AI companions in social VR spaces and propose three design principles to inform future efforts to create AI companions to protect women and other marginalized users in social VR. Our work contributes to ongoing discussions on nuanced harassment mitigation approaches that further support marginalized social VR users’ multidimensional needs without harming their self-agency, human relationships, and supportive networks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {402},
numpages = {16},
keywords = {artificial intelligence, AI companion, online harassment, women, online safety, social VR},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713195,
author = {Crawford, Kirk Andrew and Hamidi, Foad},
title = {"Like a Love Language": Understanding Communication in Disabled LGBTQIA+ Romantic Relationships},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713195},
doi = {10.1145/3706598.3713195},
abstract = {Previous research on interactive technology design has often focused on individual aspects of marginalized identities and their impact on technology use. However, there is a growing need to adopt a more holistic approach that considers how multiple, intersecting aspects of marginalized identities shape technology engagement across various contexts. In this qualitative case study, we investigate the communication experiences of LGBTQIA+ individuals with disabilities within romantic relationships, focusing on the role of technology in facilitating connection, intimacy, and joy. Our findings emphasize the dynamic experiences of early disability disclosure, the transformation of vulnerability into opportunities for authentic connection, and the co-creation of communication practices tailored to the relationship’s needs. We advocate for inclusive technologies that adapt to evolving intersectional experiences, advocating for assistive technology (AT) that supports communication while nurturing emotional and relational well-being. Moreover, drawing on the concept of interdependence, we show how access is co-created in LGBTQIA+ romantic relationships, challenging the traditional views of AT as specialized tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {403},
numpages = {17},
keywords = {Assistive Technology, Disability, Stigma, Marginalized Communities, LGBTQIA+, Intersectionality, Interdependence, Romantic Relationships, Communication, Qualitative Research, Thematic Analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714248,
author = {Read, Janet and Horton, Matthew and Fitton, Daniel and Sim, Gavin},
title = {Child Centred Ethics (CCE): A Practical Framework for Enhanced Child Participation in HCI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714248},
doi = {10.1145/3706598.3714248},
abstract = {Following a review of papers in the ACM DL on ethics and children, this paper shows the growth of interest in this area, summarises the literature found, and then, using detail from 26 papers that offer practical advice, distils a Child Centred Ethics Framework that maps literature onto ethical concerns in relation to the practical application of ethics with children. The framework offers questions and solutions for researchers from the first inception of a project to the dissemination of the results back to the children. The framework is offered as an adjunct to an ethics / IRB document in that it places the child’s experience at the centre of decision-making allowing fuller exploration of aspects like assent, anonymity, inclusion and contribution. As a practical resource that researchers can use, the framework is presented as a living document waiting to be owned by the community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {404},
numpages = {16},
keywords = {Practical Ethics, Ethics, Children, CCE Framework},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713253,
author = {Mouratidis, Marios and Rosa Cardoso, Clara and Engelbutzeder, Philip and Tolmie, Peter and Aal, Konstantin Kosta and Wulf, Volker},
title = {Designing for Resilience: Fostering Ponds of Stability with Computer Clubs in Palestine},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713253},
doi = {10.1145/3706598.3713253},
abstract = {Addressing the complexities of conflict-affected regions remains a critical challenge for Human-Computer Interaction (HCI). This paper examines the establishment of computer clubs in Palestinian refugee camps, where efforts to create sustainable interventions weighed against the instability of prolonged conflict. To capture this dynamic, we introduce the notion of ‘adaptive ponds of stability,’ which extends the ‘tech public of erosion’ framework [12]. While the latter emphasizes systemic depletion of socio-technical infrastructures, adaptive ponds of stability highlight efforts to foster temporary spaces of resilience. The clubs became hubs of learning, respite, and collaboration—offering moments of routine and empowerment amidst disruption. Reflecting on this, we advocate for a paradigm shift from sustainability to resilience as the primary design goal in unstable contexts. Our findings emphasize adaptability, local agency, and cultural sensitivity that respond dynamically to context-specific challenges, offering a nuanced approach to advancing HCI interventions in conflict-affected settings.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {405},
numpages = {18},
keywords = {Resilience, Sustainability, Computer Club, Marginalized Communities},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713975,
author = {Nikolovska, Bojana and Normark, Maria and Sadowski, Helga},
title = {Imagining with the Body: Speculative Designs for Women's Embodied Empowerment in Feminist Self-Defense},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713975},
doi = {10.1145/3706598.3713975},
abstract = {Feminist self-defense combines physical self-defense with mental strength exercises through role-playing scenarios. It aims to challenge limiting beliefs about women's abilities to respond to interpersonal violence. We present the experiences from feminist self-defense classes in Sweden and the results of a set of speculative designs that combined contribute to imagine how technology could play a role in experiencing these holistic practices. The goal is to illustrate the potential of embodied interaction design to empower beginner feminist self-defense practitioners. To do so, the study was conducted via two methods: semi-structured interviews with students and teachers, and a participatory speculative design workshop with novice practitioners. The speculative concepts demonstrate how design can support the practice of feminist self-defense. Through this study we contribute to the corpus of embodied design interventions, in this case combining design for bodily movements with feminist consciousness raising in relation to the topic of gender-based violence.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {406},
numpages = {13},
keywords = {Embodiment, Feminist Self-Defense, Participatory Speculative Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713632,
author = {Garrett, Rachael and Hawkins, Kat and Brundell, Patrick and Castle-Green, Simon and Tennent, Paul and Zhou, Feng and Lampinen, Airi and H\"{o}\"{o}k, Kristina and Benford, Steve},
title = {In the Moment of Glitch: Engaging with Misalignments in Ethical Practice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713632},
doi = {10.1145/3706598.3713632},
abstract = {Glitches – moments when technologies do not work as desired – will become increasingly common as industrially-designed robots move into complex contexts. Taking glitches to be potential sites of critical ethical reflection, we examine a glitch that occurred in the context of a collaborative research project where professional dancers with different disabilities improvised with a robotic arm. Through a first-person account, we analyse how the dancer, the robot, and the rest of the research team enacted ethics in the moment of glitch. Through this analysis, we discovered a deep and implicit ethical misalignment wherein our enactments of ethics in response to the glitch did not align with the values of the project. This prompted a critical re-engagement with our research process through which we forged a dialogue between different ethical perspectives that acted as an invitation to bring us back into ethical alignment with the project’s values.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {407},
numpages = {18},
keywords = {ethics, felt ethics, research ethics, artist-led research, somabotics, robots, dance, disability, crip feminism, glitches, misalignment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714108,
author = {Key, Cayla and Gatehouse, Cally and Koepp, Stevie and Taylor, Nick},
title = {Leaky Cups: Tinkering with Hydrofeminist Temporalities for HCI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714108},
doi = {10.1145/3706598.3714108},
abstract = {This paper offers new perspectives for More-Than-Human (MTH) design and Human-Computer-Interaction (HCI) by rethinking technoscientific logics of temporality. To do this, we draw on alternative logics such as Hydrofeminism, interlocutor and autobiographical accounts, and Leaky Cups—a set of willfully dysfunctional data-enabled artefacts that leak in response to local water data. In doing so, it repositions more-than-human agency not as a passive conduit merely mediating human experiences but as a force capable of creating change and ethics through non-progressivist care labor. By engaging with these ideas, this work critiques and disrupts normative assumptions about progress, openness, fluidity, and objectivity in MTH research and design, and presents productive tensions that challenge dominant temporal frameworks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {408},
numpages = {17},
keywords = {Care Ethics, Hydrofeminism, More-Than-Human Design, Posthuman, Temporality, Temporality of Care},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713641,
author = {Ryu, Jeongwoo and Kim, Kyusik and Heo, Dongseok and Song, Hyungwoo and Oh, Changhoon and Suh, Bongwon},
title = {Cinema Multiverse Lounge: Enhancing Film Appreciation via Multi-Agent Conversations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713641},
doi = {10.1145/3706598.3713641},
abstract = {Advancements in large language models (LLMs) enable the development of interactive systems that enhance user engagement with cinematic content. We introduce Cinema Multiverse Lounge, a multi-agent conversational system where users interact with LLM-based agents embodying diverse film-related personas. We investigate how user interactions with these agents influence their film appreciation. Thirty participants engaged in three discussion sessions, freely selecting persona agents such as film characters, filmmakers, or anonymous audiences. We explored how users composed different combinations of personas, the factors affecting their engagement and interpretation, and how diverse perspectives influenced film appreciation. Results indicate that interactions with varied agents enhanced participants’ appreciation by enabling the exploration of multiple viewpoints and fostering deeper narrative engagement. Moreover, the unexpected clashes between different worldviews added a fresh and enjoyable layer to the interactions. Our findings provide empirical insights and design implications for developing multi-agent systems that support enriched media consumption experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {409},
numpages = {22},
keywords = {Film appreciation, Multi-agent systems, Conversational AI, Parasocial relationship, User engagement, Virtual personas, Media consumption},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713381,
author = {Wang, Xiyuan and Cao, Yi-Fan and Xiong, Junjie and Chen, Sizhe and Li, Wenxuan and Zhang, Junjie and Li, Quan},
title = {ClueCart: Supporting Game Story Interpretation and Narrative Inference from Fragmented Clues},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713381},
doi = {10.1145/3706598.3713381},
abstract = {Indexical storytelling is gaining popularity in video games, where the narrative unfolds through fragmented clues. This approach fosters player-generated content and discussion, as story interpreters piece together the overarching narrative from these scattered elements. However, the fragmented and non-linear nature of the clues makes systematic categorization and interpretation challenging, potentially hindering efficient story reconstruction and creative engagement. To address these challenges, we first proposed a hierarchical taxonomy to categorize narrative clues, informed by a formative study. Using this taxonomy, we designed ClueCart, a creativity support tool aimed at enhancing creators’ ability to organize story clues and facilitate intricate story interpretation. We evaluated ClueCart through a between-subjects study (N=40), using Miro as a baseline. The results showed that ClueCart significantly improved creators’ efficiency in organizing and retrieving clues, thereby better supporting their creative processes. Additionally, we offer design insights for future studies focused on player-centric narrative analysis.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {410},
numpages = {26},
keywords = {Creativity Support Tool, Game Storytelling, Indexical Storytelling, Story Interpretation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713937,
author = {Wang, Derrick M. and Cmentowski, Sebastian and Hadi Mogavi, Reza and Senthil Nathan, Kaushall and Kukshinov, Eugene and Tu, Joseph and Nacke, Lennart E.},
title = {From Solo to Social: Exploring the Dynamics of Player Cooperation in a Co-located Cooperative Exergame},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713937},
doi = {10.1145/3706598.3713937},
abstract = {Digital games offer rich social experiences and promote valuable skills, but they fall short in addressing physical inactivity. Exergames, which combine exercise with gameplay, have the potential to tackle this issue. However, current exergames are primarily single-player or competitive. To explore the social benefits of cooperative exergaming, we designed a custom co-located cooperative exergame that features three distinct forms of cooperation: free (baseline), coupled, and concurrent. We conducted a within-participants, mixed-methods study (N = 24) to evaluate these designs and their impact on players’ enjoyment, motivation, and performance. Our findings reveal that cooperative play improves social experiences. It drives increased team identification and relatedness. Furthermore, our qualitative findings support cooperative exergame play. This has design implications for creating exergames that effectively address players’ exercise and social needs. Our research contributes guidance for developers and researchers who want to create more socially enriching exergame experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {411},
numpages = {16},
keywords = {Cooperative Gameplay, Exergame, ExerCube, Mixed Reality, User Experience, Qualitative Research},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714226,
author = {Lee, Juhoon and Kim, Seoyoung and Park, Yeon Su and Kim, Juho and Jang, Jeong-woo and Seering, Joseph},
title = {Less Talk, More Trust: Understanding Players' In-game Assessment of Communication Processes in League of Legends},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714226},
doi = {10.1145/3706598.3714226},
abstract = {In-game team communication in online multiplayer games has shown the potential to foster efficient collaboration and positive social interactions. Yet players often associate communication within ad hoc teams with frustration and wariness. Though previous works have quantitatively analyzed communication patterns at scale, few have identified the motivations of how a player makes in-the-moment communication decisions. In this paper, we conducted an observation study with 22 League of Legends players by interviewing them during Solo Ranked games on their use of four in-game communication media (chat, pings, emotes, votes). We performed thematic analysis to understand players’ in-context assessment and perception of communication attempts. We demonstrate that players evaluate communication opportunities on proximate game states bound by player expectations and norms. Our findings illustrate players’ tendency to view communication, regardless of its content, as a precursor to team breakdowns. We build upon these findings to motivate effective player-oriented communication design in online games.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {412},
numpages = {17},
keywords = {League of Legends, multiplayer online battle arena, team communication, ad hoc teams, online games},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713587,
author = {Huang, Jessica and Kim, Ig-Jae and Yoon, Dongwook},
title = {Mirror to Companion: Exploring Roles, Values, and Risks of AI Self-Clones through Story Completion},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713587},
doi = {10.1145/3706598.3713587},
abstract = {Advancing technologies enable machine learning applications that replicate the appearance, behavior, and thought patterns of users based on their personal data. Termed as AI self-clones, these digital doppelgangers present introspective opportunities and existential risks, as they might amplify self-awareness or echo problematic self-views. In our study, based on the story completion method, we involved 20 diverse individuals to explore the values and risks they associate with creating AI self-clones. Our participants conceptualized AI self-clones by the roles these clones could assume, such as mirror, probe, companion, delegate, and representative. The perceived values and risks tend to correspond to these roles. For example, using self-clones as representatives could enhance relationship maintenance, yet it might also lead to diminished authenticity in personal connections; utilizing self-clones as probes to explore life scenarios could aid decision-making, but it might amplify regrets about unchosen paths. This research lays the groundwork for an ethical design of AI self-clone applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {413},
numpages = {15},
keywords = {AI self-clone, mimetic model, roles, values, risks, story completion method, design fiction, speculative design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713218,
author = {He, Gaole and Demartini, Gianluca and Gadiraju, Ujwal},
title = {Plan-Then-Execute: An Empirical Study of User Trust and Team Performance When Using LLM Agents As A Daily Assistant},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713218},
doi = {10.1145/3706598.3713218},
abstract = {Since the explosion in popularity of ChatGPT, large language models (LLMs) have continued to impact our everyday lives. Equipped with external tools that are designed for a specific purpose (e.g.,&nbsp;for flight booking or an alarm clock), LLM agents exercise an increasing capability to assist humans in their daily work. Although LLM agents have shown a promising blueprint as daily assistants, there is a limited understanding of how they can provide daily assistance based on planning and sequential decision making capabilities. We draw inspiration from recent work that has highlighted the value of ‘LLM-modulo’ setups in conjunction with humans-in-the-loop for planning tasks. We conducted an empirical study (N = 248) of LLM agents as daily assistants in six commonly occurring tasks with different levels of risk typically associated with them (e.g.,&nbsp;flight ticket booking and credit card payments). To ensure user agency and control over the LLM agent, we adopted LLM agents in a plan-then-execute manner, wherein the agents conducted step-wise planning and step-by-step execution in a simulation environment. We analyzed how user involvement at each stage affects their trust and collaborative team performance. Our findings demonstrate that LLM agents can be a double-edged sword — (1) they can work well when a high-quality plan and necessary user involvement in execution are available, and (2) users can easily mistrust the LLM agents with plans that seem plausible. We synthesized key insights for using LLM agents as daily assistants to calibrate user trust and achieve better overall task outcomes. Our work has important implications for the future design of daily assistants and human-AI collaboration with LLM agents.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {414},
numpages = {22},
keywords = {Human-AI Collaboration, Large Language Models, LLM agents, User Trust, Daily Assistant},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714293,
author = {Pinder, Samann and Odom, William and Yoo, MinYoung and Misra, Ayush and Lin, Henry and Neustaedter, Carman and Barnett, Samuel},
title = {Queue Player: Investigating Distributed Co-Listening Experiences for Social Connection across Space, Time, and Tempo},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714293},
doi = {10.1145/3706598.3714293},
abstract = {We describe the design and deployment of Queue Player, four networked domestic music players that combine music listening histories of close friends to explore new potentialities for interacting with this shared archive. We deployed the Queue Players with four close friends living in separate homes for six weeks. Our goals are to (i) explore how this system might enable co-listening experiences that foster social presence, interaction, and reflection and (ii) empirically explore conceptual propositions related to slow technology. Findings revealed that, after overcoming initial frictions, Queue Player became integrated in participants’ lives and triggered a range of social interactions and reflections on past life experiences. They also showed that Queue Player provoked questions on the benefits and limits of data capturing one's life history as well as the role and pace of technology in everyday life at home. Findings are interpreted to present opportunities for future HCI research and practice.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {415},
numpages = {24},
keywords = {Co-listening, Digital Music, Research through Design, Slow Technology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713771,
author = {Cros Vila, Laura and Sturm, Bob},
title = {(Mis)Communicating with our AI Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713771},
doi = {10.1145/3706598.3713771},
abstract = {Explainable Artificial Intelligence (XAI) is a discipline concerned with understanding predictions of AI systems. What is ultimately desired from XAI methods is for an AI system to link its input and output in a way that is interpretable with reference to the environment in which it is applied. A variety of methods have been proposed, but we argue in this paper that what has yet to be considered is miscommunication: the failure to convey and/or interpret an explanation accurately. XAI can be seen as a communication process and thus looking at how humans explain things to each other can provide guidance to its application and evaluation. We motivate a specific model of communication to help identify essential components of the process, and show the critical importance for establishing common ground, i.e., shared mutual knowledge, beliefs, and assumptions of the participants communicating.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {416},
numpages = {9},
keywords = {Communication, Miscommunication, Dialog, Mutual-Understanding, Conversation, Explanation, Explainability, Explainable AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713406,
author = {Boggust, Angie and Bang, Hyemin and Strobelt, Hendrik and Satyanarayan, Arvind},
title = {Abstraction Alignment: Comparing Model-Learned and Human-Encoded Conceptual Relationships},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713406},
doi = {10.1145/3706598.3713406},
abstract = {While interpretability methods identify a model’s learned concepts, they overlook the relationships between concepts that make up its abstractions and inform its ability to generalize to new data. To assess whether models’ have learned human-aligned abstractions, we introduce abstraction alignment, a methodology to compare model behavior against formal human knowledge. Abstraction alignment externalizes domain-specific human knowledge as an abstraction graph, a set of pertinent concepts spanning levels of abstraction. Using the abstraction graph as a ground truth, abstraction alignment measures the alignment of a model’s behavior by determining how much of its uncertainty is accounted for by the human abstractions. By aggregating abstraction alignment across entire datasets, users can test alignment hypotheses, such as which human concepts the model has learned and where misalignments recur. In evaluations with experts, abstraction alignment differentiates seemingly similar errors, improves the verbosity of existing model-quality metrics, and uncovers improvements to current human abstractions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {417},
numpages = {20},
keywords = {interpretability, human-AI alignment, visualization, abstraction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713873,
author = {Boonprakong, Nattapat and Pareek, Saumya and Tag, Benjamin and Goncalves, Jorge and Dingler, Tilman},
title = {Assessing Susceptibility Factors of Confirmation Bias in News Feed Reading},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713873},
doi = {10.1145/3706598.3713873},
abstract = {Individuals tend to apply preferences and beliefs as heuristics to effectively sift through the sheer amount of information available online. Such tendencies, however, often result in cognitive biases, which can skew judgment and open doors for manipulation. In this work, we investigate how individual and contextual factors lead to instances of confirmation bias when seeking, evaluating, and recalling polarising information. We conducted a lab study, in which we exposed participants to opinions on controversial issues through a Twitter-like news feed. We found that low-effortful thinking, strong political beliefs, and content conveying a strong issue amplify the occurrences of confirmation bias, leading to skewed information processing and recall. We discuss how the adverse effects of confirmation bias can be mitigated by taking bias-susceptibility into account. Specifically, social media platforms could aim to reduce strong expressions and integrate media literacy-building mechanisms, as low-effortful thinking styles and strong political beliefs render individuals especially susceptible to cognitive biases.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {418},
numpages = {19},
keywords = {cognitive bias, confirmation bias, individual difference, recall, social media},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714058,
author = {Lim, Brian Y. and Cahaly, Joseph P. and Sng, Chester Y. F. and Chew, Adam},
title = {Diagrammatization and Abduction to Improve AI Interpretability With Domain-Aligned Explanations for Medical Diagnosis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714058},
doi = {10.1145/3706598.3714058},
abstract = {Many visualizations have been developed for explainable AI (XAI), but they often require further reasoning by users to interpret. Investigating XAI for high-stakes medical diagnosis, we propose improving domain alignment with diagrammatic and abductive reasoning to reduce the interpretability gap. We developed DiagramNet to predict cardiac diagnoses from heart auscultation, select the best-fitting hypothesis based on criteria evaluation, and explain with clinically-relevant murmur diagrams. The ante-hoc interpretable model leverages domain-relevant ontology, representation, and reasoning process to increase trust in expert users. In modeling studies, we found that DiagramNet not only provides faithful murmur shape explanations, but also has better performance than baseline models. We demonstrate the interpretability and trustworthiness of diagrammatic, abductive explanations in a qualitative user study with medical students, showing that clinically-relevant, diagrammatic explanations are preferred over technical saliency map explanations. This work contributes insights into providing domain-aligned explanations for user-centric XAI in complex domains.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {419},
numpages = {25},
keywords = {Explainable AI, diagrams, abductive explanations, medical diagnosis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714020,
author = {Kim, Sunnie S. Y. and Vaughan, Jennifer Wortman and Liao, Q. Vera and Lombrozo, Tania and Russakovsky, Olga},
title = {Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714020},
doi = {10.1145/3706598.3714020},
abstract = {Large language models (LLMs) can produce erroneous responses that sound fluent and convincing, raising the risk that users will rely on these responses as if they were correct. Mitigating such overreliance is a key challenge. Through a think-aloud study in which participants use an LLM-infused application to answer objective questions, we identify several features of LLM responses that shape users’ reliance: explanations (supporting details for answers), inconsistencies in explanations, and sources. Through a large-scale, pre-registered, controlled experiment (N=308), we isolate and study the effects of these features on users’ reliance, accuracy, and other measures. We find that the presence of explanations increases reliance on both correct and incorrect responses. However, we observe less reliance on incorrect responses when sources are provided or when explanations exhibit inconsistencies. We discuss the implications of these findings for fostering appropriate reliance on LLMs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {420},
numpages = {19},
keywords = {Large language models, Overreliance, Human-AI interaction, Question answering, Explanations, Sources, Inconsistencies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713277,
author = {Warren, Greta and Shklovski, Irina and Augenstein, Isabelle},
title = {Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713277},
doi = {10.1145/3706598.3713277},
abstract = {The pervasiveness of large language models and generative AI in online media has amplified the need for effective automated fact-checking to assist fact-checkers in tackling the increasing volume and sophistication of misinformation. The complex nature of fact-checking demands that automated fact-checking systems provide explanations that enable fact-checkers to scrutinise their outputs. However, it is unclear how these explanations should align with the decision-making and reasoning processes of fact-checkers to be effectively integrated into their workflows. Through semi-structured interviews with fact-checking professionals, we bridge this gap by: (i) providing an account of how fact-checkers assess evidence, make decisions, and explain their processes; (ii) examining how fact-checkers use automated tools in practice; and (iii) identifying fact-checker explanation requirements for automated fact-checking tools. The findings show unmet explanation needs and identify important criteria for replicable fact-checking explanations that trace the model’s reasoning path, reference specific evidence, and highlight uncertainty and information gaps.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {21},
keywords = {Explainable AI, fact-checking, explanation, natural language processing, misinformation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714015,
author = {Wang, Jingying and Zhang, Jingjing and Capizzano, Juana Nicoll and Sigakis, Matthew and Wang, Xu and Popov, Vitaliy},
title = {eXplainMR: Generating Real-time Textual and Visual eXplanations to Facilitate UltraSonography Learning in MR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714015},
doi = {10.1145/3706598.3714015},
abstract = {Mixed-Reality physical task guidance systems have the benefit of providing virtual instructions while enabling learners to interact with the tangible world. However, they are mostly built around single-path tasks and often employ visual cues for motion guidance without explanations on why an action was recommended. In this paper, we introduce eXplainMR, a mixed-reality tutoring system that teaches medical trainees to perform cardiac ultrasound. eXplainMR automatically generates subgoals for obtaining an ultrasound image that contains clinically relevant information, and textual and visual explanations for each recommended move based on the visual difference between the two consecutive subgoals. We performed a between-subject experiment (N=16) in one US teaching hospital comparing eXplainMR with a baseline MR system that offers commonly used arrow and shadow guidance. We found that after using eXplainMR, medical trainees demonstrated a better understanding of anatomy and showed more systematic reasoning when deciding on the next moves, which was facilitated by the real-time explanations provided in eXplainMR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {422},
numpages = {18},
keywords = {intelligent tutor, automatic feedback generation, healthcare training, subgoal, mixed reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713816,
author = {Yu, Xue and DiVerdi, Stephen and Gingold, Yotam},
title = {A Scaffold-Based Tool for Product Design Variations in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713816},
doi = {10.1145/3706598.3713816},
abstract = {Product design is an iterative process involving several kinds of drawing techniques. Analytic drawing, which involves the use of guidelines or scaffolds to draw the object’s shape curves, aids in achieving precision and accuracy. Freehand drawing allows designers to add details without guidance. The set of scaffold, shape, and detail curves are heavily interrelated. As a result, once a draft set of curves is completed, modifications are extremely difficult. This impedes iterative exploration.We propose to use scaffold manipulation in virtual reality to assist designers in exploring and modifying their product designs. Our key insight is that the same scaffolds designers create for analytic drawing provide an intuitive set of handles. Given a scaffolded 3D product sketch as input, our VR-based system allows designers to directly manipulate the scaffold lines and add detail strokes in any order. Whenever scaffold lines are edited, our system solves for a scaffold line configuration that preserves inter-scaffold relationships. The shape and detail curves are then deformed to match the new scaffold lines. This allows exploratory product design in which a simple template scaffolded 3D drawing is modified and detailed—and further modified—to create a variety of designs. We validated our approach with professional product designers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {423},
numpages = {14},
keywords = {industrial design, sketching, auto-correct, virtual reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714087,
author = {Shi, Xinyu and Wang, Yinghou and Rossi, Ryan and Zhao, Jian},
title = {Brickify: Enabling Expressive Design Intent Specification through Direct Manipulation on Design Tokens},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714087},
doi = {10.1145/3706598.3714087},
abstract = {Expressing design intent using natural language prompts requires designers to verbalize the ambiguous visual details concisely, which can be challenging or even impossible. To address this, we introduce Brickify, a visual-centric interaction paradigm — expressing design intent through direct manipulation on design tokens. Brickify extracts visual elements (e.g., subject, style, and color) from reference images and converts them into interactive and reusable design tokens that can be directly manipulated (e.g., resize, group, link, etc.) to form the visual lexicon. The lexicon reflects users’ intent for both what visual elements are desired and how to construct them into a whole. We developed Brickify to demonstrate how AI models can interpret and execute the visual lexicon through an end-to-end pipeline. In a user study, experienced designers found Brickify more efficient and intuitive than text-based prompts, allowing them to describe visual details, explore alternatives, and refine complex designs with greater ease and control.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {424},
numpages = {20},
keywords = {Design Intent Expression, Interaction Techniques, Direct Manipulation, Interactive Design Token},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714211,
author = {Tao, Sirui and Liang, Ivan and Peng, Cindy and Wang, Zhiqing and Palani, Srishti and Dow, Steven P.},
title = {DesignWeaver: Dimensional Scaffolding for Text-to-Image Product Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714211},
doi = {10.1145/3706598.3714211},
abstract = {Generative AI has enabled novice designers to quickly create professional-looking visual representations for product concepts. However, novices have limited domain knowledge that could constrain their ability to write prompts that effectively explore a product design space. To understand how experts explore and communicate about design spaces, we conducted a formative study with 12 experienced product designers and found that experts — and their less-versed clients — often use visual references to guide co-design discussions rather than written descriptions. These insights inspired DesignWeaver, an interface that helps novices generate prompts for a text-to-image model by surfacing key product design dimensions from generated images into a palette for quick selection. In a study with 52 novices, DesignWeaver enabled participants to craft longer prompts with more domain-specific vocabularies, resulting in more diverse, innovative product designs. However, the nuanced prompts heightened participants’ expectations beyond what current text-to-image models could deliver. We discuss implications for AI-based product design support tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {425},
numpages = {26},
keywords = {Creativity support tools, design ideation, idea management, human-AI interaction, text-to-image models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713934,
author = {Chen, Liuqing and Cheang, Wengteng and Jiang, Zhaojun and Xu, Yuan and Cai, Zebin and Sun, Lingyun and Childs, Peter and Han, Ji and Hansen, Preben and Zuo, Haoyu},
title = {I-Card: A Generative AI-Supported Intelligent Design Method Card Deck},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713934},
doi = {10.1145/3706598.3713934},
abstract = {A design method card deck helps designers understand and provoke thinking by presenting each method in a simple format and allow designers to switch between methods seamlessly by maintaining the same simple format across the deck. However, recent observations have shown designers hesitate to use a card deck due to the lack of support, while other tools have provided identified support with generative AI. Through a formative study, we identified the specific support designers need when applying the design method cards and intentions in integrating generative AI. Accordingly, we developed the intelligent design method card deck, I-Card, which integrates generative AI to provide applicable design methods, design knowledge and data support, and interactive and dynamic support. A user study demonstrates that I-Card improved the design efficiency and applicability by offering personalized guidance, enhanced decision-making with comprehensive data generation and provided more design inspiration via interactive support.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {426},
numpages = {22},
keywords = {Design method, design method cards, design cards, generative AI, design support tool},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713397,
author = {Lin, David Chuan-En and Kang, Hyeonsu B. and Martelaro, Nikolas and Kittur, Aniket and Chen, Yan-Ying and Hong, Matthew K.},
title = {Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713397},
doi = {10.1145/3706598.3713397},
abstract = {With recent advancements in the capabilities of Text-to-Image (T2I) AI models, product designers have begun experimenting with them in their work. However, T2I models struggle to interpret abstract language and the current user experience of T2I tools can induce design fixation rather than a more iterative, exploratory process. To address these challenges, we developed Inkspire, a sketch-driven tool that supports designers in prototyping product design concepts with analogical inspirations and a complete sketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, we conducted an exchange session with designers and distilled design goals for improving T2I interactions. In a within-subjects study comparing Inkspire to ControlNet, we found that Inkspire supported designers with more inspiration and exploration of design ideas, and improved aspects of the co-creative process by allowing designers to effectively grasp the current state of the AI to guide it towards novel design intentions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {427},
numpages = {18},
keywords = {generative AI, sketching, iterative design, co-creative design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713935,
author = {Zhou, Qinyi and Deng, Jie and Liu, Yu and Wang, Yun and Xia, Yan and Ou, Yang and Lu, Zhicong and Ma, Sai and Li, Scarlett and Xu, Yingqing},
title = {ProductMeta: An Interactive System for Metaphorical Product Design Ideation with Multimodal Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713935},
doi = {10.1145/3706598.3713935},
abstract = {Product metaphors, which involve creating products that convey meaning through metaphorical associations, are a powerful tool in product design. However, according to our formative study, novice designers often struggle to establish coherent links between target and source, to manage the complexity of diverse mapping possibilities, and to balance product usability with metaphorical expression. To address these challenges, we introduce ProductMeta, a creativity support tool designed to support novice designers in exploring and developing metaphorical product designs. ProductMeta incorporates domain knowledge and decomposes the design process into iterative modules and framework-based interfaces, fostering both divergent and convergent thinking. Through user studies, we demonstrate that ProductMeta enables novice designers to generate diverse and contextually relevant design ideas by facilitating structured exploration. We conclude with design implications for human-AI co-creation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {428},
numpages = {24},
keywords = {Creativity support tool, Product Design Ideation, Metaphor Design, Machine Learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713144,
author = {Lee, Minha and Min, Soyeong and Kim, Gahyeon and Lee, Sangsu},
title = {Understanding Practical Challenges and Enablers for Embedding Environmental Perspectives in Digital Product Design and Development},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713144},
doi = {10.1145/3706598.3713144},
abstract = {Although awareness of and urgency around the environmental impact of energy consumption in digital infrastructures such as data centers are gradually increasing, many academic efforts still struggle to translate research into practical, real-world applications for reducing digital carbon footprints. Recent studies have highlighted incorporating environmental interventions such as sustainable interaction design (SID) into digital product development practices holds significant potential to reduce their carbon footprint, but integrating sustainability perspectives into everyday design and development practices remains limited in the industry. In this study, we report on the results of in-depth interviews with eight practitioners who have attempted to embed environmental interventions into their practices, capturing their experiences that highlight complex challenges and motivational enablers within the organizational context. Based on these findings, we propose implications for the broader engagement in sustainability-centered design and development practices that resonate with the organizational complexities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {429},
numpages = {15},
keywords = {Sustainable HCI, Sustainability, Carbon Footprint, Energy Consumption, Digital Infrastructure, Digital Service, Practitioner, Sustainable Interaction Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714038,
author = {DeVrio, Alicia and Cheng, Myra and Egede, Lisa and Olteanu, Alexandra and Blodgett, Su Lin},
title = {A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714038},
doi = {10.1145/3706598.3714038},
abstract = {Recent attention to anthropomorphism—the attribution of human-like qualities to non-human objects or entities—of language technologies like LLMs has sparked renewed discussions about potential negative impacts of anthropomorphism. To productively discuss the impacts of this anthropomorphism and in what contexts it is appropriate, we need a shared vocabulary for the vast variety of ways that language can be anthropomorphic. In this work, we draw on existing literature and analyze empirical cases of user interactions with language technologies to develop a taxonomy of textual expressions that can contribute to anthropomorphism. We highlight challenges and tensions involved in understanding linguistic anthropomorphism, such as how all language is fundamentally human and how efforts to characterize and shift perceptions of humanness in machines can also dehumanize certain humans. We discuss ways that our taxonomy supports more precise and effective discussions of and decisions about anthropomorphism of language technologies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {430},
numpages = {18},
keywords = {Anthropomorphism, Responsible AI, Language Technologies, Taxonomy, Critical Algorithm Studies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713533,
author = {Cameron, Harriet R and Reyes-Cruz, Gisela and Piskopani, Anna-Maria and Barnard, Pepita and Boudouraki, Andriana and Caleb-Solly, Praminda and Castle-Green, Simon D and Fischer, Joel E and Hyde, Richard and Kucukyilmaz, Ayse and Maior, Horia A.},
title = {Acceptability, Acceptance and Adoption of Telepresence Robots in Museums: The Museum Professionals' Perspectives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713533},
doi = {10.1145/3706598.3713533},
abstract = {Telepresence robots have the potential to change our experiences in galleries and museums, allowing for a range of hybrid interactions for visitors and museum professionals, improving accessibility, offering activities or information, and providing a range of practical use cases (e.g. the robots augmenting museum exhibits). We present the results of 3 qualitative studies conducted in the UK exploring the acceptability (1 - interviews with museum professionals with no previous exposure to telepresence), acceptance (2 – focus groups for initial exposure to telepresence robots), and adoption (3 – interviews with museum professionals with long-term exposure to robots) of telepresence robots in museums. Our results identified opportunities and barriers focusing on the unique perspective of museum professionals and showed how priorities of museums shift and change according to their exposure to different technologies. We proposed a set of practical guidelines for future telepresence robots in museums, including design implications, potential applications, and integration strategies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {431},
numpages = {18},
keywords = {telepresence robotics, museums and galleries, technology acceptance lifecycle},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714172,
author = {Boonyard, Chandhawat and Jouffrais, Christophe and Cauchard, Jessica R. and Brock, Anke M.},
title = {Firefighting with Drone Assistance: User Needs and Design Considerations for Thailand},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714172},
doi = {10.1145/3706598.3714172},
abstract = {Drones are increasingly being deployed to assist firefighting crews in their missions, with the technology being chosen based on availability, rather than aligned with their specific needs. This phenomenon is exacerbated in the Global South, where infrastructure is scarce and where specific processes and user needs have to be adequately mapped to successfully introduce new technologies. We conducted semi-structured interviews with firefighting professionals (N=15) from Thailand, covering their prior experience with drones, challenges they encounter in their job, and how they envision this technology could better support them in the future. Our findings describe users’ technological needs and their expectations in terms of interaction and collaboration with drones. We identified specific challenges in Thailand that hinder the deployment of drone technology, including mismatches in technical and financial decisions. Furthermore, participants advocated for sharing physical systems between fire departments. We conclude with design considerations for drones in resource-limited firefighting contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {432},
numpages = {18},
keywords = {Human-Drone Interaction; UAV; Firefighting; Situational Awareness, Global South, Technology Adoption},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714238,
author = {Ge, Yate and Li, Meiying and Huang, Xipeng and Hu, Yuanda and Wang, Qi and Sun, Xiaohua and Guo, Weiwei},
title = {GenComUI: Exploring Generative Visual Aids as Medium to Support Task-Oriented Human-Robot Communication},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714238},
doi = {10.1145/3706598.3714238},
abstract = {This work investigates the integration of generative visual aids in human-robot task communication. We developed GenComUI, a system powered by large language models (LLMs) that dynamically generates contextual visual aids—such as map annotations, path indicators, and animations—to support verbal task communication and facilitate the generation of customized task programs for the robot. This system was informed by a formative study that examined how humans use external visual tools to assist verbal communication in spatial tasks. To evaluate its effectiveness, we conducted a user experiment (n = 20) comparing GenComUI with a voice-only baseline. The results demonstrate that generative visual aids, through both qualitative and quantitative analysis, enhance verbal task communication by providing continuous visual feedback, thus promoting natural and effective human-robot communication. Additionally, the study offers a set of design implications, emphasizing how dynamically generated visual aids can serve as an effective communication medium in human-robot interaction. These findings underscore the potential of generative visual aids to inform the design of more intuitive and effective human-robot communication, particularly for complex communication scenarios in human-robot interaction and LLM-based end-user development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {433},
numpages = {21},
keywords = {Human-Robot Interaction, Robot Programming, Service Robots, Conversational Interaction, Large Language Models, Generative UI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713228,
author = {Cho, Hyungjun and Nam, Tek-Jin},
title = {Living Alongside Areca: Exploring Human Experiences with Things Expressing Thoughts and Emotions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713228},
doi = {10.1145/3706598.3713228},
abstract = {Technological advancements such as LLMs have enabled everyday things to use language, fostering increased anthropomorphism during interactions. This study employs material speculation to investigate how people experience things that express their thoughts, emotions, and intentions. We utilized Areca, an air purifier capable of keeping a diary, and placed it in the everyday spaces of eight participants over three weeks. Weekly interviews were conducted to capture participants’ evolving interactions with Areca, concluding with a session collaboratively speculating on the future of everyday things. Our findings indicate that things expressing thoughts, emotions, and intentions can be perceived as possessing agency beyond mere functionality. While some participants exhibited emotional engagement with Areca over time, responses varied, including moments of detachment. We conclude with design implications for HCI designers, offering insights into how emerging technologies may shape human-thing relationships in complex ways.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {434},
numpages = {16},
keywords = {anthropomorphism, affective computing, human-agent interaction, speculative design, material speculation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713459,
author = {Vatavu, Radu-Daniel},
title = {Non-Natural Interaction Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713459},
doi = {10.1145/3706598.3713459},
abstract = {Natural interactions, such as those based on gesture input, feel intuitive, familiar, and well-suited to user abilities in context, and have been supported by extensive research. Contrary to the conventional mainstream, we advocate for non-natural interaction design as a transformative process that results in highly effective interactions by deliberately deviating from user intuition and expectations of physical-world naturalness or the context in which innate human modalities, such as gestures used for interaction and communication, are applied—departing from the established notion of the “natural,” yet prioritizing usability. To this end, we offer four perspectives on the relationship between natural and non-natural design, and explore three prototypes addressing gesture-based interactions with digital content in the physical environment, on the user’s body, and through digital devices, to challenge assumptions in natural design. Lastly, we provide a formalization of non-natural interaction, along with design principles to guide future developments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {435},
numpages = {16},
keywords = {Natural user interfaces, natural interaction, gesture interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713180,
author = {Zeqiri, Albin and Britten, Julian and Schramm, Clara and Jansen, Pascal and Rietzler, Michael and Rukzio, Enrico},
title = {PlantPal: Leveraging Precision Agriculture Robots to Facilitate Remote Engagement in Urban Gardening},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713180},
doi = {10.1145/3706598.3713180},
abstract = {Urban gardening is widely recognized for its numerous health and environmental benefits. However, the lack of suitable garden spaces, demanding daily schedules and limited gardening expertise present major roadblocks for citizens looking to engage in urban gardening. While prior research has explored smart home solutions to support urban gardeners, these approaches currently do not fully address these practical barriers. In this paper, we present PlantPal, a system that enables the cultivation of garden spaces irrespective of one’s location, expertise level, or time constraints. PlantPal enables the shared operation of a precision agriculture robot (PAR) that is equipped with garden tools and a multi-camera system. Insights from a 3-week deployment (N=18) indicate that PlantPal facilitated the integration of gardening tasks into daily routines, fostered a sense of connection with one’s field, and provided an engaging experience despite the remote setting. We contribute design considerations for future robot-assisted urban gardening concepts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {21},
keywords = {Urban Gardening; Sensors; Nature Engagement; Urban Informatics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714165,
author = {Peng, Yuecheng and Miyatake, Mako and Peng, Tyler L and Lu, Qiuyu and Yang, Yue and Yao, Lining},
title = {BioTube: Designing and Fabricating Biodegradable Hollow Tubular Devices Through Progressive Crosslinking Alginate},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714165},
doi = {10.1145/3706598.3714165},
abstract = {We present BioTube, a sustainable and highly accessible DIY fabrication approach for creating hollow tubular alginate, and demonstrate its potential for making biodegradable transient devices. This technique involves extruding alginate into a calcium solution, initiating a progressive crosslinking process that starts from the outer shell and progresses inward. This controlled process removes the uncrosslinked core before complete gelation, yielding hollow alginate fibers. To further enhance the capabilities of BioTube, we explored three further crosslinking strategies to customize the fiber shape, local cross-sectional geometry, and stiffness. The versatility of this method is demonstrated through three key functional primitives: shape, morphing, and sensing. These capabilities are further illustrated through five application examples, including transient wearables, edible shape-changing interfaces, experimental gastronomy, underwater grippers, and sacrificial casting molds. We believe that BioTube will expand the design possibilities for alginate, enabling the creation of innovative biodegradable devices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {437},
numpages = {21},
keywords = {Biomaterials, hydrogels, Bio-HCI, bio-design, sustainability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713735,
author = {Tayal, Sapna and Albaugh, Lea and McCann, James and Hudson, Scott E},
title = {Creating Furniture-Scale Deployable Objects with a Computer-Controlled Sewing Machine},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713735},
doi = {10.1145/3706598.3713735},
abstract = {We introduce a novel method for fabricating functional flat-to-shape objects using a large computer-controlled sewing machine (11 ft / 3.4m wide), a process that is both rapid and scalable beyond the machine’s sewable area. Flat-to-shape deployable objects can allow for quick and easy need-based activation, but the selective flexibility required can involve complex fabrication or tedious assembly. In our method, we sandwich rigid form-defining materials, such as plywood and acrylic, between layers of fabric. The sewing process secures these layers together, creating soft hinges between the rigid inserts which allow the object to transition smoothly into its three-dimensional functional form with little post-processing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {438},
numpages = {15},
keywords = {Computational fabrication, textiles, CNC sewing, furniture},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713167,
author = {Ghane Ezabadi, Mahdie and Nittala, Aditya Shekhar and Yang, Xing-Dong and Wu, Te-Yen},
title = {IntelliLining: Activity Sensing through Textile Interlining Sensors Using TENGs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713167},
doi = {10.1145/3706598.3713167},
abstract = {We introduce a novel component for smart garments: smart interlining, and validate its technical feasibility through a series of experiments. Our work involved the implementation of a prototype that employs a textile vibration sensor based on Triboelectric Nanogenerators (TENGs), commonly used for activity detection. We explore several unique features of smart interlining, including how sensor signals and patterns are influenced by factors such as the size and shape of the interlining sensor, the location of the vibration source within the sensor area, and various propagation media, such as airborne and surface vibrations. We present our study results and discuss how these findings support the feasibility of smart interlining. Additionally, we demonstrate that smart interlinings on a shirt can detect a variety of user activities involving the hand, mouth, and upper body, achieving an accuracy rate of 93.9\% in the tested activities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {439},
numpages = {14},
keywords = {Interactive textile, TENGs, Machine learning, Vibration sensing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713860,
author = {Wang, Tongyan and Chi, Mohan and Yu, Yue and Yan, Kedi and Li, Mo and Luo, Yiyue and Williams, Rua Mae},
title = {LuxKnit: Fabricating Interactive Display Textiles Integrated with Sensing by Machine Knitting},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713860},
doi = {10.1145/3706598.3713860},
abstract = {Displays are crucial in modern smart devices, conveying information visually. Wearable displays have gained increasing interest due to their ability to integrate into everyday environments while maintaining an unobtrusive presence. Textile-based displays, in particular, offer extra advantages of comfort, lightness, and natural feel. We present LuxKnit, a design and fabrication pipeline for textile-based displays with integrated sensing using digital machine knitting. LuxKnit employs electroluminescent (EL) yarn for displays and conductive yarn for sensing. We offer an interactive design interface for users to customize the display’s color, shape, position, and size. We evaluate display luminance and sensing performance across various knitted layouts, deformations, and conductive yarn types. LuxKnit offers a scalable, deformable, stretchable, washable, and interactive display textile system with applications in assistive wearables, interactive educational interfaces, interactive input devices, and common display formats like the seven-segment display.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {440},
numpages = {12},
keywords = {Smart textiles, wearable display, machine knitting, rapid prototyping, ubiquitous computing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714309,
author = {Asor, Shahar and Sterman, Yoav},
title = {Selective Water-Based Hardening of Polyvinyl Alcohol (PVA) Knitted Textiles},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714309},
doi = {10.1145/3706598.3714309},
abstract = {The increasing emphasis on sustainable practices in HCI requires the development of new materials-based approaches for fabrication, which consider degradation and recycling. In particular, textile products containing rigid elements are usually hard to recycle since they are assembled from different materials, which must be disassembled before recycling. We introduce a novel method for fabricating knitted textile objects containing both soft and rigid segments using PVA (Polyvinyl Alcohol). PVA is a biodegradable synthetic material that dissolves in water. When exposed to a controlled amount of water and dried, the textile hardens and becomes rigid. We contribute a hardening method and protocol. Additionally, we present methods to achieve selective hardening by using intarsia knitting with two types of PVA. After being subjected to the hardening protocol, one type of PVA hardens while the other remains soft. To illustrate the potential, capabilities, and applications, a series of selectively hardened knitted objects are presented.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {441},
numpages = {16},
keywords = {3D knitting, design for disassembly, variable properties, water solubility},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714396,
author = {Han, Bo and Lim, Jared and Lim, Kianne and Choo, Adam and Yen, Ching Chiuan and Ang, Genevieve and Zheng, Clement},
title = {Slip Casting as a Machine for Making Textured Ceramic Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714396},
doi = {10.1145/3706598.3714396},
abstract = {Ceramics provide a rich domain for exploring craft, fabrication, and diverse material textures that enhance tangible interaction. In this work, we explored slip-casting, a traditional ceramic technique where liquid clay is poured into a porous plaster mold that absorbs water from the slip to form a clay body. We adapted this process into an approach we called Resist Slip-Casting. By selectively masking the mold’s surface with stickers to vary its water absorption rate, our approach enables makers to create ceramic objects with intricate textured surfaces, while also allowing the customization of a single mold for different outcomes. In this paper, we detail the resist slip-casting process and demonstrate its application by crafting a range of tangible interfaces with customizable visual symbols, tactile features, and decorative elements. We further discuss our approach within the broader conversation in HCI on fabrication machines that promote creative collaboration between humans, materials, and tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {18},
keywords = {Slip-Casting, Textures, Ceramic, Masking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713740,
author = {Faruqi, Faraz and Perroni-Scharf, Maxine and Walia, Jaskaran Singh and Zhu, Yunyi and Feng, Shuyue and Degraen, Donald and Mueller, Stefanie},
title = {TactStyle: Generating Tactile Textures with Generative AI for Digital Fabrication},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713740},
doi = {10.1145/3706598.3713740},
abstract = {Recent work in Generative AI enables the stylization of 3D models based on image prompts. However, these methods do not incorporate tactile information, leading to designs that lack the expected tactile properties. We present TactStyle, a system that allows creators to stylize 3D models with images while incorporating the expected tactile properties. TactStyle accomplishes this using a modified image-generation model fine-tuned to generate heightfields for given surface textures. By optimizing 3D model surfaces to embody a generated texture, TactStyle creates models that match the desired style and replicate the tactile experience. We utilize a large-scale dataset of textures to train our texture generation model. In a psychophysical experiment, we evaluate the tactile qualities of a set of 3D-printed original textures and TactStyle’s generated textures. Our results show that TactStyle successfully generates a wide range of tactile features from a single image input, enabling a novel approach to haptic design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {443},
numpages = {16},
keywords = {Personal Fabrication; Digital Fabrication; 3D Printing; Generative AI.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713366,
author = {Cao, Jerry and Jain, Krish and Zhang, Julie and Peng, Yuecheng and Patel, Shwetak and Mankoff, Jennifer},
title = {"A Tool for Freedom": Co-Designing Mobility Aid Improvements Using Personal Fabrication and Physical Interface Modules with Primarily Young Adults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713366},
doi = {10.1145/3706598.3713366},
abstract = {Mobility aids (e.g., canes, crutches, and wheelchairs) are crucial for people with mobility disabilities; however, pervasive dissatisfaction with these aids keeps usage rates low. Through semi-structured interviews with 17 mobility aid users, mostly under the age of 30, we identified specific sources of dissatisfaction among younger users of mobility aids, uncovered community-based solutions for these dissatisfactions, and explored ways these younger users wanted to improve mobility aids. We found that users sought customizable, reconfigurable, multifunctional, and more aesthetically pleasing mobility aids. Participants’ feedback guided our prototyping of tools/accessories, such as laser cut decorative sleeves, hot-swappable physical interface modules, and modular canes with custom 3D-printed handles. These prototypes were then the focus of additional co-design sessions where six returning participants offered suggestions for improvements and provided feedback on their usefulness and usability. Our findings highlight that many mobility aid users have the desire, ability, and need to customize and improve their aids in different ways compared to older adults. We propose various solutions and design guidelines to facilitate the modifications of mobility aids.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {444},
numpages = {16},
keywords = {Assistive Technology, Mobility Aid, Digital Fabrication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714152,
author = {Ye, Qian and Teng, Sheryl and Siew, E Ian and Yen, Ching Chiuan and Zheng, Clement},
title = {Crafting Interactive Paper Composites through Ancient Papermaking Techniques},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714152},
doi = {10.1145/3706598.3714152},
abstract = {Papermaking is an ancient yet evolving craft, with changes in techniques and materials giving paper contemporary qualities that keep it relevant for everyday use. This adaptability makes papermaking an ideal process for crafting computational composites for tangible interactions. We began by studying ancient Chinese papermaking, replicating it by hand and simplifying the practice into five key steps and tools accessible to novices. We then adapted these steps to imbue the paper with interactive and computational properties, such as integrating conductive materials during pulp preparation, modifying fiber properties through soaking, and customizing sheet texture through watermarking, multi-layering, and coating. We detail our exploration in this paper, as well as demonstrate our findings through four interactive systems focusing on expressive applications made with the computational paper from our adapted process. We also document our exploration in a detailed workbook that captures recipes, failures, and key moments of discovery.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {445},
numpages = {19},
keywords = {Paper, Craft, Computational Composites, Making},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714401,
author = {Moore, Robert John and An, Sungeun and Gala, Jay Pankaj and Jadav, Divyesh},
title = {Finding the Conversation: A Method for Scoring Documents for Natural Conversation Content},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714401},
doi = {10.1145/3706598.3714401},
abstract = {With generative AI acquiring the right training data is a critical part of designing the user experience. Training large language models to talk like humans requires exposing them to the interaction patterns distinctive of natural conversation. Although models are typically fine-tuned on question-answer or instruction pairs, they are less often trained on real-time human conversations. Natural conversation data are hard to find and "conversation" is used to mean very different kinds of interaction or content. We demonstrate a method for scoring language content using generic conversational phrase detection. We generate three scores: 1) range of unique features, 2) density of features within sections of the content, and 3) overall score combining these. Using our method, we score over 27,000 documents from 6 datasets, which vary widely in terms of whether or not they contain conversation content. Our results show this approach is effective in distinguishing conversation content from non-conversation and from conversation-like content.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {446},
numpages = {17},
keywords = {Natural Conversation, Conversational AI, Large Language Model, Conversation Features, Conversation Score, Conversationality, Dialogue Dataset, Conversation Detector},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713286,
author = {Feick, Martin and Tang, Xuxin and Garcia-Martin, Raul and Luchianov, Alexandru and Huang, Roderick Wei Xiao and Xiao, Chang and Siu, Alexa and Dogan, Mustafa Doga},
title = {Imprinto: Enhancing Infrared Inkjet Watermarking for Human and Machine Perception},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713286},
doi = {10.1145/3706598.3713286},
abstract = {Hybrid paper interfaces leverage augmented reality to combine the desired tangibility of paper documents with the affordances of interactive digital media. Typically, virtual content can be embedded through direct links (e.g., QR codes); however, this impacts the aesthetics of the paper print and limits the available visual content space. To address this problem, we present Imprinto, an infrared inkjet watermarking technique that allows for invisible content embeddings only by using off-the-shelf IR inks and a camera. Imprinto&nbsp; was established through a psychophysical experiment, studying how much IR ink can be used while remaining invisible to users regardless of background color. We demonstrate that we can detect invisible IR content through our machine learning pipeline, and we developed an authoring tool that optimizes the amount of IR ink on the color regions of an input document for machine and human detectability. Finally, we demonstrate several applications, including augmenting paper documents and objects.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {447},
numpages = {18},
keywords = {augmented reality; mixed reality; infrared imaging; watermarking; digital fabrication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713692,
author = {Wall, Ludwig Wilhelm and Schneider, Oliver and Vogel, Daniel},
title = {Intermittent Interaction in Digital Fabrication: User Perception of Periodic Intervention in Semi-Automated Creation Tasks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713692},
doi = {10.1145/3706598.3713692},
abstract = {Intermittent Interaction is a turn-taking approach used to interact with fabrication devices to do something that otherwise would be impractical or impossible for the machine. We investigate how people perceive intermittent interactions in a controlled study. A LEGO assembly task with timed lock boxes simulates human involvement with a semi-automated machine process, similar to a 3D printer. This is used in an in situ study with 12 participants over 4-hour sessions with experimental controls for number of interactions and step complexity. Results suggest complex interactions during assembly can amplify the perceived value of the assembled object and increase enjoyment. Participants used either a clustered or evenly distributed strategy to schedule interactions, which can be modelled with simple heuristics. We contribute evidence that intermittent interaction is generally acceptable for creation tasks and practical guidelines for integrating intermittent interactions into semi-automated fabrication systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {448},
numpages = {16},
keywords = {intermittent interaction, controlled experiments, personal fabrication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713354,
author = {Subbaraman, Blair and Bursch, Nathaneal and Peek, Nadya},
title = {It's Not the Shape, It's the Settings: Tools for Exploring, Documenting, and Sharing Physical Fabrication Parameters in 3D Printing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713354},
doi = {10.1145/3706598.3713354},
abstract = {The material properties of 3D prints depend on their constituent materials, how they were printed, and local geometrical features. Motivated by challenges in sharing physical details of 3D printing workflows including machine state and print settings, we contribute tools to support the exploration of the vast design space these interdependent parameters make up. Inspired by live music performance and video captioning, we contribute an interactive controller for parameters not represented in geometry such as speed and extrusion rate, and a system for automatically syncing video documentation to machine settings, G-Code, and print commands. By synchronizing video with machine instructions and interactive adjustments, we archive the relationship between digital settings and physical output for revisiting and sharing. We demonstrate example workflows in multiple materials. Our approach suggests how maker tools that promote settings exploration and sharing can support the integration of fabrication technologies in new contexts, with new materials.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {449},
numpages = {19},
keywords = {3D Printing, Digital Fabrication, Material Exploration, p5.js, Creativity, Creative Code},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714129,
author = {Kwatra, Amritansh and Weinberg, Tobias M and Mandel, Ilan and Batra, Ritik and He, Peter and Guimbretiere, Francois and Roumen, Thijs},
title = {SplatOverflow: Asynchronous Hardware Troubleshooting},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714129},
doi = {10.1145/3706598.3714129},
abstract = {As tools for designing and manufacturing hardware become more accessible, smaller producers can develop and distribute novel hardware. However, processes for supporting end-user hardware troubleshooting or routine maintenance aren’t well defined. As a result, providing technical support for hardware remains ad-hoc and challenging to scale. Inspired by patterns that helped scale software troubleshooting, we propose a workflow for asynchronous hardware troubleshooting: SplatOverflow.SplatOverflow creates a novel boundary object, the SplatOverflow scene, that users reference to communicate about hardware. A scene comprises a 3D Gaussian Splat of the user’s hardware registered onto the hardware’s CAD model. The splat captures the current state of the hardware, and the registered CAD model acts as a referential anchor for troubleshooting instructions. With SplatOverflow, remote maintainers can directly address issues and author instructions in the user’s workspace. Workflows containing multiple instructions can easily be shared between users and recontextualized in new environments.In this paper, we describe the design of SplatOverflow, the workflows it enables, and its utility to different kinds of users. We also validate that non-experts can use SplatOverflow to troubleshoot common problems with a 3D printer in a usability study.Project Page: https://amritkwatra.com/research/splatoverflow.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {16},
keywords = {Hardware Maintenance, Repair, Troubleshooting},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713280,
author = {Singh, Aneesha and Dechant, Martin Johannes and Patel, Dilisha and Soubutts, Ewan and Barbareschi, Giulia and Ayobi, Amid and Newhouse, Nikki},
title = {Exploring Positionality in HCI: Perspectives, Trends, and Challenges},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713280},
doi = {10.1145/3706598.3713280},
abstract = {Positionality acknowledges that researchers’ subjectivities, values and experiences influence approaches to and outcomes of research. It underlines and promotes self-awareness and explicit demonstration of reflexivity. To understand how positionality is conceptualised and used in HCI, we conducted two studies: (i) a scoping review of positionality and reflexivity statements in CHI papers from the last 11 years and (ii) a survey of HCI researchers (n=75). Our findings show that positionality statements are often viewed as a box-ticking exercise and their influence on the research is seldom discussed. They are also often restricted to more sensitive areas of research and may impact marginalised identities. We argue that positionality statements may be valuable but not as markers of methodological rigour; their content should be at the discretion of authors and methodologically consistent. Our contributions include a current snapshot of positionality in HCI and reflections on its current role and future directions in HCI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {451},
numpages = {18},
keywords = {positionality, reflexivity, identity, methodology, methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713464,
author = {Oppenlaender, Jonas and Hosio, Simo},
title = {Keeping Score: A Quantitative Analysis of How the CHI Community Appreciates Its Milestones},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713464},
doi = {10.1145/3706598.3713464},
abstract = {The ACM CHI Conference has a tradition of citing its intellectual heritage. At the same time, we know CHI is highly diverse and evolving. In this highly dynamic context, it is not clear how the CHI community continues to appreciate its milestones (within and outside of CHI). We present an investigation into how the community’s citations to milestones have evolved over 43&nbsp;years of CHI Proceedings (1981–2024). Forgetting curves plotted for each year suggest that milestones are slowly fading from the CHI community’s collective memory. However, the picture is more nuanced when we trace citations to the top-cited milestones over time. We identify three distinct types of milestones cited at CHI, a typology of milestone contributions, and define the Milestone Coefficient as a metric to assess the impact of milestone papers on a continuous scale. Further, our findings suggest the potential presence of a Matthew effect at CHI. We discuss the broader ramifications for the CHI community and the field of HCI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {452},
numpages = {17},
keywords = {milestones, CHI, citations, forgetting curves, Matthew effect, quantitative analysis, bibliometrics, meta-science, meta-HCI.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713556,
author = {Oppenlaender, Jonas},
title = {Past, Present, and Future of Citation Practices in HCI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713556},
doi = {10.1145/3706598.3713556},
abstract = {Science is a complex system comprised of many scientists who individually make decisions that, due to the size and nature of the academic system, largely do not affect the system as a whole. However, certain decisions at the meso-level of research communities, such as the Human-Computer Interaction (HCI) community, may result in deep and long-lasting behavioral changes in scientists.In this article, we provide empirical evidence on how a change in editorial policies introduced at the ACM CHI Conference in 2016 destabilized the CHI research community and launched it on an expansive path, denoted by a year-by-year increase in the mean number of references included in CHI articles. If this near-linear trend continues undisrupted, an article at CHI 2030 will include on average almost 130&nbsp;references.The trend toward more citations reflects a citation culture where quantity is prioritized over quality, contributing to both author and peer reviewer fatigue. Our exploratory analysis highlights the profound impact of meso-level policy adjustments on the evolution of scientific fields and disciplines, urging all stakeholders to carefully consider the broader implications of such changes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {453},
numpages = {16},
keywords = {references, citations, CHI, bibliometric analysis, event study, meta-science, meta-HCI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713917,
author = {Chen, Zhilong and Li, Yong},
title = {The Sharply Decreasing Disruptiveness of HCI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713917},
doi = {10.1145/3706598.3713917},
abstract = {How creative is HCI research? Although creativity has been a notable theme in HCI, the landscape of the creativity of HCI research itself remains unclear. In this paper, we address this by measuring the disruptiveness of HCI research, one important dimension distinguishing the level of creativity, through a large-scale data-driven bibliometric analysis. By quantitatively tracing its evolution over the past 40 years, we find that the disruptiveness of HCI is decreasing sharply, even at a faster speed than the global average across all fields. We characterize the patterns shown by the themes, knowledge use, and authorship of disruptive papers in HCI, and identify how they associate with disruptiveness, e.g., the positive relationship between author freshness and disruptiveness. Based on our results, we discuss practical implications to improve and secure disruptiveness and creativity in HCI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {454},
numpages = {24},
keywords = {Creativity, disruptiveness, bibliometric analysis, human-computer interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713884,
author = {Yoo, MinYoung and Ppali, Sophia and Odom, William and Zhuang, Yumeng and Kritika, Kritika and Olson, Wyatt and Wieczorek, Catherine and Biggs, Heidi and Berger, Arne and Desjardins, Audrey and Wakkary, Ron and Ringland, Kathryn E.},
title = {Translating HCI Research to Broader Audiences: Motivation, Inspiration, and Critical Factors on Alternative Research Outcomes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713884},
doi = {10.1145/3706598.3713884},
abstract = {Alternative Research Outcomes (AROs) go beyond traditional academic publications, taking diverse forms such as documentaries, DIY tutorials, or exhibitions. With growing recognition of the need for more inclusive and contextually appropriate research dissemination, AROs are particularly relevant in HCI and design research. Yet, little has been discussed on why it is important to work on AROs. What are key qualities of AROs? How can the HCI community benefit from learning more about creating AROs? By analyzing six case studies, we propose four qualities of AROs and demonstrate how they emerge in the timeline of a research project. We argue AROs can be adapted to diverse audience needs and share research insights that may extend beyond the original research goals. Our work contributes to a deeper understanding of how AROs can support inclusive research dissemination practices, enabling HCI researchers to engage broader audiences and extend the relevance of their work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {455},
numpages = {24},
keywords = {Alternative Forms, Art Installation, Audio/Video Documentary, DIY Tutorial, Digital Media Content, Knowledge Production, Research Communication, Research Outcomes, Zine},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713726,
author = {Pang, Rock Yuren and Schroeder, Hope and Smith, Kynnedy Simone and Barocas, Solon and Xiao, Ziang and Tseng, Emily and Bragg, Danielle},
title = {Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713726},
doi = {10.1145/3706598.3713726},
abstract = {Large language models (LLMs) have been positioned to revolutionize HCI, by reshaping not only the interfaces, design patterns, and sociotechnical systems that we study, but also the research practices we use. To-date, however, there has been little understanding of LLMs’ uptake in HCI. We address this gap via a systematic literature review of 153 CHI papers from 2020-24 that engage with LLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in HCI projects; (3) contribution types; and (4) acknowledged limitations and risks. We find LLM work in 10 diverse domains, primarily via empirical and artifact contributions. Authors use LLMs in five distinct roles, including as research tools or simulated users. Still, authors often raise validity and reproducibility concerns, and overwhelmingly study closed models. We outline opportunities to improve HCI research with and on LLMs, and provide guiding questions for researchers to consider the validity and appropriateness of LLM-related work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {456},
numpages = {20},
keywords = {Large language models, human-AI interaction, systematic literature review, HCI theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713505,
author = {Jansen, Bernard J and Guan, Kathleen W and Salminen, Joni and Aldous, Kholoud Khalil and Jung, Soon-Gyo},
title = {What is User Engagement?: A Systematic Review of 241 Research Articles in Human-Computer Interaction and Beyond},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713505},
doi = {10.1145/3706598.3713505},
abstract = {User engagement (UE) is widely discussed in HCI articles, but its definition, reliability, and application remain elusive. This research conducts a systematic literature review of 241 articles from 1993 to 2023 to analyze how UE is defined and measured within the domain of HCI. Our findings reveal significant definitional inconsistencies that hinder UE's practical application in HCI research and system design. Based on our findings, we recommend using UE as a categorical label rather than a unified construct until more systematic frameworks are established. We also highlight the need for divergent views of UE across HCI research communities as a valuable avenue to pursue. This divergent view approach can help HCI researchers focus on specific, measurable aspects of UE that align with specific community practices and norms. Our findings also suggest that until such a framework emerges, researchers should be aware of its limitations when using UE as a research construct.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {457},
numpages = {19},
keywords = {user experience, user interaction, user metrics, user needs},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714075,
author = {V\"{a}kev\"{a}, Jaakko and H\"{a}m\"{a}l\"{a}inen, Perttu and Lindqvist, Janne},
title = {"Don't You Dare Go Hollow": How Dark Souls Helps Players Cope with Depression, a Thematic Analysis of Reddit Discussions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714075},
doi = {10.1145/3706598.3714075},
abstract = {Entertainment videogames have been recognized for their potential therapeutic benefits, but there is a need for more in-depth, game-specific explorations of the game features that could contribute to such benefits. This study examines how players of Dark Souls describe the game as helping them cope with depression. We conducted a thematic analysis of Reddit discussions where players narrate their mental health experiences with the game, using AI tools to assist in identifying relevant data for a purposive sample. Our findings suggest that Dark Souls could support players’ mental health, for example, by (1) cultivating resilience and perseverance through its challenging gameplay, (2) triggering existential reflections through symbolic representations of depression, and (3) enabling supportive online communities and interactions. Our findings offer rich, player-centered insights into the perceived mental health benefits of commercial videogames, highlighting their potential to transcend entertainment and inform the design of engaging digital mental health tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {458},
numpages = {20},
keywords = {human-computer interaction, mental health, therapy, user experience, online research},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713561,
author = {Hu, Yang and Freeman, Guo and Panchanadikar, Ruchi},
title = {"Grab the Chat and Stick It to My Wall": Understanding How Social VR Streamers Bridge Immersive VR Experiences with Streaming Audiences Outside VR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713561},
doi = {10.1145/3706598.3713561},
abstract = {Social VR platforms are increasingly transforming online social spaces by enhancing embodied and immersive social interactions within VR. However, how social VR users also share their activities outside the social VR platform, such as on 2D live streaming platforms, is an increasingly popular yet understudied phenomenon that blends social VR and live streaming research. Through 17 interviews with experienced social VR streamers, we unpack social VR streamers’ innovative strategies to further blur the boundary between VR and non-VR spaces to engage their audiences and potential limitations of their strategies. We add new insights into how social VR streamers transcend traditional 2D streamer-audience engagement, which also extend our current understandings of cross-reality interactions. Grounded in these insights, we propose design implications to better support more complicated cross-reality dynamics in social VR streaming while mitigating potential tensions, in hopes of achieving more inclusive, engaging, and secure cross-reality environments in the future.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {459},
numpages = {19},
keywords = {Social Virtual Reality, Live Streaming, Audience Management, Online Engagement, Cross-Reality Interactions},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713177,
author = {Dang, Minh Duc and Luong, Duy Phuoc and Napier, Christopher and Kim, Lawrence H},
title = {Co-Design \&amp; Evaluation of Visual Interventions for Head Posture Correction in Virtual Reality Games},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713177},
doi = {10.1145/3706598.3713177},
abstract = {While virtual reality (VR) games offer immersive experiences, prolonged improper head posture during VR gaming sessions can cause neck discomfort and injuries. To address this issue, we prototyped a framework to detect instances of improper head posture and apply various visual interventions to correct them. After assessing the prototype’s usability in a co-design workshop with participants experienced in VR design and kinesiology, we refined the interventions in two main directions — using explicit visual indicators or employing implicit background changes. The refined interventions were subsequently tested in a controlled experiment involving a target selection task. The study results demonstrate that the interventions effectively helped participants maintain better head posture during VR gameplay compared to the control condition.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {460},
numpages = {15},
keywords = {Posture Correction, Virtual Reality Games},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713403,
author = {Lu, Yingtong and Li, Zhuying and Wang, Yan and Ding, Ding},
title = {Light Up Fireflies: Exploring the Design of Interpersonal Bodily Intertwinement in Social Body Games},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713403},
doi = {10.1145/3706598.3713403},
abstract = {This paper explores the design of interpersonal bodily intertwinement in social body games. We present “Light Up Fireflies”, a two-player VR game where players embody a single avatar, with each player responsible for controlling one half of the avatar’s body. Players must coordinate closely to navigate the virtual environment and engage with the game’s tasks, where any misalignment might cause the avatar to fall. Unlike previous research, which often focused on partial or segmented bodily interactions, our game encourages a fully integrated form of bodily coordination. Players do not merely react to each other’s movements but co-experience the avatar’s body, fostering a richer and more immersive connection between them. Through a study with 16 participants, we identified three key player experiences: bodily strangeness, intertwined bodily movements, and interpersonal bodily understanding. We also provide design implications for future social body games that aim to facilitate deeper, more intertwined embodied experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {461},
numpages = {16},
keywords = {Bodily Play, Social Games, Interpersonal Bodily Intertwinement, Virtual Reality, Virtual Embodiment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713191,
author = {Lankes, Michael and Wallner, G\"{u}nter and Kocur, Martin},
title = {Pathways of Desire: Enhancing Navigation and Sense of Community Through Player-Generated Desire Paths},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713191},
doi = {10.1145/3706598.3713191},
abstract = {Navigating is essential in many video games. However, previous work suggests that many games still suffer from navigational problems that decrease enjoyment. In this paper, we focus on "Desire Paths", informal trails collectively created by pedestrians representing the most convenient route. While they are known to be useful wayfinding aids, it is unclear how they affect navigation and experience in games. We therefore investigated diegetically visualized player trajectory data in a 2D game through virtual footprints that were persistently visible for all subsequent players. Through a mixed-methods study involving 50 participants, we found that virtual footprints improved navigation by guiding players to points of interest and reducing disorientation for early players. However, visual clutter from excessive footprints reduced their effectiveness in later stages. They also fostered a sense of community, especially for late-stage players and prompted exploration of yet undiscovered areas. We further discuss design implications and future research directions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {462},
numpages = {19},
keywords = {Games, Footprints, Desire Paths, Player Trajectory, Navigation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713957,
author = {Potts, Dominic and Gada, Miloni and Gupta, Aastha and Goel, Kavya and Krzok, Klaus Philipp and Pate, Genevieve and Hartley, Joseph and Weston-Arnold, Mark and Aylott, Jakob and Clarke, Christopher and Jicol, Crescent and Lutteroth, Christof},
title = {RetroSketch: A Retrospective Method for Measuring Emotions and Presence in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713957},
doi = {10.1145/3706598.3713957},
abstract = {Virtual Reality (VR) designers and researchers often need to measure emotions and presence as they evolve over time. The experience sampling method (ESM) is a common way to achieve this, however, ESM disrupts the experience and lacks granularity. We propose RetroSketch, a new method for measuring subjective emotions and presence in VR, where users watch back their VR experience and retrospectively sketch a plot of their feelings. RetroSketch leaves the VR experience undisturbed and yields highly granular data, including information about salient events and qualitative descriptions of their feelings. We compared RetroSketch and ESM in a large study (n=140) using five different VR experiences over one-hour sessions. Our results show that RetroSketch and ESM measures are highly correlated with each other, as well as physiological measures indicative of emotion. The correlations are robust across different VR experiences and user demographics. They also highlight the impact of ESM on users’ experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {463},
numpages = {25},
keywords = {virtual reality, emotion, presence, emotion measurement, presence measurement, emotion appraisal, experience sampling, physiological sensing, physiological correlates, games},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713576,
author = {Choong, Lydia and Cmentowski, Sebastian and Kukshinov, Eugene and Tu, Joseph and Nacke, Lennart E.},
title = {Support Autonomy: Exploring Player Perspectives on AI-Supported Onboarding in Video Games},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713576},
doi = {10.1145/3706598.3713576},
abstract = {Video game onboarding faces the challenge of teaching game mechanics in a fun and engaging way. Artificial intelligence (AI) solutions have become a quick fix to help users understand technology. However, little is known about how AI supports player onboarding in video games. To address this knowledge gap, this research explores player perspectives on AI-supported onboarding. We conducted a qualitative user study (n = 20) to investigate player expectations, attitudes, and concerns about AI-supported learning experiences. Players learn primarily through the lived experience of a game and value personalized guidance during onboarding. Participants emphasized the importance of maintaining control over how AI is used during onboarding and the freedom to choose their support level. Our results suggest that players want future AI-supported onboarding systems to prioritize their agency, encourage active learning, and maintain transparency throughout the learning process. We contribute to game design research by proposing balanced, player-centric AI-supported onboarding experiences in video games.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {464},
numpages = {17},
keywords = {artificial intelligence, onboarding, player experience, video games},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714036,
author = {Smith Nicholls, Florence and Cook, Michael},
title = {Archaeological Gameworld Affordances: A Grounded Theory of How Players Interpret Environmental Storytelling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714036},
doi = {10.1145/3706598.3714036},
abstract = {Environmental storytelling is a design technique commonly used to convey narrative through assemblages of content in video games. To date there has been limited empirical work investigating how and on what basis players form interpretations about game environments. We report on a study in which participants (N=202) played a game about exploring a procedurally generated ruined village and were then surveyed on their interpretations. We draw on methods and theory from archaeology – a field that specialises in the interpretation of material remains – to support a grounded theory analysis of the survey responses, from which we form the theory of an archaeological gameworld mental model. Our study draws a novel link between affordance theory, archaeological knowledge production and game systems, and contributes new theoretical concepts that can be applied to procedurally generated and handcrafted methods in game design, narrative design and game preservation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {465},
numpages = {20},
keywords = {environmental storytelling, mental models, grounded theory, archaeological methods, affordance theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713543,
author = {Tu, Joseph and Kukshinov, Eugene and Hadi Mogavi, Reza and Wang, Derrick M. and Nacke, Lennart E.},
title = {Designing Biofeedback Board Games: The Impact of Heart Rate on Player Experience},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713543},
doi = {10.1145/3706598.3713543},
abstract = {Biofeedback provides a unique opportunity to intensify tabletop gameplay. It permits new play styles through digital integration while keeping the tactile appeal of physical components. However, integrating biofeedback systems, like heart rate (HR), into game design needs to be better understood in the literature and still needs to be explored in practice. To bridge this gap, we employed a Research through Design (RtD) approach. This included (1) gathering insights from enthusiast board game designers (n = 10), (2) conducting two participatory design workshops (n = 20), (3) prototyping game mechanics with experts (n = 5), and (4) developing the game prototype artifact One Pulse: Treasure Hunter’s. We identify practical design implementation for incorporating biofeedback, particularly related to heart rate, into tabletop games. Thus, we contribute to the field by presenting design trade-offs for incorporating HR into board games, offering valuable insights for HCI researchers and game designers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {466},
numpages = {21},
keywords = {Board Games, Biofeedback, Design, Game Mechanics, Heart Rate, Play, Prototyping, Research through Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714247,
author = {\"{O}zkaya, Mehmed Nihad and Baykal, G\"{o}k\c{c}e Elif},
title = {Investigating the Motivational Game Elements in Game-based Interventions in School Context: A Literature Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714247},
doi = {10.1145/3706598.3714247},
abstract = {This paper presents a scoping review on motivational game elements examined in game-based interventions for children’s learning in school context in ACM Digital Library and Scopus, with a total of 119 articles reviewed. The aim of the review is to (1) reveal the current state of the art, (2) identify the types of interventions, the game elements, and investigate the core drives of the interventions, (3) examine the empirical findings on the link between motivation and game elements, and (4) define a future research agenda. The results of the scoping review show that interventions that utilize gamification for children are increasingly gaining attention, mostly involve game elements that address the drive for development and accomplishment, the studies mostly target children between 7 to 13 years and the educational domain. The results further show a wide range of game elements in relation to the core drives, and a need for more diverse studies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {467},
numpages = {16},
keywords = {Game-Based Intervention, Gamification, Drives, Motivation, School},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713162,
author = {Pfau, Johannes},
title = {Progression Balancing \texttimes{} Baldur's Gate 3: Insights, Terms and Tools for Multi-Dimensional Video Game Balance},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713162},
doi = {10.1145/3706598.3713162},
abstract = {Internal game balancing is one of the major components that affect player experience, as it is responsible for a large share of development time, the majority of game update patches and long-term player satisfaction. This makes tools and methodologies of assessing and advancing game balance a valuable endeavor for industry and academia. During the past decades, scientific research produced numerous outputs to inform and enhance game balancing, yet most of them only adhere to a single dimension of balance: fixed (end-game) scenarios. However, games are usually experienced throughout a continuous spectrum of ever-changing constellations, which should be reflected. Using simulation, game-playing AI, visual analytics and informative metrics, we introduce a methodology and implementation of Progression Balancing, incorporating multi-dimensional game aspects. For the sake of exposition and ecological validity, we applied it in one of the most successful recent games (Baldur’s Gate 3), and evaluated its efficacy with help of its player community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {468},
numpages = {12},
keywords = {Video Games, Balancing, Artificial Intelligence, Analytics, Community Survey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713246,
author = {Cormier, Michelle V and Liang, Shano and Hamilton, Bill and LaLone, Nicolas and Bohrer, Rose and Toups Dugas, Phoebe O.},
title = {This Game SUX: Why \&amp; How to Design Sh@*!y User Experiences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713246},
doi = {10.1145/3706598.3713246},
abstract = {While normative – “good” – game design and user experiences have been established, we look to games that challenge those notions. Intentional frustration and failure can be worthwhile. Through a reflexive thematic analysis of 31 games we identify how intentionally non-normative design choices lead to meaningful experiences. Working within the established Mechanics Dynamics Aesthetics (MDA) Game Design Framework, we lay out themes to design Shitty User Experiences (SUX). We contribute SUX MDA themes for designers and researchers to counter the status quo and identify new forms of play and interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {469},
numpages = {15},
keywords = {Shitty User Experience, SUX, jank, abusive game design, fumblecore, queer play},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713591,
author = {Liang, Zilu and Hwang, Daeun and Chen, Samantha and Hoang, Nhung Huyen and Khotchasing, Kingkarn and Melcer, Edward F.},
title = {User Preferences for Interaction Timing in Smartwatch Sleep Hygiene Games},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713591},
doi = {10.1145/3706598.3713591},
abstract = {Good sleep hygiene is essential for quality sleep. This study investigates user preferences for the timing of interactions with features in smartwatch-based sleep hygiene games. Findings reveal that interactions during sleep are generally undesirable, with Sleep Health Points being the only exception. We also identified a misconception that games must involve active play, overlooking the potential of passive and idle game mechanics. Participants preferred engaging with planning and behavior-triggering features before the associated behavior, while reflection and reinforcement features, like reports and rewards, were favored post-behavior. The perceived dual functionality of certain features suggests that preferred interaction timing depends on users’ perceptions of the features’ roles. Users’ schedules and situational context, especially evening availability, also influenced their preferences. This study highlights the importance of aligning feature timing with user routines and perceptions, and advocates for game designs that blend active and passive elements to boost engagement and promote sleep hygiene.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {470},
numpages = {17},
keywords = {Games for health; sleep; serious games; just-in-time adaptive interventions; timing.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713170,
author = {Kou, Yubo and Hernandez, Rie Helene (Lindy) and Gui, Xinning},
title = {“The System is Made to Inherently Push Child Gambling in my Opinion”: Child Safety, Monetization, and Moderation on Roblox},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713170},
doi = {10.1145/3706598.3713170},
abstract = {User-generated game (UGG) platforms like Roblox are enormously popular among children but are increasingly scrutinized for safety risks, such as gambling-like gameplay features and disturbing game themes such as slavery and Nazi roleplay. Researchers have started to examine harms in UGGs, but little attention has been paid to how game creators themselves consider child safety in their game making practices. To answer this question, we conducted an interview study with 20 Roblox creators with varied degrees of success. We found that our interviewees observed several types of risks to child players’ safety in their games, such as child-specific deceptive design, gambling-like gameplay, sexual abuse, and scamming. They further reasoned about major causes of these safety risks, such as Roblox's profit-driven monetization model, and leaving the burden of moderation to individual game creators. We discuss implications for platform governance on UGG platforms as well as policymaking.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {471},
numpages = {18},
keywords = {Child Safety, Design Ethics, Gambling, Governance, User-Generated Game},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714055,
author = {Uhl, Jakob Carl and Regal, Georg and Koesten, Laura and Oppermann, Michael and Murtinger, Markus and Tscheligi, Manfred},
title = {Embodied Measurement: Tangible Interactions to Enhance the Validity of Self-Report Measures},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714055},
doi = {10.1145/3706598.3714055},
abstract = {This work introduces the concept of Embodied Measurement (EM), designed to improve the validity and inclusivity of cognitive load assessments by incorporating physical interactions that mirror mental effort. We implemented a haptic force-feedback turning knob as an alternative to traditional Likert-scale ratings and compared it with visual (mouse-based) and combined (haptic and visual) modalities. Participants completed a cognitive load task with varying difficulty levels using each modality, while biosignals such as heart rate variability, skin conductance, and pupil size were recorded to objectively assess cognitive load. In addition, qualitative feedback was gathered to explore participants’ experiences with each input method. Our findings highlight the potential of EM to offer more tangible and intuitive ways of measuring cognitive load, with the combined modality providing the most comprehensive feedback. This study contributes to human-computer interaction (HCI) research by proposing new approaches for measuring cognitive and emotional effort through physical interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {472},
numpages = {16},
keywords = {Cognitive load, Embodied measurement, Haptic feedback, Biosignals},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713450,
author = {Boonprakong, Nattapat and Tag, Benjamin and Goncalves, Jorge and Dingler, Tilman},
title = {How Do HCI Researchers Study Cognitive Biases? A Scoping Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713450},
doi = {10.1145/3706598.3713450},
abstract = {Computing systems are increasingly designed to adapt to users’ cognitive states and mental models. Yet, cognitive biases affect how humans form such models and, therefore, they can impact their interactions with computers. To better understand this interplay, we conducted a scoping review to chart how Human-Computer Interaction (HCI) researchers study cognitive biases. Our findings show that computing systems not only have the potential to induce and amplify cognitive biases but also can be designed to steer users’ behaviour and decision-making by capitalising on biases. We describe how HCI researchers develop algorithms and sensing methods to detect and quantify the effects of cognitive biases and discuss how we can use their understanding to inform system design. In this paper, we outline a research agenda for more theory-grounded research and highlight ethical issues when researching and designing computing systems with cognitive biases in mind as they affect real-world behaviour.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {473},
numpages = {20},
keywords = {cognitive bias; decision-making; bias-aware systems},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714252,
author = {Ajmani, Leah Hope and Bhatt, Talia and DeVito, Michael Ann},
title = {Moving Towards Epistemic Autonomy: A Paradigm Shift for Centering Participant Knowledge},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714252},
doi = {10.1145/3706598.3714252},
abstract = {Justice, epistemology, and marginalization are rich areas of study in HCI. And yet, we repeatedly find platforms and algorithms that push communities further into the margins. In this paper, we propose epistemic autonomy–—one’s ability to govern knowledge about themselves—as a necessary HCI paradigm for working with marginalized communities. We establish epistemic autonomy by applying the transfeminine principle of autonomy to the problem of epistemic injustice. To articulate the harm of violating one’s epistemic autonomy, we present six stories from two trans women: (1) a transfem online administrator and (2) a transfem researcher. We then synthesize our definition of epistemic autonomy in research into a research paradigm. Finally, we present two variants of common HCI methods, autoethnography and asynchronous remote communities, that stem from these beliefs. We discuss how CHI is uniquely situated to champion this paradigm and, thereby, the epistemic autonomy of our research participants.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {474},
numpages = {17},
keywords = {epistemic injustice, transfeminism, HCI paradigms, HCI methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714193,
author = {Cheng, Ti-Chung and Zhang, Yutong and Chou, Yi-Hung and Koshy, Vinay and Li, Tiffany Wenting and Karahalios, Karrie and Sundaram, Hari},
title = {Organize, Then Vote: Exploring Cognitive Load in Quadratic Survey Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714193},
doi = {10.1145/3706598.3714193},
abstract = {Quadratic Surveys (QSs) elicit more accurate preferences than traditional methods like Likert-scale surveys. However, the cognitive load associated with QSs has hindered their adoption in digital surveys for collective decision-making. We introduce a two-phase “organize-then-vote” QS to reduce cognitive load. As interface design significantly impacts survey results and accuracy, our design scaffolds survey takers’ decision-making while managing the cognitive load imposed by QS. In a 2x2 between-subject in-lab study on public resource allotment, we compared our interface with a traditional text interface across a QS with 6 (short) and 24 (long) options. Two-phase interface participants spent more time per option and exhibited shorter voting edit distances. We qualitatively observed shifts in cognitive effort from mechanical operations to constructing more comprehensive preferences. We conclude that this interface promoted deeper engagement, potentially reducing satisficing behaviors caused by cognitive overload in longer QSs. This research clarifies how human-centered design improves preference elicitation tools for collective decision-making.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {475},
numpages = {35},
keywords = {Quadratic Survey; Preference Construction; Survey Response Format; Interactive User Interface; Cognitive Load},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714160,
author = {Becker, Steffen and Walendy, Ren\'{e} and Weber, Markus and Wiesen, Carina and Rummel, Nikol and Paar, Christof},
title = {ReverSim: An Open-Source Environment for the Controlled Study of Human Aspects in Hardware Reverse Engineering},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714160},
doi = {10.1145/3706598.3714160},
abstract = {Hardware Reverse Engineering (HRE) is a technique for analyzing integrated circuits. Experts employ HRE for security-critical tasks, like detecting Trojans or intellectual property violations, relying not only on their experience and customized tools but also on their cognitive abilities. In this work, we introduce ReverSim, a software environment that models key HRE subprocesses and integrates standardized cognitive tests. ReverSim enables quantitative studies with easier-to-recruit non-experts to uncover cognitive factors relevant to HRE. We empirically evaluated ReverSim in three studies. Semi-structured interviews with 14 HRE professionals confirmed its comparability to real-world HRE processes. Two online user studies with 170 novices and intermediates revealed effective differentiation of participant performance across a spectrum of difficulties, and correlations between participants’ cognitive processing speed and task performance. ReverSim is available as open-source software, providing a robust platform for controlled experiments to assess cognitive processes in HRE, potentially opening new avenues for hardware protection.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {476},
numpages = {24},
keywords = {hardware reverse engineering, semi-structured interviews, quantitative studies, cognitive tests},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713149,
author = {Roesler, Eileen and Karrer-Gau\ss{}, Katja and Siebert, Felix Wilhelm},
title = {The TAEG Questionnaire: Assessing Individual Affinity for Technology Across Different Countries},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713149},
doi = {10.1145/3706598.3713149},
abstract = {People have different levels of affinity for technology, which impacts their attitudes and behavior when using novel technologies. Capturing this difference requires a validated multi-language instrument. Hence, we translated and validated English, Japanese, and Spanish versions of the Affinity for Technology questionnaire (TAEG), which has so far only been available in German. The TAEG consists of four scales assessing enthusiasm, perceived competence, and positive and negative consequences of technology. After systematic translation, we collected and analyzed age and gender-stratified samples from Germany, Mexico, Japan, and the US, with a total sample &nbsp;N=1206. All TAEG versions showed an excellent fit with the four-factor model and good criterion validity. We also introduced a short-scale (TAEG-S) that captures the global construct. We found significant cross-country variations, with Mexico reporting the highest TAEG scores on all scales. The validated versions of TAEG provide a robust tool to assess individuals’ affinity for technology internationally.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {477},
numpages = {17},
keywords = {Affinity for Technology, Cross-Country Comparison, Age, Gender, Germany, Japan, Mexico, United States},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713565,
author = {Salovaara, Antti and Vahvelainen, Leevi},
title = {Triangulating on Possible Futures: Conducting User Studies on Several Futures Instead of Only One},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713565},
doi = {10.1145/3706598.3713565},
abstract = {Plausible findings about futures are inherently difficult to obtain as they require critical, well-informed speculations backed with data. HCI scholars tackle this challenge via user studies wherein futuristic prototypes and other props concretise possible futures for participants. By observing participants’ actions, researchers then can ‘time travel’ to see that future as reality, in action. However, such studies may yield particularised findings, inherent to study’s intricacies, and lack broader plausibility. This paper suggests that triangulation of possible futures may help researchers disentangle particularities from more generalisable findings. We explored this approach by conducting a study on two alternative futures of AI-augmented knowledge work. Some findings emerged in both futures while others were particular to only one or the other. This approach enabled cross-checking of plausibility and simultaneously afforded deeper insight. The paper discusses how triangulating possible futures renders HCI studies more future-proof and provides means for reflective anticipation of possible futures.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {478},
numpages = {16},
keywords = {Triangulation, Possible futures, Methodology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714022,
author = {Ortloff, Anna-Marie and Grohs, Julia Angelika and Lenau, Simon and Smith, Matthew},
title = {A Qualitative Study on How Usable Security and HCI Researchers Judge the Size and Importance of Odds Ratio and Cohen's d Effect Sizes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714022},
doi = {10.1145/3706598.3714022},
abstract = {Researchers often place a strong focus on statistical significance when reporting the results of statistical tests. However, effect sizes are reported less frequently, and interpretation in the context of the study and the research field is even rarer. These interpretations of effect sizes are, however, necessary to understand the practical importance of a result for the community. To explore how Usable Security \&amp; Privacy (USP) and HCI researchers interpret effect sizes and make judgments on practical importance, we conducted survey and interview studies with a total of 63 researchers at CHI and SOUPS 2023. Our studies focused on Cohen’s d and odds ratios in two USP and one HCI scenario. We analyzed which artifacts researchers consider when judging effect size, and found misconceptions and variation between the participants, highlighting how difficult judging statistics can be. Based on our findings, we make concrete recommendations for improved reporting practices around effect sizes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {479},
numpages = {16},
keywords = {meta-science, effect size, interpretation, odds ratio, Cohen’s d, interviews, survey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713106,
author = {Meissner, Janis Lena},
title = {Configuring Participatory Research as Give and Take Relationships: Methodological Reflections on Co-Designing Booklets with a Men Shed},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713106},
doi = {10.1145/3706598.3713106},
abstract = {Researchers ask a lot from their study participants: data, time, attention, ideas, and (almost) anything that helps them to pursue their research goals. But what do they give back? This question becomes especially critical in longer-term participatory research with low-resourced communities. This paper offers methodological reflections on a collaboration with a Men’s Shed that was tailored around both my research agenda and the interests of my community partner. As part of my research, we designed a booklet that eventually became their promotion brochure. By reviewing both the trouble and the gains of this process for both partners, I argue for re-imagining community-based participatory research as an opportunity for fostering give-and-take relationships with participants. The case demonstrates the method’s capacity to critically extend existing HCI work on Men’s Sheds while also making participation worthwhile for my partners. The careful documentation of this process contributes methodological nuance to discussions around configuring participation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {480},
numpages = {17},
keywords = {Participation, Co-Design, Men’s Shed, gender, activism, feminist research, Men’s Rights Activism},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713120,
author = {Schroeder, Hope and Aubin Le Qu\'{e}r\'{e}, Marianne and Randazzo, Casey and Mimno, David and Schoenebeck, Sarita},
title = {Large Language Models in Qualitative Research: Uses, Tensions, and Intentions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713120},
doi = {10.1145/3706598.3713120},
abstract = {Qualitative researchers use tools to collect, sort, and analyze their data. Should qualitative researchers use large language models (LLMs) as part of their practice? LLMs could augment qualitative research, but it is unclear if their use is appropriate, ethical, or aligned with qualitative researchers’ goals and values. We interviewed twenty qualitative researchers to investigate these tensions. Many participants see LLMs as promising interlocutors with attractive use cases across the stages of research, but wrestle with their performance and appropriateness. Participants surface concerns regarding the use of LLMs while protecting participant interests, and call attention to an urgent lack of norms and tooling to guide the ethical use of LLMs in research. We document the rapid and broad adoption of LLMs across surfaces, which can interfere with intentional use vital to qualitative research. We use the tensions surfaced by our participants to outline recommendations for researchers considering using LLMs in qualitative research and design principles for LLM-assisted qualitative research tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {481},
numpages = {17},
keywords = {Qualitative methods, large language models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714422,
author = {Heimann, Katrin and Nouwens, Minke and Saggurthi, Suneetha and Dalsgaard, Peter},
title = {Micro-Phenomenology as a Method for Studying User Experience in Human-Computer Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714422},
doi = {10.1145/3706598.3714422},
abstract = {We examine how micro-phenomenology, a qualitative research method developed to attend to, articulate, and analyse lived experience in fine detail, can be employed to study the experience of using digital systems. Micro-phenomenological interviews unpack the specific experiences of interviewees in fine-grained detail and have previously been acknowledged as a potent tool for Human-Computer Interaction Research. More recently, the method has been extended to comprise a structured analysis method to systematically analyse the temporal unfolding and qualitative dimensions of experiences captured by the interviews. This is the first paper demonstrating the combined use of interviews and analysis via a case in which they were employed to examine the experience of using WeUsedTo, a website for sharing experiences related to the COVID-19 pandemic. On this basis, we discuss the potentials of the method for eliciting and understanding experiential aspects of interactive systems, particularly pertaining to embodiment, temporality, attention, agency, and the systemic nature of experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {482},
numpages = {17},
keywords = {User Experience; Micro-phenomenology; Qualitative Research; Qualitative Interviews; Qualitative Analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713671,
author = {Ortloff, Anna-Marie and Martius, Florin and Meier, Mischa and Raimbault, Theo and Geierhaas, Lisa and Smith, Matthew},
title = {Small, Medium, Large? A Meta-Study of Effect Sizes at CHI to Aid Interpretation of Effect Sizes and Power Calculation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713671},
doi = {10.1145/3706598.3713671},
abstract = {Statistical reporting, especially of effect sizes, is at the root of many methodological issues in quantitative research at CHI. Effect sizes are necessary for assessing practical relevance of results, a-priori power analysis, and meta-analyses, but currently, they are often not reported. Interpretations in the context of the study and the research field are also rare. To aid to researchers in reporting and contextualizing their effect sizes within their research field as well as choosing effect sizes for power analysis, we conducted a meta-study of quantitative CHI papers. We extracted statistics from all quantitative CHI papers published between 2019-2023 (N=1692). Based on effect sizes and the papers’ CCS categories, we present effect size distributions in 12 CHI research fields. Through an additional qualitative analysis of 67 quantitative CHI’23 publications, we identify five categories of approaches that researchers take when interpreting effect size: Comparing test-specific values, assigning size labels, using a statistical or methodological reference frame, comparing different observations and interpreting for the big picture.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {483},
numpages = {28},
keywords = {meta-science, effect size, statistical power, reporting, data extraction, statistics interpretation, LLM},
location = {
},
series = {CHI '25}
}

@inbook{10.1145/3706598.3713789,
author = {Velloso, Eduardo and Hornb\ae{}k, Kasper},
title = {Theorising in HCI using Causal Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713789},
abstract = {Although the literature on Human-Computer Interaction (HCI) catalogues many theories, it offers surprisingly few tools for theorising. This paper critiques dominant approaches to engaging with theory and proposes a working model for theorising in HCI. We then present graphical causal modelling as an effective theorising tool. This includes a step-by-step guide to building causal models and examples of their use in different stages of the research process. We explain how causal models help develop method-agnostic representations of research problems using directed acyclic graphs, identify potential confounders, and construct alternative interpretations of data. Finally, we discuss their limitations and challenges for adoption by the HCI community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {484},
numpages = {17}
}

@inproceedings{10.1145/3706598.3713087,
author = {Leusmann, Jan and Villa, Steeven and Berberoglu, Burak and Wang, Chao and Mayer, Sven},
title = {Developing and Validating the Perceived System Curiosity Scale (PSC): Measuring Users' Perceived Curiosity of Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713087},
doi = {10.1145/3706598.3713087},
abstract = {Like humans, today’s systems, such as robots and voice assistants, can express curiosity to learn and engage with their surroundings. While curiosity is a well-established human trait that enhances social connections and drives learning, no existing scales assess the perceived curiosity of systems. Thus, we introduce the Perceived System Curiosity (PSC) scale to determine how users perceive curious systems. We followed a standardized process of developing and validating scales, resulting in a validated 12-item scale with 3 individual sub-scales measuring explorative, investigative, and social dimensions of system curiosity. In total, we generated 831 items based on literature and recruited 414 participants for item selection and 320 additional participants for scale validation. Our results show that the PSC scale has inter-item reliability and convergent and construct validity. Thus, this scale provides an instrument to explore how perceived curiosity influences interactions with technical systems systematically.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {485},
numpages = {18},
keywords = {Human Computer Interaction, Scale, Questionnaire, Perceived Curiosity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714168,
author = {Otuu, Obinna Ogbonnia and Sahoo, Deepak},
title = {How Should We Design Technology With Diverse Stakeholders Who Wish Not to Attend Design Activities Together?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714168},
doi = {10.1145/3706598.3714168},
abstract = {The relationship between the Nigerian police and citizens is strained, hindering the co-design of conventional technologies to enhance community policing (CP) initiatives, hence the imperative to involve both in the design of a usable CP technology that can carter for their needs. Our preliminary findings indicate that Nigerian citizens are reluctant to participate in co-design activities with the police due to discomfort and fear, which could potentially bias the design outcomes. Designing a CP technology with such stakeholders is crucial, but a new challenge for the Human Computer Interaction (HCI) community, as no existing framework has addressed it. We introduce Conflict Sensitive Design (CSD), a co-design approach that leverages mediation techniques (tension reduction, leveling, common ground reminder, separated meetings, formalizing agreements) to iteratively collect, analyze, and reconcile design inputs, ensuring that the final design is usable for CP enhancement. Our case application worked in CP technology requirements gathering with Nigerian CP stakeholders, and it could be extended to related HCI contexts. We present a structured approach to conflict resolution in co-design processes, and discuss the lessons learned as a spotlight to guide other designers in related contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {486},
numpages = {14},
keywords = {Co-design, Participatory Design, Value Sensitive Design, Non-collocated Design, Design Justice, Marginalized Users, Authority Users, Adversarial Stakeholders, Power Imbalance, Conflict Mediation, Community Policing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713759,
author = {Sanchez, Camilo and Wang, Sui and Savolainen, Kaisa and Epp, Felix Anand and Salovaara, Antti},
title = {Let's Talk Futures: A Literature Review of HCI's Future Orientation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713759},
doi = {10.1145/3706598.3713759},
abstract = {HCI is future-oriented by nature: it explores new human–technology interactions and applies the findings to promote and shape vital visions of society. Still, the visions of futures in HCI publications seem largely implicit, techno-deterministic, narrow, and lacking in roadmaps and attention to uncertainties. A literature review centered on this problem examined futuring and its forms in the ACM Digital Library’s most frequently cited HCI publications. This analysis entailed developing the four-category framework SPIN, informed by futures studies literature. The results confirm that, while technology indeed drives futuring in HCI, a growing body of HCI research is coming to challenge techno-centric visions. Emerging foci of HCI futuring demonstrate active exploration of uncertainty, a focus on human experience, and contestation of dominant narratives. The paper concludes with insight illuminating factors behind techno-centrism’s continued dominance of HCI discourse, as grounding for five opportunities for the field to expand its contribution to futures and anticipation research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {487},
numpages = {36},
keywords = {Literature Review, Futures, Futures Studies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713214,
author = {Kang, Bo and Hodges, Steve and Kristensson, Per Ola},
title = {Making Hardware Devices at Scale is Still Hard: Challenges and Opportunities for the HCI Community.},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713214},
doi = {10.1145/3706598.3713214},
abstract = {Embedded systems and interactive devices form an essential interface between the physical and digital world and are understandably an important focus for the HCI research community. However, scaling an interactive prototype of a new device concept to enable effective evaluation or to support the transition to a production-ready device is incredibly challenging. To better understand the issues innovators face when scaling up interactive device prototypes we report the results from 22 interviews with practitioners in the interactive device field, including eight academics involved in the HCI and manufacturing research communities. In our two-phase analysis we identify and validate the following four recurring themes. First and foremost is the observation that “creating relationships with industry” is hard. Second, “effective communication requires a lot of effort” despite the availability of modern collaboration tools. Thirdly, we observed that “understanding the manufacturer’s perspective” can be difficult. Finally, “prototyping is nothing like production”—the vast difference between these two activities still surprises many. Additionally, our university-based participants gave us further insights and helped us to identify challenges specific to the academic context, pointing to a number of opportunities relating to hardware device scaling.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {488},
numpages = {13},
keywords = {interactive device, production, engineering experience},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713220,
author = {Kapania, Shivani and Agnew, William and Eslami, Motahhare and Heidari, Hoda and Fox, Sarah E},
title = {Simulacrum of Stories: Examining Large Language Models as Qualitative Research Participants},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713220},
doi = {10.1145/3706598.3713220},
abstract = {The recent excitement around generative models has sparked a wave of proposals suggesting the replacement of human participation and labor in research and development–e.g., through surveys, experiments, and interviews—with synthetic research data generated by large language models (LLMs). We conducted interviews with 19 qualitative researchers to understand their perspectives on this paradigm shift. Initially skeptical, researchers were surprised to see similar narratives emerge in the LLM-generated data when using the interview probe. However, over several conversational turns, they went on to identify fundamental limitations, such as how LLMs foreclose participants’ consent and agency, produce responses lacking in palpability and contextual depth, and risk delegitimizing qualitative research methods. We argue that the use of LLMs as proxies for participants enacts the surrogate effect, raising ethical and epistemological concerns that extend beyond the technical limitations of current models to the core of whether LLMs fit within qualitative ways of knowing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {489},
numpages = {17},
keywords = {large language models, simulating research participants, LLM agents, qualitative research, LLMs in qualitative research, synthetic users, synthetic research data},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713958,
author = {Mothilal, Ramaravind Kommiya and Lalani, Faisal M. and Ahmed, Syed Ishtiaque and Guha, Shion and Sultana, Sharifa},
title = {Talking About the Assumption in the Room},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713958},
doi = {10.1145/3706598.3713958},
abstract = {The reference to assumptions in how practitioners use or interact with machine learning (ML) systems is ubiquitous in HCI and responsible ML discourse. However, what remains unclear from prior works is the conceptualization of assumptions and how practitioners identify and handle assumptions throughout their workflows. This leads to confusion about what assumptions are and what needs to be done with them. We use the concept of an argument from Informal Logic, a branch of Philosophy, to offer a new perspective to understand and explicate the confusions surrounding assumptions. Through semi-structured interviews with 22 ML practitioners, we find what contributes most to these confusions is how independently assumptions are constructed, how reactively and reflectively they are handled, and how nebulously they are recorded. Our study brings the peripheral discussion of assumptions in ML to the center and presents recommendations for practitioners to better think about and work with assumptions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {490},
numpages = {16},
keywords = {Assumption, Machine Learning, Responsible ML, Informal Logic, Critical Thinking, ML Practitioners},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714073,
author = {Singh, Divyanshu Kumar and Das, Dipto and Semaan, Bryan},
title = {The Power of Language: Resisting Western Heteropatriarchal Normative Writing Standards},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714073},
doi = {10.1145/3706598.3714073},
abstract = {Language is more than communication; it is a form of power. Whereas science has been scrutinized for privileging Western values and norms, what has been less explored is scientific linguistic performance (e.g. writing). The enforcement of English as the “normative standard” has prioritized hegemonic values and assumptions, thereby shaping the expectations of scientific performance. HCI/CSCW is dominated by heteropatriarchal Western practices, overlooking entangled values and assumptions impacting non-Western colleagues. Our work presents a design fiction (fictitious case study) envisioning a research contribution which embodies non-Western linguistic nuances as an alternative “normative standard” for scientific communication. Through this work, not only are we championing care in developing responsible linguistic practices in HCI/CSCW, but also epistemically challenging readers with intentional confusion. We establish a call to action for acknowledging and embracing different writing practices that are more inclusive of the diverse representation of scholars in HCI/CSCW.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {491},
numpages = {17},
keywords = {Language, Design Fiction, Coloniality, Human-Computer Interaction, Decolonization, Feminism, People of Color, Power, Justice},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713834,
author = {Shi, Tianzheng and Schneider, Oliver},
title = {Development and Initial Validation of the Haptic Experience Inventory (HXI)},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713834},
doi = {10.1145/3706598.3713834},
abstract = {Haptic Experience (HX) encompasses distinct quality criteria specific to haptic interactions, yet no standardized instrument exists to measure it. This makes understanding and evaluating HX challenging. This paper reports on the development and validation of the Haptic Experience Inventory (HXI), a questionnaire measuring HX. An item pool of 50 items is developed through theoretical construction, expert reviews (N=10), and cognitive interviews (N=9). These items are then subjected to exploratory and confirmatory factor analysis using data from 591 participants across in-person and online studies, covering vibrotactile, force-feedback, and mid-air devices. Eventually, a 20-item HXI with five dimensions is established: Autotelics, Realism, Involvement, Harmony, and Discord. The HXI converges with theory and shows strong reliability, validity, and measurement invariance, suggesting it is effective across deployed modalities and contexts. The HXI provides empirical evidence about the structure of HX and offers a robust, standardized tool for assessing haptic feedback in research and practice.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {492},
numpages = {21},
keywords = {Haptics, Scale Development, HCI, User Experience Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714225,
author = {Mun, Buyoung and Lee, Junsu and Kim, Jiseong and Heo, Seongkook and Lee, Jaeyeon},
title = {Diversifying Grain-Based Compliance Illusion by Varying Base Compliance},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714225},
doi = {10.1145/3706598.3714225},
abstract = {Grain-based compliance illusion mimics the mechanical vibrations that occur when a compliant object deforms with grain-like, short (∼ 15&nbsp;ms) impulse-response vibrations. Previous work has demonstrated its robust effect on various types of devices. However, the impact of the device’s inherent compliance (i.e., base compliance) on perceived compliance remains unclear. This paper investigates the influence of base compliance on the perception of illusory compliance through three psychophysical experiments. The results show that (1) the compliance illusion remained effective with base compliance, (2) the description of compliance was affected by both illusory and base compliance, and (3) it is possible to render the compliance with the same magnitude but multiple different feelings.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {493},
numpages = {16},
keywords = {Haptic interfaces, Compliance illusion, Psychophysical experiments},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713231,
author = {Ooms, Simone and Lee, Minha and Stepanova, Ekaterina R. and Cesar, Pablo and El Ali, Abdallah},
title = {Haptic Biosignals Affect Proxemics Toward Virtual Reality Agents},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713231},
doi = {10.1145/3706598.3713231},
abstract = {Encounters with virtual agents currently lack the haptic viscerality of human contact. While digital biosignal communication can mediate such virtual social interactions, how artificial haptic biosignals influence users’ personal space during Virtual Reality (VR) experiences is unknown. Designing vibrotactile heartbeats and thermally-actuated body temperature, we ran a within-subjects study (N=31) to investigate feedback (Thermal, Vibration, Thermal+Vibration, None) and agent stories (Negative, Neutral, Positive) on objective and subjective interpersonal distance (IPD), perceived arousal and comfort, presence, and post-experience responses. Findings showed that thermal feedback decreased objective but not subjective IPD, whereas vibrotactile heartbeats (signaling agent’s closeness) increased both while heightening arousal and discomfort. Agents’ stories did not affect IPD, arousal, or comfort. Our qualitative findings shed light on signal ambiguity and presence constructs within VR-based haptic stimulation. We contribute insights into artificial biosignals and their influence on VR proxemics, with cautionary considerations should the boundaries blur between physical and virtual touch.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {494},
numpages = {18},
keywords = {haptics, biosignals, proxemics, agents, virtual reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713609,
author = {Sung, Youjin and John, Kevin and Yoon, Sang Ho and Seifi, Hasti},
title = {HapticGen: Generative Text-to-Vibration Model for Streamlining Haptic Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713609},
doi = {10.1145/3706598.3713609},
abstract = {Designing haptic effects is a complex, time-consuming process requiring specialized skills and tools. To support haptic design, we introduce HapticGen, a generative model designed to create vibrotactile signals from text inputs. We conducted a formative workshop to identify requirements for an AI-driven haptic model. Given the limited size of existing haptic datasets, we trained HapticGen on a large, labeled dataset of 335k audio samples using an automated audio-to-haptic conversion method. Expert haptic designers then used HapticGen’s integrated interface to prompt and rate signals, creating a haptic-specific preference dataset for fine-tuning. We evaluated the fine-tuned HapticGen with 32 users, qualitatively and quantitatively, in an A/B comparison against a baseline text-to-audio model with audio-to-haptic conversion. Results show significant improvements in five haptic experience (e.g., realism) and system usability factors (e.g., future use). Qualitative feedback indicates HapticGen streamlines the ideation process for designers and helps generate diverse, nuanced vibrations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {495},
numpages = {24},
keywords = {Haptics, Designers, Generative AI, Extended Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713821,
author = {Lee, Kyungyeon and Yang, Daniel S and Singh, Kriti and Nishida, Jun},
title = {Hapticus: Exploring the Effects of Haptic Feedback and its Customization on Motor Skill Learning: Tactile, Haptic, and Somatosensory Approaches},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713821},
doi = {10.1145/3706598.3713821},
abstract = {Numerous haptic devices have been proposed to support motor learning, such as a hand exoskeleton with mechanical linkages, a vibrotactile glove, and an Electrical Muscle Stimulation (EMS) device. Understanding the impact of each type of feedback on users’ learning performance and experience, as well as the effects of customizing the haptic feedback each user receives, is vital to achieving both efficient and highly motivating learning. To this end, we compared learning performance and experience while using these haptic devices for piano learning. It revealed the distinct characteristics of each device, notably, the exoskeleton was the most preferred despite certain drawbacks. We then conducted a user study to evaluate the effectiveness of haptic customization, allowing participants to customize the order of haptic feedback, demonstrating its advantages such as improved agency and performance. These findings would benefit haptic designers by providing more efficient and optimized haptic feedback for motor learning scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {496},
numpages = {20},
keywords = {Motor skill learning; Electrical muscle stimulation; Exoskeleton; Vibrotactile; Customization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713355,
author = {Yun, Gyeore and Choi, Seungmoon},
title = {Real-time Semantic Full-Body Haptic Feedback Converted from Sound for Virtual Reality Gameplay},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713355},
doi = {10.1145/3706598.3713355},
abstract = {We present a multisensory virtual reality (VR) system that enables users to experience concurrent visual, auditory, and haptic feedback, featuring semantic classification of events from sound, sound-to-haptic conversion, and full-body haptic effects. This concept is applied to enhance the user experience of virtual reality (VR) gameplay. The system utilizes a Long-Short-Term Memory (LSTM) model to classify game sounds and detect key events such as gunfire, explosions, and hits. These events are translated into full-body haptic patterns through a haptic suit, providing users with realistic and immersive haptic experiences. The system operates with low latency, ensuring the seamless synchrony between sound and haptic feedback. Evaluations through user studies demonstrate significant improvements in user experience compared to traditional sound-to-haptic methods, emphasizing the importance of accurate sound classification and well-designed haptic effects.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {497},
numpages = {17},
keywords = {sound-haptic conversion, semantic sound classification, automatic generation, real time, haptic suit, full body, game, user experience},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713891,
author = {Lee, Jungeun and Jeon, Minha and Lee, Jinyoung and Choi, Seungmoon and Oh, Seungjae},
title = {SkinHaptics: Exploring Skin Softness Perception and Virtual Body Embodiment Techniques to Enhance Self-Haptic Interactions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713891},
doi = {10.1145/3706598.3713891},
abstract = {Providing haptic feedback for soft, deformable objects is challenging, requiring complex mechanical hardware combined with modeling and rendering software. As an alternative, we advance the concept of self-haptics, where the user’s own body delivers physical feedback, to convey dynamically varying softness in VR. Skin can exhibit different levels of contact softness by altering the biomechanical state of the body. We propose SkinHaptics, a device-free approach that changes the states of musculoskeletal structures and virtual hand-object representations. In this study, we conduct three experiments to demonstrate SkinHaptics. Using the same scale, we measure skin softness across various hand poses and contact points and evaluate the just noticeable difference in skin softness. We investigate the effect of hand-object representations on self-haptic interactions. Our findings indicate that the visual representations have a significant influence on the embodiment of a self-haptic hand, and the degree of the hand embodiment strongly affects the haptic experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {498},
numpages = {18},
keywords = {Softness Perception, Self-Haptics, Embodiment, Virtual Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714264,
author = {Jang, Hyuckjin and Lee, Jeongmi},
title = {Birds of a Rhythm: The Effects of Haptic Pattern Similarity on People's Social Perceptions in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714264},
doi = {10.1145/3706598.3714264},
abstract = {Virtual reality (VR) expands opportunities for social interaction, yet its heavy reliance on visual cues can limit social engagement and hinder immersive experiences in visually overwhelming situations. To explore alternative social cues beyond the visual domain, we verified the potential of haptic cues for social identification in VR by examining the effects of haptic pattern similarity on social perceptions. Unique haptic patterns were assigned to participants and virtual agents for identification, while the similarity of haptic patterns was manipulated (same, similar, distinct). The results demonstrated that participants maintained closer interpersonal distances and reported higher senses of belonging, social connection, and comfort toward agents as the similarity of patterns increased. Our findings validate the potential of haptic patterns in social identification and provide scientific evidence that homophily extends beyond the visual domain to the haptic domain. We also suggest a novel haptic-based methodology for conveying relationship information and enhancing social VR experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {499},
numpages = {18},
keywords = {Haptic Pattern Similarity, Social Perception, Interpersonal Distance, Multidimensional Scaling, Virtual Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713555,
author = {Terenti, Mihail and Vatavu, Radu-Daniel},
title = {Distal-Haptic Touchscreens: Understanding the User Experience of Vibrotactile Feedback Decoupled from the Touch Point},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713555},
doi = {10.1145/3706598.3713555},
abstract = {We examine the user experience of distal haptics for touchscreen input through confirmatory vibrations of on-screen touches at various on-body locations. To this end, we introduce the Distal Haptics Continuum, a conceptual framework of haptic feedback delivery across the body, organized along the dimensions of Body Laterality and Proximity to the touch point. Our results, from three experiments involving 45 participants and 16 locations across the hand, arm, and whole body, reveal a strong preference for distal haptics over no haptics at all, despite the spatial decoupling from the touch point, with the index finger yielding the highest user experience. We also identify additional on-body locations—the adjacent fingers, wrist, and abdomen—that unlock distinctive design opportunities. Building on our insights, demonstrating haptics effectiveness even when distant from the touch point, we outline implications for integrating various on-body locations, well beyond the index finger, into the user experience of touchscreen input.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {500},
numpages = {19},
keywords = {User experience, haptics, distal haptics, vibrotactile feedback, touch input, touchscreens},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714139,
author = {Ju, Yulan and Meng, Xiaru and Taguchi, Harunobu and Gunasekaran, Tamil Selvan and Hoppe, Matthias and Ishikawa, Hironori and Tanaka, Yoshihiro and Pai, Yun Suen and Minamizawa, Kouta},
title = {Haptic Empathy: Investigating Individual Differences in Affective Haptic Communications},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714139},
doi = {10.1145/3706598.3714139},
abstract = {Nowadays, touch remains essential for emotional conveyance and interpersonal communication as more interactions are mediated remotely. While many studies have discussed the effectiveness of using haptics to communicate emotions, incorporating affect into haptic design still faces challenges due to individual user tactile acuity and preferences. We assessed the conveying of emotions using a two-channel haptic display, emphasizing individual differences. First, 24 participants generated 187 haptic messages reflecting their immediate sentiments after watching 8 emotionally charged film clips. Afterwards, 19 participants were asked to identify emotions from haptic messages designed by themselves and others, yielding 593 samples. Our findings suggest potential links between haptic message decoding ability and emotional traits, particularly Emotional Competence (EC) and Affect Intensity Measure (AIM). Additionally, qualitative analysis revealed three strategies participants used to create touch messages: perceptive, empathetic, and metaphorical expression.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {501},
numpages = {25},
keywords = {affective computing, emotion encoding, emotion recognition, emotion expression, haptic interfaces, vibration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713396,
author = {Niijima, Arinobu and Shindo, Masato and Aoki, Ryosuke},
title = {Invisible Light Touch: Standing Balance Improvement by Mid-Air Haptic Feedback},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713396},
doi = {10.1145/3706598.3713396},
abstract = {Improving standing balance is critical for preventing falls and ensuring the well-being of older adults. In this paper, we present Invisible Light Touch (ILT), a mid-air haptic feedback application designed to improve standing balance by utilizing the light touch effect, a well-documented phenomenon in medical research. The light touch effect refers to improved balance when a person lightly touches a surface, such as a wall or handrail, with a force of 1&nbsp;N or less. We replicate this effect utilizing focused ultrasound to create a tactile point in mid-air. When users interact with this invisible tactile point, they experience the light touch effect, which subsequently improves their balance. We conducted a pilot study with 29 participants and a user study with 25 older adults, evaluating the balance improvement by measuring the center of pressure trajectory. The results confirmed that standing balance improved significantly when using the ILT.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {502},
numpages = {11},
keywords = {Mid-air haptics, Ultrasound-focusing device, Light touch effect, Standing balance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713987,
author = {Mazursky, Alex and Gupta, Aryan and de la Cruz, Andre and Lopes, Pedro},
title = {Power-on-Touch: Powering Actuators, Sensors, and Devices during Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713987},
doi = {10.1145/3706598.3713987},
abstract = {We introduce Power-on-Touch, a novel method for powering devices during interaction. Power-on-Touch comprises two main components: (1) a wearable-transmitter attached to the user's body (e.g., fingernail, back of the hand, feet) with wireless power-coils and a battery; and (2) receiver-tags embedded in interactive devices, making them battery-free. Many devices only require power during interaction (e.g., TV remotes, digital calipers). We leverage this interactive opportunity by inductively transferring energy from the user's coil to the device's coil when in close proximity. To achieve this, we engineered receiver-tags and coils, including thin pancake-coils best-suited for wearables and spherical-coils that receive power omnidirectionally. To understand which coils best support a wide range of interactions (e.g., grasping, touching, hovering), we performed technical characterizations, including impedance and 3D efficiency analysis. We believe our technical approach can inspire ubiquitous computing with new ways to scale up the number and diversity of battery-free devices, not just sensors (µWatts) but also actuators (Watts).},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {503},
numpages = {16},
keywords = {haptics, ubiquitous computing, wearable, wireless power transfer},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713981,
author = {Zhou, Ran and Ding, Jianru and Gao, Chenfeng and Qian, Wanli and Erickson, Benjamin and Balaam, Madeline and Leithinger, Daniel and Nakagaki, Ken},
title = {Shape-Kit: A Design Toolkit for Crafting On-Body Expressive Haptics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713981},
doi = {10.1145/3706598.3713981},
abstract = {Driven by the vision of everyday haptics, the HCI community is advocating for “design touch first” and investigating “how to touch well.” However, a gap remains between the exploratory nature of haptic design and technical reproducibility. We present Shape-Kit, a hybrid design toolkit embodying our “crafting haptics” metaphor, where hand touch is transduced into dynamic pin-based sensations that can be freely explored across the body. An ad-hoc tracking module captures and digitizes these patterns. Our study with 14 designers and artists demonstrates how Shape-Kit facilitates sensorial exploration for expressive haptic design. We analyze how designers collaboratively ideate, prototype, iterate, and compose touch experiences and show the subtlety and richness of touch that can be achieved through diverse crafting methods with Shape-Kit. Reflecting on the findings, our work contributes key insights into haptic toolkit design and touch design practices centered on the “crafting haptics” metaphor. We discuss in-depth how Shape-Kit’s simplicity, though remaining constrained, enables focused crafting for deeper exploration, while its collaborative nature fosters shared sense-making of touch experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {504},
numpages = {26},
keywords = {Haptic Design Toolkit, Crafting Haptics, On-body Expressive Haptics, Design Research, Passive Shape Display, Computer Vision, Soma Design, Collaborative Haptic Design, Sensorial Exploration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713736,
author = {Zheng, Caroline Yan and Chen, Yuting and Latupeirissa, Adrian and Andrikopoulos, Georgios and St\r{a}hl, Anna and Balaam, Madeline},
title = {Towards Caring Touch From Technologies: Knowledge From Healthcare Practitioners},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713736},
doi = {10.1145/3706598.3713736},
abstract = {We present a qualitative study with five healthcare experts specialised in different types of touch practice to gain insight in how caring touch can be enacted. Through our analysis we focus on how to transfer this learning into design considerations towards enacting caring touch from technologies. Despite the rapidly growing expectation for and design interest in touch from technologies intending to enhance care and well-being, the knowledge on how to design caring touch is still fragmented. How caring touch is enacted in inter-personal touch is under-explored and such expertise from healthcare practitioners has not been engaged from the perspective of HCI design research. We propose designers to consider caring as an experiential quality instead of a division between instrumental types of touch and caring types. We recommend when designing for a caring quality in technology-initiated touch that designers create a progression of touch with dynamic sensitivity and adapt the materiality of actuating devices to the plural dimensions of the body’s textures.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {505},
numpages = {16},
keywords = {caring touch, haptic design, care robotics, assistive robots, social robotics, experiential quality, healthcare practitioner, robot-initiated touch},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713498,
author = {Theopilus, Yansen and Davis, Hilary and Pedell, Sonja},
title = {Digital technology for supporting Aged Care Services: A Scoping Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713498},
doi = {10.1145/3706598.3713498},
abstract = {Digital technology has great potential to support human health, including the complex needs of older adults in aged care services and treatments. This scoping review aims to explore the current state and roles of digital technology in supporting aged care following the PRISMA-ScR guidelines. We included 47 studies from the last 10 years covering five databases discussing the development, implementation, evaluation, or review of digital technology in aged care services and the broader clinical system. Seven key roles of digital technology were identified, including health monitoring and assessment, remote healthcare services, assistive technology to support treatment, self-care management, social technology to facilitate interaction, clinical decision support, and aged care quality measurement carried out by twelve technology types. Our findings show the potential of digital technology in enhancing the capability and efficiency of aged care services for developing or improving socio-technical aged care systems. We conclude with six recommendations for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {506},
numpages = {12},
keywords = {aged care, caregiver, clinical, digital, elderly, healthcare, older adult, scoping review, service providers, services, socio-technical},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713852,
author = {Wang, Xingbo and Griffith, Janessa and Adler, Daniel A. and Castillo, Joey and Choudhury, Tanzeem and Wang, Fei},
title = {Exploring Personalized Health Support through Data-Driven, Theory-Guided LLMs: A Case Study in Sleep Health},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713852},
doi = {10.1145/3706598.3713852},
abstract = {Despite the prevalence of sleep-tracking devices, many individuals struggle to translate data into actionable improvements in sleep health. Current methods often provide data-driven suggestions but may not be feasible and adaptive to real-life constraints and individual contexts. We present HealthGuru, a novel large language model-powered chatbot to enhance sleep health through data-driven, theory-guided, and adaptive recommendations with conversational behavior change support. HealthGuru’s multi-agent framework integrates wearable device data, contextual information, and a contextual multi-armed bandit model to suggest tailored sleep-enhancing activities. The system facilitates natural conversations while incorporating data-driven insights and theoretical behavior change techniques. Our eight-week in-the-wild deployment study with 16 participants compared HealthGuru to a baseline chatbot. Results show improved metrics like sleep duration and activity scores, higher quality responses, and increased user motivation for behavior change with HealthGuru. We also identify challenges and design considerations for personalization and user engagement in health chatbots.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {507},
numpages = {15},
keywords = {Personalized Health, Sleep Health, Behavior Change, Large Language Models, Activity Recommendations},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713669,
author = {Xu, Tian and Cook, Sid and Semaan, Bryan and Voida, Stephen},
title = {Expression-in-action and Expression-on-action: A Systematic Review of Mediums for Expression in Mental Health},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713669},
doi = {10.1145/3706598.3713669},
abstract = {Expression facilitates the externalization of personal experiences and inner states (e.g., thoughts and emotions) embedded in everyday life. Yet, in mental health contexts, expression is often marginalized or systematically and structurally excluded from technology and system design. While HCI scholarship has explored expression in specific settings to advance user experience, a comprehensive understanding of expression remains limited. This limitation constrains the design space for future technologies that support and embrace expression, resulting in a potential lack of authentic experiential data reflecting individuals’ lived experiences embedded in everyday management of mental health. Through a systematic review of n = 105 studies, we explore the mediums, populations, and practices of expression in mental health contexts. Our study contributes a nuanced sociotechnical understanding of expression for the HCI community, developing two concepts for enriching expression and offering insights for designing experience-rich technologies that better support expression for everyday mental health management.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {508},
numpages = {20},
keywords = {expression; mental health; design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713859,
author = {Staab, Phoebe A and Bhattacharya, Arpita and Slovak, Petr},
title = {Identifying Opportunities and Envisioning Ecological Momentary Interoceptive Awareness Interventions With Young Women},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713859},
doi = {10.1145/3706598.3713859},
abstract = {Developing an awareness of internal sensations, or interoceptive awareness (IA), can benefit those with various mental health concerns, including disordered eating. Although IA interventions exist, there is limited research on embedding this skill into daily life through ecological momentary interventions (EMIs). Multidisciplinary research has focused on how and when to deliver EMIs based on users’ contexts, but often oversimplifies or relies on proxies to represent their circumstances and environments. Here, we explore context through a user-centered lens, investigating how and when 21 young women are willing to practice IA. During a 2-week experience sampling study, they shared their activities and openness to IA throughout each day. Later, they sketched EMIs to scaffold their activities with IA and shared further qualitative insights across several one-on-one interviews. Our findings identify activities and internal and external qualities conducive to IA and offer broader implications for designing digital EMIs tailored to users’ contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {509},
numpages = {22},
keywords = {interoceptive awareness, ecological momentary intervention, interviews, experience sampling, health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713105,
author = {Simpson, Ellen and Semaan, Bryan},
title = {Infrastructures for Inspiration: The Routine of Creative Identity Through Inspiration on the Creative Internet},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713105},
doi = {10.1145/3706598.3713105},
abstract = {Online, visual artists have more places than ever to routinely share their creative work and connect with other artists. These interactions support the routine enactment of creative identity in artists and provide inspirational opportunities for artists. As creative work shifts online, interactions between artists and routines around how these artists get inspired to do creative work are mediated by and through the logics of the online platforms where they take place. In an interview study of 22 artists, this paper explores the interplay between the development of artists’ creative identities and the, at times, contradictory practices they have around getting inspired. We find platforms which support the disciplined practice of creative work while supporting spontaneous moments of inspiration, play an increasing role in passive approaches to searching for inspiration, and foster numerous small community spaces for artists to negotiate their creative identities. We discuss how platforms can better support and embed mechanisms for inspiration into their infrastructures into their design and platform policy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {510},
numpages = {16},
keywords = {inspiration, infrastructure, creative identity, art, artists, online communities},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713839,
author = {Mahmood, Amama and Cao, Shiye and Stiber, Maia and Antony, Victor Nikhil and Huang, Chien-Ming},
title = {Voice Assistants for Health Self-Management: Designing for and with Older Adults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713839},
doi = {10.1145/3706598.3713839},
abstract = {Supporting older adults in health self-management is crucial for promoting independent aging, particularly given the growing strain on healthcare systems. While voice assistants (VAs) hold the potential to support aging in place, they often lack tailored assistance and present usability challenges. We addressed these issues through a five-stage design process with older adults to develop a personal health assistant. Starting with in-home interviews (N = 17), we identified two primary challenges in older adult’s health self-management: health awareness and medical adherence. To address these challenges, we developed a high-fidelity LLM-powered VA prototype to debrief doctor’s after-visit summary and generate tailored medication reminders. We refined our prototype with feedback from co-design workshops (N = 10) and validated its usability through in-home studies (N = 5). Our work highlights key design features for personal health assistants and provides broader insights into desirable VA characteristics, including personalization, adapting to user context, and respect for user autonomy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {511},
numpages = {22},
keywords = {voice assistant, LLMs, voice interactions, ChatGPT, conversational assistants, health self-management, personal health assistant, aging adults, healthy aging, co-design, prototyping},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713699,
author = {Jha, Smriti and Chan, Gerry and Jewer, Seana and Agyapong, Vincent I.O. and Orji, Rita},
title = {“Bring them back to life”: LifeLink Application for Caregivers Dealing with Suicidality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713699},
doi = {10.1145/3706598.3713699},
abstract = {Suicide is a complex phenomenon wherein, in addition to the individual impacted, its effects seep into many lives including those of their caregivers. Caregivers seek help everywhere but face unique challenges including limited access to timely resources and personal mental health struggles. Mobile health apps offer a promising solution, but addressing caregivers’ specific needs remains a concern. We present LifeLink, a persuasive mobile app to support caregivers of individuals experiencing suicidal thoughts. The app was developed in three stages. First, we reviewed 80 existing suicide prevention apps. Second, we designed a low-fidelity prototype of LifeLink using the Persuasive System Design model and refined it through a study conducted with 45 caregivers. Finally, incorporating evidence-based strategies and caregiver feedback, we developed and evaluated LifeLink in another study with 50 caregivers. Results show that LifeLink is user-friendly, engaging, elicits positive user experience and effectively empowers caregivers. LifeLink usage was associated with improved mental wellbeing, increased mental health literacy, and a more supportive environment. Our findings highlight the importance of involving caregivers in the design process. We offer recommendations for designers and researchers developing impactful persuasive technology for suicide prevention and for those working in related areas.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {512},
numpages = {25},
keywords = {Behavior change, Empirical study, HCI for development, Health, Mobile health, Wellbeing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714134,
author = {Timinis, Constantinos and Opie, Jeremy and Watt, Simon and Rogers, Yvonne and Drobnjak, Ivana},
title = {Co-Creating Reassurance Journey Maps to Foster Engagement in Remote Patient Monitoring for Post-Operative Cancer Care},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714134},
doi = {10.1145/3706598.3714134},
abstract = {Remote patient monitoring can significantly enhance post-operative home recovery for cancer patients, yet its effectiveness is often hindered by low patient engagement. Reassurance has been identified as a key factor in improving engagement. Our study explored how cancer patients seek reassurance through a Patient Public Involvement workshop with former patients. This involved developing personas for participants to navigate reassurance scenarios and share their post-operative experiences. Based on this, we co-created a reassurance journey map to illustrate when reassurance is needed, the behaviours patients use to seek it, and how it can be effectively provided. Our findings highlight three key design principles: the limitations of digital technology in offering reassurance, the personalised nature of reassurance, and the need for holistic integration. These are intended to inform the design of reassurance-focused RPM systems that better support cancer patients during home recovery. Practical design recommendations are also provided for developers and clinicians.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {513},
numpages = {21},
keywords = {engagement, reassurance, remote patient monitoring, cancer, user-centred},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714399,
author = {Bogdanova, Karin and Cila, Nazli and Kudina, Olya and Bozzon, Alessandro},
title = {Digital Phenotyping as Felt Informatics: Designing AI-Based Mental Health Diagnostic Tools Through Aesthetics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714399},
doi = {10.1145/3706598.3714399},
abstract = {With psychiatry lagging behind other medical fields in terms of innovation in instruments and methods, AI provides it an opportunity to catch up. Advocates of digital phenotyping promise to provide an objective tool that detects symptoms by analysing data from personal devices. We argue that digital phenotyping requires a more reflexive and critical approach to its design and an alignment of the clinicians’ interests in generating relevant evidence with the needs of service users who seek tools to manage their condition. We propose a felt informatics approach, situating digital phenotyping design within the problem space of pragmatist aesthetics. Within this perspective, felt life becomes a central object and a site for digital phenotyping design. This paper reveals the ways diagnostic data mediates mental ill health experience, emphasises the cultivation of aesthetic sensibility as a fundamental element of digital phenotyping and includes design considerations for practitioners and researchers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {514},
numpages = {16},
keywords = {Digital mental health, Digital phenotyping, Pragmatist aesthetics, Felt informatics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714189,
author = {Yeo, ShunYi and Jiang, Zhuoqun and Tang, Anthony and Perrault, Simon Tangi},
title = {Enhancing Deliberativeness: Evaluating the Impact of Multimodal Reflection Nudges},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714189},
doi = {10.1145/3706598.3714189},
abstract = {Nudging participants with text-based reflective nudges enhances deliberation quality on online deliberation platforms. The effectiveness of multimodal reflective nudges, however, remains largely unexplored. Given the multi-sensory nature of human perception, incorporating diverse modalities into self-reflection mechanisms has the potential to better support various reflective styles. This paper explores how presenting reflective nudges of different types (direct: persona and indirect: storytelling) in different modalities (text, image, video and audio) affects deliberation quality. We conducted two user studies with 20 and 200 participants respectively. The first study identifies the preferred modality for each type of reflective nudges, revealing that text is most preferred for persona and video is most preferred for storytelling. The second study assesses the impact of these modalities on deliberation quality. Our findings reveal distinct effects associated with each modality, providing valuable insights for developing more inclusive and effective online deliberation platforms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {515},
numpages = {26},
keywords = {deliberation, deliberativeness, deliberative quality, internal reflection, online deliberation, public discussions, nudges, indirect reflector, direct reflector, reflection, self-reflection, multimedia, multi-modality, large language model, civic engagement},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713224,
author = {Debackere, Florian and Clavel, C\'{e}line and R\"{o}ren, Alexandra and Rannou, Fran\c{c}ois and Nguyen, Christelle and Tran, Viet-thi and Messai, Yosra and Martin, Jean-Claude},
title = {Evaluation of a Tailored Mobile Application for Self-Management of Low Back Pain: Towards a Metamodel for Designing Behavior Change Technologies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713224},
doi = {10.1145/3706598.3713224},
abstract = {The mobile health market is rapidly developing, but few apps follow evidence-based guidelines. Literature recommends personalized systems grounded in behavioral science, involving healthcare professionals in design to maximize effectiveness. To address this, we propose a metamodel to guide designers. This article discusses its application to low back pain self-management, focusing on four patient profiles: Unmotivated, Cautious, Depressed, and Confident. We evaluated the app over one month with 60 users. Of these, 32 users received a version of the application tailored to their profile, and 28 users received a version of the application without tailoring (no recommendations or motivational messages). We assessed user experience, engagement and psychological characteristics involved in the behavior change process. Results showed satisfactory user experience, impact of tailoring on user behavior and features to reduce fears and false beliefs and increase self-efficacy. Further efforts are needed to increase user engagement and observe an impact on long-term behavior.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {516},
numpages = {17},
keywords = {Behavior Change, Low back pain, Tailored systems, mhealth},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713545,
author = {Umbach, Rebecca and Henry, Nicola and Beard, Gemma},
title = {Prevalence and Impacts of Image-Based Sexual Abuse Victimization: A Multinational Study},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713545},
doi = {10.1145/3706598.3713545},
abstract = {Image-based sexual abuse (IBSA) refers to the nonconsensual creating, taking, or sharing of intimate images, including threats to share intimate images. Despite the significant harms of IBSA, there is limited data on its prevalence and how it affects different identity or demographic groups. This study examines prevalence of, impacts from, and responses to IBSA via a survey with over 16,000 adults in 10 countries. More than 1 in 5 (22.6\%) respondents reported an experience of IBSA. Victimization rates were higher among LGBTQ+ and younger respondents. Although victimized at similar rates, women reported greater harms and negative impacts from IBSA than men. Nearly a third (30.9\%) of victim-survivors did not report or disclose their experience to anyone. We provide large-scale, granular, baseline data on prevalence in a diverse set of countries to aid in the development of effective interventions that address the experiences and intersectional identities of victim-survivors.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {517},
numpages = {20},
keywords = {image-based sexual abuse, nonconsensual pornography, revenge porn, technology-facilitated gender based violence, victimization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713940,
author = {Zhu, Jichen and Sanches, Pedro and Tsaknaki, Vasiliki and van der Maden, Willem and Kaklopoulou, Irene},
title = {The Centers and Margins of Modeling Humans in Well-being Technologies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713940},
doi = {10.1145/3706598.3713940},
abstract = {This paper critically examines the machine learning (ML) modeling of humans in three case studies of well-being technologies. Through a critical technical approach, it examines how these apps were experienced in daily life (technology in use) to surface breakdowns and to identify the assumptions about the “human” body entrenched in the ML models (technology design). To address these issues, this paper applies agential realism to decenter foundational assumptions, such as body regularity and health/illness binaries, and speculates more inclusive design and ML modeling paths that acknowledge irregularity, human-system entanglements, and uncertain transitions. This work is among the first to explore the implications of decentering theories in computational modeling of human bodies and well-being, offering insights for more inclusive technologies and speculations toward posthuman-centered ML modeling.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {518},
numpages = {16},
keywords = {Decentering, Machine Learning Modeling, Well-being, Diffraction, Agential Realism},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714040,
author = {Pichon, Adrienne and Blumberg, Jessica R and Mamykina, Lena and Elhadad, Noemie},
title = {The Voice of Endo: Leveraging Speech for an Intelligent System That Can Forecast Illness Flare-ups},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714040},
doi = {10.1145/3706598.3714040},
abstract = {Managing complex chronic illness is challenging due to its unpredictability. This paper explores the potential of voice for automated flare-up forecasts. We conducted a six-week speculative design study with individuals with endometriosis, tasking participants to submit daily voice recordings and symptom logs. Through focus groups, we elicited their experiences with voice capture and perceptions of its usefulness in forecasting flare-ups. Participants were enthusiastic and intrigued at the potential of flare-up forecasts through the analysis of their voice. They highlighted imagined benefits from the experience of recording in supporting emotional aspects of illness and validating both day-to-day and overall illness experiences. Participants reported that their recordings revolved around their endometriosis, suggesting that the recordings’ content could further inform forecasting. We discuss potential opportunities and challenges in leveraging the voice as a data modality in human-centered AI tools that support individuals with complex chronic conditions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {519},
numpages = {15},
keywords = {chronic illness, forecasting, voice analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713989,
author = {Serafini, Raphael and Yardim, Asli and Naiakshina, Alena},
title = {Exploring the Impact of Intervention Methods on Developers’ Security Behavior in a Manipulated ChatGPT Study},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713989},
doi = {10.1145/3706598.3713989},
abstract = {Increased AI use in software development raises concerns about AI-generated code security. We investigated the impact of security prompts, insecure AI suggestion warnings, and the use of password storage guidelines (OWASP, NIST) on the security behavior of software developers when presented with insecure AI assistance. In an online lab setting, we conducted a study with 76 freelance developers who completed a password storage task divided into four conditions. Three conditions included a manipulated ChatGPT-like AI assistant, suggesting an insecure MD5 implementation. We found a high level of trust in AI-generated code, even when insecure suggestions were presented. While security prompts, AI warnings, and guidelines improved security awareness, 32\% of those notified about insecure AI recommendations still accepted weak implementation suggestions, mistakenly considering it secure and often expressing confidence in their choice. Based on our results, we discuss security implications and provide recommendations for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {520},
numpages = {26},
keywords = {developer security study, AI assistant, LLM, artificial intelligence, trust, verification, security behaviour, password storage, system prompt},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714423,
author = {Zhai, Yuxiang and Xue, Xiao and Guo, Zekai and Jin, Tongtong and Diao, Yuting and Jeung, Jihong},
title = {Hear Us, then Protect Us: Navigating Deepfake Scams and Safeguard Interventions with Older Adults through Participatory Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714423},
doi = {10.1145/3706598.3714423},
abstract = {Deepfake—manipulating individuals’ facial features and voices with AI—has introduced new challenges to online scams, with older adults being particularly vulnerable. However, existing safeguarding efforts often portray them as passive recipients, overlooking their perspectives on understanding deepfake-enabled scams and their expectations for protective interventions. To address this gap, we conducted a participatory design workshop with 10 older adults, where participants analyzed simulated deepfake scam videos and critiqued provocative safeguarding designs. Their insights revealed key factors contributing to their vulnerability and how they perceive protective measures. The findings underscored the importance of respecting older adults’ autonomy and their role in decision-making, as well as the crucial role of enhanced digital literacy in self-protection. Moreover, while tailored safeguarding measures are essential, a broader societal approach focusing on shared responsibility is also needed. These design implications, viewed through the lens of older adults, contribute to more tailored safeguarding against Deepfake scams.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {521},
numpages = {19},
keywords = {Deepfake, Older Adults, Participatory Design, Cybersecurity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713567,
author = {Sun, Yuhao and Tenesa, Albert and Vines, John},
title = {Human-Precision Medicine Interaction: Public Perceptions of Polygenic Risk Score for Genetic Health Prediction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713567},
doi = {10.1145/3706598.3713567},
abstract = {Precision Medicine (PM) transforms the traditional “one-drug-fits-all” paradigm by customising treatments based on individual characteristics, and is an emerging topic for HCI research on digital health. A key element of PM, the Polygenic Risk Score (PRS), uses genetic data to predict an individual’s disease risk. Despite its potential, PRS faces barriers to adoption, such as data inclusivity, psychological impact, and public trust. We conducted a mixed-methods study to explore how people perceive PRS, formed of surveys (n=254) and interviews (n=11) with UK-based participants. The interviews were supplemented by interactive storyboards with the ContraVision technique to provoke deeper reflection and discussion. We identified ten key barriers and five themes to PRS adoption and proposed design implications for a responsible PRS framework. To address the complexities of PRS and enhance broader PM practices, we introduce the term Human-Precision Medicine Interaction (HPMI), which integrates, adapts, and extends HCI approaches to better meet these challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {522},
numpages = {26},
keywords = {Polygenic Risk Score, Human-Precision Medicine Interaction, Public Perception, Precision Medicine, Genetics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713282,
author = {Jelson, Andrew and Tausif, Md Tahsin and Lim, Sol Ie and Khanna, Soumya and Lee, Sang Won},
title = {Investigating the Effects of Simulated Eye Contact in Video Call Interviews},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713282},
doi = {10.1145/3706598.3713282},
abstract = {Some people suggest that deliberately watching the camera during video calls can simulate eye contact and help build trust. In this study, we investigated the effects of simulated eye contact in video calls and job interviews through an experimental study and a survey. Study 1 involved participants in a mock interview as an interviewer, where a confederate interviewee simulated eye contact half the time. The gaze patterns of the participants were tracked to understand the effects. In Study 2, we conducted an online survey to confirm the findings of Study 1 on a larger scale by asking those with experience interviewing to evaluate interviewees based on interview videos, half of which simulated eye contact. The results of both studies indicate that simulated eye contact had little impact on their evaluation compared to common belief. We discuss how the results motivate future work and how computational approaches to correcting eye gaze can be deceptive.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {523},
numpages = {12},
keywords = {video call, job interviews, eye contact, video-mediated communication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713524,
author = {Meyer, Anna P. and Kim, Yea-Seul and D'Antoni, Loris and Albarghouthi, Aws},
title = {Perceptions of the Fairness Impacts of Multiplicity in Machine Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713524},
doi = {10.1145/3706598.3713524},
abstract = {Machine learning (ML) is increasingly used in high-stakes settings, yet multiplicity – the existence of multiple good models – means that some predictions are essentially arbitrary. ML researchers and philosophers posit that multiplicity poses a fairness risk, but no studies have investigated whether stakeholders agree. In this work, we conduct a survey to see how multiplicity impacts lay stakeholders’ – i.e., decision subjects’ – perceptions of ML fairness, and which approaches to address multiplicity they prefer. We investigate how these perceptions are modulated by task characteristics (e.g., stakes and uncertainty). Survey respondents think that multiplicity threatens the fairness of model outcomes, but not the appropriateness of using the model, even though existing work suggests the opposite. Participants are strongly against resolving multiplicity by using a single model (effectively ignoring multiplicity) or by randomizing the outcomes. Our results indicate that model developers should be intentional about dealing with multiplicity in order to maintain fairness.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {524},
numpages = {15},
keywords = {Fairness, Fairness Perceptions, Fairness in Machine Learning, Multiplicity, Stakeholder Survey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713501,
author = {Andalibi, Nazanin and Ingber, Alexis Shore},
title = {Public Perceptions About Emotion AI Use Across Contexts in the United States},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713501},
doi = {10.1145/3706598.3713501},
abstract = {Emotion artificial intelligence (AI) is deployed in many high-impact areas. However, we know little about people’s general attitudes towards and comfort with it across application domains. We conducted a survey with a U.S. representative sample, oversampling for marginalized groups who are more likely to experience emotion AI harms (i.e., people of color, disabled people, minoritized genders) (n=599). We find: 1) although comfort was distinct across 11 contexts, even the most favorable context (healthcare) yielded low comfort levels; 2) participants were significantly more comfortable with inferences of happiness and surprise compared to other emotions; 3) individuals with disabilities and minoritized genders were significantly less comfortable than others across a variety of contexts; and 4) perceived accuracy explained a large proportion of the variance in comfort levels across contexts. We argue that attending to identity is key in examining emotion AI’s societal and ethical impacts, and discuss implications for emotion AI deployment and regulation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {525},
numpages = {16},
keywords = {emotion recognition, emotion sensing, emotion inference, affect recognition, affective computing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713426,
author = {Liao, Jingxian and Cherng, Fu-Yin and Singh, Mrinalini and Wang, Hao-Chuan},
title = {Signals Beyond Text: Understanding How Accessing Peer Concept Mapping and Commenting Augments Reflective Mind for High-Stake Videos},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713426},
doi = {10.1145/3706598.3713426},
abstract = {In high-stakes domains, deep analytical processing of online videos is essential for decision-making and knowledge acquisition. However, individuals may lack sufficient cognitive resources and triggers to engage in such processes. To address this, we introduce DeepThinkingMap, a collaborative video mapping system with affordances designed to leverage peers’ thoughts and comments to promote reflective and critical thinking. Thee design supports collaborative mapping of video concepts and supports open deliberations of personal thoughts over concepts as "thinking nudges" to foster deeper thinking for themselves and others. Through two experimental studies, we investigated the potential of deeper thinking by accessing peers’ thoughts in standalone and collaborative information work respectively. Results illustrated that accessing peers’ comments enhances personal engagement in reflective and critical thinking, and reinforces their confidence in their correct beliefs toward the video topics. This work contributes to understanding the socio-technical-cognitive mechanism of thinking while accessing peer comments, and presents design implications for information and knowledge work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {526},
numpages = {21},
keywords = {Thinking Nudge, Reflection, Critical Thinking, Higher-order Thinking, Concept Mapping},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713906,
author = {Tao, Hongyi and Vyas, Dhaval},
title = {"Housing Diversity Means Diverse Housing": Blending Generative AI into Speculative Design in Rural Co-Housing Communities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713906},
doi = {10.1145/3706598.3713906},
abstract = {In response to various environmental and societal challenges, co-housing has emerged to support social cohesion, grassroots innovation and ecological regeneration. Co-housing communities typically have smaller personal spaces, closer neighbourly relationships, and engage in more mutually supportive sustainable practices. To understand such communities’ motivations and visions, we developed a speculative design tool that harnesses Generative Artificial Intelligence (GenAI) to facilitate the envisioning of alternative future scenarios that challenge prevailing values, beliefs, lifestyles, and ways of knowing in contemporary society. Within the context of co-housing communities, we conducted a participatory design study with participants in co-creating their future communities. This paper unpacks implications and also reflects on the co-design approach employing GenAI. Our main findings highlight that GenAI, as a catalyst for imagination, empowers individuals to create visualisations that pose questions through a plural and situated speculative discourse.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {527},
numpages = {17},
keywords = {Generative AI, speculative design, co-housing, sustainability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713319,
author = {Rosbach, Emely and Ammeling, Jonas and Kr\"{u}gel, Sebastian and Kie\ss{}ig, Angelika and Fritz, Alexis and Ganz, Jonathan and Puget, Chlo\'{e} and Donovan, Taryn and Klang, Andrea and K\"{o}ller, Maximilian C. and Bolfa, Pompei and Tecilla, Marco and Denk, Daniela and Kiupel, Matti and Paraschou, Georgios and Kok, Mun Keong and Haake, Alexander F. H. and de Krijger, Ronald R. and Sonnen, Andreas F.-P. and Kasantikul, Tanit and Dorrestein, Gerry M. and Smedley, Rebecca C. and Stathonikos, Nikolas and Uhl, Matthias and Bertram, Christof A. and Riener, Andreas and Aubreville, Marc},
title = {"When Two Wrongs Don't Make a Right" - Examining Confirmation Bias and the Role of Time Pressure During Human-AI Collaboration in Computational Pathology},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713319},
doi = {10.1145/3706598.3713319},
abstract = {Artificial intelligence (AI)-based decision support systems hold promise for enhancing diagnostic accuracy and efficiency in computational pathology. However, human-AI collaboration can introduce and amplify cognitive biases, like confirmation bias caused by false confirmation when erroneous human opinions are reinforced by inaccurate AI output. This bias may increase under time pressure, a ubiquitous factor in routine pathology, as it strains practitioners’ cognitive resources. We quantified confirmation bias triggered by AI-induced false confirmation and examined the role of time constraints in a web-based experiment, where trained pathology experts (n=28) estimated tumor cell percentages. Our results suggest that AI integration fuels confirmation bias, evidenced by a statistically significant positive linear-mixed-effects model coefficient linking AI recommendations mirroring flawed human judgment and alignment with system advice. Conversely, time pressure appeared to weaken this relationship. These findings highlight potential risks of AI in healthcare and aim to support the safe integration of clinical decision support systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {528},
numpages = {18},
keywords = {Cognitive Bias, Confirmation Bias, Time Pressure, Artificial Intelligence, Decision Support Systems, Clinical Decision Support Systems, Computational Pathology, Healthcare},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713248,
author = {Aoyagui, Paula Akemi and Stemmler, Kelsey and Ferguson, Sharon A and Kim, Young-Ho and Kuzminykh, Anastasia},
title = {A Matter of Perspective(s): Contrasting Human and LLM Argumentation in Subjective Decision-Making on Subtle Sexism},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713248},
doi = {10.1145/3706598.3713248},
abstract = {In subjective decision-making, where decisions are based on contextual interpretation, Large Language Models (LLMs) can be integrated to present users with additional rationales to consider. The diversity of these rationales is mediated by the ability to consider the perspectives of different social actors; however, it remains unclear whether and how models differ in the distribution of perspectives they provide. We compare the perspectives taken by humans and different LLMs when assessing subtle sexism scenarios. We show that these perspectives can be classified within a finite set (perpetrator, victim, decision-maker), consistently present in argumentations produced by humans and LLMs, but in different distributions and combinations, demonstrating differences and similarities with human responses, and between models. We argue for the need to systematically evaluate LLMs’ perspective-taking to identify the most suitable models for a given decision-making task. We discuss the implications for model evaluation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {529},
numpages = {16},
keywords = {Human-Computer Interaction, Large Language Models, LLM, Bias, Sexism},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713946,
author = {Schecter, Aaron and Richardson, Benjamin},
title = {How the Role of Generative AI Shapes Perceptions of Value in Human-AI Collaborative Work},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713946},
doi = {10.1145/3706598.3713946},
abstract = {As artificial intelligence (AI) continues to transform the modern workplace, generative AI (GenAI) has emerged as a prominent tool capable of augmenting work processes. Defined by its ability to create or modify content, GenAI differs significantly from traditional machine learning models that classify, recognize, or predict patterns from existing data. This study explores the role of GenAI in shaping perceptions of AI's contribution and how these perceptions influence both creators’ internal assessments of their work and their anticipation of external evaluators’ assessments. Our research develops and empirically tests a structural model through a between-subjects experiment, revealing that the role GenAI plays in the work process significantly impacts perceived enhancements in work quality and effort relative to human input. Additionally, we identify a critical trade-off between fostering worker assessments of creativity and managing perceived external assessments of the work's value.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {530},
numpages = {15},
keywords = {Human-AI collaboration, creative work, generative AI, lab experiments},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713861,
author = {Gmeiner, Frederic and Marquardt, Nicolai and Bentley, Michael and Romat, Hugo and Pahud, Michel and Brown, David and Roseway, Asta and Martelaro, Nikolas and Holstein, Kenneth and Hinckley, Ken and Riche, Nathalie},
title = {Intent Tagging: Exploring Micro-Prompting Interactions for Supporting Granular Human-GenAI Co-Creation Workflows},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713861},
doi = {10.1145/3706598.3713861},
abstract = {Despite Generative AI (GenAI) systems’ potential for enhancing content creation, users often struggle to effectively integrate GenAI into their creative workflows. Core challenges include misalignment of AI-generated content with user intentions (intent elicitation and alignment), user uncertainty around how to best communicate their intents to the AI system (prompt formulation), and insufficient flexibility of AI systems to support diverse creative workflows (workflow flexibility). Motivated by these challenges, we created IntentTagger: a system for slide creation based on the notion of Intent Tags—small, atomic conceptual units that encapsulate user intent—for exploring granular and non-linear micro-prompting interactions for Human-GenAI co-creation workflows. Our user study with 12 participants provides insights into the value of flexibly expressing intent across varying levels of ambiguity, meta-intent elicitation, and the benefits and challenges of intent tag-driven workflows. We conclude by discussing the broader implications of our findings and design considerations for GenAI-supported content creation workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {531},
numpages = {31},
keywords = {intent tagging, human-AI interaction, human-AI co-creation, generative AI, rich content creation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714119,
author = {Siddiqui, Momin N and Pea, Roy D and Subramonyam, Hari},
title = {Script&amp;Shift: A Layered Interface Paradigm for Integrating Content Development and Rhetorical Strategy with LLM Writing Assistants},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714119},
doi = {10.1145/3706598.3714119},
abstract = {Good writing is a dynamic process of knowledge transformation, where writers refine and evolve ideas through planning, translating, and reviewing. Generative AI-powered writing tools can enhance this process but may also disrupt the natural flow of writing, such as when using LLMs for complex tasks like restructuring content across different sections or creating smooth transitions. We introduce Script&amp;Shift, a layered interface paradigm designed to minimize these disruptions by aligning writing intents with LLM capabilities to support diverse content development and rhetorical strategies. By bridging envisioning, semantic, and articulatory distances, Script&amp;Shift’s interactions allow writers to leverage LLMs for various content development tasks (scripting) and experiment with diverse organization strategies while tailoring their writing for different audiences (shifting). This approach preserves creative control while encouraging divergent and iterative writing. Our evaluation shows that Script&amp;Shift enables writers to creatively and efficiently incorporate LLMs while preserving a natural flow of composition.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {532},
numpages = {19},
keywords = {Human-AI collaborative writing, large language models, writing assistants, creativity support},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713708,
author = {Gebreegziabher, Simret Araya and Yang, Yukun and Glassman, Elena L. and Li, Toby Jia-Jun},
title = {Supporting Co-Adaptive Machine Teaching through Human Concept Learning and Cognitive Theories},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713708},
doi = {10.1145/3706598.3713708},
abstract = {An important challenge in interactive machine learning, particularly in subjective or ambiguous domains, is fostering bi-directional alignment between humans and models. Users teach models their concept definition through data labeling, while refining their own understandings throughout the process. To facilitate this, we introduce Mocha, an interactive machine learning tool informed by two theories of human concept learning and cognition. First, it utilizes a neuro-symbolic pipeline to support Variation Theory-based counterfactual data generation. By asking users to annotate counterexamples that are syntactically and semantically similar to already-annotated data but predicted to have different labels, the system can learn more effectively while helping users understand the model and reflect on their own label definitions. Second, Mocha uses Structural Alignment Theory to present groups of counterexamples, helping users comprehend alignable differences between data items and annotate them in batch. We validated Mocha’s effectiveness and usability through a lab study with 18 participants.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {533},
numpages = {18},
keywords = {human-AI collaboration, machine teaching, variation theory, structural alignment theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713085,
author = {Leusmann, Jan and Villa, Steeven and Liang, Thomas and Wang, Chao and Schmidt, Albrecht and Mayer, Sven},
title = {An Approach to Elicit Human-Understandable Robot Expressions to Support Human-Robot Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713085},
doi = {10.1145/3706598.3713085},
abstract = {Understanding the intentions of robots is essential for natural and seamless human-robot collaboration. Ensuring that robots have means for non-verbal communication is a basis for intuitive and implicit interaction. For this, we describe an approach to elicit and design human-understandable robot expressions. We outline the approach in the context of non-humanoid robots. We paired human mimicking and enactment with research from gesture elicitation in two phases: first, to elicit expressions, and second, to ensure they are understandable. We present an example application through two studies (N=16 \&amp; N=260) of our approach to elicit expressions for a simple 6-DoF robotic arm. We show that the approach enabled us to design robot expressions that signal curiosity and interest in getting attention. Our main contribution is an approach to generate and validate understandable expressions for robots, enabling more natural human-robot interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {534},
numpages = {17},
keywords = {Human-Robot Interaction, Gesture Elicitation, Understandable Robot Expressions, Approach},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713168,
author = {Gupta, Meghna and Desjardins, Audrey},
title = {Echoes of Care: Unveiling the Intertwined Tensions between Childcare Work and Voice Assistants},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713168},
doi = {10.1145/3706598.3713168},
abstract = {Childcare workers, particularly in-home childcare workers and nannies, navigate the unique complexities of a job that is both paid and intimate. As domestic technologies like smart home cameras and voice assistants (VAs) become increasingly prevalent, nannies may interact with and need to navigate these technologies in their care routines. Although prior research has examined the use of VAs in family settings, little attention has been paid to nannies’ interactions with these emerging technologies. In this work, we present three scenarios – speculative yet grounded – to illustrate underlying tensions and issues that may unfold in nannies’ interactions with voice assistant technologies. We found that while VAs could deepen existing tensions around autonomy, responsibilities, and surveillance, they also held potential as tools for reflection and self-advocacy, enabling workers to renegotiate their responsibilities and identities. We conclude by discussing intertwined tensions between in-home childcare work and VAs, offering insights for designing more equitable domestic technologies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {535},
numpages = {7},
keywords = {childcare work, voice assistant, labor, domestic technology, design research, scenarios},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713758,
author = {Morris, Meredith Ringel and Brubaker, Jed R.},
title = {Generative Ghosts: Anticipating Benefits and Risks of AI Afterlives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713758},
doi = {10.1145/3706598.3713758},
abstract = {As AI systems quickly improve in both breadth and depth of performance, they lend themselves to creating increasingly powerful and realistic agents, including the possibility of agents modeled on specific people. We anticipate that within our lifetimes it may become common practice for people to create custom AI agents to interact with loved ones and/or the broader world after death; indeed, the past year has seen a boom in startups purporting to offer such services. We call these generative ghosts since such agents will be capable of generating novel content rather than merely parroting content produced by their creator while living. In this paper, we reflect on the history of technologies for AI afterlives, including current early attempts by individual enthusiasts and startup companies to create generative ghosts. We then introduce a novel design space detailing potential implementations of generative ghosts. We use this analytic framework to ground a discussion of the practical and ethical implications of various approaches to designing generative ghosts, including potential positive and negative impacts on individuals and society. Based on these considerations, we lay out a research agenda for the AI and HCI research communities to better understand the risk/benefit landscape of this novel technology to ultimately empower people who wish to create and interact with AI afterlives to do so in a beneficial manner.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {536},
numpages = {14},
keywords = {AI, AI agents, Generative AI, AI Afterlives, HCI, digital afterlife, digital legacy, post-mortem AI, post-mortem data management, end-of-life planning, death, griefbots},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713926,
author = {Cao, Chen and Wu, Yu and Fang, Xiao Zoe and Liang, Zhenwen and Mamykina, Lena and Sbaffi, Laura and Xu, Xuhai},
title = {MedAI-SciTS: Enhancing Interdisciplinary Collaboration between AI Researchers and Medical Experts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713926},
doi = {10.1145/3706598.3713926},
abstract = {Integrating AI in healthcare requires effective interdisciplinary collaboration, yet challenges like methodological differences, terminology barriers, and divergent objectives persist. To address the issues, we introduce MedAI-SciTS, a structured approach combining a theoretical framework and a toolkit to improve collaboration across disciplines. The framework builds on a formative study (N=12) and literature review, identifying the key challenges and potential solutions in medical-AI projects. We further develop an innovative toolkit with twelve tools, featuring an AI-enhanced research glossary with personalized analogies, an agile co-design platform, and an integrated resource management system. A three-month case study involving AI and medical professionals (N=16 total) applying a segmentation algorithm for adrenal CT images confirmed the toolkit’s effectiveness in enhancing team engagement, communication, trust, and collaboration outcomes. We envision MedAI-SciTS could potentially be applied to a wide range of medical applications and facilitate broader medical-AI collaboration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {537},
numpages = {24},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713697,
author = {Pataranutaporn, Pat and Archiwaranguprok, Chayapatr and Chan, Samantha W. T. and Loftus, Elizabeth and Maes, Pattie},
title = {Synthetic Human Memories: AI-Edited Images and Videos Can Implant False Memories and Distort Recollection},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713697},
doi = {10.1145/3706598.3713697},
abstract = {AI is increasingly used to enhance images and videos, both intentionally and unintentionally. As AI editing tools become more integrated into smartphones, users can modify or animate photos into realistic videos. This study examines the impact of AI-altered visuals on false memories—recollections of events that didn’t occur or deviate from reality. In a pre-registered study, 200 participants were divided into four conditions of 50 each. Participants viewed original images, completed a filler task, then saw stimuli corresponding to their assigned condition: unedited images, AI-edited images, AI-generated videos, or AI-generated videos of AI-edited images. AI-edited visuals significantly increased false recollections, with AI-generated videos of AI-edited images having the strongest effect (2.05x compared to control). Confidence in false memories was also highest for this condition (1.19x compared to control). We discuss potential applications in HCI, such as therapeutic memory reframing, and challenges in ethical, legal, political, and societal domains.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {538},
numpages = {20},
keywords = {Memory, AI-generated Media, Misinformation, Generative AI, Human-AI Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713751,
author = {Mohanty, Vikram and Lim, Jude and Luther, Kurt},
title = {What Lies Beneath? Exploring the Impact of Underlying AI Model Updates in AI-Infused Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713751},
doi = {10.1145/3706598.3713751},
abstract = {AI models are constantly evolving, with new versions released frequently. Human-AI interaction guidelines encourage notifying users about changes in model capabilities, ideally supported by thorough benchmarking. However, as AI systems integrate into domain-specific workflows, exhaustive benchmarking can become impractical, often resulting in silent or minimally communicated updates. This raises critical questions: Can users notice these updates? What cues do they rely on to distinguish between models? How do such changes affect their behavior and task performance? We address these questions through two studies in the context of facial recognition for historical photo identification: an online experiment examining users’ ability to detect model updates, followed by a diary study exploring perceptions in a real-world deployment. Our findings highlight challenges in noticing AI model updates, their impact on downstream user behavior and performance, and how they lead users to develop divergent folk theories. Drawing on these insights, we discuss strategies for effectively communicating model updates in AI-infused systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {539},
numpages = {21},
keywords = {AI Model Updates, Crowdsourcing, Facial Recognition, User Perception of AI Models, User Behavior, Historical Photo Identification, Folk Theories, Diary Study, Quantitative Methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713522,
author = {He, Jessica and Houde, Stephanie and Weisz, Justin D.},
title = {Which Contributions Deserve Credit? Perceptions of Attribution in Human-AI Co-Creation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713522},
doi = {10.1145/3706598.3713522},
abstract = {AI systems powered by large language models can act as capable assistants for writing and editing. In these tasks, the AI system acts as a co-creative partner, making novel contributions to an artifact-under-creation alongside its human partner(s). One question that arises in these scenarios is the extent to which AI should be credited for its contributions. We examined knowledge workers’ views of attribution through a survey study (N=155) and found that they assigned different levels of credit across different contribution types, amounts, and initiative. Compared to a human partner, we observed a consistent pattern in which AI was assigned less credit for equivalent contributions. Participants felt that disclosing AI involvement was important and used a variety of criteria to make attribution judgments, including the quality of contributions, personal values, and technology considerations. Our results motivate and inform new approaches for crediting AI contributions to co-created work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {540},
numpages = {18},
keywords = {Co-creation, Authorship, Attribution},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714292,
author = {Jain, Rahul and Goel, Amit and Niinuma, Koichiro and Gupta, Aakar},
title = {AdaptiveSliders: User-aligned Semantic Slider-based Editing of Text-to-Image Model Output},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714292},
doi = {10.1145/3706598.3714292},
abstract = {Precise editing of text-to-image model outputs remains challenging. Slider-based editing is a recent approach wherein the image’s semantic attributes are manipulated via sliders. However, it has significant user-centric issues. First, slider variations are often inconsistent across the sliding range. Second, the optimal slider range is unpredictable, with default values often being too large or small depending on the prompt and attribute. Third, manipulating one attribute can unintentionally alter others due to the complex entanglement of latent spaces. We introduce AdaptiveSliders, a tool that addresses these challenges by adapting to the specific attributes and prompts, generating consistent slider variations and optimal bounds while minimizing unintended changes. AdaptiveSliders also suggests initial attributes and generates initial images more aligned with prompt semantics. Through three validation studies and one end-to-end user study, we demonstrate that AdaptiveSliders significantly improves user control and experience, enabling semantic slider-based editing aligned with user needs and expectations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {541},
numpages = {27},
keywords = {Generative AI, Diffusion Model, Sliders, Latent Space Interaction, Large Language Models(LLMs), Multi-Modal Models, Visual Question Answering(VQA) model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713683,
author = {Sun, Zhida and Zhang, Zhenyao and Zhang, Yue and Lu, Min and Lischinski, Dani and Cohen-Or, Daniel and Huang, Hui},
title = {Creative Blends of Visual Concepts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713683},
doi = {10.1145/3706598.3713683},
abstract = {Visual blends combine elements from two distinct visual concepts into a single, integrated image, with the goal of conveying ideas through imaginative and often thought-provoking visuals. Communicating abstract concepts through visual blends poses a series of conceptual and technical challenges. To address these challenges, we introduce Creative Blends, an AI-assisted design system that leverages metaphors to visually symbolize abstract concepts by blending disparate objects. Our method harnesses commonsense knowledge bases and large language models to align designers’ conceptual intent with expressive concrete objects. Additionally, we employ generative text-to-image techniques to blend visual elements through their overlapping attributes. A user study (N=24) demonstrated that our approach reduces participants’ cognitive load, fosters creativity, and enhances the metaphorical richness of visual blend ideation. We explore the potential of our method to expand visual blends to include multiple object blending and discuss the insights gained from designing with generative AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {542},
numpages = {17},
keywords = {Visual Blends, Metaphor, Text-to-Image Generation, Creativity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713529,
author = {Page, Rowan and See, Jian Shin},
title = {Creative Reflections on Image-Making with Artificial Intelligence: Interactions with a Provocative 'Camera'},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713529},
doi = {10.1145/3706598.3713529},
abstract = {Cameras are increasingly augmented with computational processing, producing images that blur the line between documenting reality and creative expression. The rise of text-to-image models has redefined the concept of imagery, sparking ethical and philosophical debates. This paper presents the findings of a qualitative study that employed a provocative prototype ‘camera’ – the A(I)Cam – to engage creative practitioners directly in these discussions. Developed using a Research-through-Design (RtD) approach, the tangible prototype generates and instantly prints AI-created images. A(I)Cam facilitated reflection among creative practitioners (N=15) on their experiences with AI-driven tools and the broader implications for their future practices. We examine the shifts in perspective that emerged from engaging with this embodied form of generative AI (genAI), challenging traditional text-based interaction paradigms, and inviting new modes of creative exploration and reflection. In addition, we offer insights from the RtD project, highlighting the integration of genAI tools into the industrial design process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {543},
numpages = {16},
keywords = {Creative AI, Generative AI, Research through Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713418,
author = {Hou, Yihan and Zeng, Xingchen and Wang, Yusong and Yang, Manling and Chen, Xiaojiao and Zeng, Wei},
title = {GenColor: Generative Color-Concept Association in Visual Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713418},
doi = {10.1145/3706598.3713418},
abstract = {Existing approaches for color-concept association typically rely on query-based image referencing, and color extraction from image references. However, these approaches are effective only for common concepts, and are vulnerable to unstable image referencing and varying image conditions. Our formative study with designers underscores the need for primary-accent color compositions and context-dependent colors (e.g., ‘clear’ vs.‘polluted’ sky) in design. In response, we introduce a generative approach for mining semantically resonant colors leveraging images generated by text-to-image models. Our insight is that contemporary text-to-image models can resemble visual patterns from large-scale real-world data. The framework comprises three stages: concept instancing produces generative samples using diffusion models, text-guided image segmentation identifies concept-relevant regions within the image, and color association extracts primary accompanied by accent colors. Quantitative comparisons with expert designs validate our approach’s effectiveness, and we demonstrate the applicability through cases in various design scenarios and a gallery.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {544},
numpages = {19},
keywords = {Color-concept association, Visual design, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713722,
author = {Park, Soobin and Kim, Hankyung and Lim, Youn-kyung},
title = {Reimagining Personal Data: Unlocking the Potential of AI-Generated Images in Personal Data Meaning-Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713722},
doi = {10.1145/3706598.3713722},
abstract = {Image-generative AI provides new opportunities to transform personal data into alternative visual forms. In this paper, we illustrate the potential of AI-generated images in facilitating meaningful engagement with personal data. In a formative autobiographical design study, we explored the design and use of AI-generated images derived from personal data. Informed by this study, we designed a web-based application as a probe that represents personal data through generative images utilizing Open AI’s GPT-4 model and DALL-E 3. We then conducted a 21-day diary study and interviews using the probe with 16 participants to investigate users’ in-depth experiences with images generated by AI in everyday lives. Our findings reveal new qualities of experiences in users’ engagement with data, highlighting how participants constructed personal meaning from their data through imagination and speculation on AI-generated images. We conclude by discussing the potential and concerns of leveraging image-generative AI for personal data meaning-making.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {545},
numpages = {25},
keywords = {generative AI, image generation, human-AI interaction, personal data, reflection, introspection, self-tracking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713801,
author = {Lin, Haichuan and Ye, Yilin and Xia, Jiazhi and Zeng, Wei},
title = {SketchFlex: Facilitating Spatial-Semantic Coherence in Text-to-Image Generation with Region-Based Sketches},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713801},
doi = {10.1145/3706598.3713801},
abstract = {Text-to-image models can generate visually appealing images from text descriptions. Efforts have been devoted to improving model controls with prompt tuning and spatial conditioning. However, our formative study highlights the challenges for non-expert users in crafting appropriate prompts and specifying fine-grained spatial conditions (e.g., depth or canny references) to generate semantically cohesive images, especially when multiple objects are involved. In response, we introduce SketchFlex, an interactive system designed to improve the flexibility of spatially conditioned image generation using rough region sketches. The system automatically infers user prompts with rational descriptions within a semantic space enriched by crowd-sourced object attributes and relationships. Additionally, SketchFlex refines users’ rough sketches into canny-based shape anchors, ensuring the generation quality and alignment of user intentions. Experimental results demonstrate that SketchFlex achieves more cohesive image generations than end-to-end models, meanwhile significantly reducing cognitive load and better matching user intentions compared to region-based generation baseline.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {546},
numpages = {19},
keywords = {Generative artificial intelligence, Diffusion model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713227,
author = {Han, Shu-Jung and Fussell, Susan R.},
title = {Understanding User Perceptions and the Role of AI Image Generators in Image Creation Workflows},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713227},
doi = {10.1145/3706598.3713227},
abstract = {The emergence of AI Image Generators (AIGs) has transformed image creation, making it more accessible to generate customized images from simple text prompts. While HCI research has explored the applications of text-to-image generation, the role of AIGs in visual content creation workflow remains relatively underexplored. To address this, we conducted in-depth interviews with 26 end users who had experience across 14 different AIGs and investigated users’ adoption and perceptions of AIGs and AI’s role throughout the entire workflow. Key factors examined include user goals, initial vision, tool integration, and decision-making. Our results indicated that functional goals often drive cross-tool integration to achieve desired outcomes, while in use cases motivated by recreational goals, the usage of AIGs influences the social implications of image sharing. We concluded with four distinct use cases, each highlighting how AIGs are integrated at different stages of the creative process based on varying user goals and visions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {547},
numpages = {17},
keywords = {Text-to-Image, Image Creation, Creation Workflow, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714179,
author = {Xia, Ziyi and Huang, Xincheng and Fels, Sidney S and Xiao, Robert},
title = {HaloTouch: Using IR Multi-Path Interference to Support Touch Interactions with General Surfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714179},
doi = {10.1145/3706598.3714179},
abstract = {Sensing touch on arbitrary surfaces has long been a goal of ubiquitous computing, but often requires instrumenting the surface. Depth camera-based systems have emerged as a promising solution for minimizing instrumentation, but at the cost of high touch-down detection error rates, high touch latency, and high minimum hover distance, limiting them to basic tasks. We developed HaloTouch, a vision-based system which exploits a multipath interference effect from an off-the-shelf time-of-flight depth camera to enable fast, accurate touch interactions on general surfaces. HaloTouch achieves a 99.2\% touch-down detection accuracy across various materials, with a motion-to-photon latency of 150 ms. With a brief (20s) user-specific calibration, HaloTouch supports millimeter-accurate hover sensing as well as continuous pressure sensing. We conducted a user study with 12 participants, including a typing task demonstrating text input at 26.3 AWPM. HaloTouch shows promise for more robust, dynamic touch interactions without instrumenting surfaces or adding hardware to users.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {548},
numpages = {17},
keywords = {Input Techniques, Touch Sensing, Ubiquitous Computing, Pressure and Proximity Sensing, Ad-hoc Surface Interaction, On-world Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713964,
author = {Li, Junxian and Wang, Yanan and Cui, Zhitong and Brooks, Jas and Yan, Yifan and Lou, Zhengyu and Li, Yucheng},
title = {Mid-Air Gestures for Proactive Olfactory Interactions in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713964},
doi = {10.1145/3706598.3713964},
abstract = {Olfactory experiences are increasingly in demand due to their immersive benefits. However, most interaction implementations are passive and rely on conventions established for other modalities. In this work, we investigated proactive olfactory interactions, where users actively engage with scents, focusing on mid-air gestures as an input modality miming real-world object- and scent-manipulation, e.g., fanning away an odor. Our study had participants develop a user-defined gesture set for interacting with scents in Virtual Reality (VR), covering various object types (solid, liquid, gas) and interaction modes (out-of-reach, not graspable, graspable), participants compared interacting with scents in VR using traditional controllers versus proactive gestures, revealing that proactive gestures enhanced user experience, presence, and task performance. Finally, an exploratory study showed strong participants’ preferences for personalization, enhanced interaction capabilities, and multi-sensory integration. Based on these findings, we propose design guidelines and applications for proactive interactions with scents.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {549},
numpages = {18},
keywords = {Olfactory interactions, Proactive olfactory experiences, Mid-air gestures, User-defined gestures, Virtual reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713461,
author = {Hou, Baosheng James and Abramyan, Lucy and Gurumurthy, Prasanthi and Adams, Haley and Tosic Rodgers, Ivana and Gonzalez, Eric J and Patel, Khushman and Cola\c{c}o, Andrea and Pfeuffer, Ken and Gellersen, Hans and Ahuja, Karan and Gonzalez-Franco, Mar},
title = {Online-EYE: Multimodal Implicit Eye Tracking Calibration for XR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713461},
doi = {10.1145/3706598.3713461},
abstract = {Unlike other inputs for extended reality (XR) that work out of the box, eye tracking typically requires custom calibration per user or session. We present a multimodal inputs approach for implicit calibration of eye tracker in VR, leveraging UI interaction for continuous, background calibration. Our method analyzes gaze data alongside controller interaction with UI elements, and employing ML techniques it continuously refines the calibration matrix without interrupting users from their current tasks. Potentially eliminating the need for explicit calibration. We demonstrate the accuracy and effectiveness of this implicit approach across various tasks and real time applications achieving comparable eye tracking accuracy to native, explicit calibration. While our evaluation focuses on VR and controller-based interactions, we anticipate the broader applicability of this approach to various XR devices and input modalities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {550},
numpages = {16},
keywords = {Gaze estimation, implicit calibration, eye tracking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714130,
author = {He, Zhe and Wang, Xiangyang and Shi, Yuanchun and Hsia, Chi and Liang, Chen and Yu, Chun},
title = {Palmpad: Enabling Real-Time Index-to-Palm Touch Interaction with a Single RGB Camera},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714130},
doi = {10.1145/3706598.3714130},
abstract = {Index-to-palm interaction plays a crucial role in Mixed Reality(MR) interactions. However, achieving a satisfactory inter-hand interaction experience is challenging with existing vision-based hand tracking technologies, especially in scenarios where only a single camera is available. Therefore, we introduce Palmpad, a novel sensing method utilizing a single RGB camera to detect the touch of an index finger on the opposite palm. Our exploration reveals that the incorporation of optical flow techniques to extract motion information between consecutive frames for the index finger and palm leads to a significant improvement in touch status determination. By doing so, our CNN model achieves 97.0\% recognition accuracy and a 96.1\% F1 score. In usability evaluation, we compare Palmpad with Quest’s inherent hand gesture algorithms. Palmpad not only delivers superior accuracy 95.3\% but also reduces operational demands and significantly improves users’ willingness and confidence. Palmpad aims to enhance accurate touch detection for lightweight MR devices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {551},
numpages = {16},
keywords = {finger touch, index-to-palm interaction, computer vision},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713388,
author = {Kim, Daehwa and Xiao, Robert and Harrison, Chris},
title = {PatternTrack: Multi-Device Tracking Using Infrared, Structured-Light Projections from Built-in LiDAR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713388},
doi = {10.1145/3706598.3713388},
abstract = {As augmented reality devices (e.g., smartphones and headsets) proliferate in the market, multi-user AR scenarios are set to become more common. Co-located users will want to share coherent and synchronized AR experiences, but this is surprisingly cumbersome with current methods. In response, we developed PatternTrack, a novel tracking approach that repurposes the structured infrared light patterns emitted by VCSEL-driven depth sensors, like those found in the Apple Vision Pro, iPhone, iPad, and Meta Quest 3. Our approach is infrastructure-free, requires no pre-registration, works on featureless surfaces, and provides the real-time 3D position and orientation of other users’ devices. In our evaluation — tested on six different surfaces and with inter-device distances of up to 260 cm — we found a mean 3D positional tracking error of 11.02 cm and a mean angular error of 6.81°.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {552},
numpages = {14},
keywords = {Multi-device tracking, augmented reality, co-located collaboration.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713467,
author = {Xiao, Tianyi and Chen, Yizi and Zhong, Sailin and Kiefer, Peter and Krukar, Jakub and Kim, Kevin Gonyop and Hurni, Lorenz and Schwering, Angela and Raubal, Martin},
title = {Sketch2Terrain: AI-Driven Real-Time Terrain Sketch Mapping in Augmented Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713467},
doi = {10.1145/3706598.3713467},
abstract = {Sketch mapping is an effective technique to externalize and communicate spatial information. However, it has been limited to 2D mediums, making it difficult to represent 3D information, particularly for terrains with elevation changes. We present Sketch2Terrain, an intuitive generative-3D-sketch-mapping system combining freehand sketching with generative Artificial Intelligence that radically changes sketch map creation and representation using Augmented Reality. Sketch2Terrain empowers non-experts to create unambiguous sketch maps of natural environments and provides a homogeneous interface for researchers to collect data and conduct experiments. A between-subject study (N=36) revealed that generative-3D-sketch-mapping improved efficiency by 38.4\%, terrain-topology accuracy by 12.5\%, and landmark accuracy by up to 12.1\%, with only a 4.7\% trade-off in terrain-elevation accuracy compared to freehand 3D-sketch-mapping. Additionally, generative-3D-sketch-mapping reduced perceived strain by 60.5\% and stress by 39.5\% over 2D-sketch-mapping. These findings underscore potential applications of generative-3D-sketch-mapping for in-depth understanding and accurate representation of vertically complex environments. The implementation is publicly available.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {553},
numpages = {24},
keywords = {Generative 3D sketch mapping, augmented reality, generative AI, terrain generation, spatial cognition},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713874,
author = {Abe, Yuki and Kusakabe, Kan and Choi, Myungguen and Sakamoto, Daisuke and Ono, Tetsuo},
title = {Understanding Usability of VR Pointing Methods with a Handheld-style HMD for Onsite Exhibitions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713874},
doi = {10.1145/3706598.3713874},
abstract = {Handheld-style head-mounted displays (HMDs) are becoming increasingly popular as a convenient option for onsite exhibitions. However, they lack established practices for basic interactions, particularly pointing methods. Through our formative study involving practitioners, we discovered that controllers and hand gestures are the primary pointing methods being utilized. Building upon these findings, we conducted a usability study to explore seven different pointing methods, incorporating insights from the formative study and current virtual reality (VR) practices. The results showed that while controllers remain a viable option, hand gestures are not recommended. Notably, dwell time-based methods, which are not fast and are not commonly recognized by practitioners, demonstrate high usability and user confidence, particularly for inexperienced VR users. We recommend the use of dwell-based methods for onsite exhibition contexts. This research provides insights for the adoption of handheld-style HMDs, laying the groundwork for improving user interaction in exhibition environments, thereby potentially enhancing visitor experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {554},
numpages = {21},
keywords = {Handheld-style HMD Interface, Virtual Reality (VR), Usability, Pointing Methods, Onsite VR Exhibition, Inexperienced VR Users},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714005,
author = {Jones, Katherine and Grayson, Martin and Morrison, Cecily and Leonards, Ute and Metatla, Oussama},
title = {"Put Your Hands Up": How Joint Attention Is Initiated Between Blind Children And Their Sighted Peers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714005},
doi = {10.1145/3706598.3714005},
abstract = {Initiating joint attention (JA) is a fundamental first step in social interactions. In sighted individuals, it relies predominantly on visual cues, such as gaze and hand gestures. These features can reduce opportunities for blind and visually impaired (BVI) and sighted people to interact. Understanding the strategies to navigate these challenges is necessary to develop technology that can facilitate more inclusive JA. To address this, we conducted a longitudinal case study of five children with mixed visual abilities engaging in activities rich with JA opportunities. In a teacher-led classroom, the children experimented with the use of an AI-powered headset designed to support BVI people in social situations. Interaction analysis established that situational complexity affects the children’s responses to initiation attempts. Furthermore, the headset adds to this complexity, affecting the frequency and reactions to attempts to initiate JA. The findings informed the creation of a JA initiation framework and suggestions for future design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {555},
numpages = {18},
keywords = {Joint Attention, Joint Engagement, Social Interaction, Blind, Visually Impaired, Children, Inclusion, Mixed-Visual Ability, AI, Headset},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713792,
author = {Choi, Dasom and Park, SoHyun and Lee, Kyungah and Hong, Hwajung and Kim, Young-Ho},
title = {AACessTalk: Fostering Communication between Minimally Verbal Autistic Children and Parents with Contextual Guidance and Card Recommendation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713792},
doi = {10.1145/3706598.3713792},
abstract = {As minimally verbal autistic (MVA) children communicate with parents through few words and nonverbal cues, parents often struggle to encourage their children to express subtle emotions and needs and to grasp their nuanced signals. We present AACessTalk, a tablet-based, AI-mediated communication system that facilitates meaningful exchanges between an MVA child and a parent. AACess-Talk provides real-time guides to the parent to engage the child in conversation and, in turn, recommends contextual vocabulary cards to the child. Through a two-week deployment study with 11 MVA child-parent dyads, we examine how AACessTalk fosters everyday conversation practice and mutual engagement. Our findings show high engagement from all dyads, leading to increased frequency of conversation and turn-taking. AACessTalk also encouraged parents to explore their own interaction strategies and empowered the children to have more agency in communication. We discuss the implications of designing technologies for balanced communication dynamics in parent-MVA child interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {556},
numpages = {25},
keywords = {Parent-child interaction, autism, minimally verbal, AAC, large language model, LLM, artificial intelligence, conversational guidance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713851,
author = {Das, Maitraye and Tran, Megan and Ong, Amanda Chih-han and Kientz, Julie A. and Feldner, Heather},
title = {Cultivating Computational Thinking and Social Play among Neurodiverse Preschoolers in Inclusive Classrooms},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713851},
doi = {10.1145/3706598.3713851},
abstract = {Computational thinking (CT) is regarded as a fundamental twenty-first century skill and has been implemented in many early childhood education curriculum. Yet, the needs of neurodivergent children have remained largely overlooked in the extensive research and technologies built to foster CT among children. To address this, we investigated how to support neurodiverse (i.e., groups involving neurodivergent and neurotypical) preschoolers aged 3-5 in learning CT concepts. Grounded in interviews with six teachers, we deployed an age-appropriate, programmable robot called KIBO in two preschool classrooms involving 12 neurodivergent and 17 neurotypical children for eight weeks. Using interaction analysis, we illustrate how neurodivergent children found enjoyment in assembling KIBO and learned to code with it while engaging in cooperative and competitive play with neurotypical peers and the adults. Through this, we discuss accessible adaptations needed to enhance CT among neurodivergent preschoolers and ways to reimagine technology-mediated social play for them.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {557},
numpages = {22},
keywords = {Computational thinking; inclusive classroom; neurodiverse; preschool},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714131,
author = {Lewis, Aaleyah and Dangol, Aayushi and Suh, Hyewon and Olszewski, Abbie and Fogarty, James and Kientz, Julie A.},
title = {Exploring AI-Based Support in Speech-Language Pathology for Culturally and Linguistically Diverse Children},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714131},
doi = {10.1145/3706598.3714131},
abstract = {Speech-language pathologists (SLPs) provide support to children with speech and language difficulties through delivering evaluation, assessment, and interventions. Despite growing research on how Artificial Intelligence (AI) can support SLPs, there is limited research examining how AI can assist SLPs in delivering equitable care to culturally and linguistically diverse (CLD) children with disabilities. Through interviews with 15 SLPs and a two-part survey study with 13 SLPs, we report on SLP challenges in delivering responsive care to CLD children with disabilities (i.e.,&nbsp;unrepresentative materials, unreliable translation, insufficient support for language variations), areas for AI-based support, evaluations of how available AI performs in addressing these challenges, and bias assessments of AI-generated materials. We discuss implications of contextually unaware AI, the range of care in AI-prompting, tensions and tradeoffs of AI-based support, and honoring diverse representations in AI-generated materials. We offer considerations for SLPs using AI-based tools and general-purpose AI in their practice.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {558},
numpages = {19},
keywords = {Speech and language difficulties, Artificial Intelligence, Generative AI, AI harms, Human-centered AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713878,
author = {Moon, Junhyung and Lee, Sukhyun and Kim, Youngchan and Go, Juhee and Ku, Han Mo and Jung, Yeohyun and Hwang, Seonyeong and Lee, Bongshin and Lee, Yong Seung and Lee, Hyun-Kyung and Lee, Kyoungwoo and Choe, Eun Kyoung},
title = {FluidTrack: Investigating Child-Parent Collaborative Tracking for Pediatric Voiding Dysfunction Management},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713878},
doi = {10.1145/3706598.3713878},
abstract = {Daytime urinary frequency syndrome (DUFS) is a prevalent pediatric voiding dysfunction. Managing DUFS involves sufficient water intake and monitoring voiding and defecation behaviors, which can be challenging for preschool-aged patients to perform throughout the day for prolonged periods. To address this problem, we created FluidTrack, a semi-automated tracking system enabling child and parents to collaboratively track child’s fluid intake, voiding, and defecation, while encouraging adequate water consumption. To examine preschoolers’ engagement in behavior tracking with their parents, we conducted a 4-week deployment study with 14 DUFS patients (4–6 years) and their parents as part of DUFS management. The majority of patient participants enthusiastically engaged in semi-automated data capture, driven by their initial interest in FluidTrack. Sustaining the children’s enthusiasm and behind-the-scenes parental assistance were critical for continuing semi-automated tracking. Our findings demonstrated the feasibility of children’s semi-automated self-tracking in collaboration with their parents, and identified design suggestions for future work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {559},
numpages = {18},
keywords = {pediatric patients, self-tracking, child-parent collaboration, water intake improvement, wearable device, daytime urinary frequency syndrome (DUFS)},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714230,
author = {Zhang, Kexin and Spencer, Edward Glenn Scott and Manikandan, Abijith and Li, Andric and Li, Ang and Yao, Yaxing and Zhao, Yuhang},
title = {Inclusive Avatar Guidelines for People with Disabilities: Supporting Disability Representation in Social Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714230},
doi = {10.1145/3706598.3714230},
abstract = {Avatar is a critical medium for identity representation in social virtual reality (VR). However, options for disability expression are highly limited on current avatar interfaces. Improperly designed disability features may even perpetuate misconceptions about people with disabilities (PWD). As more PWD use social VR, there is an emerging need for comprehensive design standards that guide developers and designers to create inclusive avatars.  Our work aim to advance the avatar design practices by delivering a set of centralized, comprehensive, and validated design guidelines that are easy to adopt, disseminate, and update. Through a systematic literature review and interview with 60 participants with various disabilities,  we derived 20 initial design guidelines that cover diverse disability expression methods through five aspects, including avatar appearance, body dynamics, assistive technology design, peripherals around avatars, and customization control. We further evaluated the guidelines via a heuristic evaluation study with 10 VR practitioners, validating the guideline coverage, applicability, and actionability. Our evaluation resulted in a final set of 17 design guidelines with recommendation levels.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {560},
numpages = {26},
keywords = {Social virtual realities, avatars, design guidelines, disability representation, diversity and inclusion},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713637,
author = {Jiang, Lucy and Ko, Woojin and Yuan, Shirley and Shende, Tanisha and Azenkot, Shiri},
title = {Shifting the Focus: Exploring Video Accessibility Strategies and Challenges for People with ADHD},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713637},
doi = {10.1145/3706598.3713637},
abstract = {Despite the growth of video as a medium, videos remain inaccessible to many people. Prior video accessibility research has focused primarily on blind and low vision or d/Deaf and hard of hearing audiences. However, the video watching experiences of people with ADHD are largely unexplored. Through semi-structured interviews with 20 participants self-identifying with ADHD, we uncovered video watching frustrations, current strategies for access, and desired accessibility features. Participants faced both overstimulation and understimulation from visuals and audio (e.g., flashing lights, slower speech), which impacted their attention, engagement, and information retention. Common strategies included altering video speed, using captions, and leveraging timestamps for skipping through videos. Participants desired adjustable sound channels for aiding focus, video summaries for retaining information, and warnings for preempting sensory discomfort. We close by discussing (1) design recommendations for platforms and creators to support users in achieving their viewing goals and (2) ADHD-inclusive design principles.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {561},
numpages = {16},
keywords = {video accessibility, ADHD, neurodivergence, audiovisual, captions, audio descriptions, neurodiversity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713160,
author = {Barber, Polly and Soubutts, Ewan and Knowles, Bran and Singh, Aneesha},
title = {Beyond the 'Unofficial Proxy' - Navigating Technology Support for Older Adults' Banking Activities with Close Others},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713160},
doi = {10.1145/3706598.3713160},
abstract = {In the context of extensive bank branch closures, and a rapidly ageing population, older adults’ (OAs’) reluctance to adopt digital banking platforms by themselves is concerning. However, many OAs rely on the support of close others (COs) to complete banking activities with them. This support is mostly provided through “unofficial” mechanisms such as sharing online banking credentials, which risk an OA's privacy and security. This paper replicates a Canadian study with OAs in a UK context and extends it with co-design workshops focused on novel banking solutions for OAs and COs, helping to formalise the role of unofficial proxies within online platforms. Results show that unofficial proxy banking also occurs with COs in a UK context and co-design reveals barriers to OAs’ use of banking technology independently. We discuss recommendations for flexible, easily authenticated and easy to learn digital banking solutions for OAs in the future.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {562},
numpages = {16},
keywords = {Caregivers, Close others, Older adults, Online Banking, Power of Attorney, Privacy, Security},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713704,
author = {Khan, F. Ria and Brewster, Kat and DeGuia, Aloe and Starks, Denny L. and Manacop, Malaya and Mayworm, Samuel and Dillahunt, Tawanna R. and Haimson, Oliver L.},
title = {Cataloging Augmented, Ambivalent Transgender Futures: Designing Inclusive AR Technologies for Trans Communities Through Speculative, Participatory Zine-Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713704},
doi = {10.1145/3706598.3713704},
abstract = {Technologies designed to support marginalized communities have often led to unintended harm. This frequently occurs when misaddressing or failing to understand communities’ experiences, needs, and desires. User-centered research often focus on needs versus desires (leveraging deficit versus assets-based approaches), which have been contested in HCI. To promote technology design that better balances the tensions between needs and desires, we contribute participatory zine-making as an effective approach for speculatively designing trans augmented reality (AR) technologies. We facilitated in-person and virtual workshops with trans participants (n=44) focused on designing AR technologies, observing participants’ zine-making processes and artifacts to gather visual ethnographic data alongside transcripts and facilitator field notes. In participants’ zines we identified ambivalence as critical in addressing trans people’s needs and desires, and participants conveyed this ambivalence through metaphor and anti-assimilationist aesthetics. Our participatory zine-making approach enabled us to uncover perspectives and design implications crucial to designing trans technologies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {563},
numpages = {18},
keywords = {Transgender; Nonbinary; LGBTQ+; Participatory design; Zines; Augmented reality; Anti-assimilationist design; Ambivalence; Trans technology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714397,
author = {Zhu, Wenqi and Soubutts, Ewan and Wernersbach, Julia and Singh, Aneesha},
title = {Challenges and Opportunities for the Design of Inclusive Social Media Experiences with LGBT+ Older Adults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714397},
doi = {10.1145/3706598.3714397},
abstract = {Social isolation is a common experience for LGBT+ older adults (OAs) that is often compounded by prejudices of age, sexuality, or gender identity. Little research has explored the specific social needs and barriers that LGBT+ OAs face, particularly in online spaces. To address this gap, we conducted interviews with 10 LGBT+ OAs and an inclusive housing service provider. Our research highlights the importance of LGBT+ community engagement and digitally-supported social networks’ role for LGBT+ OAs. We identify challenges such as managing online identity, navigating LGBT+ social media apps and websites, as well as digital disconnectedness challenges among those with lower digital literacy. Recommendations include improving social platforms allowing LGBT+ OAs to manage selective identity characteristics, promoting genuineness and trust in LGBT+ platforms by employing tiered blocking and interest-driven connections, and non-digital outreach strategies for collaborations between LGBT+ organizations and senior centers to engage hidden and isolated LGBT+ OAs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {564},
numpages = {16},
keywords = {Older adults, LGBT+, social media, online, social facilitation, qualitative, shared},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713194,
author = {Fung, Ka Yan and Lee, Lik Hang and Yuan, Linping and Fung, Kwong Chiu and Sin, Kuen Fung and Lui, Tze Leung Rick and Qu, Huamin and Song, Shenghui},
title = {DysVis: A User-Centred Data Visualization System for Dyslexia Pre-screening},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713194},
doi = {10.1145/3706598.3713194},
abstract = {Dyslexia is a common neurobiological learning disorder significantly impacting reading, writing, and spelling worldwide. Early identification and intervention are essential, but most pre-screening tools focus on Latin languages, leaving Chinese-speaking students underserved. To address this gap, we conduct semi-structured interviews with special education (special-ed) teachers to gather their needs for dyslexia pre-screening tailored to Chinese contexts. Using their insights, we have developed DysVis, a user-centered data visualization system that combines handwriting analysis, body movement keypoint conversion, and a comprehensive visualization interface. DysVis provides teachers with multi-level visualizations, such as performance overviews, task analyses, handwriting observations, and behavioural insights, enabling them to identify the root causes of learning difficulties. Our evaluations, including case studies, a user study, and expert interviews, demonstrate that DysVis is user-friendly and effective in quickly identifying at-risk students, ultimately enhancing learning outcomes for Chinese-speaking students with dyslexia.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {565},
numpages = {18},
keywords = {Data Visualization System, User-centred Design, Data-driven Technology-enabled Analytics, Dyslexia Pre-screening},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713973,
author = {Yoo, Suhyeon and Truong, Khai N. and Kim, Young-Ho},
title = {ELMI: Interactive and Intelligent Sign Language Translation of Lyrics for Song Signing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713973},
doi = {10.1145/3706598.3713973},
abstract = {d/Deaf and hearing song-signers have become prevalent across video-sharing platforms, but translating songs into sign language remains cumbersome and inaccessible. Our formative study revealed the challenges song-signers face, including semantic, syntactic, expressive, and rhythmic considerations in translations. We present ELMI, an accessible song-signing tool that assists in translating lyrics into sign language. ELMI enables users to edit glosses line-by-line, with real-time synced lyric and music video snippets. Users can also chat with a large language model-driven AI to discuss meaning, glossing, emoting, and timing. Through an exploratory study with 13 song-signers, we examined how ELMI facilitates their workflows and how song-signers leverage and receive an LLM-driven chat for translation. Participants successfully adopted ELMI to song-signing, with active discussions throughout. They also reported improved confidence and independence in their translations, finding ELMI encouraging, constructive, and informative. We discuss research and design implications for accessible and culturally sensitive song-signing translation tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {566},
numpages = {21},
keywords = {Song Signing, Deaf Music, Lyrics Translation, Large Language Model, Human-AI Collaboration, Creativity Support},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713333,
author = {Fan, Danyang and Tomassetti, Olivia and Mouallem, Aya and Kim, Gene S-H and Patel, Shloke Nirav and Hwang, Saehui and Leader, Patricia and Sugrue, Danielle and Chen, Tristen and Ou, Darren Reese and Lee, Victor R and Balasubramanian, Lakshmi and Subramonyam, Hariharan and O'Modhrain, Sile and Follmer, Sean},
title = {Promoting Comprehension and Engagement in Introductory Data and Statistics for Blind and Low-Vision Students: A Co-Design Study},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713333},
doi = {10.1145/3706598.3713333},
abstract = {Statistical literacy involves understanding, interpreting, and critically evaluating statistical information in a contextually grounded way. Current instructional practices rely heavily on visual techniques, which renders them inaccessible to students who are blind or have low vision (BLV). To bridge this gap, we formed an extended co-design partnership with a statistics teacher, a teacher for students with visual impairments (TVI), and two BLV students to develop accessibility-first practices for building statistical literacy. Through several months of collaboration that included discussion, exploration, design, and evaluation, we identified specific approaches to promote comprehension and engagement. The enactive approaches we designed, using scaffolding and timely feedback, fostered insights through pattern recognition and analogical reasoning. Additionally, inquiry-based methods promoted contextually situated reasoning and reflection on how statistics can improve students’ lives and communities. We present these findings alongside participants’ experiences and discuss their implications for inclusive learning frameworks and tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {20},
keywords = {Data, Statistics, Accessibility, Math, Instructional Design, Co-Design, Embodied, Interactive Systems, Education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714302,
author = {Smith, Kersten and Sien, Sang-Wha and Dai, Jiamin and McGrenere, Joanna},
title = {Touching Experiences: How Older Adults Envision Ambient and Tangible Social Technology Through the Lens of Time},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714302},
doi = {10.1145/3706598.3714302},
abstract = {Older adults face unique challenges in adopting social technology, particularly through retirement. Whereas existing digital solutions are often disconnected from the motivations of older adults, ambient and tangible technologies (ATTs) are emerging as promising social tools that integrate into users’ routines and leverage familiar physical interactions. This study investigates how older adults envision ATTs to meaningfully support their social connections. Through two phases of co-design with 25 retiring older adults (55+) and 5 social partners (25+), we explore the intersection of social health, life transitions, and technology use. Our thematic analysis reveals how shifting perceptions of time influence engagement, relationship maintenance, and legacy-building. We present opportunities to align ATT design with older adults’ emotional goals, social practices, and community connections by posing design challenges, such as collective legacy building, for supporting the meaningful relationships of retiring adults as they age.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {568},
numpages = {24},
keywords = {Older Adults, Tangible Technologies, Ambient Technologies, Co-Design, Retirement, Time Perspectives, Social Technology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713752,
author = {Noh, Hayoun and Jo, Hyunah and Wang, Ge and Van Kleek, Max and Kang, Younah},
title = {Bridging Borders, Breaking Biases: Envisioning Technologies to Support North Korean Defectors in South Korea},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713752},
doi = {10.1145/3706598.3713752},
abstract = {North Korean defectors (NKDs) face significant challenges when transitioning to South Korean society. Leaving their homes permanently and adapting to a new, digitally connected environment for the first time presents difficulties, compounded by the pervasive stigma associated with their identities. Although technology alone cannot solve these issues, it can play a role in easing their transition. In this study, we conducted eight speculative co-creation sessions with 22 NKDs to identify their main challenges and envision potential technological interventions. We propose conceptualization of thirteen technologies aimed at addressing key issues NKDs face related to identity stigma, disconnection from their past, and challenges of adapting to a highly digital society. Through this empirical research on underrepresented populations undergoing significant life transitions, we provide insights into how future technologies can support other marginalized individuals as they navigate pervasive stigma and establish new lives in a digital society.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {569},
numpages = {24},
keywords = {Envisioning Technologies, Future Technologies, Co-Creation Workshops, North Korean Defector, Marginalized Individuals},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713107,
author = {India, Gesu and Robinson, Simon and Pearson, Jennifer and Morrison, Cecily and Jones, Matt},
title = {Exploring the Experiences of Individuals Who are Blind or Low-Vision Using Object-Recognition Technologies in India},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713107},
doi = {10.1145/3706598.3713107},
abstract = {Assistive technologies, such as smartphone-based object-recognition (OR) apps, provide visual assistance to people who are blind or low-vision to enable increased independent participation in society. While previous research has explored the functional accessibility of object-recognition technologies, little attention has been given to their social accessibility, particularly in interdependent socio-cultural contexts of the Global South. Through a mixed-methods approach, employing a seven-day diary study followed by one-on-one interviews with seven OR app users in India, we explore their experiences in depth. Our findings highlight the nuances of what interdependence looks like in a multicultural, Indian society, as people navigate public and private spheres with a camera-based assistive technology designed for independent, western contexts. We argue for the necessity to design assistive technologies following the interdependence framework that accommodates the social and cultural context of the Global South. Additionally, we propose design guidelines for assistive technologies in community-oriented societies, emphasizing community-centered approaches, cultural alignment, and locally adaptable designs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {570},
numpages = {11},
keywords = {Object-recognition, vision impairments, human-computer interaction, assistive technologies, low-resource environments},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714322,
author = {Hohendanner, Michel and Ullstein, Chiara and Onyekwelu, Bukola Abimbola and Katirai, Amelia and Kuribayashi, Jun and Babalola, Olusola and Ema, Arisa and Grossklags, Jens},
title = {Initiating the Global AI Dialogues: Laypeople Perspectives on the Future Role of genAI in Society from Nigeria, Germany and Japan},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714322},
doi = {10.1145/3706598.3714322},
abstract = {With the rapid development and release of generative AI (genAI) applications, policy discourses primarily take place on an expert level. Little space is given to laypeople – who have to adapt to and adopt the genAI innovations – to share their opinions and experiences. Addressing this gap, we organized 6h/3.5h laypeople dialogues in Nigeria, Japan, and Germany in July and August 2024. During the dialogues, participants discussed what a desirable future in light of genAI development could look like in one of three contexts: education, public service, and arts \&amp; culture. Participants explored the consequences of technology deployment, assessed the risks, mapped stakeholders, and derived measures to achieve a desirable goal. This study contributes to policy debates on genAI by providing recommendations derived from participants’ identified requirements and suggested measures for genAI to create value and to foster a socially desirable future. We reflect on the results through a cross-national lens.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {571},
numpages = {35},
keywords = {citizen dialogue, civic participation, participatory AI, stakeholder involvement, public perception, generative artificial intelligence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713323,
author = {Fujii, Takao and Seaborn, Katie and Steeds, Madeleine and Kato, Jun},
title = {Inter(sectional) Alia(s): Ambiguity in Voice Agent Identity via Intersectional Japanese Self-Referents},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713323},
doi = {10.1145/3706598.3713323},
abstract = {Conversational agents that mimic people have raised questions about the ethics of anthropomorphizing machines with human social identity cues. Critics have also questioned assumptions of identity neutrality in humanlike agents. Recent work has revealed that intersectional Japanese pronouns can elicit complex and sometimes evasive impressions of agent identity. Yet, the role of other “neutral” non-pronominal self-referents (NPSR) and voice as a socially expressive medium remains unexplored. In a crowdsourcing study, Japanese participants (N = 204) evaluated three ChatGPT voices (Juniper, Breeze, and Ember) using seven self-referents. We found strong evidence of voice gendering alongside the potential of intersectional self-referents to evade gendering, i.e., ambiguity through neutrality and elusiveness. Notably, perceptions of age and formality intersected with gendering as per sociolinguistic theories, especiallyぼく (boku) andわたくし (watakushi). This work provides a nuanced take on agent identity perceptions and champions intersectional and culturally-sensitive work on voice agents.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {572},
numpages = {18},
keywords = {Human-Machine Dialogue, Conversational User Interface, Voice Interaction, Social Identity, Identity Perception, Pronouns, ChatGPT, Chatbot, Intersectionality, Gender, Japan},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713217,
author = {Havens, Lucy and Bach, Benjamin and Terras, Melissa and Alex, Beatrice},
title = {Investigating the Capabilities and Limitations of Machine Learning for Identifying Bias in English Language Data with Information and Heritage Professionals},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713217},
doi = {10.1145/3706598.3713217},
abstract = {Despite numerous efforts to mitigate their biases, ML systems continue to harm already-marginalized people. While predominant ML approaches assume bias can be removed and fair models can be created, we show that these are not always possible, nor desirable, goals. We reframe the problem of ML bias by creating models to identify biased language, drawing attention to a dataset’s biases rather than trying to remove them. Then, through a workshop, we evaluated the models for a specific use case: workflows of information and heritage professionals. Our findings demonstrate the limitations of ML for identifying bias due to its contextual nature, the way in which approaches to mitigating it can simultaneously privilege and oppress different communities, and its inevitability. We demonstrate the need to expand ML approaches to bias and fairness, providing a mixed-methods approach to investigating the feasibility of removing bias or achieving fairness in a given ML use case.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {573},
numpages = {22},
keywords = {Human-Centered Machine Learning, Human-Centered AI, Gender Bias, Data Bias, Language Bias, Cultural Heritage},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713867,
author = {Trindade, Pedro and Guerreiro, Jo\~{a}o and Rodrigues, Andr\'{e}},
title = {Perspectives on Mixed-Ability Competition},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713867},
doi = {10.1145/3706598.3713867},
abstract = {Competition is typically centered on balance, fairness, and symmetric play. However, in mixed-ability competition, symmetric play is often not possible or desirable. Currently, it is not clear what can or should be done in the pursuit of the design of inclusive competitive experiences (in sports and games). In this paper, we interview 15 people with motor or visual disabilities who actively engage in competitive activities (e.g., Paralympics, competitive gaming). We focus on understanding engagement and fairness perspectives within mixed-ability competitive scenarios, highlighting the obstacles and opportunities these interactions present. We relied on thematic analysis to examine the motivations to compete, team structures and roles, perspectives on ability disclosure and rankings, and a reflection on the role of technology in mediating competition. We contribute with an understanding of (1) how competition is experienced, (2) key factors influencing inclusive and fair competition, and (3) reflections for the design of inclusive competitive experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {574},
numpages = {15},
keywords = {mixed-ability, competition, disabilities, competitive gaming, sports, accessibility},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714151,
author = {Riek, Laurel D. and Irani, Lilly},
title = {The Future Is Rosie?: Disempowering Arguments About Automation and What to Do About It},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714151},
doi = {10.1145/3706598.3714151},
abstract = {Many technologists who work in robotics and AI bristle at the idea that human worker displacement is problematic. Others wish to account for workers’ needs, but face pervasive myths about the impacts of these technologies. This paper aims to clear the air by refuting five common arguments for automation: 1) the jobs being automated are undesirable, 2) labor shortages necessitate automation, 3) by “augmenting rather than automating” labor displacement will be prevented, 4) there will be new and better job creation, and 5) automation will give us all more leisure time. The advent of foundational models has led to an industrial gold rush, accelerating deployment without careful consideration of responsible and sustaiable design and deployment of these technologies. Despite technologists’ best intentions, this path of pervasive automation we are on is not a good one, and we offer suggestions for how technologists, designers, and decision makers can push for worker-centered technological change moving forward.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {575},
numpages = {14},
keywords = {automation, robotics, AI, labor, ethics, social theory, critical computing, future of work},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713090,
author = {Li, Wenan and Yu, Junnan and Zhou, Yehong and Shi, Jinlei and You, Weitao and Zhou, Zhibin},
title = {Exploring the Design of Human Speech Indicators to Enhance Waiting Experience in Voice User Interface},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713090},
doi = {10.1145/3706598.3713090},
abstract = {Waiting for system loading is a common scenario that often diminishes user experience, leading to dissatisfaction. Well-established visual indicators like progress bars can not directly apply to the interactions with voice assistants (VAs) like Siri. As VAs continue to rise in popularity, this research aims to explore the design of auditory indicators, particularly human speech, for optimizing waiting experiences in Voice User Interfaces (VUIs). We first organized focus groups (N=35) to identify design considerations for speech indicators, uncovering design opportunities in integrating explanations and humor. Subsequently, we conducted an empirical study (N=30) to evaluate the effects of speech indicators with two levels of explanation and humor on the waiting experience, measured by attention, perceived time, pleasure, and overall satisfaction, during both short and long loading durations. Our findings suggest significant potential for incorporating explanations and humor into VUIs, offering actionable insights for designing effective speech indicators that improve waiting experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {576},
numpages = {19},
keywords = {Design strategies, Speech indicators, Voice assistants, Voice user interfaces, Waiting experience},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714149,
author = {Srabonee, Jannatul Ferdous and Alharbi, Ohoud Mosa and Stuerzlinger, Wolfgang and Arif, Ahmed Sabbir},
title = {Exploring the Impacts of HEXACO Personality Traits on Text Composition and Transcription},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714149},
doi = {10.1145/3706598.3714149},
abstract = {This study investigates the relationship between the HEXACO personality traits and text entry behaviors in composition and transcription tasks. By analyzing metrics such as entry speed, accuracy, editing efforts, and readability, we identified correlations between specific traits and text entry performance. In composition, honesty-humility and agreeableness were the strongest predictors, correlating significantly with composition time, text length, and editing efforts. In transcription, openness, honesty-humility, and agreeableness influenced performance, though no single trait consistently predicted all metrics. Interestingly, extraversion did not show strong correlations in either task, despite its established link to composition performance in academic contexts. These findings suggest that personality traits affect text entry behavior differently depending on the task, with creative tasks like composition being shaped by distinct traits compared to repetitive tasks like transcription. This research provides valuable insights into the relationship between personality and text entry, opening avenues for personalizing interaction systems based on individual traits.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {577},
numpages = {24},
keywords = {Text Entry, Transcription, Composition, Texting, Writing, Data Entry, HEXACO},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714288,
author = {Tao, Jeffrey and Yan, Litao and Shi, Jessica and Ginsberg, Mia and Head, Andrew},
title = {FreeForm: Flexibly Augmenting Formulas with Synchronized Markup and Graphical Edits},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714288},
doi = {10.1145/3706598.3714288},
abstract = {Authors of typeset formulas augment those formulas to make them easier to understand. When they do so, they trade off between using markup tools like LaTeX and formula-unaware graphical editors. In this paper, we explore how editing tools could combine the best affordances of both kinds of tools. We develop FreeForm, a projectional editor wherein authors can augment formulas—with color, labels, spacing, and more—across multiple synchronized representations. Augmentations are created graphically using direct selections and compact menus. Those augmentations propagate to LaTeX markup, which can itself be edited and easily exported. In two lab studies, we observe the value of our editor versus baselines of a widely-used LaTeX document editor and a state-of-the-art formula augmentation tool. Finally, we make recommendations for the design of projectional markup augmentation editors.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {578},
numpages = {12},
keywords = {formulas, annotation, projectional editing, LaTeX},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714213,
author = {Park, Seokhyeon and Song, Yumin and Lee, Soohyun and Kim, Jaeyoung and Seo, Jinwook},
title = {Leveraging Multimodal LLM for Inspirational User Interface Search},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714213},
doi = {10.1145/3706598.3714213},
abstract = {Inspirational search, the process of exploring designs to inform and inspire new creative work, is pivotal in mobile user interface (UI) design. However, exploring the vast space of UI references remains a challenge. Existing AI-based UI search methods often miss crucial semantics like target users or the mood of apps. Additionally, these models typically require metadata like view hierarchies, limiting their practical use. We used a multimodal large language model (MLLM) to extract and interpret semantics from mobile UI images. We identified key UI semantics through a formative study and developed a semantic-based UI search system. Through computational and human evaluations, we demonstrate that our approach significantly outperforms existing UI retrieval methods, offering UI designers a more enriched and contextually relevant search experience. We enhance the understanding of mobile UI design semantics and highlight MLLMs’ potential in inspirational search, providing a rich dataset of UI semantics for future studies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {579},
numpages = {22},
keywords = {Interface Design, UI Design, UI Retrieval, UI Search, Semantic Search, Multimodal LLM},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713370,
author = {Kim, Hyeok and Jeng, Mingyoung Jessica and Smith, Kaitlin N},
title = {Toward Human-Quantum Computer Interaction: Interface Techniques for Usable Quantum Computing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713370},
doi = {10.1145/3706598.3713370},
abstract = {By leveraging quantum-mechanical properties like superposition, entanglement, and interference, quantum computing (QC) offers promising solutions for problems that classical computing has not been able to solve efficiently, such as drug discovery, cryptography, and physical simulation. Unfortunately, adopting QC remains difficult for potential users like QC beginners and application-specific domain experts, due to limited theoretical and practical knowledge, the lack of integrated interface-wise support, and poor documentation. For example, to use quantum computers, one has to convert conceptual logic into low-level codes, analyze quantum program results, and share programs and results. To support the wider adoption of QC, we, as designers and QC experts, propose interaction techniques for QC through design iterations. These techniques include writing quantum codes conceptually, comparing initial quantum programs with optimized programs, sharing quantum program results, and exploring quantum machines. We demonstrate the feasibility and utility of these techniques via use cases with high-fidelity prototypes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {580},
numpages = {18},
keywords = {Quantum computing, computational notebook},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713595,
author = {Grafton, Richard and Metatla, Oussama and Roudaut, Anne},
title = {Understanding Break-ability through Screen-based Affordances},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713595},
doi = {10.1145/3706598.3713595},
abstract = {Can J.J. Gibson’s concept of affordances be empirically examined using screen-based technology? We show how screen-based affordances can be examined through the use case of perceptual toughness, i.e. the break-ability of a virtual object. We present two user experiments (n=72, n=66) examining break-ability through a novel ’Perceptual Impact Testing’ methodology and online screen-based 3D virtual environment. We show that judgements of break-ability are systematically distorted when a perceiver’s virtual ‘Point of Observation’ or virtual environment’s ‘Horizonal Geometry’ are manipulated. These statistically significant results provide evidence that: 1) direct perception can account for perceptual distortions of break-ability; 2) Gibsonian affordances can be empirically examined through screen-based interactions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {581},
numpages = {15},
keywords = {Affordance, Gibson, Ecological Psychology, Embodied Cognition, Screen-based Interaction, Material Perception, Material Science},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713770,
author = {Yang, Yitian and Tan, Yugin and Lin, Yang Chen and King, Jung-Tai and Liu, Zihan and Lee, Yi-Chieh},
title = {Understanding How Psychological Distance Influences User Preferences in Conversational versus Web Search},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713770},
doi = {10.1145/3706598.3713770},
abstract = {Conversational search offers an easier and faster alternative to conventional web search, while having downsides like a lack of source verification. Research has examined performance disparities between these two systems in various settings. However, little work has investigated how changes in the nature of a search task affect user preferences. We investigate how psychological distance - the perceived closeness of one to an event - affects user preferences between conversational and web search. We hypothesise that tasks with different psychological distances elicit different information needs, which in turn affect user preferences between systems. Our study finds that, under fixed condition ordering, greater psychological distances lead users to prefer conversational search, which they perceive as more credible, useful, enjoyable, and easy to use. We reveal qualitative reasons for these differences and provide design implications for search system designers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {582},
numpages = {18},
keywords = {Conversational Search, Web Search, Information Seeking, Information Retrieval, User Experience, Psychological Distance, Construal Level Theory, Large Language Models, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713984,
author = {Chen, Sifan and Peng, Danyang and Barbareschi, Giulia and Chen, Dunya and Sato, Chihiro},
title = {A Reflective Journey for Individuals with Intellectual Disabilities: Rediscovering Competency Through AI-Enhanced Iron Beads Crafting},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713984},
doi = {10.1145/3706598.3713984},
abstract = {In addition to trained work skills, employed individuals with intellectual disabilities (IDs) possess unique competencies that are often insufficiently supported or overlooked by both themselves and their work environments. This study proposes using reflective practices to help employees with IDs and employers rediscover competencies beyond job-related skills. To facilitate participation, we employed personalized crafting with iron beads, supported by a custom-developed application integrated with text-to-image generative AI. We conducted two workshops involving 5–7 employees with IDs to explore and enhance our approach to competency discovery. In the first workshop, facilitators manually created templates for participants, while in the second, we leveraged an AI-assisted application for self-creation of personalized templates. Findings from group discussions reveal (1) the development of a framework that positions AI-enhanced crafting activities as an effective way for uncovering and fostering competencies, and (2) insights into reflection on self-concept as a foundation for competency development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {583},
numpages = {18},
keywords = {Intellectual Disabilities, Competency, Reflection, Accessible Crafting},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714261,
author = {Zhu, Yihao and Ye, Zhoutong and Yuan, Yichen and Tang, Wenxuan and Yu, Chun and Shi, Yuanchun},
title = {AutoPBL: An LLM-powered Platform to Guide and Support Individual Learners Through Self Project-based Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714261},
doi = {10.1145/3706598.3714261},
abstract = {Self project-based learning (SPBL) is a popular learning style where learners follow tutorials and build projects by themselves. SPBL combines project-based learning’s benefit of being engaging and effective with the flexibility of self-learning. However, insufficient guidance and support during SPBL may lead to unsatisfactory learning experiences and outcomes. While LLM chatbots (e.g., ChatGPT) could potentially serve as SPBL tutors, we have yet to see an SPBL platform with responsible and systematic LLM integration. To address this gap, we present AutoPBL, an interactive learning platform for SPBL learners. We examined human PBL tutors’ roles through formative interviews to inform our design. AutoPBL features an LLM-guided learning process with checkpoint questions and in-context Q&amp;A. In a user study where 29 beginners learned machine learning through entry-level projects, we found that AutoPBL effectively improves learning outcomes and elicits better learning behavior and metacognition by clarifying current priorities and providing timely assistance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {584},
numpages = {26},
keywords = {AI for education, Project-based Learning, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713748,
author = {Ma, Shuai and Wang, Junling and Zhang, Yuanhao and Ma, Xiaojuan and Wang, April Yi},
title = {DBox: Scaffolding Algorithmic Programming Learning through Learner-LLM Co-Decomposition},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713748},
doi = {10.1145/3706598.3713748},
abstract = {Decomposition is a fundamental skill in algorithmic programming, requiring learners to break down complex problems into smaller, manageable parts. However, current self-study methods, such as browsing reference solutions or using LLM assistants, often provide excessive or generic assistance that misaligns with learners’ decomposition strategies, hindering independent problem-solving and critical thinking. To address this, we introduce Decomposition Box (DBox), an interactive LLM-based system that scaffolds and adapts to learners’ personalized construction of a step tree through a “learner-LLM co-decomposition” approach, providing tailored support at an appropriate level. A within-subjects study (N=24) found that compared to the baseline, DBox significantly improved learning gains, cognitive engagement, and critical thinking. Learners also reported a stronger sense of achievement and found the assistance appropriate and helpful for learning. Additionally, we examined DBox’s impact on cognitive load, identified usage patterns, and analyzed learners’ strategies for managing system errors. We conclude with design implications for future AI-powered tools to better support algorithmic programming education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {585},
numpages = {20},
keywords = {Programming Learning, Self-Paced Learning, Large Language Models, AI for Coding, Human-AI Collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713125,
author = {Thompson, Gabriella and Dombrowski, Lynn and Smith, Angela D. R.},
title = {Embracing Social Justice within a Computing Curriculum to Foster Social Change},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713125},
doi = {10.1145/3706598.3713125},
abstract = {To ensure that technology serves as a tool for empowerment rather than oppression, Human-Computer Interaction (HCI) scholars have examined the ethical considerations of HCI research to explore pathways that inspire social change. In this work, we consider post-secondary education as one such pathway to social change. We engaged in a qualitative content analysis of the course, Introduction to Social Justice Informatics, with 47 students to understand how students developed knowledge of social justice and what sociotechnical tools facilitated their learning. We found that course materials coupled with peer discussion and reflective practice contributed to their development of critical consciousness. We discuss the significance of critical consciousness as a grounding theoretical approach within a social justice computing curriculum and the role of hope within social justice efforts and the workplace. We conclude by providing collectivist design strategies to nurture hope in the workplace.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {586},
numpages = {17},
keywords = {social justice, computing education, social change, critical consciousness, hope},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714062,
author = {Blanchet, Jules Brooks and Hillis, Megan E. and Lee, Yeongji and Shao, Qijia and Zhou, Xia and Balkcom, Devin and Kraemer, David J. M.},
title = {Enhancing the Educational Potential of Online Movement Videos: System Development and Empirical Studies with TikTok Dance Challenges},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714062},
doi = {10.1145/3706598.3714062},
abstract = {We hypothesize that online movement videos have untapped potential for teaching physical skills, and we developed a platform that automatically generates practice plans from raw TikTok dance videos. The practice plans teach one segment at a time using fading guidance and part-learning principles and are presented using a web-based interface featuring concurrent visual aids. Two user studies (n=54, n=38) were conducted. The first showed significant improvements in learning outcomes compared to standard tutorials, underscoring the importance of well-structured practice plans and offering nuanced insights into the design and effectiveness of visual aids. The second study found that segmentation and emoji-based dual-coding only benefit learning when integrated into a well-designed lesson structure. We provide a set of practical recommendations for enhancing online movement learning, focusing on the need for substantive part-learning activities and careful use of visual aids to prevent cognitive overload.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {587},
numpages = {19},
keywords = {Human-Computer Interaction, User Experience Design, Embodied Interaction, Multimedia Learning, Motor Learning, Observational Learning, Culturally Responsive Teaching, Part Learning, Fading Guidance, Dance, Dance Education, TikTok},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713811,
author = {Kleinman, Erica and Jahani, Rana and McGivney, Eileen and Kosa, Mehmet and Cooper, Seth and Harteveld, Casper},
title = {From Locked Rooms to Open Minds: Escape Room Best Practices to Enhance Reflection in Extended Reality Learning Environments},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713811},
doi = {10.1145/3706598.3713811},
abstract = {Extended reality (XR) learning environments result in greater knowledge gains when coupled with opportunities to reflect on one’s actions and learning. However, when and how one should prompt reflection in XR learning environments (XRLEs) to effectively enhance learning, without breaking immersion, remains an open question. In this work, we argue that we can extract insights on how to design effective, immersive reflection for XRLEs from the expertise of escape room game masters (GMs) who regularly provide reflective hints and prompts in complex, immersive problem solving environments. To explore what we can learn from GMs, we conducted exploratory semi-structured interviews with 13 escape room GMs and, via iterative open coding, captured their best practices in how they provide hints and give nudges to escape room players. From these results, we present a foundation and model of how GMs observe and intervene and discuss implications for XRLE-based reflection.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {588},
numpages = {16},
keywords = {Reflection, Extended Reality, Learning Environments, Reflection Prompts, Escape Rooms},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714295,
author = {Chaudhury, Rimika and Huffman, Courtenay and Kwan, Isabelle and Deol, Gurnoor S. and Dhillon, Supreet and Chilana, Parmit K},
title = {MILESTONES: The Design and Field Evaluation of a Semi-Automated Tool for Promoting Self-Directed Learning Among Online Learners},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714295},
doi = {10.1145/3706598.3714295},
abstract = {Self-directed learning of computational skills online poses significant challenges, particularly the lack of effective tools for tracking progress and fostering reflection. To address this, we designed and implemented MILESTONES, a semi-automated self-monitoring tool that tracks online learning sessions and organizes web resources through three visual overviews: Time Pulse, Cue-Connect, and Sortify. In a week-long field deployment study (N=17), learners found MILESTONES intuitive and effective, even without prior experience with self-monitoring. The on-demand visual overviews encouraged learners to pause, reflect, and adjust their learning habits to better align with their goals. These overviews further fostered micro-reflections - brief, spontaneous reflections during learning. We also explored the role of a companion journal, which, although used inconsistently, helped learners form and reflect on their goals after learning sessions. Our findings contribute insights for designing learner-centered semi-automatic self-monitoring tools that can cater to diverse learning needs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {589},
numpages = {16},
keywords = {Semi-Automated Tracking, Self-Directed Learning, Interactive Visualizations, Micro-Reflections},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713951,
author = {Tan, Felicia Fang-Yi and Ram, Ashwin and Messerschmidt, Moritz Alexander and Dissanayake, Hasini Amanda and Nanayakkara, Suranga},
title = {Curious Shorts: Curiosity-Driven Exploration and Learning on Short-Form Video Platforms},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713951},
doi = {10.1145/3706598.3713951},
abstract = {Short-form video platforms like YouTube Shorts captivate users with engaging content, but their potential for promoting incidental learning remains underexplored. We present Curious Shorts, a conceptual framework that extends the Hook Model, designed to enhance curiosity-driven exploration and incidental learning on these platforms. In Study 1, we empirically tested two designs that incorporate "curiosity nudges" — interactive prompts that spark curiosity and encourage further exploration — with follow-up videos to satisfy that curiosity. Results show that specific, question-driven prompts proved most effective, significantly boosting curiosity and encouraging more focused and intentional viewing compared to the baseline. Study 2 examined whether this design enhances incidental learning without compromising engagement. Findings confirmed improved learning outcomes. However, when applied to a realistic viewing environment interspersed with entertainment videos, engagement remained high while learning benefits diminished. We conclude with implications for balancing learning and engagement on short-form video platforms and propose directions for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {590},
numpages = {22},
keywords = {Short-Form Video, Social Media, Incidental Learning, Curiosity, Exploration, Engagement},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713507,
author = {Li, Ziming and Babar, Pinaki Prasanna and Peiris, Roshan L},
title = {Generative Role-Play Communication Training in Virtual Reality for Autistic Individuals: A Study on Job Coach Experiences in Vocational Training Programs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713507},
doi = {10.1145/3706598.3713507},
abstract = {Our study explores the usability and challenges of a Virtual Reality (VR) and Large Language Model (LLM)-based platform designed for soft skills training in vocational programs for autistic individuals, from the perspective of job coaches. The platform features a VR application that integrates an LLM-powered virtual avatar for role-playing scenarios, alongside a web interface system that enables job coaches to develop training scenarios through prompts. We conducted a two-phase longitudinal study with 13 job coaches. Phase 1 involved workshops to introduce the platform and prompt-writing, and assess initial user experiences, while Phase 2 included interviews to gather insights on the system’s usability after 3 months of use. The findings highlight job coaches’ perceptions of the system’s practicality, the difficulties in integrating the technology into routine coaching, and the challenges faced by non-tech-savvy users. Our study contributes to understanding how VR and LLM tools can be effectively utilized in vocational training.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {591},
numpages = {22},
keywords = {Communication Training, Autism Spectrum Disorder, Job Coaches, Soft Skills Training, Large Language Models, Virtual Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713845,
author = {Sch\"{o}ni, Lorin and Roch, Neele and Sievers, Hannah and Strohmeier, Martin and Mayer, Peter and Zimmermann, Verena},
title = {It's a Match - Enhancing the Fit between Users and Phishing Training through Personalisation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713845},
doi = {10.1145/3706598.3713845},
abstract = {Effective training is essential for enhancing users’ ability to detect phishing attempts. Personalised training offers huge potential to more closely align training content with individuals’ needs and skill levels. In an online study, we assigned N=342 participants to personalised training or a random training variant to compare their effectiveness. The personalisation was based on a phishing proficiency score calculated from factors such as detection ability, knowledge, and security attitude. After training, the participants demonstrated greater proficiency, with an increased ability to detect phishing emails and higher security attitudes. These effects were most pronounced in the personalised condition, demonstrating the potential of personalisation to improve training outcomes. Overall, personalised training levelled the playing field, efficiently bringing all groups, regardless of their initial proficiency, to a comparable and desired post-training phishing proficiency level. Finally, we derived recommendations for designing personalised phishing training content and assigning users to suitable training programmes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {592},
numpages = {25},
keywords = {Phishing, Personalisation, Training, Human-Centred Security},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714014,
author = {Steenstra, Ian and Nouraei, Farnaz and Bickmore, Timothy},
title = {Scaffolding Empathy: Training Counselors with Simulated Patients and Utterance-level Performance Visualizations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714014},
doi = {10.1145/3706598.3714014},
abstract = {Learning therapeutic counseling involves significant role-play experience with mock patients, with current manual training methods providing only intermittent granular feedback. We seek to accelerate and optimize counselor training by providing frequent, detailed feedback to trainees as they interact with a simulated patient. Our first application domain involves training motivational interviewing skills for counselors. Motivational interviewing is a collaborative counseling style in which patients are guided to talk about changing their behavior, with empathetic counseling an essential ingredient. We developed and evaluated an LLM-powered training system that features a simulated patient and visualizations of turn-by-turn performance feedback tailored to the needs of counselors learning motivational interviewing. We conducted an evaluation study with professional and student counselors, demonstrating high usability and satisfaction with the system. We present design implications for the development of automated systems that train users in counseling skills and their generalizability to other types of social skills training.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {593},
numpages = {22},
keywords = {Training Systems, Simulated Patients, Large Language Models, Health Counseling, Cognitive Modeling, Substance Misuse},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714023,
author = {Sch\"{o}ni, Lorin and Strohmeier, Martin and Sluganovic, Ivo and Zimmermann, Verena},
title = {Stop the Clock - Counteracting Bias Exploited by Attackers through an Interactive Augmented Reality Phishing Training},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714023},
doi = {10.1145/3706598.3714023},
abstract = {Phishing attacks become increasingly sophisticated in targeting humans and exploiting cognitive biases, e.g., through inducing authority or urgency. Previous approaches to user training focused on URL warnings, textual, or click-based training, yielding mixed results. For more interactive training, uncoupled from users’ screens, we explore the potential of Augmented Reality (AR) technologies to enhance phishing detection. Through visual representations of biases that attackers typically exploit and gesture-based interactions with them, the training aims to enable users to counteract cognitive biases by increasing awareness and suspicion. In a laboratory study with N = 117 users, we evaluated phishing detection rates, user interaction with, and feedback on the AR-based training in comparison with a click-based variant and a control condition. Our results show that interactive phishing training addressing cognitive biases increased detection rates by 33\% and that interactive elements were well perceived. AR technologies further enhance the training.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {594},
numpages = {23},
keywords = {Phishing, Augmented Reality, Training, Human-Centred Security},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713515,
author = {Park, JunSeo and Yang, Yechan and Kim, Gerard Jounghyun and Kim, Hanseob},
title = {The Impact of Observer Presence on Trainees' Mental States and Performance in Remote Military Training with Virtual Humans in Mixed Reality Environment},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713515},
doi = {10.1145/3706598.3713515},
abstract = {Remote, vs. in situ, instruction may be regarded to decrease trainee engagement and concentration, potentially reducing training effectiveness. As such, local evaluative observers are often deployed to create the situated atmosphere. However, these observers can also have a negative effect on the trainees’ mental state and performance. This study investigates the impact of a local human observer’s presence on trainees’ mental state and task performance during military training conducted in a mixed reality (MR) environment, where a tele-presence avatar, controlled by the remote instructor, leads the training. An experiment was conducted comparing three conditions: remote training with (1) no observer, (2) a real observer, and (3) a virtual observer. The study found that although the observer, real or virtual, indeed negatively impacted the trainee’s mental state, the remote trainer avatar helped maintain the immersion/concentration, ensuring the trainees achieved the performance comparable to the no observer condition.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {595},
numpages = {19},
keywords = {Military Training, Observer Effect, Mixed Reality, Virtual Humans, Remote Collaboration, Tele-presence, Co-presence, Expert Review},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714004,
author = {Djern\ae{}s, Helena B\o{}jer and Jacobsen, Rune M\o{}berg and Hosio, Simo and van Berkel, Niels},
title = {Visual Augmentations for Ultrasound Assessment Training of Medical Students},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714004},
doi = {10.1145/3706598.3714004},
abstract = {Ultrasound assessments are key in assessing traumatic injuries to the human body during urgent medical emergencies. Obtaining proficiency in conducting ultrasound assessments is challenging, and relies on hands-on, individually instructed training provided by a scarce number of ultrasound experts. We investigate how to support medical students’ learning of ultrasound assessment through visual augmentations. By enhancing the learning process, we seek to support medical students in reaching higher proficiency in ultrasound assessments. We followed an ultrasound assessment course to identify the primary challenges faced by medical students learning to conduct ultrasound assessments. Based on our findings, we designed four distinct visual augmentations in collaboration with a course educator that guide students in achieving better ultrasound image quality. We evaluated these visual augmentations in a mixed-method study with 15 medical students. Our findings provide insights on the use of digital technology in supporting clinical training, and the possibilities of bridging existing training practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {596},
numpages = {18},
keywords = {Human-centered AI, Visual Augmentation, Support System, Ultrasound, FAST, Focused Assessment with Sonography for Trauma},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713306,
author = {Saberpour Abadian, Artin and Liao, Yi-Chi and Otaran, Ata and Dabral, Rishabh and Muehlhaus, Marie and Theobalt, Christian and Schmitz, Martin and Steimle, J\"{u}rgen},
title = {3HANDS Dataset: Learning from Humans for Generating Naturalistic Handovers with Supernumerary Robotic Limbs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713306},
doi = {10.1145/3706598.3713306},
abstract = {Supernumerary robotic limbs are robotic structures integrated closely with the user’s body, which augment human physical capabilities and necessitate seamless, naturalistic human-machine interaction. For effective assistance in physical tasks, enabling SRLs to hand over objects to humans is crucial. Yet, designing heuristic-based policies for robots is time-consuming, difficult to generalize across tasks, and results in less human-like motion. When trained with proper datasets, generative models are powerful alternatives for creating naturalistic handover motions. We introduce 3HANDS, a novel dataset of object handover interactions between a participant performing a daily activity and another participant enacting a hip-mounted SRL in a naturalistic manner. 3HANDS captures the unique characteristics of SRL interactions: operating in intimate personal space with asymmetric object origins, implicit motion synchronization, and the user’s engagement in a primary task during the handover. To demonstrate the effectiveness of our dataset, we present three models: one that generates naturalistic handover trajectories, another that determines the appropriate handover endpoints, and a third that predicts the moment to initiate a handover. In a user study (N=10), we compare the handover interaction performed with our method compared to a baseline. The findings show that our method was perceived as significantly more natural, less physically demanding, and more comfortable.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {597},
numpages = {19},
keywords = {supernumerary robotic limb, wearable robotic arm, third arm, handover, dataset, motion synthesis, generative model, data-driven control in robotics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713825,
author = {Chang, Fangyuan and Chen, Bingliang and Zhang, Xingguo and Sheng, Lin and Zhu, Dian and Zhao, Jianan and Gu, Zhenyu},
title = {Crossmodal Interactions in Human-Robot Communication: Exploring the Influences of Scent and Voice Congruence on User Perceptions of Social Robots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713825},
doi = {10.1145/3706598.3713825},
abstract = {Olfactory stimuli have demonstrated the potential to evoke emotional depth and enhance user experiences in HCI. Yet, their role in shaping perceptions of social robots remains largely untapped. This study investigates how olfactory (scent) and auditory (voice) stimuli influence user perceptions of social robots. Using a 2x2 between-subjects design, participants interacted with a social robot under conditions with pleasant/unpleasant scents and friendly/unfriendly voices. The study measured perceived trust, friendliness, competence, and engagement. Our findings show that pleasant scents can enhance the perceptions of friendliness and engagement, while friendly voices can improve trust, friendliness, and engagement. The congruent combination of scents and voices affects friendliness and engagement but does not influence trust and competence. This study contributes to the growing work on multi-sensory Human-Robot Interaction (HRI) design, offering implications for creating more socially interactive robots.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {598},
numpages = {15},
keywords = {Crossmodal interactions, Human-robot interaction, Olfaction stimuli, Sensory congruence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713923,
author = {Leusmann, Jan and Belardinelli, Anna and Haliburton, Luke and Hasler, Stephan and Schmidt, Albrecht and Mayer, Sven and Gienger, Michael and Wang, Chao},
title = {Investigating LLM-Driven Curiosity in Human-Robot Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713923},
doi = {10.1145/3706598.3713923},
abstract = {Integrating curious behavior traits into robots is essential for them to learn and adapt to new tasks over their lifetime and to enhance human-robot interaction. However, the effects of robots expressing curiosity on user perception, user interaction, and user experience in collaborative tasks are unclear. In this work, we present a Multimodal Large Language Model-based system that equips a robot with non-verbal and verbal curiosity traits. We conducted a user study (N = 20) to investigate how these traits modulate the robot’s behavior and the users’ impressions of sociability and quality of interaction. Participants prepared cocktails or pizzas with a robot, which was either curious or non-curious. Our results show that we could create user-centric curiosity, which users perceived as more human-like, inquisitive, and autonomous while resulting in a longer interaction time. We contribute a set of design recommendations allowing system designers to take advantage of curiosity in collaborative tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {599},
numpages = {16},
keywords = {Human-Robot Interaction, LLM, Curiosity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713996,
author = {Madill, Philippa and Newton, Matthew and Zhao, Huanjun and Lian, Yichen and McKendrick, Zachary and Finn, Patrick and Nittala, Aditya Shekhar and Sharlin, Ehud},
title = {Playing with Robots: Performing Arts Techniques for Designing and Understanding Robot Group Movement},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713996},
doi = {10.1145/3706598.3713996},
abstract = {In this work, we introduce a formal design approach derived from the performing arts to design robot group behaviour. In our first experiment, we worked with professional actors, directors, and non-specialists using a participatory design approach to identify common group behaviour patterns. In a follow-up studio work, we identified twelve common group movement patterns, transposed them into a performance script, built a scale model to support the performance process, and evaluated the patterns with a senior actor under studio conditions. We evaluated our refined models with 20 volunteers in a user study in the third experiment. Results from our affective circumplex modelling suggest that the patterns elicit positive emotional responses from the users. Also, participants performed better than chance in identifying the motion patterns without prior training. Based on our results, we propose design guidelines for social robots’ behaviour and movement design to improve their overall comprehensibility in interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {600},
numpages = {20},
keywords = {Humanities, Art, Robots, Method},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713471,
author = {Gunawan, Johanna and Gillespie, Sarah Elizabeth and Choffnes, David and Hartzog, Woodrow and Wilson, Christo},
title = {Promises, Promises: Understanding Claims Made in Social Robot Consumer Experiences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713471},
doi = {10.1145/3706598.3713471},
abstract = {Social robots are a class of emerging smart consumer electronics devices that promise sophisticated experiences featuring emotive capabilities, artificial intelligence, conversational interaction, and more. With unique risk factors like emotional attachment, little is known on how social robots communicate these promises to consumers and whether they adequately deliver upon them within their overall product experiences prior to and during user interaction.Animated by a consumer protection lens, this paper systematically investigates manufacturer claims made for four commercially available social robots, evaluating these claims against the provided user experience and consumer reviews. We find that social robots vary widely in the manner and extent to which they communicate intelligent features and the supposed benefits of these features, while consumer perspectives similarly include a wide range of perceptions on robot and AI performance, capabilities, and product frustrations. We conclude by discussing social robots’ unique propensities for consumer risk, and consider implications for regulators, developers, and researchers of social robots.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {601},
numpages = {22},
keywords = {UX design, IoT, human-robot interaction, AI, consumer protections},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714283,
author = {Xu, Peisen and Garcia, J\'{e}r\'{e}mie and Ooi, Wei Tsang and Jouffrais, Christophe},
title = {SafeSpect: Safety-First Augmented Reality Heads-up Display for Drone Inspections},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714283},
doi = {10.1145/3706598.3714283},
abstract = {Current tablet-based interfaces for drone operations often impose a heavy cognitive load on pilots and reduce situational awareness by dividing attention between the video feed and the real world. To address these challenges, we designed a heads-up augmented reality (AR) interface that overlays in-situ information to support drone pilots in safety-critical tasks. Through participatory design workshops with professional pilots, we identified key features and developed an adaptive AR interface that dynamically switches between task and safety views to prevent information overload. We evaluated our prototype by creating a realistic building inspection task and comparing three interfaces: a 2D tablet, a static AR, and our adaptive AR design. A user study with 15 participants showed that the AR interface improved access to safety information, while the adaptive AR interface reduced cognitive load and enhanced situational awareness without compromising task performance. We offer design insights for developing safety-first heads-up AR interfaces.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {602},
numpages = {17},
keywords = {Augmented Reality, Heads-up Display, Drones, UAV, Adaptive UI, Safety},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714235,
author = {Lyu, Hanfang and Wang, Xiaoyu and Zhang, Nandi and Ma, Shuai and Zhu, Qian and Luo, Yuhan and Tsung, Fugee and Ma, Xiaojuan},
title = {Signaling Human Intentions to Service Robots: Understanding the Use of Social Cues during In-Person Conversations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714235},
doi = {10.1145/3706598.3714235},
abstract = {As social service robots become commonplace, it is essential for them to effectively interpret human signals, such as verbal, gesture, and eye gaze, when people need to focus on their primary tasks to minimize interruptions and distractions. Toward such a socially acceptable Human-Robot Interaction, we conducted a study (N=24) in an AR-simulated context of a coffee chat. Participants elicited social cues to signal intentions to an anthropomorphic, zoomorphic, grounded technical, or aerial technical robot waiter when they were speakers or listeners. Our findings reveal common patterns of social cues over intentions, the effects of robot morphology on social cue position and conversational role on social cue complexity, and users’ rationale in choosing social cues. We offer insights into understanding social cues concerning perceptions of robots, cognitive load, and social context. Additionally, we discuss design considerations on approaching, social cue recognition, and response strategies for future service robots.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {603},
numpages = {21},
keywords = {understanding social cues, social service robot, robot morphology, conversation role, human-robot interaction, elicitation study.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714308,
author = {Kim, Jiwan and Son, Jiwan and Oakley, Ian},
title = {Cross, Dwell, or Pinch: Designing and Evaluating Around-Device Selection Methods for Unmodified Smartwatches},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714308},
doi = {10.1145/3706598.3714308},
abstract = {Smartwatches offer powerful features, but their small touchscreens limit the expressiveness of the input that can be achieved. To address this issue, we present, and open-source, the first sonar-based around-device input on an unmodified consumer smartwatch. We achieve this using a fine-grained, one-dimensional sonar-based finger-tracking system. In addition, we use this system to investigate the fundamental issue of how to trigger selections during around-device smartwatch input through two studies. The first examines the methods of double-crossing, dwell, and finger tap in a binary task, while the second considers a subset of these designs in a multi-target task and in the presence and absence of haptic feedback. Results showed double-crossing was optimal for binary tasks, while dwell excelled in multi-target scenarios, and haptic feedback enhanced comfort but not performance. These findings offer design insights for future around-device smartwatch interfaces that can be directly deployed on today’s consumer hardware.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {604},
numpages = {11},
keywords = {Around-device sensing, Selection method, Smartwatch, Sonar},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713929,
author = {Xu, Zhanwei and Pei, Haoxiang and Feng, Jianjiang and Zhou, Jie},
title = {FingerGlass: Enhancing Smart Glasses Interaction via Fingerprint Sensing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713929},
doi = {10.1145/3706598.3713929},
abstract = {Smart glasses hold immense potential, but existing input methods often hinder their seamless integration into everyday life. Touchpads integrated into the smart glasses suffer from limited input space and precision; voice commands raise privacy concerns and are contextually constrained; vision-based or IMU-based gesture recognition faces challenges in computational cost or privacy concerns. We present FingerGlass, an interaction technique for smart glasses that leverages side-mounted fingerprint sensors to capture fingerprint images. With a combined CNN and LSTM network, FingerGlass identifies finger identity and recognizes four types of gestures (nine in total): sliding, rolling, rotating, and tapping. These gestures, coupled with finger identification, are mapped to common smart glasses commands, enabling comprehensive and fluid text entry and application control. A user study reveals that FingerGlass represents a promising step towards a fresh, discreet, ergonomic, and efficient input interaction with smart glasses, potentially contributing to their wider adoption and integration into daily life.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {605},
numpages = {18},
keywords = {Smart Glasses, Fingerprint Sensing, Gesture Recognition, CNN, LSTM},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714114,
author = {van Gemert, Thomas and Knibbe, Jarrod and Velloso, Eduardo},
title = {How your Physical Environment Affects Spatial Presence in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714114},
doi = {10.1145/3706598.3714114},
abstract = {Virtual reality (VR) is often used in small physical environments, requiring users to remain aware of their environment to avoid injury or damage. However, this can reduce their spatial presence in VR. Previous work and theory lack an account of how the physical environment (PE) affects spatial presence. To address this gap, we investigated the effect on spatial presence of (1) the degree of spatial knowledge of the PE and (2) knowledge of and (3) collisions with obstacles in the PE. Estimates from Bayesian regression models suggest that limiting spatial knowledge of the PE increases spatial presence initially but amplifies the detrimental effect of obstacle collisions. Repeatedly avoiding obstacles further decreases spatial presence, but removing them from the user’s path yields a partial recovery. Our work contributes empirical evidence to theories of spatial presence formation and highlights the need to consider the physical environment when designing for presence in VR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {606},
numpages = {16},
keywords = {virtual reality, room-scale, presence, behaviour, movement, walking, spatial presence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713694,
author = {Wilson, Graham and McCready, Jamie and Freeman, Euan and Mathis, Florian and Russell, Harvey and McGill, Mark},
title = {InterFACE: Establishing a Facial Action Unit Input Vocabulary for Hands-Free Extended Reality Interactions, From VR Gaming to AR Web Browsing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713694},
doi = {10.1145/3706598.3713694},
abstract = {Extended Reality (XR) interactions often rely on spatial hand or controller inputs - necessitating dexterous wrist, hand and finger movements including pressing virtual buttons, pinching to select, and performing hand gestures. However, there are scenarios where such dependencies may render XR devices and apps inaccessible to users - from situational/temporary impairments such as encumbrance, to physical motor impairments. In this paper, we contribute to a growing literature considering facial input as an alternative. In a user study (N=20) we systematically evaluate the usability of 53 Facial Action Units in VR, deriving a set of optimal (comfort, effort, performance) FAUs for interaction. We then use these facial inputs to drive and evaluate (N=10) two demonstrator apps: VR locomotion, and AR web browsing, showcasing how close facial interaction can get to existing baselines, and demonstrating that FAUs offer a viable, generalizable input modality for XR devices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {607},
numpages = {23},
keywords = {Virtual Reality, Facial Action Units, Face, Interaction, Impairment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713837,
author = {Wentzel, Johann and Luz, Alessandra and Mott, Martez E and Vogel, Daniel},
title = {MotionBlocks: Modular Geometric Motion Remapping for More Accessible Upper Body Movement in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713837},
doi = {10.1145/3706598.3713837},
abstract = {Movement-based spatial interaction in VR can present significant challenges for people with limited mobility, particularly due to the mismatch between the upper body motion a VR app requires and the user’s capabilities. We describe MotionBlocks, an approach which enables 3D spatial input with smaller motions or simpler input devices using modular geometric motion remapping. A formative study identifies common accessibility issues within VR motion design, and informs a design language of VR motions that fall within simple geometric primitives. These 3D primitives enable collapsing spatial or non-spatial input into a normalized input vector, which is then expanded into a second 3D primitive representing larger, more complex 3D motions. An evaluation with people with mobility limitations found that using geometric primitives for highly customized upper body input remapping reduced physical workload, temporal workload, and perceived effort.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {608},
numpages = {16},
keywords = {review, formative design study, spatial input, spatial computing, accessibility, controlled experiment, geometric primitives},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713340,
author = {Kim, YoungIn and Yun, Yohan and Kim, Taejun and Lee, Geehyuk},
title = {Over the Mouse: Navigating across the GUI with Finger-Lifting Operation Mouse},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713340},
doi = {10.1145/3706598.3713340},
abstract = {Modern GUIs often have a hierarchical structure, i.e., the z-axis of the GUI interaction space. However, conventional mice do not support effective navigation along the z-axis, leading to increased physical movements and cognitive load. To address this inefficiency, we present the OtMouse, a novel mouse that supports finger-lifting operations by detecting finger height through proximity sensors embedded beneath the mouse buttons, and ‘Over the Mouse’ (OtM) interface, a set of interaction techniques along the z-axis of the GUI interaction space with the OtMouse. Initially, We evaluated the performance of finger-lifting operations (n = 8) with the OtMouse for two- and three-level lifting discrimination tasks. Subsequently, we conducted a user study (n = 16) to compare the usability of the OtM interface and traditional mouse interface for three representative tasks: ‘Context Switch,’ ‘Video Preview,’ and ‘Map Zooming.’ The results showed that OtM interface was both qualitatively and quantitatively superior to using traditional mouse in the Context Switch and Video Preview tasks. This research contributes to the ongoing efforts to enhance mouse-based GUI navigation experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {609},
numpages = {14},
keywords = {Input device, Augmented mouse, Finger-lifting operations},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713615,
author = {DeVrio, Nathan and Harrison, Chris},
title = {Reel Feel: Rich Haptic XR Experiences Using an Active, Worn, Multi-String Device},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713615},
doi = {10.1145/3706598.3713615},
abstract = {While many haptic systems have been demonstrated for use in virtual and augmented reality, they most often enable a single category of feedback (e.g., kinematic breaking, object compliance, texture). Combining prior systems to achieve multi-dimensional effects is unwieldy, expensive, and often physically impossible. We believe this is holding back the ubiquity of rich haptics in both the consumer and industrial AR/VR/XR domains. In this work, we describe Reel Feel, a novel, shoulder-worn haptic system capable of rendering rigid geometry, object-bound haptic animations, impulsive forces, surface compliance, and fine-grained spatial effects all in one unified, worn device. Our design aimed to minimize the weight on the hands (&lt;10 g), where a system’s mass is most felt, as many prior systems are heavy gloves and exoskeletons. Finally, we sought to keep the device practical, being self-contained, low-cost, and low enough power to be feasible for consumer adoption with a high degree of mobility. In a user evaluation, our device rated better than a conventional vibrotactile baseline for all qualitative measures (immersion, realism, etc.) and allowed participants to more accurately discern object compliance and fine-grained spatial effects.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {610},
numpages = {20},
keywords = {Haptics; Virtual Reality; Augmented Reality; Wearable; Interaction techniques},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713590,
author = {Kujala, Tuomo and Sarkar, Abhishek},
title = {Evaluating In-Car Tasks’ Distraction Effects with Drive-In Lab},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713590},
doi = {10.1145/3706598.3713590},
abstract = {Existing measurements of driver distraction in laboratory settings lack construct and ecological validity, and therefore, cannot provide reliable estimates of in-car tasks’ distraction effects. In this paper, we operationalize driver distraction in a novel way with the help of Drive-In Lab, where any passenger car can be connected to a driving simulation. The operationalization is based on drivers’ headway maintenance during in-car tasks as compared to baseline driving, while accommodating situational and driver-specific variables, such as brake response times. Realistic visual looming cues enable evaluation of distraction effects on cognitive processes crucial for safe driving. Validation studies with two 2024 car models indicate that the method can reliably differentiate distraction effects between cars, in-car tasks, and drivers as large, medium, small, or no effect on crash potential. The method supports design of in-car interactions by providing valid means to reveal the worst and best practices in in-car user interface design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {611},
numpages = {24},
keywords = {Driver distraction, Inattention, Measurement, Operationalization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713858,
author = {Jannat, Marium-E- and Phan, Ngan and Chadha, Anmol and Katsuragawa, Keiko and Hasan, Khalad},
title = {HAI-AR: Exploring Hand-Anchored Interfaces in Augmented Reality while Walking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713858},
doi = {10.1145/3706598.3713858},
abstract = {To interact with Augmented Reality (AR) content while walking, the user interfaces (UIs) need to move along with the user without distracting their field of view. This paper investigates on-hand reference frames for AR interaction while walking. First, we conduct a user study evaluating six on-hand reference frames. Results show that the Pinch Grip With Offset (PGWO), which anchors UIs to the pinch grip while floating at a distance, outperforms other on-hand reference frames regarding speed, accuracy, workload, and user preference. Next, we conduct a follow-up study to compare PGWO’s performance with head and torso reference frames, commonly used in previous studies, to see whether PGWO’s benefits hold up against well-established reference frames. Results revealed better performance and higher user preference for PGWO than both reference frames. Finally, we present design recommendations for developing future AR systems that are more efficient and user-friendly for on-the-go interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {612},
numpages = {18},
keywords = {Augmented Reality, Walking Interfaces, Hand Anchored UIs, Fitts’ Law, Pinch, Reference Frame},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714116,
author = {Bao, Xiyu and Lv, Gaorong and Bian, Yulong and Gai, Wei and Xin, Shiqing and Luan, Hongqiu and Ma, Xiaojuan and Yang, Chenglei},
title = {QCM: A Curvature Manipulation Method to Suppress Discomfort in Redirected Walking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714116},
doi = {10.1145/3706598.3714116},
abstract = {In redirected walking techniques, curvature gain and bending gain, which are referred to as curvature manipulation, are important redirection gains. The applied gains can differ when multiple paths are mapped, and sudden changes in gain may cause discomfort. This study proposes quadratic curvature manipulation (QCM) based on the habituation mechanism to effectively reduce discomfort. This method quadratically adjusts the path curvature, thereby reducing user’s perception of curvature changes. Furthermore, we introduce the segmented curvature change (SCC) mode that combines QCM with linear curvature manipulation to facilitate more natural gain transitions, thereby reducing discomfort. Two experiments were conducted. Experiment 1 examined the relationship between QCM parameters and gains at which users felt discomfort. Experiment 2 further examined the effects of different curvature change modes on discomfort. The results indicate that using the SCC mode in curvature manipulations is more effective than other methods in reducing discomfort.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {613},
numpages = {17},
keywords = {Redirected walking, Curvature gain, Bending gain, Dynamic change, Discomfort},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713313,
author = {Le, Quang-Tri and Huynh, Duc-Nham and Tran, Tanh Quang and Fjeld, Morten and Stuerzlinger, Wolfgang and Zank, Markus and Tran, Minh-Triet and Le, Khanh-Duy},
title = {RedirectedStepper: Exploring Walking-In-Place Locomotion in VR Using a Mini Stepper for Ascents},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713313},
doi = {10.1145/3706598.3713313},
abstract = {Walking on inclined surfaces is common in some Virtual Reality (VR) scenarios, for instance, when moving between floors of a building, climbing a tower, or ascending a virtual mountain. Existing approaches enabling realistic walking experiences in such settings typically require the user to use bulky walking-in-place hardware or to walk in a physical area. Addressing this challenge, we present RedirectedStepper, a locomotion technique leveraging a novel device based on a mini exercise stepper to provide realistic VR staircase walking experiences by alternating the tilt of the two stepper pedals. RedirectedStepper employs a new exponential mapping function to visually morph the user’s real foot motion to a corresponding curved path in the virtual environment (VE). Combining this stepper and the visual mapping function provides an in-place locomotion technique allowing users to virtually ascend an infinite staircase or slope while walking-in-place (WIP). We conducted three within-subject user studies (n=36) comparing RedirectedStepper with a WIP locomotion technique using the Kinect. Our studies indicate that RedirectedStepper improves the users’ sense of realism in walking on staircases in VR. Based on a set of design implications derived from the user studies, we developed SnowRun, a VR exergame application, demonstrating the use of the RedirectedStepper concept.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {614},
numpages = {17},
keywords = {Virtual Reality, Usability, Experience, Haptic Feedback, Study, Height Change, Stair},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713659,
author = {Shih, Meng Ting and Chou, Chun-Jui and Mi, Tzu-Wei and Chan, Liwei},
title = {SeeThroughBody: Mitigating Occlusion through Body Transparency to Enhance Foot-Floor Touch Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713659},
doi = {10.1145/3706598.3713659},
abstract = {Occlusion, often caused by the user’s body or fingers, can significantly reduce the efficiency and usability of touch interfaces. As foot-based interactions in HMDs become more prevalent, self-occlusion becomes a more pronounced issue due to the involvement of the body and legs. This work presents SeeThroughBody, a body-rendering approach designed to mitigate occlusion and enhance touch interactions between the foot and interactive floor in virtual environments. Our user study unveiled twofold results. First, changing VisualizationStyles and BodyPartsVisibility can improve objective performance (e.g., time, movement) by reducing occlusion. Second, these modifications also affect the subjective user experience (e.g., embodiment, usability). Different VisualizationStyles and BodyPartsVisibility have varying impacts, presenting trade-offs between performance and experience. Based on these insights, we recommend Transparent-Foot and Outline-Foot for interactions focused on efficiency, and Transparent-All and Transparent-Thigh for enhancing overall user experience. Finally, we demonstrate the application of these recommendations in a map browsing scenario using foot touch.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {615},
numpages = {17},
keywords = {Occlusion, Foot Interaction, Touch Interaction, Virtual Reality, Transparent, Embodiment, Interaction Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713208,
author = {Dublin, Tamar and Zuckerman, Oren},
title = {The Walking Meditation Mat: Leveraging Targeted Heat Sensation to Guide Attention Inward},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713208},
doi = {10.1145/3706598.3713208},
abstract = {We present the walking meditation mat research, leveraging targeted heat to help meditators focus attention inward. The mat, measuring three meters in length, is designed with 10 visual signifiers and 10 corresponding heater pads arranged in a step-by-step pattern. Walking meditation is challenging, as it requires both inward and outward attention. In a qualitative study we studied the walking meditation experience with or without heat, evaluating the impact of the mat’s visual signifiers and the gentle feet-focused targeted heat during the walking experience. Our findings reveal the tension participants experience between external design factors and their internal meditation process. Visual signifiers were more commonly associated with outward attention, dizziness and imbalance, while targeted heat affordances were more commonly associated with attention to bodily sensations, calmness, grounding, and reflection. We conclude with insights regarding the role of targeted heat in balancing inward and outward attention in walking meditation and introspective processes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {616},
numpages = {12},
keywords = {Walking Meditation, Somaesthetic design, Targeted Heat, Introspection, Somatic Awareness, Mind-Body Connection, Well-being},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714254,
author = {Ying-Lei, Shih and Tang, Dongxu and Hu, Weiming and Yoon, Sang Ho and Shao, Yitian},
title = {VibWalk: Mapping Lower-limb Haptic Experiences of Everyday Walking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714254},
doi = {10.1145/3706598.3714254},
abstract = {Walking is among the most common human activities where the feet can gather rich tactile information from the ground. The dynamic contact between the feet and the ground generates vibration signals that can be sensed by the foot skin. While existing research focuses on foot pressure sensing and lower-limb interactions, methods of decoding tactile information from foot vibrations remain underexplored. Here, we propose a foot-equipped wearable system capable of recording wideband vibration signals during walking activities. By enabling location-based recording, our system generates maps of haptic data that encode information on ground materials, lower-limb activities, and road conditions. Its efficacy was demonstrated through studies involving 31 users walking over 18 different ground textures, achieving an overall identification accuracy exceeding 95\% (cross-user accuracy of 87\%). Our system allows pedestrians to map haptic information through their daily walking activities, which has potential applications in creating digitalized walking experiences and monitoring road conditions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {617},
numpages = {18},
keywords = {Vibration sensing, wearable device, haptic information, haptic map},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714270,
author = {Milesi, Mikaela Elizabeth and Mejia-Domenzain, Paola and Brandl, Laura and Echeverria, Vanessa and Jin, Yueqiao and Gasevic, Dragan and Tsai, Yi-Shan and K\"{a}ser, Tanja and Martinez-Maldonado, Roberto},
title = {"Piecing Data Connections Together Like a Puzzle": Effects of Increasing Task Complexity on the Effectiveness of Data Storytelling Enhanced Visualisations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714270},
doi = {10.1145/3706598.3714270},
abstract = {The emerging concept of data storytelling (DS) suggests that enhancing visualisations with annotations and narratives can make complex data more insightful than conventional visualisations. Previous works found that DS-enhanced visualisations are more effective than conventional visualisations for simple tasks like identifying key data points or the main message. However, no previous work has explored the extent to which DS enhancements influence task completion across different levels of cognitive complexity. We address this gap by presenting the results of a study where 128 participants completed tasks based on four visualisations (two line charts and two choropleth maps, either with or without DS elements) spanning a range of complexity based on Bloom’s taxonomy, which has been applied in data visualisation to categorise tasks hierarchically from lower to higher-order thinking. Results suggest that while DS-enhanced visualisations effectively support lower-order tasks (finding data points and understanding insights), they don’t necessarily aid the correct completion of higher-order tasks (application, analysis, evaluation and creation). However, DS enhancements improve how efficiently participants complete complex tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {618},
numpages = {18},
keywords = {data storytelling, information visualisation, annotated visualisations, bloom’s taxonomy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714320,
author = {Shi, Yao and Li, Boyan and Luo, Yuyu and Chen, Lei and Tang, Nan},
title = {Augmenting Realistic Charts with Virtual Overlays},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714320},
doi = {10.1145/3706598.3714320},
abstract = {In this paper, we introduce the concept of realistic charts, referring to charts in the real world that cannot be digitally altered, such as those printed in newspapers or used in PDF documents. By enabling interaction with and virtual enhancement of these realistic charts as if they were digital, we transform realistic charts into “digital charts” by adding virtual overlays. To achieve this, we identify 34 overlay strategies (e.g., highlights and trendlines) for five widely-used chart types (e.g., line charts) through systematic exploration and a formative study. To simplify overlay creation, we introduce a new grammar named Vega-Overlay. Leveraging this design space and grammar, we develop a system called HARVis, which allows users to generate virtual overlays through augmented reality devices using speech and optional gestures. A user study involving 33 participants from diverse fields, across 17 tasks, demonstrates the effectiveness and usability of HARVis.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {619},
numpages = {23},
keywords = {Visualization, Realistic Charts, Virtual Overlays, Augmented Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713612,
author = {Burns, Alyxander and Gonzalez-Vazquez, Claudia},
title = {Intra, Extra, Read all about it! How Readers Interpret Visualizations with Intra- and Extratextual Information},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713612},
doi = {10.1145/3706598.3713612},
abstract = {A reader’s interpretation of a visualization is informed by both intratextual information (the information directly represented in the visualization) and extratextual information (information not represented in the visualization but known by the reader). Yet, we do not know what kinds of intra- and extratextual information readers use or how they integrate it to form meaning. To explore this area, we conducted semi-structured interviews about four real-world visualizations. We used thematic analysis to understand the types of information that participants used and diffractive reading to reveal how participants blended intra- and extratextual information. Our thematic analysis showed that participants utilized a broad assortment of information from both expected and unexpected sources. Additionally, our diffractive reading exposed three ways that participants incorporated intra- and extratextual information: to decide what to look at, to make (in)accurate assumptions about what the visualization showed, and to discover insights beyond what was directly encoded.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {620},
numpages = {13},
keywords = {Data Visualization, Critical Data Visualization, Interpretation, Intratextual Information, Extratextual Information},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713352,
author = {Schlieder, Antonia and Rummel, Jan and Albers, Peter and Sadlo, Filip},
title = {Sequential Visual Cues from Gaze Patterns: Reasoning Assistance for Bar Charts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713352},
doi = {10.1145/3706598.3713352},
abstract = {Even for well-studied visual reasoning tasks such as those performed on bar charts, little is known about the cognitive strategies users adopt to solve them. Guidance systems that support users in learning visual reasoning require information on successful strategies to help unsuccessful users improve or change their strategies. We introduce the guidance paradigm of sequential visual cues (SVCs), accompanied by a differential pattern mining approach that determines relevant visual attention patterns from gaze data, and exemplified for bar charts. The novel feature of SVCs is to give hints on critical fragments of successful strategies, guiding users where to look in a visualization and in which order, but not what to do with this information. Results from an empirical study (N=30) show how critical patterns of successful and unsuccessful strategies differ for various bar chart tasks. In a qualitative survey (N=5), we explore how to surface relevant gaze patterns as SVCs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {621},
numpages = {17},
keywords = {visual reasoning, sequential pattern mining, eye tracking, bar charts, deceptive visualization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713499,
author = {Shapiro, Ben Rydal and Metts, Elizabeth C and Zhao, Edwin},
title = {The Interaction Geography Slicer: Designing Exploratory Spatial Data Visualization Tools for Teachers' Reflective Practice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713499},
doi = {10.1145/3706598.3713499},
abstract = {Researchers in HCI and teacher education have long recognized the potential of visualization to support teachers’ reflective practice. Despite much progress however, teacher educators continue to highlight the need for more dynamic classroom data visualizations to better support teachers’ reflective practice, particularly about spatial dimensions of their pedagogy. In response, this article makes three contributions. First, we build on prior work to present the Interaction Geography Slicer (IGS), an open-source tool to dynamically visualize movement, conversation, and video data over space and time in settings such as classrooms. Second, we share findings from a participatory design-based research project involving 11 experienced high school mathematics teachers who used the IGS over one year to support their reflective practice. Finally, we propose new directions for exploratory spatial classroom data visualization.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {622},
numpages = {17},
keywords = {classroom data visualization, teacher reflective practice, spatial data visualization, exploratory data analysis, interaction geography, learning sciences, teacher education, visual analytics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714229,
author = {While, Zack and Sarvghad, Ali},
title = {Toward Filling a Critical Knowledge Gap: Charting the Interactions of Age with Task and Visualization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714229},
doi = {10.1145/3706598.3714229},
abstract = {We present the results of a study comparing the performance of younger adults&nbsp;(YA) and people in late adulthood&nbsp;(PLA) across ten low-level analysis tasks and five basic visualizations, employing Bayesian regression to aggregate and model participant performance. We analyzed performance at the task level and across combinations of tasks and visualizations, reporting measures of performance at aggregate and individual levels. These analyses showed that PLA on average required more time to complete tasks while demonstrating comparable accuracy. Furthermore, at the individual level, PLA exhibited greater heterogeneity in task performance as well as differences in best-performing visualization types for some tasks. We contribute empirical knowledge on how age interacts with analysis task and visualization type and use these results to offer actionable insights and design recommendations for aging-inclusive visualization design. We invite the visualization research community to further investigate aging-aware data visualization. Supplementary materials can be found at&nbsp;https://osf.io/a7xtz/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {623},
numpages = {18},
keywords = {GerontoVis, people in late adulthood, data visualization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713385,
author = {Lisnic, Maxim and Cutler, Zach and Kogan, Marina and Lex, Alexander},
title = {Visualization Guardrails: Designing Interventions Against Cherry-Picking in Interactive Data Explorers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713385},
doi = {10.1145/3706598.3713385},
abstract = {The growing popularity of interactive time series exploration platforms has made data visualization more accessible to the public. However, the ease of creating polished charts with preloaded data also enables selective information presentation, often resulting in biased or misleading visualizations. Research shows that these tools have been used to spread misinformation, particularly in areas such as public health and economic policies during the COVID-19 pandemic. Post hoc fact-checking may be ineffective because it typically addresses only a portion of misleading posts and comes too late to curb the spread. In this work, we explore using visualization design to counteract cherry-picking, a common tactic in deceptive visualizations. We propose a design space of guardrails—interventions to expose cherry-picking in time-series explorers. Through three crowd-sourced experiments, we demonstrate that guardrails, particularly those superimposing data, can encourage skepticism, though with some limitations. We provide recommendations for developing more effective visualization guardrails.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {624},
numpages = {19},
keywords = {Visualization, cherry-picking, general public visualizations, misinformation interventions.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713623,
author = {Amini, Mohammadreza and Stuerzlinger, Wolfgang and Teather, Robert J and Batmaz, Anil Ufuk},
title = {A Systematic Review of Fitts' Law in 3D Extended Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713623},
doi = {10.1145/3706598.3713623},
abstract = {Fitts’ law is widely used as an evaluation tool for pointing or selection tasks, evolving into diverse applications, including 3D extended reality (XR) environments like virtual, augmented, and mixed reality. Despite standards like ISO 9241:411, the application of Fitts’ law varies significantly across studies, complicating comparisons and undermining the reliability of findings in 3D XR research. To address this, we conducted a systematic review of 119 publications, focusing on 122 studies that used Fitts’ law in 3D XR user experiments. Our analysis shows that over half of these studies referenced Fitts’ law without thoroughly investigating throughput, movement time, or error rate. We performed an in-depth meta-analysis to examine how Fitts’ law is incorporated into research. By highlighting trends and inconsistencies, and making recommendations this review aims to guide researchers in designing and performing more effective and consistent Fitts-based studies in 3D XR, enhancing the quality and impact of future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {625},
numpages = {25},
keywords = {Fitts’ Law, Systematic Review, Extended Reality (XR), Virtual Reality (VR), Augmented Reality (AR), Mixed Reality (MR)},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713230,
author = {Katins, Christopher and Strecker, Jannis and Hinrichs, Jan and Knierim, Pascal and Pfleging, Bastian and Kosch, Thomas},
title = {Ad-Blocked Reality: Evaluating User Perceptions of Content Blocking Concepts Using Extended Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713230},
doi = {10.1145/3706598.3713230},
abstract = {Inspired by the concepts of diminishing reality and ad-blocking in browsers, this study investigates the perceived benefits and concerns of blocking physical, real-world content, particularly ads, through Extended Reality (XR). To understand how users perceive this concept, we first conducted a user study (N = 18) with an ad-blocking prototype to gather initial insights. The results revealed a mixed willingness to adopt XR blockers, with participants appreciating aspects such as customizability, convenience, and privacy. Expected benefits included enhanced focus and reduced stress, while concerns centered on missing important information and increased feelings of isolation. Hence, we investigated the user acceptance of different ad-blocking visualizations through a follow-up online survey (N = 120), comparing six concepts based on related work. The results indicated that the XR ad-blocker visualizations play a significant role in how and for what kinds of advertisements such a concept might be used, paving the path for future feedback-driven prototyping.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {626},
numpages = {18},
keywords = {Extended Reality, Content Curation, Visualization, Physical Ad Blocker},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714249,
author = {Li, Yi and Fischer, Florian and Dwyer, Tim and Ens, Barrett and Crowther, Robert and Kristensson, Per Ola and Tag, Benjamin},
title = {AlphaPIG: The Nicest Way to Prolong Interactive Gestures in Extended Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714249},
doi = {10.1145/3706598.3714249},
abstract = {Mid-air gestures serve as a common interaction modality across Extended Reality (XR) applications, enhancing engagement and ownership through intuitive body movements. However, prolonged arm movements induce shoulder fatigue—known as "Gorilla Arm Syndrome"—degrading user experience and reducing interaction duration. Although existing ergonomic techniques derived from Fitts’ law (such as reducing target distance, increasing target width, and modifying control-display gain) provide some fatigue mitigation, their implementation in XR applications remains challenging due to the complex balance between user engagement and physical exertion. We present AlphaPIG, a meta-technique designed to Prolong Interactive Gestures by leveraging real-time fatigue predictions. AlphaPIG assists designers in extending and improving XR interactions by enabling automated fatigue-based interventions. Through adjustment of intervention timing and intensity decay rate, designers can explore and control the trade-off between fatigue reduction and potential effects such as decreased body ownership. We validated AlphaPIG’s effectiveness through a study (N=22) implementing the widely-used Go-Go technique. Results demonstrated that AlphaPIG significantly reduces shoulder fatigue compared to non-adaptive Go-Go, while maintaining comparable perceived body ownership and agency. Based on these findings, we discuss positive and negative perceptions of the intervention. By integrating real-time fatigue prediction with adaptive intervention mechanisms, AlphaPIG constitutes a critical first step towards creating fatigue-aware applications in XR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {627},
numpages = {14},
keywords = {Mid-air Interaction, Adaptive Interaction, Gorilla Arm, Shoulder Fatigue},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713982,
author = {Shen, Songjia and Tan, Chek Tien and Chen, Hsiang-Ting and Raffe, William L and Leong, Tuck Wah},
title = {Educator Perceptions of XRAuthor: An Accessible Tool for Authoring Learning Content with Different Immersion Levels},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713982},
doi = {10.1145/3706598.3713982},
abstract = {The promise of Extended Reality (XR) in education is significant but one size does not fit all learning contexts and student preferences. Varied content with different immersion levels is hence beneficial, but creating XR content remains daunting for educators using conventional tools. This paper introduces XRAuthor, a web-based authoring tool designed to empower educators to create varying immersive learning content - ranging from conventional video to interactive animations and full-fledged VR - all from a single authoring experience with a webcam. Through online one-to-one workshops with 14 educators, we found strong endorsement for the new authoring workflow enabled by XRAuthor. Participants also found that the varied interactive exercises automatically generated by the tool aligned well with effective pedagogical practices. High ease of use and efficiency were identified as crucial attributes of XRAuthor. The design knowledge facilitated by XRAuthor underscores the potential of such tool designs to democratize XR content creation for learning.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {628},
numpages = {11},
keywords = {virtual reality, augmented reality, learning tools, self-driven learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713954,
author = {Tsimbalistaia, Uliana and Berger, Caroline and Gellersen, Hans and Manakhov, Pavel},
title = {On-body Icons: Designing a 3D Interface for Launching Apps in Augmented Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713954},
doi = {10.1145/3706598.3713954},
abstract = {On-body tapping provides a quick way to launch augmented reality (AR) apps using virtual shortcuts placed on the user’s skin, clothes, and jewelry. While prior work has focused on tapping performance, social acceptance, and sensing techniques, users’ behaviour in placing shortcuts on their body has been underexplored. In this work, we propose On-body Icons — a novel interface for launching apps via touching virtual icons placed across the user’s entire body, and use it to investigate locations, reasons for chosen icon placement, and users’ attitudes towards the feature. Results of the qualitative study conducted with 24 participants demonstrated that people employ a wide variety of placement strategies that balance memorability of the locations with accuracy and comfort of reaching the icons. We discuss these findings in regard to current understanding of memorability of icon placement, placement appropriateness, and privacy, and offer design implications for similar features in spatial applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {629},
numpages = {15},
keywords = {embodied interaction, app launcher, spatial UIs, body-based UIs, extended reality, augmented reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713656,
author = {Taninaka, Kentaro and Jain, Rahul and Shi, Jingyu and Takashio, Kazunori and Ramani, Karthik},
title = {Transparent Barriers: Natural Language Access Control Policies for XR-Enhanced Everyday Objects},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713656},
doi = {10.1145/3706598.3713656},
abstract = {Extended Reality (XR)-enabled headsets that overlay digital content onto the physical world, are gradually finding their way into our daily life. This integration raises significant concerns about privacy and access control, especially in shared spaces where XR applications interact with everyday objects. Such issues remain subtle in the absence of widespread applications of XR and studies in shared spaces are required for a smooth progress. This study evaluated a prototype system facilitating natural language policy creation for flexible, context-aware access control of personal objects. We assessed its usability, focusing on balancing precision and user effort in creating access control policies. Qualitative interviews and task-based interactions provided insights into users’ preferences and behaviors, informing future design directions. Findings revealed diverse user needs for controlling access to personal items in various situations, emphasizing the need for flexible, user-friendly access control in XR-enhanced shared spaces that respects boundaries and considers social contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {630},
numpages = {20},
keywords = {Access control, Natural language policies, Extended reality, Mixed reality, Everyday objects, Tangible user interface},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713953,
author = {Cai, Runze and Janaka, Nuwan and Kim, Hyeongcheol and Chen, Yang and Zhao, Shengdong and Huang, Yun and Hsu, David},
title = {AiGet: Transforming Everyday Moments into Hidden Knowledge Discovery with AI Assistance on Smart Glasses},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713953},
doi = {10.1145/3706598.3713953},
abstract = {Unlike the free exploration of childhood, the demands of daily life reduce our motivation to explore our surroundings, leading to missed opportunities for informal learning. Traditional tools for knowledge acquisition are reactive, relying on user initiative and limiting their ability to uncover hidden interests. Through formative studies, we introduce AiGet, a proactive AI assistant integrated with AR smart glasses, designed to seamlessly embed informal learning into low-demand daily activities (e.g., casual walking and shopping). AiGet analyzes real-time user gaze patterns, environmental context, and user profiles, leveraging large language models to deliver personalized, context-aware knowledge with low disruption to primary tasks. In-lab evaluations and real-world testing, including continued use over multiple days, demonstrate AiGet’s effectiveness in uncovering overlooked yet surprising interests, enhancing primary task enjoyment, reviving curiosity, and deepening connections with the environment. We further propose design guidelines for AI-assisted informal learning, focused on transforming everyday moments into enriching learning experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {631},
numpages = {26},
keywords = {HMD, smart glasses, AI, large language model, multimodal information, incidental learning, informal learning, wearable-AI assistance, human-ai interaction, knowledge discovery},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713682,
author = {Zhang, Yuanhao and Wang, Yumeng and Wang, Xiyuan and He, Changyang and Huang, Chenliang and Ma, Xiaojuan},
title = {CoKnowledge: Supporting Assimilation of Time-synced Collective Knowledge in Online Science Videos},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713682},
doi = {10.1145/3706598.3713682},
abstract = {Danmaku, a system of scene-aligned, time-synced, floating comments, can augment video content to create ‘collective knowledge’. However, its chaotic nature often hinders viewers from effectively assimilating the collective knowledge, especially in knowledge-intensive science videos. With a formative study, we examined viewers’ practices for processing collective knowledge and the specific barriers they encountered. Building on these insights, we designed a processing pipeline to filter, classify, and cluster danmaku, leading to the development of CoKnowledge – a tool incorporating a video abstract, knowledge graphs, and supplementary danmaku features to support viewers’ assimilation of collective knowledge in science videos. A within-subject study (N=24) showed that CoKnowledge significantly enhanced participants’ comprehension and recall of collective knowledge compared to a baseline with unprocessed live comments. Based on our analysis of user interaction patterns and feedback on design features, we presented design considerations for developing similar support tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {632},
numpages = {22},
keywords = {Collective Knowledge, Online Video Platforms, Danmaku, Science Communication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714262,
author = {Liu, Yuhan and Shah, Aadit and Ackerman, Jordan and Saha, Manaswi},
title = {Exploring the Design Space of Real-time LLM Knowledge Support Systems: A Case Study of Jargon Explanations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714262},
doi = {10.1145/3706598.3714262},
abstract = {Knowledge gaps often arise during communication due to diverse backgrounds, knowledge bases, and vocabularies. With recent LLM developments, providing real-time knowledge support is increasingly viable, but is challenging due to shared and individual cognitive limitations (e.g.,&nbsp;attention, memory, and comprehension) and the difficulty in understanding the user’s context and internal knowledge. To address these challenges, we explore the key question of understanding how people want to receive real-time knowledge support. We built StopGap—a prototype that provides real-time knowledge support for explaining jargon words in videos—to conduct a design probe study (N=24) that explored multiple visual knowledge representation formats. Our study revealed individual differences in preferred representations and highlighted the importance of user agency, personalization, and mixed-initiative assistance. Based on our findings, we map out six key design dimensions for real-time LLM knowledge support systems and offer insights for future research in this space.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {633},
numpages = {20},
keywords = {Knowledge Support Systems, Knowledge Representation, Real-time Communication, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713337,
author = {Yun, Bhada and Feng, Dana and Chen, Ace S. and Nikzad, Afshin and Salehi, Niloufar},
title = {Generative AI in Knowledge Work: Design Implications for Data Navigation and Decision-Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713337},
doi = {10.1145/3706598.3713337},
abstract = {Our study of 20 knowledge workers revealed a common challenge: the difficulty of synthesizing unstructured information scattered across multiple platforms to make informed decisions. Drawing on their vision of an ideal knowledge synthesis tool, we developed Yodeai, an AI-enabled system, to explore both the opportunities and limitations of AI in knowledge work. Through a user study with 16 product managers, we identified three key requirements for Generative AI in knowledge work: adaptable user control, transparent collaboration mechanisms, and the ability to integrate background knowledge with external information. However, we also found significant limitations, including overreliance on AI, user isolation, and contextual factors outside the AI’s reach. As AI tools become increasingly prevalent in professional settings, we propose design principles that emphasize adaptability to diverse workflows, accountability in personal and collaborative contexts, and context-aware interoperability to guide the development of human-centered AI systems for product managers and knowledge workers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {634},
numpages = {19},
keywords = {Knowledge Synthesis, Information Visualization, Human-AI Interaction, Large Language Models, Interaction Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713448,
author = {Li, Jiahao Nick and Zhang, Zhuohao (Jerry) and Ma, Jiaju},
title = {OmniQuery: Contextually Augmenting Captured Multimodal Memories to Enable Personal Question Answering},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713448},
doi = {10.1145/3706598.3713448},
abstract = {People often capture memories through photos, screenshots, and videos. While existing AI-based tools enable querying this data using natural language, they only support retrieving individual pieces of information like certain objects in photos, and struggle with answering more complex queries that involve interpreting interconnected memories like sequential events. We conducted a one-month diary study to collect realistic user queries and generated a taxonomy of necessary contextual information for integrating with captured memories. We then introduce OmniQuery, a novel system that is able to answer complex personal memory-related questions that require extracting and inferring contextual information. OmniQuery augments individual captured memories through integrating scattered contextual information from multiple interconnected memories. Given a question, OmniQuery retrieves relevant augmented memories and uses a large language model (LLM) to generate answers with references. In human evaluations, we show the effectiveness of OmniQuery with an accuracy of 71.5\%, outperforming a conventional RAG system by winning or tying for 74.5\% of the time.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {635},
numpages = {20},
keywords = {personal memory, contextual augmentation, diary study, multimodal question answering, RAG},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714044,
author = {Kim, Dae Hyun and Jeong, Daeheon and Yadgarova, Shakhnozakhon and Shin, Hyungyu and Son, Jinho and Subramonyam, Hariharan and Kim, Juho},
title = {PlanTogether: Facilitating AI Application Planning Using Information Graphs and Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714044},
doi = {10.1145/3706598.3714044},
abstract = {In client-AI expert collaborations, the planning stage of AI application development begins from the client; a client outlines their needs and expectations while assessing available resources (pre-collaboration planning). Despite the importance of pre-collaboration plans for discussions with AI experts for iteration and development, the client often fails to reflect their needs and expectations into a concrete actionable plan. To facilitate pre-collaboration planning, we introduce PlanTogether, a system that generates tailored client support using large language models and a Planning Information Graph, whose nodes and edges represent information in the plan and the information dependencies. Using the graph, the system links and presents information that guides client’s reasoning; it provides tips and suggestions based on relevant information and displays an overview to help understand the progression through the plan. A user study validates the effectiveness of PlanTogether in helping clients navigate information dependencies and write actionable plans reflecting their domain expertise.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {636},
numpages = {23},
keywords = {AI application planning, planning support system, information graph, personalized guidance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3715579,
author = {Prasongpongchai, Thanawit and Pataranutaporn, Pat and Lertsutthiwong, Monchai and Maes, Pattie},
title = {Talk to the Hand: an LLM-powered Chatbot with Visual Pointer as Proactive Companion for On-Screen Tasks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3715579},
doi = {10.1145/3706598.3715579},
abstract = {This paper presents Pointer Assistant, a novel human-AI interaction technique for on-screen tasks. The design features a chatbot displayed as an extra mouse pointer, alongside the user’s, which proactively gives feedback on user actions while directing them to relevant areas on the screen and responding to the user’s direct chat messages. The effectiveness of the design’s key characteristics, pointer form and proactivity, was investigated in a study involving 220 participants in a financial budget planning task. Results demonstrated that the pointer design and interaction reduced task load while improving satisfaction with the experience, and increased the number of budget categories ideated during the task compared to the traditional passive chat log design. Participants viewed Pointer Assistant as a fun, innovative, and helpful visual guide while noting that its assertiveness can be improved. Future developments could offer even further enhancements to the user experience of human-AI collaboration and task outcomes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {637},
numpages = {16},
keywords = {Human-AI Interaction Technique, Large Language Models, Human-AI Collaboration, Pointing Devices, Real-Time Feedback},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713362,
author = {Deva, Roshini and Ramani, Dhruv and Divate, Tanvi and Jalota, Suhani and Ismail, Azra},
title = {"Kya family planning after marriage hoti hai?": Integrating Cultural Sensitivity in an LLM Chatbot for Reproductive Health},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713362},
doi = {10.1145/3706598.3713362},
abstract = {Access to sexual and reproductive health information remains a challenge in many communities globally, due to cultural taboos and limited availability of healthcare providers. Public health organizations are increasingly turning to Large Language Models (LLMs) to improve access to timely and personalized information. However, recent HCI scholarship indicates that significant challenges remain in incorporating context awareness and mitigating bias in LLMs. In this paper, we study the development of a culturally-appropriate LLM-based chatbot for reproductive health with underserved women in urban India. Through user interactions, focus groups, and interviews with multiple stakeholders, we examine the chatbot’s response to sensitive and highly contextual queries on reproductive health. Our findings reveal strengths and limitations of the system in capturing local context, and complexities around what constitutes “culture”. Finally, we discuss how local context might be better integrated, and present a framework to inform the design of culturally-sensitive chatbots for community health.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {638},
numpages = {23},
keywords = {LLM, chatbot, reproductive health, HCI4D},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713613,
author = {Li, Brenna and Tauseef, Saba and Truong, Khai N. and Mariakakis, Alex},
title = {A Comparative Analysis of Information Gathering by Chatbots, Questionnaires, and Humans in Clinical Pre-Consultation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713613},
doi = {10.1145/3706598.3713613},
abstract = {Information gathering is an important capability that allows chatbots to understand and respond to users’ needs, yet the effectiveness of LLM-powered chatbots at this task remains underexplored. Our work investigates this question in the context of clinical pre-consultation, wherein patients provide information to an intermediary before meeting with a physician to facilitate communication and reduce consultation inefficiencies. We conducted a study at a walk-in clinic with 45 patients who interacted with one of three conversational agents: a chatbot, a questionnaire, and a Wizard-of-Oz. We analyzed patients’ messages using metrics adapted from Grice’s maxims to assess the quality of information gathered at each conversation turn. We found that the Wizard and LLM were more successful than the questionnaire because they modified questions and asked follow-ups when participants provided unsatisfactory answers. However, the LLM did not ask nearly as many follow-up questions as the Wizard, particularly when participants provided unclear answers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {639},
numpages = {17},
keywords = {Pre-consultation, chatbot, LLM, primary care, walk-in clinic},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713918,
author = {Geng, Shixian and Inayoshi, Remi and Yang, Chi-Lan and Sramek, Zefan and Umeda, Yuya and Kasahara, Chiaki and Sato, Arissa J. and Hosio, Simo and Yatani, Koji},
title = {Beyond the Dialogue: Multi-chatbot Group Motivational Interviewing for Premenstrual Syndrome (PMS) Management},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713918},
doi = {10.1145/3706598.3713918},
abstract = {Premenstrual syndrome (PMS) is a prevalent disorder among women, often exacerbated by a lack of peer support due to associated stigmatization. Drawing inspiration from the established benefits of group therapy, particularly the sense of belonging it fosters, we developed a multi-chatbot group motivational interviewing system. The system consists of a facilitator bot and two peer bots, and simulates a group counseling environment for PMS management using Large Language Models (LLMs). We conducted a study with 63 participants and divided them into three conditions (no intervention, 1-on-1 chatbot, group chatbots) over two menstruation cycles for evaluation. Our findings revealed that participants in the group chat condition exhibited higher levels of engagement and language convergence with the chatbots. These participants were also able to engage in social learning and demonstrated motivation in coping through interactions with the chatbots. Finally, we discuss design implications for multi-chatbot interactions in supporting mental health.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {640},
numpages = {18},
keywords = {Premenstrual syndrome, Group therapy, Motivational interviewing, Chatbot, Mental Health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714255,
author = {Meng, Han and Zhang, Renwen and Wang, Ganyi and Yang, Yitian and Qin, Peinuan and Lee, Jungup and Lee, Yi-Chieh},
title = {Deconstructing Depression Stigma: Integrating AI-driven Data Collection and Analysis with Causal Knowledge Graphs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714255},
doi = {10.1145/3706598.3714255},
abstract = {Mental-illness stigma is a persistent social problem, hampering both treatment-seeking and recovery. Accordingly, there is a pressing need to understand it more clearly, but analyzing the relevant data is highly labor-intensive. Therefore, we designed a chatbot to engage participants in conversations; coded those conversations qualitatively with AI assistance; and, based on those coding results, built causal knowledge graphs to decode stigma. The results we obtained from 1,002 participants demonstrate that conversation with our chatbot can elicit rich information about people’s attitudes toward depression, while our AI-assisted coding was strongly consistent with human-expert coding. Our novel approach combining large language models (LLMs) and causal knowledge graphs uncovered patterns in individual responses and illustrated the interrelationships of psychological constructs in the dataset as a whole. The paper also discusses these findings’ implications for HCI researchers in developing digital interventions, decomposing human psychological constructs, and fostering inclusive attitudes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {641},
numpages = {21},
keywords = {Social Stigma, Depression, Causal Knowledge Graph, AI-assisted Coding, Chatbot, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713485,
author = {Choi, Ryuhaerang and Kim, Taehan and Park, Subin and Kim, Jennifer G. and Lee, Sung-Ju},
title = {Private Yet Social: How LLM Chatbots Support and Challenge Eating Disorder Recovery},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713485},
doi = {10.1145/3706598.3713485},
abstract = {Eating disorders (ED) are complex mental health conditions that require long-term management and support. Recent advancements in large language model (LLM)-based chatbots offer the potential to assist individuals in receiving immediate support. Yet, concerns remain about their reliability and safety in sensitive contexts such as ED. We explore the opportunities and potential harms of using LLM-based chatbots for ED recovery. We observe the interactions between 26&nbsp;participants with ED and an LLM-based chatbot, WellnessBot, designed to support ED recovery, over 10 days. We discovered that our participants have felt empowered in recovery by discussing ED-related stories with the chatbot, which served as a personal yet social avenue. However, we also identified harmful chatbot responses, especially concerning individuals with ED, that went unnoticed partly due to participants’ unquestioning trust in the chatbot’s reliability. Based on these findings, we provide design implications for safe and effective LLM-based interventions in ED management.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {642},
numpages = {19},
keywords = {chatbots, large language models, conversational agents, eating disorder, mental health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714196,
author = {Liu, Dingdong and Zhang, Yujing and Zhao, Bolin and Ma, Shuai and Shi, Chuhan and Ma, Xiaojuan},
title = {Scaffolded Turns and Logical Conversations: Designing Humanized LLM-Powered Conversational Agents for Hospital Admission Interviews},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714196},
doi = {10.1145/3706598.3714196},
abstract = {Hospital admission interviews are critical for patient care but strain nurses’ capacity due to time constraints and staffing shortages. While LLM-powered conversational agents (CAs) offer automation potential, their rigid sequencing and lack of humanized communication skills risk misunderstandings and incomplete data capture. Through participatory design with clinicians and volunteers, we identified essential communication strategies and developed a novel CA that implements these strategies through: (1) dynamic topic management using graph-based conversation flows, and (2) context-aware scaffolding with few-shot prompt tuning. Technical evaluation on an admission interview dataset showed our system achieving performance comparable to or surpassing human-written ground truth, while outperforming prompt-engineered baselines. A between-subject study (N=44) demonstrated significantly improved user experience and data collection accuracy compared to existing solutions. We contribute a framework for humanizing medical CAs by translating clinician expertise into algorithmic strategies, alongside empirical insights for balancing efficiency and empathy in healthcare interactions, and considerations for generalizability.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {643},
numpages = {23},
keywords = {Conversational Agents, Clinical Communication, Hospital Admission Interview, Healthcare Automation, Scaffolded Dialogue, Participatory Design, Large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713307,
author = {Haag, David and Kumar, Devender and Gruber, Sebastian and Hofer, Dominik P. and Sareban, Mahdi and Treff, Gunnar and Niebauer, Josef and Bull, Christopher N and Schmidt, Albrecht and Smeddinck, Jan David},
title = {The Last JITAI? Exploring Large Language Models for Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac Rehabilitation Setting},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713307},
doi = {10.1145/3706598.3713307},
abstract = {We evaluated the viability of using Large Language Models (LLMs) to trigger and personalize content in Just-in-Time Adaptive Interventions (JITAIs) in digital health. As an interaction pattern representative of context-aware computing, JITAIs are being explored for their potential to support sustainable behavior change, adapting interventions to an individual's current context and needs. Challenging traditional JITAI implementation models, which face severe scalability and flexibility limitations, we tested GPT-4 for suggesting JITAIs in the use case of heart-healthy activity in cardiac rehabilitation. Using three personas representing patients affected by CVD with varying severeness and five context sets per persona, we generated 450 JITAI decisions and messages. These were systematically evaluated against those created by 10 laypersons (LayPs) and 10 healthcare professionals (HCPs). GPT-4-generated JITAIs surpassed human-generated intervention suggestions, outperforming both LayPs and HCPs across all metrics (i.e., appropriateness, engagement, effectiveness, and professionalism). These results highlight the potential of LLMs to enhance JITAI implementations in personalized health interventions, demonstrating how generative AI could revolutionize context-aware computing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {644},
numpages = {18},
keywords = {JITAIs, LLMs, adaptive interventions, context-aware computing, digital health, generative AI, healthcare AI, human-AI interaction, just-in-time adaptive interventions, large language models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714212,
author = {Liu, Yujia and Zha, Siyu and Zhang, Yuewen and Wang, Yanjin and Zhang, Yangming and Xin, Qi and Nie, Lun Yiu and Zhang, Chao and Xu, Yingqing},
title = {BrickSmart: Leveraging Generative AI to Support Children's Spatial Language Learning in Family Block Play},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714212},
doi = {10.1145/3706598.3714212},
abstract = {Block-building activities are crucial for developing children’s spatial reasoning and mathematical skills, yet parents often lack the expertise to guide these activities effectively. BrickSmart, a pioneering system, addresses this gap by providing spatial language guidance through a structured three-step process: Discovery \&amp; Design, Build \&amp; Learn, and Explore \&amp; Expand. This system uniquely supports parents in 1) generating personalized block-building instructions, 2) guiding parents to teach spatial language during building and interactive play, and 3) tracking children’s learning progress, altogether enhancing children’s engagement and cognitive development. In a comparative study involving 12 parent-child pairs children aged 6-8 years) for both experimental and control groups, BrickSmart demonstrated improvements in supportiveness, efficiency, and innovation, with a significant increase in children’s use of spatial vocabularies during block play, thereby offering an effective framework for fostering spatial language skills in children.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {645},
numpages = {19},
keywords = {AI Agent, Parent-child, Spatial Language, Block Play, Large Language Model, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713394,
author = {Matthews, Sarah and Danby, Susan and Westwood, Sophie and Theobald, Maryanne and Wyeth, Peta},
title = {Designing for Transactional Moments: Features of Tools for Child-centred Speech Language Teletherapy},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713394},
doi = {10.1145/3706598.3713394},
abstract = {Teletherapy for speech-language therapy (SLT) has become essential for many families. Early intervention for young children is important to ensure that developmental milestones are met. In this study, from a corpus of 10 videos, we present three cases of online and in-person therapy sessions with children between the ages of 3 and 6. Our analysis shows how online and in-person SLT sessions use tools, how they are conscripted into social and transactional moments, and identifies features of tools that support or hinder therapists’ goals (see Figure 1). From our findings, we discuss in detail four overarching features of tools and implications for design. These features support engagement, space usage, child-centred play, and adaptability in therapy sessions. The paper outlines how these features are present in the tools used in SLT, and describes how they impact SLT activities, therapists’ and children's goals, and the environment for social transactional activities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {646},
numpages = {17},
keywords = {Children, Speech-language Therapy, Teletherapy, Therapy Tools},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713386,
author = {Kim, Minji and Shim, Minkyu and Chai, Jun Ho and Ko, Eon-Suk and Lee, Youngki},
title = {Lookee: Gaze Tracking-based Infant Vocabulary Comprehension Assessment and Analysis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713386},
doi = {10.1145/3706598.3713386},
abstract = {Measuring preverbal vocabulary comprehension of young children is vital for early intervention and developmental evaluation, yet challenging due to their limited communication abilities. We introduce Lookee, an AI-powered vocabulary comprehension assessment tool through gaze tracking for toddlers in the preverbal stage. Lookee incorporates the Intermodal Preferential Looking Paradigm (IPLP), which is one of the prominent word comprehension measures for toddlers and estimates word comprehension through a random forest model analysis. We design and validate Lookee through user studies involving 19 toddlers and their parents. Then we identify necessary design requirements from potential stakeholders’ perspectives through in-depth interviews including researchers, clinicians, and parents. As a result, Lookee achieves considerable estimation accuracy with sufficient system usability and demonstrates key design requirements for each stakeholder group. From our study, we highlight necessary design implications in developing and validating AI-powered clinical tools for toddlers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {647},
numpages = {15},
keywords = {human-AI Interaction, children, healthcare, gaze tracking, language assessment, machine learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713380,
author = {Arunkumar, Anjana and Padilla, Lace M. and Bryan, Chris},
title = {Lost in Translation: How Does Bilingualism Shape Reader Preferences for Annotated Charts?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713380},
doi = {10.1145/3706598.3713380},
abstract = {Visualizations are powerful tools for conveying information but often rely on accompanying text for essential context and guidance. This study investigates the impact of annotation patterns on reader preferences and comprehension accuracy among multilingual populations, addressing a gap in visualization research. We conducted experiments with two groups fluent in English and either Tamil (n = 557) or Arabic (n = 539) across six visualization types, each varying in annotation volume and semantic content. Full-text annotations yielded the highest comprehension accuracy across all languages, while preferences diverged: English readers favored highly annotated charts, whereas Tamil/Arabic readers preferred full-text or minimally annotated versions. Semantic variations in annotations (L1–L4) did not significantly affect comprehension, demonstrating the robustness of text comprehension across languages. English annotations were generally preferred, with a tendency to think technically in English linked to greater aversion to non-English annotations, though this diminished among participants who regularly switched languages internally. Non-English annotations incorporating visual or external knowledge were less favored, particularly in titles. Our findings highlight cultural and educational factors influencing perceptions of visual information, underscoring the need for inclusive annotation practices for diverse linguistic audiences. All data and materials are available at: https://osf.io/ckdb4/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {648},
numpages = {22},
keywords = {Visualization, Text, Annotation, Multilingualism, Preference},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713376,
author = {Zhao, Maozheng and Huang, Michael Xuelin and Huang, Nathan G and Cai, Shanqing and Huang, Henry and Huang, Michael G and Zhai, Shumin and Ramakrishnan, IV and Bi, Xiaojun},
title = {Tap&amp;Say: Touch Location-Informed Large Language Model for Multimodal Text Correction on Smartphones},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713376},
doi = {10.1145/3706598.3713376},
abstract = {While voice input offers a convenient alternative to traditional text editing on mobile devices, practical implementations face two key challenges: 1) reliably distinguishing between editing commands and content dictation, and 2) effortlessly pinpointing the intended edit location. We propose Tap&amp;Say, a novel multimodal system that combines touch interactions with Large Language Models (LLMs) for accurate text correction. By tapping near an error, users signal their edit intent and location, addressing both challenges. Then, the user speaks the correction text. Tap&amp;Say utilizes the touch location, voice input, and existing text to generate contextually relevant correction suggestions. We propose a novel touch location-informed attention layer that integrates the tap location into the LLM’s attention mechanism, enabling it to utilize the tap location for text correction. We fine-tuned the touch location-informed LLM on synthetic touch locations and correction commands, achieving significantly higher correction accuracy than the state-of-the-art method VT&nbsp;[45]. A 16-person user study demonstrated that Tap&amp;Say outperforms VT &nbsp;[45] with (16.4\%) shorter task completion time and (47.5\%) fewer keyboard clicks and is preferred by users.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {649},
numpages = {17},
keywords = {LLMs, text correction, voice input, multi-modal},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714181,
author = {Ding, Jiexin and Zhao, Bowen and Wang, Yuntao and Liu, Xinyun and Hao, Rui and Chatterjee, Ishan and Shi, Yuanchun},
title = {Unknown Word Detection for English as a Second Language (ESL) Learners using Gaze and Pre-trained Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714181},
doi = {10.1145/3706598.3714181},
abstract = {English as a Second Language (ESL) learners often encounter unknown words that hinder their text comprehension. Automatically detecting these words as users read can enable computing systems to provide just-in-time definitions, synonyms, or contextual explanations, thereby helping users learn vocabulary in a natural and seamless manner. This paper presents EyeLingo, a transformer-based machine learning method that predicts the probability of unknown words based on text content and eye gaze trajectory in real time with high accuracy. A 20-participant user study revealed that our method can achieve an accuracy of 97.6\%, and an F1-score of 71.1\%. We implemented a real-time reading assistance prototype to show the effectiveness of EyeLingo. The user study shows improvement in willingness to use and usefulness compared to baseline methods.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {650},
numpages = {16},
keywords = {Unknown word detection, gaze, pre-trained language model.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713945,
author = {Zhao, Yijun and Pan, Jiangyu and Cao, Jiacheng and Zhang, Jiarong and Dong, Yan and Wang, Yicheng and Hansen, Preben and Wang, Guanyun},
title = {Unlocking the Power of Speech: Game-Based Accent and Oral Communication Training for Immigrant English Language Learners via Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713945},
doi = {10.1145/3706598.3713945},
abstract = {With the growing number of immigrants globally, language barriers have become a significant challenge, particularly for those entering English-speaking countries. Traditional language learning methods often fail to provide sufficient practical opportunities, especially for diverse accents. To address this, we introduce Language Urban Odyssey (LUO), a serious game that leverages large language models (LLMs) and game-based learning to offer a low-cost, accessible virtual environment for English learners. Built on the Minecraft platform, LUO offers real-time speech interaction with NPCs of various accents, supported by multi-modal feedback. A controlled study (N=30) showed improvements in speaking abilities, accent comprehension, and emotional confidence. Our findings suggest that LUO provides a scalable, immersive platform that bridges gaps in language learning for immigrants facing cultural and social challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {651},
numpages = {24},
keywords = {Game-Based Learning, Large Language Models, Immigrant English Language Learners, Oral Communication, Human-AI Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713820,
author = {Neil, Lorenzo C. and Healy, Charlotte and Haney, Julie},
title = {"A five-year-old could understand it" versus "This is way too confusing": Exploring Non-expert Understandings and Perceptions of Cybersecurity Definitions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713820},
doi = {10.1145/3706598.3713820},
abstract = {Experts struggle with explaining cybersecurity in a language and tone appropriate for non-expert audiences. This communication gap may make it difficult for a broad and diverse audience to fully engage in cybersecurity. Fundamental forms of communication, such as definitions, can be for a means for experts to communicate cybersecurity concepts to non-experts. To explore how non-experts perceive cybersecurity definitions and identify potential areas of misunderstanding and misconception, we performed a semi-structured interview study with 30 non-experts of different generations (ages) and education levels. Our findings reveal that non-experts may have incomplete mental models of cybersecurity, misinterpret terms and concepts commonly used in definitions, and express strong preferences for how cybersecurity is defined. While our study focuses on definitions, our results have broader implications for how cybersecurity should be communicated to a diverse range of individuals.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {652},
numpages = {19},
keywords = {cybersecurity, definitions, communications},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714053,
author = {Kang, Hyeonsu B and Lin, David Chuan-En and Chen, Yan-Ying and Hong, Matthew K. and Martelaro, Nikolas and Kittur, Aniket},
title = {BioSpark: Beyond Analogical Inspiration to LLM-augmented Transfer},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714053},
doi = {10.1145/3706598.3714053},
abstract = {We present BioSpark, a system for analogical innovation designed to act as a creativity partner in reducing the cognitive effort in finding, mapping, and creatively adapting diverse inspirations. While prior approaches have focused on initial stages of finding inspirations, BioSpark uses LLMs embedded in a familiar, visual, Pinterest-like interface to go beyond inspiration to supporting users in identifying the key solution mechanisms, transferring them to the problem domain, considering tradeoffs, and elaborating on details and characteristics. To accomplish this BioSpark introduces several novel contributions, including a tree-of-life enabled approach for generating relevant and diverse inspirations, as well as AI-powered cards including ‘Sparks’ for analogical transfer; ‘Trade-offs’ for considering pros and cons; and ‘Q&amp;A’ for deeper elaboration. We evaluated BioSpark through workshops with professional designers and a controlled user study, finding that using BioSpark led to a greater number of generated ideas; those ideas being rated higher in creative quality; and more diversity in terms of biological inspirations used than a control condition. Our results suggest new avenues for creativity support tools embedding AI in familiar interaction paradigms for designer workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {653},
numpages = {29},
keywords = {Goal-driven Analogies, Analogical Transfer, Design Creativity, Ideation, Large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713312,
author = {Hanafi, Maeda F and Reiss, Frederick and Katsis, Yannis and Moore, Robert and Falakmasir, Mohammad H and Wang, Pauline and Wood, David and Liu, Changchang},
title = {Diagnosing and Prioritizing Issues in Automated Order-Taking Systems: A Machine-Assisted Error Discovery Approach},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713312},
doi = {10.1145/3706598.3713312},
abstract = {Troubles in speaking, hearing, and understanding occur routinely in any kind of natural conversational setting. The natural flow of conversation includes methods for repairing such troubles by repeating or paraphrasing all or parts of prior turns. In the case of conversational AI systems, these troubles occur due to failure of different components of the system such as the speech recognition, natural language understanding, and natural language generation. Such errors may occur infrequently, but often enough to have a significant impact on key performance indicators (KPIs). Identifying the root cause of these errors is a complex task that requires a team to meticulously examine and interpret the interaction between the voice agent and customers. In this work, we present an interactive system, DTTool, that surfaces system-generated annotations that hint at anomalous events that lead to candidate errors that impact KPIs and demonstrate how the team could discover unknown errors using DTTool.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {654},
numpages = {18},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713164,
author = {Grace D, Thomas and Abel, Christie and Salen Tekinba\c{s}, Katie},
title = {Learning Curiosity through Play: Exploring the Role of Games and Interactive Design in Museums},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713164},
doi = {10.1145/3706598.3713164},
abstract = {This paper investigates museum educators' perceptions of play, games, and learning, as well as their approaches to designing and implementing interactive experiences. Through a thematic analysis, we found that museum educators tend to favor games and hands-on learning due to the strong association between learning, play, and curiosity. This connection often drives educators to integrate games and interactive elements into museum experiences. Key challenges in the design process included limited resources, time, and skills, as well as more contextual tensions. These included balancing 'fun' versus serious learning objectives and addressing discomfort that may arise from certain learning experiences, with the recognition that not all games need to be designed solely for fun. Our paper contributes to a deeper understanding of how educators incorporate game-like and playful learning in museums. We also offer a design considerations in the form of a checklist to guide other museum educators in developing effective play-based learning experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {655},
numpages = {14},
keywords = {Games, Interaction Design, Learning, Museums, Play},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713480,
author = {Xu, Songlin and Hu, Dongyin and Wang, Ru and Zhang, Xinyu},
title = {PeerEdu: Bootstrapping Online Learning Behaviors via Asynchronous Area of Interest Sharing from Peer Gaze},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713480},
doi = {10.1145/3706598.3713480},
abstract = {Human visual attention is susceptible to social influences. In education, peer effects impact student learning, but their precise role in modulating attention remains unclear. To this end, we have developed an online education system that provides visual feedback to students based on the area of interest sharing of peer students’ gaze patterns. Our experiment (N=311) suggested that although peer attention manipulated students’ gaze, individuals adapted their viewing strategies rather than always mirroring peer focus. Furthermore, intentionally guiding students’ gaze along the lecture pace did not always improve learning outcomes. Instead, students able to adaptively adjust their focus based on personal needs showed enhanced performance. These findings elucidate how peer visual attention shapes students’ gaze patterns, deepening understanding of peer influence on learning. They also offer insights into designing adaptive online learning interventions leveraging peer attention modelling to optimize student attentiveness and learning success.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {656},
numpages = {14},
keywords = {Student Behavioral Intervention, Peer Effect, Gaze Sharing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713321,
author = {Shen, Ximing and Li, Xuan and Kamiyama, Youichi and Hynds, Danny and Barbareschi, Giulia and LC, RAY and Wakisaka, Sohei and Horie, Arata and Minamizawa, Kouta},
title = {"It's Like Being On Stage": Conveying Dancers' Expressiveness Through A Haptic-Installed Contemporary Dance Performance},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713321},
doi = {10.1145/3706598.3713321},
abstract = {In dance performances, choreography, music and lighting are combined to convey meaning to the audience. However, this communication typically relies on visual and auditory stimuli alone. While haptic technologies have been leveraged to enhance the perception of dancers’ movements, less focus has been placed on exploring their potential in enhancing dancers’ somatic expressiveness. Through co-design activities with 5 professional contemporary dancers, we crafted an interdisciplinary combination of choreography and haptics. In total, 128 audience members watched one of three live performances while wearing custom-made haptic wristbands. From an open-ended questionnaire and interviews with audience members, we explore how the introduction of haptics deepens their embodied sensations and helps to create a sense of resonance with the dancers. Based on our findings, we discuss implications for future directions in how haptic technologies could drive innovation in dance performances from the point of view of both dancers’ creativity and audience experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {657},
numpages = {18},
keywords = {contemporary dance, embodied interaction, improvisation, haptic feedback},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713281,
author = {Tao, Ye and Fu, Xiaohui and Wu, Jiaying and Bian, Ze and Zhu, Aiyu and Bao, Qi and Zheng, Weiyue and Wang, Yubo and Zhu, Bin and Yang, Cheng and Zhou, Chuyi},
title = {AIFiligree: A Generative AI Framework for Designing Exquisite Filigree Artworks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713281},
doi = {10.1145/3706598.3713281},
abstract = {Filigree art, which represents typical intricate metalwork, has been captivating audiences worldwide with its delicate lace-like patterns and interwoven metal wires’ refined aesthetics. Particularly, Chinese Intangible Cultural Heritage filigree craftsmanship has a unique aesthetic value in fine patterns and complex three-dimensional shapes. However, designing and creating filigree artworks is a labor-intensive and technically complex task and often requires extensive training and a deep understanding of the craft, which limits its design aesthetic and cultural continuity. Aiming to overcome these challenges, this study proposes an artificial intelligence (AI) -aided method that uses AI-generated content (AIGC) technology to accelerate the visualization process of this time-consuming and intricate craft by investigating the role of AI in craft design. First, a comprehensive study of filigree art culture is conducted to identify more than ten historic filigree techniques to obtain AI opportunities. Then, an AI-powered framework called AIFiligree is developed by optimizing culture-based labels and training parameters, enabling the generation of highly authentic fine filigree structures. Further, user workflows are introduced to support diverse design scenarios. Through user studies involving 22 filigree experts and 16 designers, we finally gained insights into AI’s opportunities and challenges in cultural learning, expression, and design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {658},
numpages = {18},
keywords = {Filigree, AIGC, AI design tools, Cultural intangible culture heritage},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713274,
author = {Zheng, Chanjin and Yu, Zengyi and Jiang, Yilin and Zhang, Mingzi and Lu, Xunuo and Jin, Jing and Gao, Liteng},
title = {ArtMentor: AI-Assisted Evaluation of Artworks to Explore Multimodal Large Language Models Capabilities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713274},
doi = {10.1145/3706598.3713274},
abstract = {Can Multimodal Large Language Models (MLLMs), with capabilities in perception, recognition, understanding, and reasoning, act as independent assistants in art evaluation dialogues? Current MLLM evaluation methods, reliant on subjective human scoring or costly interviews, lack comprehensive scenario coverage. This paper proposes a process-oriented Human-Computer Interaction (HCI) space design for more accurate MLLM assessment and development. This approach aids teachers in efficient art evaluation and records interactions for MLLM capability assessment. We introduce ArtMentor, a comprehensive space integrating a dataset and three systems for optimized MLLM evaluation. It includes 380 sessions from five art teachers across nine critical dimensions. The modular system features entity recognition, review generation, and suggestion generation agents, enabling iterative upgrades. Machine learning and natural language processing ensure reliable evaluations. Results confirm GPT-4o’s effectiveness in assisting teachers in art evaluation dialogues. Our contributions are available at https://artmentor.github.io/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {18},
keywords = {AI-Assisted Artwork Evaluation, GPT-4o, Multimodal Large Language Models, Human-Computer Interaction Dataset Design, Entity Recognition, Multi-Agent for Iterative Upgrades.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714042,
author = {Li, Yongming and Zhang, Hangyue and Cui, Andrea Yaoyun and Ma, Zisong and Song, Yunpeng and Cai, Zhongmin and Huang, Yun},
title = {EyeSee: Enhancing Art Appreciation through Anthropomorphic Interpretations from Multiple Perspectives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714042},
doi = {10.1145/3706598.3714042},
abstract = {Art appreciation serves as a crucial medium for emotional communication and sociocultural dialogue. In the digital era, fostering deep user engagement on online art appreciation platforms remains a challenge. Leveraging large language models (LLMs), we present EyeSee, a system designed to engage users through anthropomorphic characters. We implemented and evaluated three modes– Narrator, Artist, and In-Situ–acting as a third-person narrator, a first-person creator, and first-person created objects, respectively, across two sessions: Narrative and Recommendation. We conducted a within-subject study with 24 participants. In the Narrative session, we found that the In-Situ and Artist modes had higher aesthetic appeal than the Narrator mode, although the Artist mode showed lower perceived usability. Additionally, from the Narrative to the Recommendation session, we found that the user-perceived relatability and believability were sustained, but the user-perceived consistency and stereotypicality changed. Our findings suggest novel implications for anthropomorphic character design in enhancing user engagement.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {660},
numpages = {23},
keywords = {Online Art Appreciation, Anthropomorphic, Character Design, Emotional Engagement, Cognitive Engagement},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714159,
author = {Wang, Huanchen and Qiu, Tianrun and Li, Jiaping and Lu, Zhicong and Ma, Yuxin},
title = {HarmonyCut: Supporting Creative Chinese Paper-cutting Design with Form and Connotation Harmony},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714159},
doi = {10.1145/3706598.3714159},
abstract = {Chinese paper-cutting, an Intangible Cultural Heritage (ICH), faces challenges from the erosion of traditional culture due to the prevalence of realism alongside limited public access to cultural elements. While generative AI can enhance paper-cutting design with its extensive knowledge base and efficient production capabilities, it often struggles to align content with cultural meaning due to users’ and models’ lack of comprehensive paper-cutting knowledge. To address these issues, we conducted a formative study (N=7) to identify the workflow and design space, including four core factors (Function, Subject Matter, Style, and Method of Expression) and a key element (Pattern). We then developed HarmonyCut, a generative AI-based tool that translates abstract intentions into creative and structured ideas. This tool facilitates the exploration of suggested related content (knowledge, works, and patterns), enabling users to select, combine, and adjust elements for creative paper-cutting design. A user study (N=16) and an expert evaluation (N=3) demonstrated that HarmonyCut effectively provided relevant knowledge, aiding the ideation of diverse paper-cutting designs and maintaining design quality within the design space to ensure alignment between form and cultural connotation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {661},
numpages = {22},
keywords = {Creativity support tool, Chinese paper-cutting, Generative AI-aided design, Intangible Cultural Heritage},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714157,
author = {Zhao, Shuo and Huang, Yifei and He, Xiaoyang and Tong, Xin and Li, Xin and Wu, Dan},
title = {Reviving Mural Art through Generative AI: A Comparative Study of AI-Generated and Hand-Crafted Recreations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714157},
doi = {10.1145/3706598.3714157},
abstract = {Virtual reality (VR) provides an immersive and interactive platform for presenting ancient murals, enhancing users’ understanding and appreciation of these invaluable culture treasures. However, traditional hand-crafted methods for recreating murals in VR are labor-intensive, time-consuming, and require significant expertise, limiting their scalability for large-scale mural scenes. To address these challenges, we propose a comprehensive pipeline that leverages generative AI to automate the mural recreation process. This pipeline is validated by the reconstruction of Foguang Temple scene in Dunhuang Murals. A user study comparing the AI-generated scene with a hand-crafted one reveals no significant differences in presence, authenticity, engagement and enjoyment, and emotion. Additionally, our findings identify areas for improvement in AI-generated recreations, such as enhancing historical fidelity and offering customization. This work paves the way for more scalable, efficient, and accessible methods of revitalizing cultural heritage in VR, offering new opportunities for mural preservation, demonstration, and dissemination using VR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {662},
numpages = {20},
keywords = {virtual reality, culture heritage, mural recreation, generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714275,
author = {Liu, Long and Ren, Junbin and Fan, Zeyuan and Li, Chenhui and He, Gaoqi and Wang, Changbo and Gao, Yang and Li, Chen},
title = {SandTouch: Empowering Virtual Sand Art in VR with AI Guidance and Emotional Relief},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714275},
doi = {10.1145/3706598.3714275},
abstract = {Sand painting is a highly aesthetic and valuable form of art but often constrained by the need for specific equipment and the associated learning curve. To address these challenges, we developed a VR sand painting system, SandTouch, offering an immersive and intuitive sand painting experience that closely mirrors the interaction with physical sand. Leveraging advanced gesture recognition technology, SandTouch allows users to create intricate sand art in a virtual environment, capturing the fine sensations of real sand manipulation along with realistic sound feedback. The integration of AI agent further enhances the experience by intelligently interpreting users’ creative intentions based on real-time interactions, offering contextually relevant artistic suggestions. Comprehensive evaluations have demonstrated a significant increase in user engagement and immersion. Furthermore, the realistic sound feedback enhances emotional relief and deepens the painting experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {663},
numpages = {21},
keywords = {Sand Painting, Virtual Reality, AI-Guidance, Emotional Relief},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714166,
author = {Zhang, Zhongyue and Huang, Yuru and Wang, Mengyang and Fan, Mingming},
title = {"Watch, Smell, Ask, Touch": Practices, Challenges, and Technological Support in Ability Assessment of Older Adults from Practitioners' Perspectives in China},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714166},
doi = {10.1145/3706598.3714166},
abstract = {As the global population ages, comprehensively assessing older adults’ physical, cognitive, and social capacities is increasingly crucial for guiding care decisions and resource allocation. While technology shows promise in enhancing these assessments, there is limited understanding of how practitioners conduct such assessments and how they perceive and experience assessment technologies in real-world settings. This paper presents an exploratory study of the practices and experiences of practitioners in China’s Ability Assessment of Older Adults (AAOA), based on 28 on-site observations and in-depth interviews with eight assessors in a large southeastern city. Our findings reveal the adaptive workflows, strategies, and diverse challenges faced by assessors, highlighting the complexity, context-specificity, and collaborative nature of these processes. While grounded in China’s evolving healthcare system, these findings also resonate with broader global challenges in aging care, particularly in resource-constrained settings. Based on these insights, we propose implications for designing practical assessment technologies and considerations for better supporting assessors and older adults across care contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {664},
numpages = {20},
keywords = {Ability Assessment of Older Adults, Needs Assessment, Older Adults, Technology, Practitioners, Geriatric Care},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714105,
author = {Hsu, Long-Jing and Foster, Alex and Sabanovic, Selma and Chung, Chia-Fang},
title = {Designing with Dynamics: Reflections on Co-design Workshops Between People Living with Dementia and Their Care Partners},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714105},
doi = {10.1145/3706598.3714105},
abstract = {Human-Computer Interaction (HCI) researchers focusing on informal care partners and people living with dementia often create personas, incorporating expectations about the pair’s relationship dynamics to guide their research and design outcome. Similarly, in our two iterations of co-design workshops aimed at designing a robot to enhance these relationships, we started with expectation that care partners would primarily lead the relationship. This assumption guided the design of the co-design workshops, which included diary studies followed by co-design sessions with eight dyads. However, our results from reflexive thematic analysis challenge the initial view that relationship dynamics follow a single persona or outcome. Instead, the diversity in relationship dynamics led to multiple design outcomes, highlighting the need for HCI researchers to consider care dynamics when designing and conducting research studies for care partnerships. Researchers can structure and create iterative co-design workshops to accommodate these dynamics by incorporating ongoing reflection on the dyad’s relationship dynamics and the researchers’ influence throughout all co-design stages. This approach enhances researchers’ ability to create more thoughtful and effective relationship technology.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {665},
numpages = {16},
keywords = {co-design, people living with dementia, PLwD, dementia, caregivers, older adults},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714012,
author = {Soubutts, Ewan and Singh, Aneesha and Ashcroft, Alice and Knowles, Bran and McDowell, Julia and Tsouvalis, Judith and Fledderjohann, Jasmine and Swarbrick, Caroline and Harper, Richard and Rogers, Yvonne},
title = {Hidden Opportunities for Elder Living: Understanding Shared Technology Troubles and Benefits for Older Adults in the UK Cost of Living Crisis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714012},
doi = {10.1145/3706598.3714012},
abstract = {The uptake of digital technology by older adults and service-providers has been partly driven by the pandemic but more recently by the erosion of in-person services because of increasing austerity and a harsher global economic climate. Against the backdrop of the UK’s cost of living crisis, we examine technology used frequently within five older adults’ households. Through two rounds of interviews and participant diaries, we show benefits and struggles of participants’ costly technology use, reflecting on what ‘cost of living’ means when technology designed to simplify older peoples lives, encounters problems. For HCI practitioners, we provide evidence of how personal smart devices can be better tailored to help older adults support themselves both economically and practically, during the cost of living crisis. We propose avenues for future research and design that better support indirect costs and reflect on how personal devices can be made self-sustaining, integrated and repairable.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {666},
numpages = {17},
keywords = {Older adults, cost of living, smart homes, workarounds, finance, energy, wellbeing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713339,
author = {Zhou, Shixu and Lin, Weiyue and Xu, Zuyu and Wei, Xiaoying and Huang, Raoyi and Ma, Xiaojuan and Fan, Mingming},
title = {JournalAIde: Empowering Older Adults in Digital Journal Writing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713339},
doi = {10.1145/3706598.3713339},
abstract = {Digital journaling offers a means for older adults to express themselves, document their lives, and engage in self-reflection, contributing to the maintenance of cognitive function and social connectivity. Although previous works have investigated the motivations and benefits of digital journaling for older adults, little technical support has been designed to offer assistance. We conducted a formative study with older adults and uncovered their encountered challenges and preferences for technical support. Informed by the findings, we designed a Large Language Model (LLM) empowered tool, JournalAIde, which provides vicarious experience, idea organization, sample text generation, and visual editing cues to enhance older adults’ confidence, writing ability, and sustained attention during digital journaling. Through a between-subjects study and a field deployment, we demonstrated the JournalAIde’s significant effectiveness compared to a baseline system in empowering older adults in digital journaling. We further investigated older adults’ experiences and perceptions of LLM writing assistance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {667},
numpages = {19},
keywords = {Older adults’ creativity; Digital journal writing; Accessibility},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714234,
author = {Barbareschi, Giulia and Sato, Chihiro and Senyer, Seray and Junpeng, Michael Pan and Zhao, Jianrui and Chen, Dunya and Ellis, Kirsten and Kunze, Kai},
title = {Sticking With Electronics for Crafting Practices: An Inclusive Approach to Promote Making Literacy Among Older Adults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714234},
doi = {10.1145/3706598.3714234},
abstract = {Making activities have been shown to offer potential for inclusive access to digital literacy amongst marginalized groups, but research exploring such approaches with older adults is still scarce. Our study introduces an electronic-card-making workshop, co-developed with Japanese older women to foster engagement aligning with their purpose, physical and cognitive skills. The workshop was initially delivered to 14 women. Following initial success, 4 participants decided to deliver a second workshop, with the support of our team, for 15 local children. We present findings from both these workshops unpacking how women’s motivation for engaging in eMaking revolved around the idea of sharing, both through displaying created artefacts and the transmission of knowledge, how their learning consolidated around implicit actions and was supported by the creation of escalation strategies when they felt that demands exceeded their level of proficiency. Based on our results, we propose guidelines for inclusive eMaking involving novice older women.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {668},
numpages = {18},
keywords = {Older adults, digital literacy, making, crafting, Japan},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714207,
author = {Hu, Ruipu and Lazar, Amanda},
title = {Surfacing Technology Routines While Studying Videoconferencing Among Older Adults with Cognitive Concerns},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714207},
doi = {10.1145/3706598.3714207},
abstract = {HCI research increasingly focuses on everyday life to inform technology design for older adults. Routines, a key aspect of everyday life, have been studied to contextualize technology use. Our work brings attention to understanding of routines around videoconferencing technology among older adults with cognitive concerns. We conducted a week-long study involving observations, interviews, and a modified diary study with six older adults with cognitive concerns who videoconference at least once a week. Our analysis revealed how routines helped people adapt to videoconferencing constraints, how participants navigated disruptions to their videoconferencing routines, and the kinds of routines that were more challenging to manage when faced disruptions. In the discussion, we describe why routines are particularly important to study and support for people with cognitive concerns, the importance of studying older adults’ routines to support technology use in HCI, and methods that can enrich HCI research by uncovering insights into routines.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {669},
numpages = {16},
keywords = {Accessibility, Cognitive Concerns, Design for Aging, Older Adults, Videoconferencing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713823,
author = {Turmo Vidal, Laia and Waern, Annika and Cabanas-Vald\'{e}s, Rosa and van Loo, Lauren and Li, Yinchu and Meenaakshisundaram, Karthik Venkataraman},
title = {Towards Personalized Physiotherapy through Interactive Machine Learning: A Conceptual Infrastructure Design for In-Clinic and Out-of-Clinic Support},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713823},
doi = {10.1145/3706598.3713823},
abstract = {Machine learning (ML) is increasingly used in healthcare practices, due to its potential to support personalization, diagnostic and prediction, automatization, and increase effectiveness. In physiotherapy, most existing ML solutions suggest replacing the physiotherapist, neglecting the complexity of their skills and practice. We articulate an alternative to the design of ML technology for physiotherapy: one that emphasizes the relational aspects of the practice and offers personalized support to physiotherapists and patients alike. Based on domain studies and design explorations with physiotherapists, interaction designers and ML experts, we present 1) insights on physiotherapy’s in-clinic and out-of-clinic looped structure, 2) opportunities and requirements to integrate ML in that loop, and 3) a conceptual interactive ML-based infrastructure that exploits those opportunities. Our work widens current ML developmental aims for physiotherapy, proposing a vision that encodes sustainable sociotechnical relationships in healthcare practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {670},
numpages = {19},
keywords = {Machine Learning, Physiotherapy, Personalization, Training, Interactive Machine Learning, Conceptual Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714112,
author = {Kamikubo, Rie and Kayukawa, Seita and Kaniwa, Yuka and Wang, Allan and Kacorri, Hernisa and Takagi, Hironobu and Asakawa, Chieko},
title = {Beyond Omakase: Designing Shared Control for Navigation Robots with Blind People},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714112},
doi = {10.1145/3706598.3714112},
abstract = {Autonomous navigation robots can increase the independence of blind people but often limit user control—following what is called in Japanese an "omakase" approach where decisions are left to the robot. This research investigates ways to enhance user control in social robot navigation, based on two studies conducted with blind participants. The first study, involving structured interviews (N=14), identified crowded spaces as key areas with significant social challenges. The second study (N=13) explored navigation tasks with an autonomous robot in these environments and identified design strategies across different modes of autonomy. Participants preferred an active role, termed the "boss" mode, where they managed crowd interactions, while the "monitor" mode helped them assess the environment, negotiate movements, and interact with the robot. These findings highlight the importance of shared control and user involvement for blind users, offering valuable insights for designing future social navigation robots.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {671},
numpages = {17},
keywords = {Autonomous robots, Social navigation, Crowded public spaces},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713727,
author = {Khot, Rucha and Arets, Teis and Wester, Joel and Burger, Franziska and van Berkel, Niels and Brankaert, Rens and IJsselsteijn, Wijnand and Lee, Minha},
title = {Challenging Futures: Using Chatbots to Reflect on Aging and Dementia},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713727},
doi = {10.1145/3706598.3713727},
abstract = {Intertemporal reflection, flexibly thinking forward and backward in time, is vital for one’s future planning. Yet, cultivating intertemporal reflection about encountering difficult futures, e.g., developing a progressive cognitive condition like dementia, can be challenging. We assessed people’s attitudes towards dementia following conversing with a chatbot presented as either neurotypical or simulating dementia symptoms. While neither the chatbot’s presentation nor the framing of participants’ future selves impacted attitudes toward dementia, it influenced participants’ experiences. When framed as future selves, the chatbot evoked a strong emotional connection, leading to reflection on aging, particularly with the chatbot simulating dementia symptoms. Participants interacting with the chatbot framed as a stranger with simulated symptoms often felt frustrated, especially when they had a task-oriented mindset.
Chatbots can be promising tools for prompting reflections on challenging futures, such as dementia, although their effectiveness varies due to the tensions between simulated cognitive decline and expectations for effective communication.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {672},
numpages = {14},
keywords = {Dementia, LLM, GPT-4, Attitudes, Reflection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714101,
author = {Ppali, Sophia and Cheung, Ethan and Covaci, Alexandra and She, Wan-Jou and Ang, Chee Siang},
title = {Creating with Care: Co-Designing Immersive Experiences through Art-Making with People Living with Dementia},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714101},
doi = {10.1145/3706598.3714101},
abstract = {This paper explores the integration of co-design and art-making in developing technologies that support personhood in dementia care. While technologies for dementia care have advanced, there remains a gap in creating solutions that are directly informed by the experiences of people living with dementia and support their individuality. In collaboration with the specialist arts organisation Bright Shadow CIO, our work involves engaging people living with dementia in the design process. Over five weeks of co-design sessions, 44 participants worked alongside artists to craft four physical boxes that represent “meaningful places.” The physical boxes were then transformed into VR environments, allowing participants to immerse themselves in and interact with their creations from a first-person perspective. Our findings demonstrate that VR alone is insufficient in dementia care. For VR to be meaningful, it must be be part of a broader intervention that includes trust-building, sensory engagement, and creative involvement. Within this process, art-making serves as both a method and medium, providing a means of self-expression and connection to identity. Our findings challenge conventional approaches to dementia-focused VR, advocating for a shift toward inclusive and care-driven technology design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {673},
numpages = {18},
keywords = {Dementia, Care, Virtual Reality, Co-creation, Collaborative Art-Making, Places},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713938,
author = {Beijer, Sanne and Houben, Maarten and IJsselsteijn, Wijnand and Brankaert, Rens},
title = {Mano: Designing for Tactile Experiences in Advanced Dementia Care},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713938},
doi = {10.1145/3706598.3713938},
abstract = {Professional caregivers want to provide feelings of security and comfort to people with dementia in advanced care, but limited resources frequently restrict professional caregivers from doing so. One potential solution to make social, non-verbal connections with people in advanced dementia care is the use of artifacts that offer comfort and stimulating tactile experiences. In this study, we explored the role of two design artifacts, the Mano Quilt, a weighted blanket, and the Mano Fold, a foldable pillow, in supporting caregivers to increase feelings of comfort and security in people with advanced dementia through warmth. In a field study, we collected data through observations of 26 residents with dementia who interacted with the two artifacts and 17 interviews with their formal caregivers in three care organizations. We reveal which aesthetic and material qualities evoke haptic and bodily experiences such as presence, comfort, and activity and how the artifacts support existing caregiving practices. We encourage future researchers to design to enrich the senses as an aesthetic experience and provide emotional support and companionship to increase well-being for people with advanced dementia.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {674},
numpages = {13},
keywords = {Dementia, Design, Non-pharmacological Interventions, Residential Care, Sensory Stimulation, Tactile Experiences},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713930,
author = {Valencia, Alicia and Houben, Maarten and Brankaert, Rens and Eggen, Berry and IJsselsteijn, Wijnand},
title = {Open-ended Play For People With Dementia},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713930},
doi = {10.1145/3706598.3713930},
abstract = {The progression of dementia leads to a loss of initiative and agency, halting daily activities, hobbies, or social encounters. Open-ended play can encourage initiative but remains underexplored in dementia. This paper explores how technology-driven design can support open-ended play, making social interactions more enjoyable and renewing interest in daily activities. We conducted five workshops at dementia daycare facilities, observing people with dementia engage with playful circuit-building toolkits to identify strategies. Findings reveal these toolkits stimulated self-direction and initiative to accomplish self-imposed goals, both independently and collaboratively. We show how open-ended play fosters confidence, resilience, social engagement, and self-expression, allowing people with dementia to exercise choice and share moments of achievement. We provide design implications for technology to stimulate initiative through open-ended play by 1) balancing structure and freedom, 2) emphasizing novelty and material diversity for non-verbal social connection, and 3) considering age-appropriate aesthetics.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {675},
numpages = {13},
keywords = {Dementia, Design, Open-ended play, Qualitative Analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713788,
author = {Kuribayashi, Masaki and Uehara, Kohei and Wang, Allan and Morishima, Shigeo and Asakawa, Chieko},
title = {WanderGuide: Indoor Map-less Robotic Guide for Exploration by Blind People},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713788},
doi = {10.1145/3706598.3713788},
abstract = {Blind people have limited opportunities to explore an environment based on their interests. While existing navigation systems could provide them with surrounding information while navigating, they have limited scalability as they require preparing prebuilt maps. Thus, to develop a map-less robot that assists blind people in exploring, we first conducted a study with ten blind participants at a shopping mall and science museum to investigate the requirements of the system, which revealed the need for three levels of detail to describe the surroundings based on users’ preferences. Then, we developed WanderGuide, with functionalities that allow users to adjust the level of detail in descriptions and verbally interact with the system to ask questions about the environment or to go to points of interest. The study with five blind participants revealed that WanderGuide could provide blind people with the enjoyable experience of wandering around without a specific destination in their minds.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {676},
numpages = {21},
keywords = {visual impairment, map-less navigation, recreational exploration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713296,
author = {Wang, Chenglong and Lee, Bongshin and Drucker, Steven M. and Marshall, Dan and Gao, Jianfeng},
title = {Data Formulator 2: Iterative Creation of Data Visualizations, with AI Transforming Data Along the Way},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713296},
doi = {10.1145/3706598.3713296},
abstract = {Data analysts often need to iterate between data transformations and chart designs to create rich visualizations for exploratory data analysis. Although many AI-powered systems have been introduced to reduce the effort of visualization authoring, existing systems are not well suited for iterative authoring. They typically require analysts to provide, in a single turn, a text-only prompt that fully describe a complex visualization. We introduce Data Formulator 2 (Df2 for short), an AI-powered visualization system designed to overcome this limitation. Df2 blends graphical user interfaces and natural language inputs to enable users to convey their intent more effectively, while delegating data transformation to AI. Furthermore, to support efficient iteration, Df2 lets users navigate their iteration history and reuse previous designs, eliminating the need to start from scratch each time. A user study with eight participants demonstrated that Df2 allowed participants to develop their own iteration styles to complete challenging data exploration sessions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {677},
numpages = {17},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713490,
author = {Shapiro, Ben Rydal and Hall, Rogers and Mathur, Arpit and Zhao, Edwin},
title = {Exploratory Visual Analysis of Transcripts for Interaction Analysis in Human-Computer Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713490},
doi = {10.1145/3706598.3713490},
abstract = {Transcripts are central to qualitative research in HCI, particularly for researchers using methods of Conversation Analysis (CA) and Interaction Analysis (IA) who study the socially situated nature of human-computer interaction. However, CA and IA researchers continue to highlight the significant need for more dynamic ways to visualize transcripts to support interaction analysis. This need is particularly evident in HCI, where transcripts as a form of data have received little attention. In this article, we make three contributions to HCI research. First, we present Transcript Explorer, an open-source visualization system that integrates three visualization techniques we have developed to interactively visualize transcripts linked to videos: Distribution Diagrams, Turn Charts and Contribution Clouds. Second, we present findings from a qualitative analysis of focus group interviews with three different qualitative research groups who engaged with this system to analyze common transcript data. Finally, we expand upon transcripts as a unique form of data for HCI research and propose directions for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {678},
numpages = {17},
keywords = {transcript visualization, interaction analysis, conversation analysis, discourse analysis, qualitative research methods, qualitative data visualization, exploratory data analysis, information visualization, learning sciences},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713881,
author = {Zou, Ruishi and Tang, Yinqi and Chen, Jingzhu and Lu, Siyu and Lu, Yan and Yang, Yingfan and Ye, Chen},
title = {GistVis: Automatic Generation of Word-scale Visualizations from Data-rich Documents},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713881},
doi = {10.1145/3706598.3713881},
abstract = {Data-rich documents are ubiquitous in various applications, yet they often rely solely on textual descriptions to convey data insights. Prior research primarily focused on providing visualization-centric augmentation to data-rich documents. However, few have explored using automatically generated word-scale visualizations to enhance the document-centric reading process. As an exploratory step, we propose GistVis, an automatic pipeline that extracts and visualizes data insight from text descriptions. GistVis decomposes the generation process into four modules: Discoverer, Annotator, Extractor, and Visualizer, with the first three modules utilizing the capabilities of large language models and the fourth using visualization design knowledge. Technical evaluation including a comparative study on Discoverer and an ablation study on Annotator reveals decent performance of GistVis. Meanwhile, the user study (N=12) showed that GistVis could generate satisfactory word-scale visualizations, indicating its effectiveness in facilitating users’ understanding of data-rich documents (+5.6\% accuracy) while significantly reducing their mental demand (p=0.016) and perceived effort (p=0.033).},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {679},
numpages = {18},
keywords = {Word-scale visualization, Automatic visualization, Natural language processing, Interactive article, Data document},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713243,
author = {Dhawka, Priya and Dasgupta, Sayamindu},
title = {The Social Construction of Visualizations: Practitioner Challenges and Experiences of Visualizing Race and Gender},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713243},
doi = {10.1145/3706598.3713243},
abstract = {Data visualizations are increasingly seen as socially constructed, with several recent studies positing that perceptions and interpretations of visualization artifacts are shaped through complex sets of interactions between members of a community. However, most of these works have focused on audiences and researchers, and little is known about if and how practitioners account for the socially constructed framing of data visualization. In this paper, we study and analyze how visualization practitioners understand the influence of their beliefs, values, and biases in their design processes and the challenges they experience. In 17 semi-structured interviews with designers working with race and gender demographic data, we find that a complex mix of factors interact to inform how practitioners approach their design process—including their personal experiences, values, and their understandings of power, neutrality, and politics. Based on our findings, we suggest a series of implications for research and practice in this space.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {680},
numpages = {16},
keywords = {visualization designers, values, feminist epistemology, demographic data},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713976,
author = {Bae, S. Sandra and Fujiwara, Takanori and Tseng, Chin and Szafir, Danielle Albers},
title = {Uncovering How Scatterplot Features Skew Visual Class Separation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713976},
doi = {10.1145/3706598.3713976},
abstract = {Multi-class scatterplots are essential for visually comparing data, such as examining class distributions in dimensionality reduction and evaluating classification models. Visual class separation (VCS) measures quantify human perception but are largely derived from and evaluated with datasets reflecting limited types of scatterplot features (e.g., data distribution, similar class densities). Quantitatively identifying which scatterplot features are influential to VCS tasks can enable more robust guidance for future measures. We analyze the alignment between VCS measures and people’s perceptions of class separation through a crowdsourced study using 70 scatterplot features relevant to class separation. To cover a wide range of scatterplot features, we generated a set of multi-class scatterplots from 6,947 real-world datasets. Our results highlight that multiple combinations of features are needed to best explain VCS. From our analysis, we develop a composite feature model that identifies key scatterplot features for measuring VCS task performance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {681},
numpages = {21},
keywords = {Visualization, Multi-class scatterplots, Classification complexity, Visual quality measures, Scagnostics, Quantitative study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713276,
author = {Mei, Xiyao and Zhang, Yu and Yang, Chaofan and Shi, Rui and Yuan, Xiaoru},
title = {ZuantuSet: A Collection of Historical Chinese Visualizations and Illustrations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713276},
doi = {10.1145/3706598.3713276},
abstract = {Historical visualizations are a valuable resource for studying the history of visualization and inspecting the cultural context where they were created. When investigating historical visualizations, it is essential to consider contributions from different cultural frameworks to gain a comprehensive understanding. While there is extensive research on historical visualizations within the European cultural framework, this work shifts the focus to ancient China, a cultural context that remains underexplored by visualization researchers. To this aim, we propose a semi-automatic pipeline to collect, extract, and label historical Chinese visualizations. Through the pipeline, we curate ZuantuSet, a dataset with over 71K visualizations and 108K illustrations. We analyze distinctive design patterns of historical Chinese visualizations and their potential causes within the context of Chinese history and culture. We illustrate potential usage scenarios for this dataset, summarize the unique challenges and solutions associated with collecting historical Chinese visualizations, and outline future research directions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {682},
numpages = {15},
keywords = {historical visualization, dataset, digital humanities, data labeling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714194,
author = {Liu, Xin and Lee, Chengkuo and Zheng, Clement and Yen, Ching Chiuan},
title = {Designing Physical Interactions with Triboelectric Material Sensing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714194},
doi = {10.1145/3706598.3714194},
abstract = {Physical interactions in Human-Computer Interaction (HCI) provide immersive ways for people to engage with technology. However, designers face challenges in integrating physical computing and modeling when designing physical interactions. We explore triboelectric material sensing, a promising technology that addresses these challenges, though its use within the design community remains underexplored. To bridge this gap, we develop a toolkit consisting of triboelectric material pairs, a mechanism taxonomy, a signal processing tool, and computer program templates. We introduce this toolkit to designers in two workshops, where reflections on the design process highlight its effectiveness and inspire innovative interaction designs. Our work contributes valuable resources and knowledge to the design community, making triboelectric sensing more accessible and fostering creativity in physical interaction design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {683},
numpages = {20},
keywords = {Physical Interaction, Triboelectric Material Sensing, Input Sensing, Toolkit.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713356,
author = {Yin, Yiwen and Mei, Yu and Yu, Chun and Li, Toby Jia-Jun and Jadoon, Aamir Khan and Cheng, Sixiang and Shi, Weinan and Chen, Mohan and Shi, Yuanchun},
title = {From Operation to Cognition: Automatic Modeling Cognitive Dependencies from User Demonstrations for GUI Task Automation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713356},
doi = {10.1145/3706598.3713356},
abstract = {Traditional Programming by Demonstration (PBD) systems primarily automate tasks by recording and replaying operations on Graphical User Interfaces (GUIs), without fully considering the cognitive processes behind operations. This limits their ability to generalize tasks with interdependent operations to new contexts (e.g. collecting and summarizing introductions depending on different search keywords from varied websites). We propose TaskMind, a system that automatically identifies the semantics of operations, and the cognitive dependencies between operations from demonstrations, building a user-interpretable task graph. Users modify this graph to define new task goals, and TaskMind executes the graph to dynamically generalize new parameters for operations, with the integration of Large Language Models (LLMs). We compared TaskMind with a baseline end-to-end LLM which automates tasks from demonstrations and natural language commands, without task graph. In studies with 20 participants on both predefined and customized tasks, TaskMind significantly outperforms the baseline in both success rate and controllability.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {684},
numpages = {24},
keywords = {Programming by Demonstration, Task Automation, Task Graph, Cognitive Dependency},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713686,
author = {Zhang, Hongbo and Chen, Pei and Xie, Xuelong and Jiang, Zhaoqu and Wu, Yifei and Li, Zejian and Chen, Xiaoyu and Sun, Lingyun},
title = {FusionProtor: A Mixed-Prototype Tool for Component-level Physical-to-Virtual 3D Transition and Simulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713686},
doi = {10.1145/3706598.3713686},
abstract = {Developing and simulating 3D prototypes is crucial in product conceptual design for ideation and presentation. Traditional methods often keep physical and virtual prototypes separate, leading to a disjointed prototype workflow. In addition, acquiring high-fidelity prototypes is time-consuming and resource-intensive, distracting designers from creative exploration. Recent advancements in generative artificial intelligence&nbsp;(GAI) and extended reality&nbsp;(XR) provided new solutions for rapid prototype transition and mixed simulation. We conducted a formative study to understand current challenges in the traditional prototype process and explore how to effectively utilize GAI and XR ability in prototype. Then we introduced FusionProtor, a mixed-prototype tool for component-level 3D prototype transition and simulation. We proposed a step-by-step generation pipeline in FusionProtor, effectively transiting 3D prototypes from physical to virtual and low- to high-fidelity for rapid ideation and iteration. We also innovated a component-level 3D creation method and applied it in XR environment for the mixed-prototype presentation and interaction. We conducted technical and user experiments to verify FusionProtor’s usability in supporting diverse designs. Our results verified that it achieved a seamless workflow between physical and virtual domains, enhancing efficiency and promoting ideation. We also explored the effect of mixed interaction on design and critically discussed its best practices for HCI community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {685},
numpages = {19},
keywords = {conceptual design, 3D prototype, generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713285,
author = {Cao, Yining and Jiang, Peiling and Xia, Haijun},
title = {Generative and Malleable User Interfaces with Generative and Evolving Task-Driven Data Model},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713285},
doi = {10.1145/3706598.3713285},
abstract = {Unlike static and rigid user interfaces, generative and malleable user interfaces offer the potential to respond to diverse users’ goals and tasks. However, current approaches primarily rely on generating code, making it difficult for end-users to iteratively tailor the generated interface to their evolving needs. We propose employing task-driven data models—representing the essential information entities, relationships, and data within information tasks—as the foundation for UI generation. We leverage AI to interpret users’ prompts and generate the data models that describe users’ intended tasks, and by mapping the data models with UI specifications, we can create generative user interfaces. End-users can easily modify and extend the interfaces via natural language and direct manipulation, with these interactions translated into changes in the underlying model. The technical evaluation of our approach and user evaluation of the developed system demonstrate the feasibility and effectiveness of the proposed generative and malleable UIs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {686},
numpages = {20},
keywords = {Generative User Interface, Malleable User Interface},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714006,
author = {Mackay, Wendy E. and Beaudouin-Lafon, Michel},
title = {Interaction Substrates: Combining Power and Simplicity in Interactive Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714006},
doi = {10.1145/3706598.3714006},
abstract = {Today’s graphical user interfaces tend to be either simple but limited, or powerful but overly complex. In order to combine power and simplicity, we introduce Substrates, which act as “places for interaction” where users can manipulate objects of interest in a principled and predictable way. Substrates structure and contain data, enforce user-defined constraints among objects and manage dependencies with other substrates. Users can “tune” and “tweak” these relationships, “curry” specialized tools or abstract relationships into interactive templates. We first define substrates and provide in-depth descriptions with examples of their key characteristics. After explaining how Substrates extend the concept of Instrumental Interaction, we apply a Generative Theory of Interaction approach to analyze and critique existing interfaces and then show how using the concepts of Instruments and Substrates inspired novel design ideas in three graduate-level HCI courses. We conclude with a discussion and directions for future work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {687},
numpages = {16},
keywords = {Substrates, Content-authoring systems, Creativity Support, Generative Theory of Interaction, Instrumental Interaction, Reification, Polymorphism, Reuse, Currying, Templating, Tuning, Tweaking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714164,
author = {Min, Bryan and Chen, Allen and Cao, Yining and Xia, Haijun},
title = {Malleable Overview-Detail Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714164},
doi = {10.1145/3706598.3714164},
abstract = {The overview-detail design pattern, characterized by an overview of multiple items and a detailed view of a selected item, is ubiquitously implemented across software interfaces. Designers often try to account for all users, but ultimately these interfaces settle on a single form. For instance, an overview map may display hotel prices but omit other user-desired attributes. This research instead explores the malleable overview-detail interface, one that end-users can customize to address individual needs. Our content analysis of overview-detail interfaces uncovered three dimensions of variation: content, composition, and layout, enabling us to develop customization techniques along these dimensions. For content, we developed Fluid Attributes, a set of techniques enabling users to show and hide attributes between views and leverage AI to manipulate, reformat, and generate new attributes. For composition and layout, we provided solutions to compose multiple overviews and detail views and transform between various overview and overview-detail layouts. A user study on our techniques implemented in two design probes revealed that participants produced diverse customizations and unique usage patterns, highlighting the need and broad applicability for malleable overview-detail interfaces.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {688},
numpages = {25},
keywords = {Overview-Detail Interfaces, End-User Customization, Malleable Interfaces, Interface Design Patterns},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713331,
author = {Iyer, Ramya and Dogan, Mustafa Doga and Larsson, Maria and Igarashi, Takeo},
title = {XR-penter: Material-Aware and In Situ Design of Scrap Wood Assemblies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713331},
doi = {10.1145/3706598.3713331},
abstract = {Woodworkers have to navigate multiple considerations when planning a project, including available resources, skill-level, and intended effort. Do it yourself (DIY) woodworkers face these challenges most acutely because of tight material constraints and a desire for custom designs tailored to specific spaces. To address these needs, we present XR-penter, an extended reality (XR) application that supports in situ, material-aware woodworking for casual makers. Our system enables users to design virtual scrap wood assemblies directly in their workspace, encouraging sustainable practices through the use of discarded materials. Users register physical material as virtual twins, manipulate these twins into an assembly in XR (while receiving feedback on material usage and alignment with their surroundings), and preview cuts needed for fabrication. We conducted a case study and feedback sessions demonstrating that XR-penter supports improvisational workflows in practice, and found that woodworkers who prioritize material-driven and adaptive workflows benefit most from our system.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {689},
numpages = {16},
keywords = {Sustainability, Mixed Reality, Personal Fabrication, Woodworking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714271,
author = {Xu, Jiaxin and Zhang, Chao and Cuijpers, Raymond H. and IJsselsteijn, Wijnand A.},
title = {Does Care Lead to Bonds? Exploring the Relationship Between Human Caregiving for Robots and Human-Robot Bonding},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714271},
doi = {10.1145/3706598.3714271},
abstract = {This study investigates how interaction scenarios of human caregiving for robots affect humans’ perceived bond with robots. In a between-subjects lab experiment (n = 88), participants played a game with a social robot during which they provided either 1) emotional care (comforting the robot); 2) instrumental care (helping with battery charging); or 3) no care for the robot. Results indicated that caregiving did not significantly affect human-robot bonding according to explicit relationship measures including closeness, social attraction, or desire for future interaction. However, caregiving mattered when bonding was measured implicitly. Those in the emotional caregiving scenario were more hesitant to replace the robot and invested more effort in a voluntary task requested by the robot than those who provided no care. These findings provide empirical evidence that emotional caregiving interactions can effectively foster initial human-robot bonding, highlighting a promising design scenario for human-robot interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {690},
numpages = {15},
keywords = {Caregiving, Human-robot bonding, Human-robot relationship, Interaction design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713969,
author = {Choi, Yubin and Choi, Jeanne and Seering, Joseph},
title = {Leveling Up Together: Fostering Positive Growth and Safe Online Spaces for Teen Roblox Developers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713969},
doi = {10.1145/3706598.3713969},
abstract = {Creating games together is both a playful and effective way to develop skills in computational thinking, collaboration, and more. However, game development can be challenging for younger developers who lack formal training. While teenage developers frequently turn to online communities for peer support, their experiences may vary. To better understand the benefits and challenges teens face within online developer communities, we conducted interviews with 18 teenagers who created games or elements in Roblox and received peer support from one or more online Roblox developer communities. Our findings show that developer communities provide teens with valuable resources for technical, social, and career growth. However, teenagers also struggle with inter-user conflicts and a lack of community structure, leading to difficulties in handling complex issues that may arise, such as financial scams. Based on these insights, we propose takeaways for creating positive and safe online spaces for teenage game creators.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {691},
numpages = {18},
keywords = {Teenagers, youth, developing games, developer communities, online communities, safety, Roblox},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713404,
author = {Lee, Kwangyoung and Jung, Yeohyun and Jung, Gyuwon and Lu, Xi and Hong, Hwajung},
title = {Peerspective: A Study on Reciprocal Tracking for Self-awareness and Relational Insight},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713404},
doi = {10.1145/3706598.3713404},
abstract = {Personal informatics helps individuals understand themselves, but it often struggles to capture non-conscious behaviors such as stress responses, habitual actions, and communication styles. Incorporating social aspects into PI systems offers new perspectives on self-understanding, yet prior research has largely focused on unidirectional approaches that center benefits on the primary tracker. To address this gap, we introduce the Peerspective study, which explores reciprocal tracking—a bidirectional practice where two participants observe and provide feedback to each other, fostering mutual self-understanding and collaboration. In a week-long study with eight peer dyads, we explored how reciprocal observation and feedback influence self-awareness and interpersonal relationships. Our findings reveal that reciprocal tracking not only helps participants uncover blind spots and expand their self-concepts but also enhances empathy, deepens communication, and promotes sustained engagement. We discuss key facilitators and challenges of integrating reciprocity into personal informatics systems and offer design considerations for supporting collaborative tracking in everyday contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {692},
numpages = {17},
keywords = {Personal Informatics, Blind Spots, Reciprocal Tracking, Peerspective, Self-Understanding, Social Features in Tracking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713371,
author = {Shirado, Hirokazu and Shimizu, Kye and Christakis, Nicholas A and Kasahara, Shunichi},
title = {Realism Drives Interpersonal Reciprocity but Yields to AI-Assisted Egocentrism in a Coordination Experiment},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713371},
doi = {10.1145/3706598.3713371},
abstract = {Virtual reality technologies that enhance realism and artificial intelligence (AI) systems that assist human behavior are increasingly interwoven in social applications. However, how these technologies might jointly influence interpersonal coordination remains unclear. We conducted an experiment with 240 participants in 120 pairs who interacted through remote-controlled robot cars in a physical space or virtual cars in a digital space, with or without autosteering assistance, using the chicken game, an established model of interpersonal coordination. We find that both realism and AI assistance help improve user performance but through opposing mechanisms. Real-world contexts enhanced communication, fostering reciprocal actions and collective benefits. In contrast, autosteering assistance diminished the need for interpersonal coordination, shifting participants’ focus towards self-interest. Notably, when combined, the egocentric effects of autosteering assistance outweighed the prosocial effects of realism. The design of HCI systems that involve social coordination will, we believe, need to take such effects into account.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {693},
numpages = {21},
keywords = {social coordination, realism, AI assistance, human agency, experiments},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713598,
author = {Doan, Bich Ngoc (Rubi) and Seering, Joseph},
title = {The Design Space for Online Restorative Justice Tools: A Case Study with ApoloBot},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713598},
doi = {10.1145/3706598.3713598},
abstract = {Volunteer moderators use various strategies to address online harms within their communities. Although punitive measures like content removal or account bans are common, recent research has explored the potential for restorative justice as an alternative framework to address the distinct needs of victims, offenders, and community members. In this study, we take steps toward identifying a more concrete design space for restorative justice-oriented tools by developing ApoloBot, a Discord bot designed to facilitate apologies when harm occurs in online communities. We present results from two rounds of interviews: first, with moderators giving feedback about the design of ApoloBot, and second, after a subset of these moderators have deployed ApoloBot in their communities. This study builds on prior work to yield more detailed insights regarding the potential of adopting online restorative justice tools, including opportunities, challenges, and implications for future designs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {694},
numpages = {19},
keywords = {Content moderation, online harassment, alternative justice, Discord},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713413,
author = {Knoll, Christian and M\"{o}ller, Torsten and Gregory, Kathleen and Koesten, Laura},
title = {The Gulf of Interpretation: From Chart to Message and Back Again},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713413},
doi = {10.1145/3706598.3713413},
abstract = {Charts are used to communicate data visually, but often, we do not know whether a chart’s intended message aligns with the message readers perceive. In this mixed-methods study, we investigate how data journalists encode data and how members of a broad audience engage with, experience, and understand these visualizations. We conducted workshops and interviews with school and university students, job seekers, designers, and senior citizens to collect perceived messages and feedback on eight real-world charts. We analyzed these messages and compared them to the intended message. Our results help to understand the gulf that can exist between messages (that producers encode) and viewer interpretations. In particular, we find that consumers are often overwhelmed with the amount of data provided and are easily confused with terms that are not well known. Chart producers tend to follow strong conventions on how to visually encode particular information that might not always benefit consumers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {695},
numpages = {17},
keywords = {Mixed-methods study, Visualization, Messages, Popular media, Data journalists, Diverse audience, Sensemaking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713653,
author = {Sackitey, Darley and Sachdev, Hiya Ashish and Parker, Andrea G},
title = {Virtual Solidarity, Concrete Care: A Review of Mutual Aid Online},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713653},
doi = {10.1145/3706598.3713653},
abstract = {In times of crisis, communities rise to fill the void of faltering institutions, self-organising to provide essential resources to marginalised populations. From providing relief to survivors of natural disasters, to addressing crises caused by societal failings like poverty, homelessness and unemployment, mutual aid is an important tool for community care and the development of new systems of survival. With mutual aid efforts increasingly entering the digital sphere, some work has investigated how the internet has transformed mutual aid, especially via social media. While such work describes mutual aid across a variety of contexts, we lack a broad understanding of how mutual aid principles translate online and the challenges organisers face in this digital landscape. To address this, we review 19 papers, identifying key characteristics, strategies, and challenges in online mutual aid. In doing so, we aim to enhance our understanding of how technology might foster sustainable community support and solidarity.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {696},
numpages = {23},
keywords = {mutual aid, solidarity, tangible support, care},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713807,
author = {Moin, Sara and Belani, Manshul and Singh, Pragya and Phutela, Nishtha and Singh, Pushpendra},
title = {"But I Won't Say That It Was Bad Seeing a Real Vagina": Understanding Perspectives toward Learning Sensitive-Critical Health Topic},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713807},
doi = {10.1145/3706598.3713807},
abstract = {In India, topics related to sexual and reproductive health (SRH) are rarely discussed openly due to stigma. Cervical cancer, a part of this SRH sphere, is the second most common cancer among women in India, yet its awareness remains low. To understand the attitudes towards SRH, we designed a Cervical cancer awareness tutorial in Virtual Reality and collected data from 66 participants across genders and life stages (single, married, and married with children) through interviews, self-reported emotions, and physiological sensor data. Our findings revealed an acute lack of knowledge about self-body anatomy and a need for creating health literacy. Our participants appreciated receiving detailed information despite the presence of explicit imagery and advocated that critical health information should not be moderated. We offer recommendations to the HCI community for teaching cervical cancer and suggest extending these approaches to enhance education on similar critical SRH issues in India.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {697},
numpages = {15},
keywords = {Sexual and Reproductive Health, Cervical Cancer, Women Health, Intimate Health, Virtual Reality Learning, India},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713680,
author = {Ramjee, Pragnya and Chhokar, Mehak and Sachdeva, Bhuvan and Meena, Mahendra and Abdullah, Hamid and Vashistha, Aditya and Nagar, Ruchit and Jain, Mohit},
title = {ASHABot: An LLM-Powered Chatbot to Support the Informational Needs of Community Health Workers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713680},
doi = {10.1145/3706598.3713680},
abstract = {Community health workers (CHWs) provide last-mile healthcare services but face challenges due to limited medical knowledge and training. This paper describes the design, deployment, and evaluation of ASHABot, an LLM-powered, experts-in-the-loop, WhatsApp-based chatbot to address the information needs of CHWs in India. Through interviews with CHWs and their supervisors and log analysis, we examine factors affecting their engagement with ASHABot, and ASHABot’s role in addressing CHWs’ informational needs. We found that ASHABot provided a private channel for CHWs to ask rudimentary and sensitive questions they hesitated to ask supervisors. CHWs trusted the information they received on ASHABot and treated it as an authoritative resource. CHWs’ supervisors expanded their knowledge by contributing answers to questions ASHABot failed to answer, but were concerned about demands on their workload and increased accountability. We emphasize positioning LLMs as supplemental fallible resources within the community healthcare ecosystem, instead of as replacements for supervisor support.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {698},
numpages = {22},
keywords = {Chatbot, GPT-4, Experts-in-the-loop, Medical, Frontline Healthcare, HCI4D, ASHA, India},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713350,
author = {Acherki, Chaymae and Nigay, Laurence and Roy, Quentin and Salque, Thibault},
title = {An Evaluation of Spatial Anchoring to position AR Guidance in Arthroscopic Surgery},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713350},
doi = {10.1145/3706598.3713350},
abstract = {This work examines spatial anchoring strategies to position augmented reality guidance during surgery. We consider three strategies: anchoring to the Patient, the surgical Tool, and the Surgeon’s head. These strategies were evaluated in a first experiment involving 24 non-professional participants, using two guidance techniques: 3D Trajectory and 2D Crosshair. For 3D Trajectory, Patient and Tool anchoring were more precise than Surgeon anchoring, and Patient anchoring was the most preferred. For 2D Crosshair, no significant effect of anchoring strategies on precision was observed. However, participants preferred Patient and Surgeon anchoring. A second experiment with 6 surgeons confirmed the first experiment’s results. For 3D trajectory, Tool anchoring proved more precise than Patient anchoring, despite surgeons’ preference for Patient anchoring. These findings contribute to empirical evidence for the design of surgical AR guidance, with potential applications for similar, less critical tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {699},
numpages = {17},
keywords = {Augmented reality, Human-computer interaction, Arthroscopic surgery, Drilling, Spatial anchoring, Guidance technique},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714285,
author = {Luo, Tianren and Zhou, Ke and Wang, Pengxiang and Chang, Shuting and Chen, Gaozhang and Zhang, Hechuan and Tan, Xiaohui and Wang, Qi and Han, Teng and Tian, Feng},
title = {Exploring the Remapping Impact of Spatial Head-hand Relations in Immersive Telesurgery},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714285},
doi = {10.1145/3706598.3714285},
abstract = {The action remapping between the user and the avatar creates significant perceptual and behavioral challenges. Recently, in addition to virtual environments, remapping has also given rise to new applications—immersive teleoperated robots. This paper selects immersive telesurgery, a representative scenario, as an opportunity for research, exploring the generalized effects of remapping. In such a scenario, the operator can observe through the robot’s camera and use their hands to control the robotic arms, as if they were the robot. However, common remapping of spatial head-hand relations—due to camera adjustments and robotic arm switching—creates significant visual-proprioceptive conflicts and physical limitations. To explore this, we simulated a telesurgery system with 6 head-camera and 12 hand-robotic-arm remapping conditions, assessing non-surgeon participants across four surgical tasks: navigation, location, cutting, and bimanual coordination. The study examines spatial perception bias, interaction deviation, workload, and task completion time. Our findings reveal how different remapping targets, attributes, intensities, and situations affect performance, contributing to the understanding of perception mechanisms and offering insights for optimizing operations or systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {700},
numpages = {18},
keywords = {Immersive Telesurgery, Spatial Perception, Remapping, Sensory Conflict},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713733,
author = {Wragg, Matthew and Sengupta, Raj and Cazzola, Dario and Alexander, Jason},
title = {Investigating the Benefits of Physical Models for Anatomical Education in Augmented Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713733},
doi = {10.1145/3706598.3713733},
abstract = {Historically, anatomical education has utilised physical models; researchers are now looking to Augmented Reality (AR) to deliver more engaging learning experiences. While there are clear educational advantages to AR, most systems lack the cognitive benefits afforded by physical models. Our work explores the potential of combining physical anatomical models and AR. We first present a design space exploring the interplay between the two. From this, we created a tangible AR system utilising a physical vertebrae model for learning spinal anatomy and axial spondyloarthritis progression. We conducted a study (n=39) to evaluate its benefits for knowledge improvement and retention, compared with a virtual AR and screen-based version. We found no difference in learning outcomes, however, the physical model improved participants’ learning experience. We then conducted an expert evaluation with clinicians to explore opportunities for using tangible AR in clinical practice. Results highlight potential benefits for patient understanding, and challenges surrounding accessibility.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {701},
numpages = {19},
keywords = {augmented reality, tangible interaction, physical models, anatomy, education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713756,
author = {Ambe, Aloha Hufana and Salisbury, Isaac and Grundgeiger, Tobias and Bodnar, Daniel and Rothwell, Sean and Brown, Nathan and Sanderson, Penelope and Matthews, Ben},
title = {Patient Handover in the Emergency Department Is Not Just a Point Event: Insights for Designing Information Support Tools},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713756},
doi = {10.1145/3706598.3713756},
abstract = {Effective information support tools are challenging to design for fast-paced, information rich, and difficult to predict circumstances, particularly when information is fragmented and sources are dispersed. To explore, we conducted a field study on handover and the associated information work, which included 40 visits and 75 hours of observation and interviews with doctors in a metropolitan emergency department (ED). Beyond information exchange, we found that handovers highlight doctors' proactive approach by anticipating information needs, managing uncertainties arising from dynamic information, and developing patient care plans through multiple contingencies. Expanding on the idea of handover as a multifaceted process rather than a single event, we reinforce existing calls for greater flexibility emphasising that the ascertainment of pertinent information is an ongoing, adaptive process. This work demonstrates that deciding what constitutes relevant information is a priori indeterminate when designing information systems and support tools in environments such as EDs. We propose the preservation of specific ‘relativities’ of information—such as uncertainty, particularity, incompleteness, and temporality—in designing information support tools for dynamic, critical and multi-disciplinary work environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {702},
numpages = {16},
keywords = {Information support tools, emergency department, information relativities, information work, patient handover},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713898,
author = {Detjen, Henrik H.J. and Densky, Lars and von Kalckreuth, Niklas and Kopka, Marvin},
title = {Who is Trusted for a Second Opinion? Comparing Collective Advice from a Medical AI and Physicians in Biopsy Decisions After Mammography Screening},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713898},
doi = {10.1145/3706598.3713898},
abstract = {Artificial Intelligence (AI) is increasingly integrated into clinical practice, but its influence on patient decision-making, particularly when AI and physicians disagree, remains unclear. To examine collective advice, we investigated a breast cancer screening scenario using (1) a qualitative interview study (N=9) and (2) a quantitative experiment (N=339) where participants received either consistent or conflicting biopsy recommendations. Qualitative findings include the need for empathetic care, the importance of patient autonomy, and a desire for a four-eyes principle. Quantitative findings accordingly show that patients generally trust physicians more than AI but still tend to follow AI recommendations due to risk aversion. When both advised a biopsy, 99\% adhered; if both advised against it, 25\% still proceeded. In conflicting scenarios, 97\% followed the physician’s advice, whereas 66\% followed the AI if it recommended the biopsy. These results underscore the need for careful interaction design of collective healthcare advice to prevent unnecessary healthcare procedures.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {703},
numpages = {15},
keywords = {Healthcare Workflow, Breast Cancer, Mammography Screening, Multi-Stakeholder Dynamics, Medical AI, Decision-Making, Human-AI Collaboration, Second Opinion, Cognitive Dissonance, Compliance, Trust in Automation, AI Acceptance, Algorithm Aversion},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713129,
author = {Br\'{e}hault, Victor and Dubois, Emmanuel and Prouzeau, Arnaud and Serrano, Marcos},
title = {A Systematic Literature Review to Characterize Asymmetric Interaction in Collaborative Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713129},
doi = {10.1145/3706598.3713129},
abstract = {Computer-mediated collaboration often relies on symmetrical interactions between users, where all the collaborators use identical devices. However, in some cases, either due to constraints (e.g. users in different environments) or by choice (e.g. using devices with different properties), users engage in asymmetrical interactions. Addressing such asymmetries in heterogeneous systems can be difficult as there has been no systematic analysis of how to define them, or their impact on collaboration. In this paper, we characterize the asymmetries that can arise between users’ interactions within collaborative heterogeneous systems. To this end, we conduct a systematic literature review of asymmetric collaborative systems, coding their properties, including the interaction spaces, their input and output modalities, and shared feedback. We then define the dimensions of asymmetry that emerge from this review. We discuss their impact on collaboration and outline a set of challenges and opportunities for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {704},
numpages = {19},
keywords = {Remote collaboration, asymmetric interaction, systematic literature review},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714052,
author = {Chen, Xinyue and Tankelevitch, Lev and Vanukuru, Rishi and Scott, Ava Elizabeth and Panda, Payod and Rintel, Sean},
title = {Are We On Track? AI-Assisted Active and Passive Goal Reflection During Meetings},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714052},
doi = {10.1145/3706598.3714052},
abstract = {Meetings often suffer from a lack of intentionality, such as unclear goals and straying off-topic. Identifying goals and maintaining their clarity throughout a meeting is challenging, as discussions and uncertainties evolve. Yet meeting technologies predominantly fail to support meeting intentionality. AI-assisted reflection is a promising approach. To explore this, we conducted a technology probe study with 15 knowledge workers, integrating their real meeting data into two AI-assisted reflection probes: a passive and active design. Participants identified goal clarification as a foundational aspect of reflection. Goal clarity enabled people to assess when their meetings were off-track and reprioritize accordingly. Passive AI intervention helped participants maintain focus through non-intrusive feedback, while active AI intervention, though effective at triggering immediate reflection and action, risked disrupting the conversation flow. We identify three key design dimensions for AI-assisted reflection systems, and provide insights into design trade-offs, emphasizing the need to adapt intervention intensity and timing, balance democratic input with efficiency, and offer user control to foster intentional, goal-oriented behavior during meetings and beyond.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {705},
numpages = {22},
keywords = {videoconferencing, meeting, goal, intentionality, generative AI, probe, active, passive, intervention, interruption},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713993,
author = {Kleinau, Julia and Gr\o{}nb\ae{}k, Jens Emil Sloth and Hoggan, Eve},
title = {Co-Designing Multimodal Tools for Radically Mobile Hybrid Meetings},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713993},
doi = {10.1145/3706598.3713993},
abstract = {Hybrid meetings have become common practice in collaborative work environments. However, they are constrained by the fixed spatial configurations of videoconferencing technology. This limits opportunities for mobile and spontaneous interactions; qualities that are critical to successful collaboration. In this paper, we explore the concept of radically mobile hybrid meetings. Our work investigates the design space of multimodal devices as mobile alternatives to traditional videoconferencing. We conducted three group co-design sessions, where participants prototyped mobile hybrid meeting technologies to explore how such meetings could be supported. From these workshops, we derive design fictions envisioning future uses of these technologies, which we evaluate with a questionnaire to spark reflections on future mobile hybrid collaboration tools and practices. We contribute an initial exploration of the design space for radically mobile hybrid meetings, laying the groundwork for developing tools that enable spontaneous, effective, and inclusive collaboration in hybrid mobile settings.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {706},
numpages = {17},
keywords = {hybrid meetings, co-design, design fiction, mobile meetings, Computer Supported Cooperative Work (CSCW)},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714064,
author = {Balc\i{}, Ozan and Poncelet, Stien and Nguyen, Alex Binh Vinh Duc and Vande Moere, Andrew},
title = {Manifesting Architectural Subspaces with Two Mobile Robotic Partitions to Facilitate Spontaneous Office Meetings},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714064},
doi = {10.1145/3706598.3714064},
abstract = {Although intended to foster spontaneous interactions among workers, a typical open-plan office layout cannot mitigate visual, acoustic, or privacy-related distractions that originate from unplanned meetings. As office workers often refrain from tackling these issues by manually demarcating or physically relocating to a more suitable subspace that is enclosed by movable partitions, we hypothesise that these subspaces could instead be robotically manifested. This study therefore evaluated the perceived impact of two mobile robotic partitions that were wizarded to jointly manifest an enclosed subspace, to: 1) either ‘mitigate’ or ‘intervene’ in the distractions caused by spontaneous face-to-face or remote meetings; or 2) either ‘gesturally’ or ‘spatially’ nudge a distraction-causing worker to relocate. Our findings suggest how robotic furniture should interact with office workers with and through transient space, and autonomously balance the distractions not only for each individual worker but also for multiple workers sharing the same workspace.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {707},
numpages = {16},
keywords = {adaptive architecture, interactive architecture, responsive architecture, kinetic architecture, robotic furniture, robotic partition, robotic architecture, interior architecture, indoor autonomous mobile robot, smart building, smart space, smart office, human-building interaction, human-robot interaction, multi-robot system},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714328,
author = {Kiuchi, Akihiro and Wieland, Jonathan and Igarashi, Takeo and Lindlbauer, David},
title = {MiniMates: Miniature Avatars for AR Remote Meetings within Limited Physical Spaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714328},
doi = {10.1145/3706598.3714328},
abstract = {Remote meetings using 3D avatars in Augmented Reality (AR) allow effective communication and enable users to retain awareness of their surroundings. However, positioning 3D avatars effectively and consistently for all users in AR is challenging since most spaces, such as offices or living rooms, are not large enough to accommodate multiple life-sized avatars without interference. To address this issue, we contribute MiniMates—a novel approach leveraging miniature avatars, which make it possible to place multiple remote users in a limited physical space. We see MiniMates as complementary to traditional 2D video conferencing and immersive telepresence. Our approach automatically adjusts the formation of avatars and redirects users’ head and body orientation to facilitate communication. Results from our user study (n = 24) show that participants experience a higher sense of co-presence compared to video conferencing, and that MiniMates enabled them to communicate the direction of their interactions non-verbally as well as manage multiple simultaneous conversations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {708},
numpages = {20},
keywords = {Augmented Reality, Communication, Telepresence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713838,
author = {Houtti, Mo and Zhou, Moyan and Terveen, Loren and Chancellor, Stevie},
title = {Observe, Ask, Intervene: Designing AI Agents for More Inclusive Meetings},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713838},
doi = {10.1145/3706598.3713838},
abstract = {Video conferencing meetings are more effective when they are inclusive, but inclusion often hinges on meeting leaders’ and/or co-facilitators’ practices. AI systems can be designed to improve meeting inclusion at scale by moderating negative meeting behaviors and supporting meeting leaders. We explored this design space by conducting 9 user-centered ideation sessions, instantiating design insights in a prototype “virtual co-host” system, and testing the system in a formative exploratory lab study (n = 68 across 12 groups, 18 interviews). We found that ideation session participants wanted AI agents to ask questions before intervening, which we formalized as the “Observe, Ask, Intervene” (OAI) framework. Participants who used our prototype preferred OAI over fully autonomous intervention, but rationalized away the virtual co-host’s critical feedback. From these findings, we derive guidelines for designing AI agents to influence behavior and mediate group work. We also contribute methodological and design guidelines specific to mitigating inequitable meeting participation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {709},
numpages = {18},
keywords = {Video Conferencing, Group Work, Meetings, Inclusion, AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713684,
author = {Jamieson, Jack and Akahori, Wataru and Yamashita, Naomi},
title = {Understanding Cyber Hostility, Gossip, Exclusion, and Social Support in Remote and Hybrid Work Settings: Benefits and Challenges of Remote Work},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713684},
doi = {10.1145/3706598.3713684},
abstract = {Workplace incivility—low-intensity deviant behavior that violates norms of mutual respect—harms workers, though social support can alleviate this. Both incivility and support-seeking are shaped by the communication environment, which has been profoundly altered by remote and hybrid work, yet the outcomes of these changes are not well understood. Using surveys and interviews, we investigated USA remote and hybrid workers’ experiences with three types of cyber incivility (hostility, gossip, and exclusion), and follow-up support. We found cyber incivility experiences are more common among workers who spend more time at the office, and among women than men. We also discover that digital communication tools reduce some harms but exacerbate others, and that support-seeking is effective but harder to access remotely. Based on these findings, we propose implications for digital communication tools and policies to reduce cyber incivility and improve support access, fostering a more respectful and supportive remote work environment.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {710},
numpages = {23},
keywords = {remote work, hybrid work, incivility, peer support, gender},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713269,
author = {Chandrasekaran, Aishwarya and Bielicke, London and Shah, Diya and Janakiraman, Harisha and Mauriello, Matthew Louis},
title = {"I spent 14 hours debugging just one assignment": Toward Computer-Mediated Personal Informatics for Computer Science Student Mental Health},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713269},
doi = {10.1145/3706598.3713269},
abstract = {Anxiety and depression rates in Computer Science (CS) students are double those of other undergraduates and 5-10 times higher than the general population. However, factors contributing to the elevated mental health issues in CS students remain unknown. To bridge this gap, we conducted need-finding interviews (N=20), which revealed that the complexity of debugging, along with imposter syndrome, are key contributors to stress and burnout. Participants expressed openness toward and feature preferences in a computer-based Personal Informatics (PI) tool to facilitate self-reflection. In response, we developed EmotionStream, an algorithm-assisted PI tool that provides both contextual and emotional insights based on individual behaviors. We found that participants rated their experience with the tool highly. Post-hoc analysis revealed that emotional states, augmented with contextual cues, show promise of predicting real-time stress. Based on our findings, we provide design implications for future PI tools to support CS student mental well-being.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {711},
numpages = {19},
keywords = {student, stress, affect, personal informatics, computer science, mental health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713800,
author = {Ahmadpour, Naseem and Waycott, Jenny},
title = {Affective Interactions in Therapeutic Virtual Reality: A Critical Perspective},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713800},
doi = {10.1145/3706598.3713800},
abstract = {Therapeutic virtual reality (VR) can be a tool, platform or experience imaginary in the healthcare setting. Emotions and affective interaction are integral to the care needs and experiences in digital healthcare, yet remain under-investigated in therapeutic VR. We reflect on four cases involving therapeutic VR to critically examine the function and value of affective interaction. Through a synthesis of the cases, we identify how affective interaction can enhance or diminish healthcare outcomes and even cause potential harm. We draw five recommendations for the design and evaluation of therapeutic VR to challenge assumptions about: (1) knowledge holders and knowledge co-production in design, (2) hyper-visiblity of medical gaze and invisibility of affective experiences, (3) diverse utilities of VR, (4) weaving assessment of affective benefits and harms into evaluation of therapeutic VR, and (5) implementation of therapeutic VR in collaboration with caregivers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {712},
numpages = {11},
keywords = {virtual reality, affect, therapeutic, critical theory, emotional harm, healthcare},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713387,
author = {Noh, Hayoun and Chishti, Salman Muin Kayser and Jo, Hyunah and Newhouse, Nikki and Kim, Songi and Van Kleek, Max and Kang, Younah},
title = {CounselAR: Exploring How AR Filters Facilitate Online Psychotherapy In the Wild With South Korean Young Adults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713387},
doi = {10.1145/3706598.3713387},
abstract = {In a society where mental health issues are prevalent, engagement with psychotherapy remains low due to stigma and accessibility barriers. Telepsychotherapy offers a potential solution but holds challenges, including difficulties in encouraging open self-disclosure and ease of access. In this paper, we introduce CounselAR, an augmented reality (AR)-mediated therapy service designed to facilitate one-on-one therapy sessions by allowing both client and therapist to use AR filters to maintain varying degrees of anonymity. Through a six-week field deployment involving nine clients and four therapists, we explored how AR-mediated therapy might support psychotherapy from both the clients’ and therapists’ perspectives. The results illustrate the potential role of AR filters in enhancing self-disclosure, building rapport, and lowering entry barriers to psychotherapy. Drawing on these findings, we discuss the nuanced role of AR filters and the implications of leveraging AR in psychotherapy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {713},
numpages = {21},
keywords = {AR, HCI, Psychotherapy, Field Deployment Study, Young Adults, Mental Health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713730,
author = {Jung, Gyuwon and Lee, Uichin},
title = {CounterStress: Enhancing Stress Coping Planning through Counterfactual Explanations in Personal Informatics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713730},
doi = {10.1145/3706598.3713730},
abstract = {Personal informatics (PI) systems have been utilized to help individuals manage health issues such as stress by leveraging insights from self-tracking data. However, PI users may struggle to develop effective coping strategies because factors influencing stress are often difficult to change in practice, and multiple factors can contribute to stress simultaneously. In this study, we introduce CounterStress, a PI system designed to assist users in identifying contextual changes needed to address high-stress situations. CounterStress employs counterfactual explanations to identify and suggest alternative contextual changes, offering users actionable strategies to achieve a desired state. We conducted both lab-based and field user studies with 12 participants to evaluate the system’s usability and applicability, focusing on the benefits of counterfactual-based coping strategies, how users select viable strategies, and their real-world applications. Based on our findings, we discuss design implications for effectively leveraging counterfactuals in PI systems to support users’ stress-coping planning.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {714},
numpages = {20},
keywords = {Personal Informatics, Counterfactual Explanation, Coping Planning, Stress, Mental Health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714142,
author = {Bautista, Justine Rose and Wong, Novia and Reddy, Madhu and Schueller, Stephen M.},
title = {Healing Through Stories: Co-designing Digital Mental Health with Asian Americans},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714142},
doi = {10.1145/3706598.3714142},
abstract = {As mental health concerns grow among Asian American communities, there is an urgent need for culturally-relevant support. While digital mental health treatments (DMHTs) offer new opportunities for interventions, they have largely been focused on non-minority populations in the U.S. (e.g., Caucasians, females, who are middle-aged). Through co-design sessions with Asian Mental Health Collective (AMHC), this study examines the unique mental health challenges faced by Asian Americans, intergenerational connections and elements of culturally-relevant mental health support. The co-design sessions resulted in two prototypes: A multifunctional community hub, to strengthen connections and resource access, and a storytelling app, for sharing and preserving cultural narratives. These prototypes drew from community co-design sessions to include elements of storytelling, community-centered approaches, and intergenerational engagement in addressing mental health concerns among Asian Americans. Leveraging the heterogeneous and similar cultural experiences among Asian Americans, this paper presents and discusses nuances and considerations for digital mental health technology (DMHT) designs for minority communities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {715},
numpages = {19},
keywords = {Asian Americans, Co-design, Community engagement, Culturally-relevant interventions, Digital mental health, Intergenerational communication, Storytelling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713115,
author = {Fang, Anna and Chhabria, Hriday and Maram, Alekhya and Zhu, Haiyi},
title = {Social Simulation for Everyday Self-Care: Design Insights from Leveraging VR, AR, and LLMs for Practicing Stress Relief},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713115},
doi = {10.1145/3706598.3713115},
abstract = {Stress is an inevitable part of day-to-day life yet many find themselves unable to manage it themselves, particularly when professional or peer support are not always readily available. As self-care becomes increasingly vital for mental well-being, this paper explores the potential of social simulation as a safe, virtual environment for practicing in-the-moment stress relief for everyday social situations. Leveraging the immersive capabilities of VR, AR, and LLMs to create realistic interactions and environments, we developed eight interactive prototypes for various social stress related scenarios (e.g. public speaking, interpersonal conflict) across design dimensions of modality, interactivity, and mental health guidance in order to conduct prototype-driven semi-structured interviews with 19 participants. Our qualitative findings reveal that people currently lack effective means to support themselves through everyday stress and perceive social simulation – even at low immersion and interaction levels – to fill a gap for practical, controlled training of mental health practices. We outline key design needs for developing social simulation for self-care needs, and identify important considerations including risks of trauma from hyper-realism, distrust of LLM-recommended timing for mental health recommendations, and the value of accessibility for self-care interventions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {716},
numpages = {23},
keywords = {virtual reality, large language models, mental health, design, speed dating},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713174,
author = {Hodd\o{} Bak\r{a}s, Sigrid and Wo\'{z}niak, Miko\l{}aj P. and Herstad, Jo and Wo\'{z}niak, Pawe\l{} W. and Niess, Jasmin},
title = {The Dual Model for Everyday Stress Technology: Understanding the Lived Experience of Data-Driven Stress},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713174},
doi = {10.1145/3706598.3713174},
abstract = {Technology plays a dual role in our daily lives, both contributing to heightened stress levels and offering potential solutions for stress management. However, the lived experience of stress in everyday contexts remains underexplored, leaving a critical gap in our understanding of how stress manifests and how technology can effectively support stress management. To address this, we conducted user interviews and expert interviews with specialists in psychology, health, and stress research, complemented by an autoethnographic study. Our findings show the complexity of stress as both a subjective experience and a response shaped by socio-technical environments, leading to the construction of the Dual Model for Everyday Stress Technology. This model highlights the paradoxical nature of stress and its management in technology-mediated settings. We identify key directions for future stress-management technology design and research, with implications for creating meaningful, human-centred technologies for managing stress in everyday life.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {717},
numpages = {18},
keywords = {HCI theory, model, framework, well-being, stress, stress-tracking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713705,
author = {Das Swain, Vedant and Zhong, Qiuyue "Joy" and Parekh, Jash Rajesh and Jeon, Yechan and Zimmermann, Roy and Czerwinski, Mary P and Suh, Jina and Mishra, Varun and Saha, Koustuv and Hernandez, Javier},
title = {AI on My Shoulder: Supporting Emotional Labor in Front-Office Roles with an LLM-based Empathetic Coworker},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713705},
doi = {10.1145/3706598.3713705},
abstract = {Client-Service Representatives (CSRs) are vital to organizations. Frequent interactions with disgruntled clients, however, disrupt their mental well-being. To help CSRs regulate their emotions while interacting with uncivil clients, we designed Care-Pilot, an LLM-powered assistant, and evaluated its efficacy, perception, and use. Our comparative analyses between 665 human and Care-Pilot-generated support messages highlight Care-Pilot’s ability to adapt to and demonstrate empathy in various incivility incidents. Additionally, 143 CSRs assessed Care-Pilot’s empathy as more sincere and actionable than human messages. Finally, we interviewed 20 CSRs who interacted with Care-Pilot in a simulation exercise. They reported that Care-Pilot helped them avoid negative thinking, recenter thoughts, and humanize clients; showing potential for bridging gaps in coworker support. Yet, they also noted deployment challenges and emphasized the indispensability of shared experiences. We discuss future designs and societal implications of AI-mediated emotional labor, underscoring empathy as a critical function for AI assistants for worker mental health.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {718},
numpages = {29},
keywords = {large language models, empathy, emotion regulation, emotional labor, human-AI interaction, future of work, mental health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713638,
author = {Okoshi, Tadashi and Gao, Zexiong and Tan, Yi Zhen and Karasawa, Takumi and Miki, Takeshi and Sasaki, Wataru and Balan, Rajesh Krishna},
title = {Cyberoception: Finding A Painlessly-Measurable New Sense In The Cyberworld Towards Emotion-awareness In Computing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713638},
doi = {10.1145/3706598.3713638},
abstract = {In Affective computing, recognizing users’ emotions accurately is the basis of affective human–computer interaction. Understanding users’ interoception contributes to a better understanding of individually different emotional abilities, which is essential for achieving inter-individually accurate emotion estimation. However, existing interoception measurement methods, such as the heart rate discrimination task, have several limitations, including their dependence on a well-controlled laboratory environment and precision apparatus, making monitoring users’ interoception challenging. This study aims to determine other forms of data that can explain users’ interoceptive or similar states in their real-world lives and propose a novel hypothetical concept “cyberoception,” a new sense (1) which has properties similar to interoception in terms of the correlation with other emotion-related abilities, and (2) which can be measured only by the sensors embedded inside commodity smartphone devices in users’ daily lives. Results from a 10-day-long in-lab/in-the-wild hybrid experiment reveal a specific cyberoception type “Turn On” (users’ subjective sensory perception about the frequency of turning-on behavior on their smartphones) significantly related to participants’ emotional valence. We anticipate that cyberoception to serve as a fundamental building block for developing more “emotion-aware”, user-friendly applications and services.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {719},
numpages = {17},
keywords = {Emotion / Affective Computing ; Cyberoception ; Interoception ; Sensing ; Mobile Devices ; Wearable Devices ; Personalization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713848,
author = {Ibrahim, Seray B and Klasnja, Predrag and Gross, James J. and Slovak, Petr},
title = {Designing Daily Supports for Parent-Child Conversations about Emotion: Ecological Momentary Assessment as Intervention},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713848},
doi = {10.1145/3706598.3713848},
abstract = {Parental emotion coaching approaches that advocate for noticing and validating child emotions can greatly impact children’s regulatory abilities. However, in daily life, parents often struggle to apply emotion coaching strategies that they access through parenting programmes or online help, suggesting a need for in situ support. This paper explores a potential new avenue for providing such support. We undertook conceptual work to develop a set of emotion-focused reflective questions that could increase parents’ attention to child emotions and delivered these as daily ecological momentary assessments (EMAs). We investigated the perceived impact of the approach through a 2-week online trial (n=33) and then co-designed child-facing component with parents through a 4-week asynchronous remote community study (n=15). Our paper contributes (1) conceptual insights on designing a potential novel intervention approach, (2) empirical insights on its acceptability and perceived impacts for parents, and (3) design implications for applying the approach to wider psychological constructs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {720},
numpages = {21},
keywords = {Emotion Coaching, Parent-Child interaction, EMA, Situated Intervention},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713947,
author = {Goel, Hitesh and Park, Yoobin and Liou, Jin and Guevarra, Darwin A and Callahan, Peggy and Smith, Jolene and Yao, Bingsheng and Wang, Dakuo and Liu, Xin and McDuff, Daniel and Elhadad, Noemie and Simon-Thomas, Emiliana and Epel, Elissa and Xu, Xuhai},
title = {Promoting Prosociality via Micro-acts of Joy: A Large-Scale Well-Being Intervention Study},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713947},
doi = {10.1145/3706598.3713947},
abstract = {Prosociality has been well-documented to positively impact mental, social, and physical well-being. However, existing studies of interventions for promoting prosociality have limitations such as small sample sizes or unclear benchmarks. To address this gap, we conducted a global-scale well-being intervention deployment study, BIG JOY , with more than 18,000 participants from 172 countries and regions. The week-long BIG JOY intervention consists of seven daily micro-acts (i.e., brief actions that require minimal effort), each adapted from validated positive psychology interventions. The analyses of large-scale intervention data reveal unique insights into the impact of well-being micro-acts across diverse populations, patterns of responses, effectiveness of specific micro-acts and their nuanced impacts across different populations, linkages between improvements in prosociality and in well-being, as well as the potential for machine learning to predict changes in prosociality. This study offers valuable insights into a set of design guidelines for future well-being and prosociality interventions. We envision our work as a stepping stone towards future large-scale prosociality interventions that foster a more unified and compassionate world.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {721},
numpages = {28},
keywords = {Prosocial behavior, Well-being, Behavior-change intervention, Global intervention, Micro-acts},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713116,
author = {Zhu, Zicheng and Tan, Yugin and Yamashita, Naomi and Lee, Yi-Chieh and Zhang, Renwen},
title = {The Benefits of Prosociality towards AI Agents: Examining the Effects of Helping AI Agents on Human Well-Being},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713116},
doi = {10.1145/3706598.3713116},
abstract = {Prosocial behaviors, such as helping others, are well-known to enhance human well-being. While there is a growing trend of humans helping AI agents, it remains unclear whether the well-being benefits of helping others extend to interactions with non-human entities. To address this, we conducted an experiment (N = 295) to explore how helping AI agents impacts human well-being, especially when the agents fulfill human basic psychological needs—relatedness, competence, and autonomy—during the interaction. Our findings showed that helping AI agents reduced participants’ feelings of loneliness. When AI met participants’ needs for competence and autonomy during the helping process, there was a further decrease in loneliness and an increase in positive affect. However, when AI did not meet participants’ need for relatedness, participants experienced an increase in positive affect. We discuss the implications of these findings for understanding how AI can support human well-being.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {722},
numpages = {18},
keywords = {Prosocial Behaviors, Helping, Well-Being, Human Basic Psychological Needs, Human-AI Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713434,
author = {So, Samuel and Sou, Vannary and Munson, Sean A. and Ghoshal, Sucheta},
title = {The Cruel Optimism of Tech Work: Tech Workers' Affective Attachments in the Aftermath of 2022-23 Tech Layoffs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713434},
doi = {10.1145/3706598.3713434},
abstract = {The aftermath of industry-wide mass layoffs has led to an increasingly discontent and disillusioned tech workforce. Our empirical study with 29 laid off tech workers presents critical reflections on tech work and the tech industry in the aftermath of mass layoffs. Through weekly creative reflection activities over 5 weeks as well as focus groups, we find that tech workers experience alienation and unfulfillment with their work. Tech workers expressed conflicted emotions in assessing their attachment to tech work as a site of labor, oscillating between discomfort with the current status of the tech industry and lack of agency in choosing alternatives. We argue that tech workers are embroiled in cruelly optimistic relationships with tech work, and trace the implications of this on conflicting sociotechnical imaginaries shaping tech work, affective attachments in the tech industry, and tech worker resistance and organizing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {723},
numpages = {20},
keywords = {tech layoffs; tech workers; labor},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713585,
author = {Burgess, Eleanor R. and Munson, Sean A. and Mohr, David C. and Reddy, Madhu C.},
title = {What's In Your Kit? Mental Health Technology Kits for Depression Self-Management},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713585},
doi = {10.1145/3706598.3713585},
abstract = {This paper characterizes the mental health technology “kits” of individuals managing depression: the specific technologies on their digital devices and physical items in their environments that people turn to as part of their mental health management. We interviewed 28 individuals living across the United States who use bundles of connected tools for both individual and collaborative mental health activities. We contribute to the HCI community by conceptualizing these tool assemblages that people managing depression have constructed over time. We detail categories of tools, describe kit characteristics (intentional, adaptable, available), and present participant ideas for future mental health support technologies. We then discuss what a mental health technology kit perspective means for researchers and designers and describe design principles (building within current toolkits; creating new tools from current self-management strategies; and identifying gaps in people’s current kits) to support depression self-management across an evolving set of tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {724},
numpages = {19},
keywords = {Mental health, depression, technology kit, technology bundle, self-management, tool, toolkit, design principles},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713936,
author = {Liu, Chang and Wang, Xiangyang and Yu, Chun and Shi, Yingtian and Wang, Chongyang and Liu, Ziqi and Liang, Chen and Shi, Yuanchun},
title = {Enhancing Smartphone Eye Tracking with Cursor-Based Interactive Implicit Calibration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713936},
doi = {10.1145/3706598.3713936},
abstract = {The limited accuracy of eye-tracking on smartphones restricts its use. Existing RGB-camera-based eye-tracking relies on extensive datasets, which could be enhanced by continuous fine-tuning using calibration data implicitly collected from the interaction. In this context, we propose COMETIC (Cursor Operation Mediated Eye-Tracking Implicit Calibration), which introduces a cursor-based interaction and utilizes the inherent correlation between cursor and eye movement. By filtering valid cursor coordinates as proxies for the ground truth of gaze and fine-tuning the eye-tracking model with corresponding images, COMETIC enhances accuracy during the interaction. Both filtering and fine-tuning use pre-trained models and could be facilitated using personalized, dynamically updated data. Results show COMETIC achieves an average eye-tracking error of 278.3 px (1.60 cm, 2.29°), representing a 27.2\% improvement compared to that without fine-tuning. We found that filtering cursor points whose actual distance to gaze is 150.0 px (0.86 cm) yields the best eye-tracking results.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {725},
numpages = {22},
keywords = {Eye Tracking, Implicit Calibration, Mobile Devices, Personalization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714021,
author = {Waugh, Kieran and McGill, Mark and Freeman, Euan},
title = {Everything to Gain: Combining Area Cursors with increased Control-Display Gain for Fast and Accurate Touchless Input},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714021},
doi = {10.1145/3706598.3714021},
abstract = {Touchless displays often use mid-air gestures to control on-screen cursors for pointer interactions. Area cursors can simplify touchless cursor input by implicitly targeting nearby widgets without the cursor entering the target. However, for displays with dense target layouts, the cursor still has to arrive close to the widget, meaning the benefits of area cursors for time-to-target and effort are diminished. Through two experiments, we demonstrate for the first time that fine-tuning the mapping between hand and cursor movements (control-display gain – CDG) can address the deficiencies of area cursors and improve the performance of touchless interaction. Across several display sizes and target densities (representative of myriad public displays used in retail, transport, museums, etc), our findings show that the forgiving nature of an area cursor compensates for the imprecision of a high CDG, helping users interact more effectively with smaller and more controlled hand/arm movements.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {726},
numpages = {16},
keywords = {Mid-Air Gestures, Area Cursors, Touchless Interaction, Touchless Widgets, Control Display Gain},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713554,
author = {Zindulka, Tim and Sekowski, Jannek Maximilian and Lehmann, Florian and Buschek, Daniel},
title = {Exploring Mobile Touch Interaction with Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713554},
doi = {10.1145/3706598.3713554},
abstract = {Interacting with Large Language Models (LLMs) for text editing on mobile devices currently requires users to break out of their writing environment and switch to a conversational AI interface. In this paper, we propose to control the LLM via touch gestures performed directly on the text. We first chart a design space that covers fundamental touch input and text transformations. In this space, we then concretely explore two control mappings: spread-to-generate and pinch-to-shorten, with visual feedback loops. We evaluate this concept in a user study (N=14) that compares three feedback designs: no visualisation, text length indicator, and length + word indicator. The results demonstrate that touch-based control of LLMs is both feasible and user-friendly, with the length + word indicator proving most effective for managing text generation. This work lays the foundation for further research into gesture-based interaction with LLMs on touch devices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {727},
numpages = {21},
keywords = {Writing assistance, Large language models, Human-AI interaction, Mobile interaction, Touch interaction, Direct manipulation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714314,
author = {Ma, Yan and Zhang, Dan and Ramakrishnan, IV and Bi, Xiaojun},
title = {LLM Powered Text Entry Decoding and Flexible Typing on Smartphones},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714314},
doi = {10.1145/3706598.3714314},
abstract = {Large language models (LLMs) have shown exceptional performance in various language-related tasks. However, their application in keyboard decoding, which involves converting input signals (e.g. taps and gestures) into text, remains underexplored. This paper presents a fine-tuned FLAN-T5 model for decoding. It achieves 93.1\% top-1 accuracy on user-drawn gestures, outperforming the widely adopted SHARK2 decoder, and 95.4\% on real-word tap typing data. In particular, our decoder supports Flexible Typing, allowing users to enter a word with taps, gestures, multi-stroke gestures, and tap-gesture combinations. User study results show that&nbsp;Flexible Typing is beneficial and well-received by participants, where 35.9\% of words were entered using word gestures, 29.0\% with taps, 6.1\% with multi-stroke gestures, and the remaining 29.0\% using tap-gestures. Our investigation suggests that the LLM-based decoder improves decoding accuracy over existing word gesture decoders while enabling the Flexible Typing &nbsp;method, which enhances the overall typing experience and accommodates diverse user preferences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {728},
numpages = {14},
keywords = {text entry, keyboard decoding, language model, gesture input},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713956,
author = {Kim, Insu and Shin, Suhyeon and Choi, Jaemin and Kim, Junseob and Lee, Junhyub and Oh, Sangeun and Park, Eunji and Kim, Hyosu},
title = {MagPie: Extending a Smartphone’s Interaction Space via a Customizable Magnetic Back-of-Device Input Accessory},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713956},
doi = {10.1145/3706598.3713956},
abstract = {Back-of-Device (BoD) interfaces have emerged as a promising solution to free up screen real estate in smartphones by offloading interactions from the display to the back, thereby reducing reliance on on-screen interfaces. However, existing BoD solutions face limitations, such as requiring specialized hardware, consuming excessive power, or offering limited input vocabularies. We introduce MagPie, a novel BoD interface that leverages the magnetic phenomenon induced by MagSafe, part of the wireless charging standard. Users can seamlessly attach MagPie to MagSafe-enabled smartphones and interact using tangible, modular interfaces that generate unique magnetic signals upon activation. MagPie then detects these signals and recognizes the input through magnetic sensing. Our experiments with real-world users demonstrate that i) MagPie achieves high performance in accuracy, usability, deployability, responsiveness, and robustness across diverse environments, and ii) its tangible, intuitive, and customizable design opens up possibilities for a whole new class of smartphone interaction scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {729},
numpages = {16},
keywords = {Back-of-Device Interaction. Tangible User Interface, Magnetic sensing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714056,
author = {Gil, Hyunjae and Pratap, Ashish and Joseph, Iniyan and Kim, Jin Ryong},
title = {PropType: Everyday Props as Typing Surfaces in Augmented Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714056},
doi = {10.1145/3706598.3714056},
abstract = {We introduce PropType, an interactive interface that transforms everyday objects into typing surfaces within an Augmented Reality (AR) environment. Users can interact with nearby props, such as cups, water bottles, boxes, and various other objects, utilizing them as on-the-go keyboards. To develop PropType, we conducted three studies. The first study involved observing users to understand how they naturally engage with prop surfaces for typing. The second study assessed the reachability and efficiency of touch input across four props with different sizes and shapes. Based on these insights, we designed customized keyboard layouts for each prop. In the third study, we evaluated typing performance using PropType, achieving an average typing speed of up to 26.1 words per minute (WPM) with 2.2\% corrected error rate (CER) and 1.1\% uncorrected error rate (UER). Finally, we present a PropType editing tool that allows users to customize keyboard layouts and visual effects for prop-based typing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {730},
numpages = {18},
keywords = {Everyday objects, text entry, object typing, object interaction, augmented reality, mixed reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714066,
author = {He, Zhe and Wang, Zixuan and Yu, Chun and Zhang, Chengwen and Shen, Xiyuan and Shi, Yuanchun},
title = {WritingRing: Enabling Natural Handwriting Input with a Single IMU Ring},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714066},
doi = {10.1145/3706598.3714066},
abstract = {Tracking continuous 2D sequential handwriting trajectories accurately using a single IMU ring is extremely challenging due to the significant displacement between the IMU’s wearing position and the location of the tracked fingertip. We propose WritingRing, a system that uses a single IMU ring worn at the base of the finger to support natural handwriting input and provide real-time 2D trajectories. To achieve this, we first built a handwriting dataset using a touchpad and an IMU ring (N=20). Next, we improved the LSTM model by incorporating streaming input and a TCN network, significantly enhancing accuracy and computational efficiency, and achieving an average trajectory accuracy of 1.63mm. Real-time usability studies demonstrated that the system achieved 88.7\% letter recognition accuracy and 68.2\% word recognition accuracy, which reached 84.36\% when restricting the output to words within a vocabulary of size 3000. WritingRing can also be embedded into existing ring systems, providing a natural and real-time solution for various applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {731},
numpages = {15},
keywords = {Ring Interaction, Handwriting, IMU, Touch Interface, Wearable},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714109,
author = {Johansen, Stine S and Donovan, Jared W and Rittenbruch, Markus},
title = {Articulating Human-World Relations from Co-Designing a Collaborative Robotic System},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714109},
doi = {10.1145/3706598.3714109},
abstract = {In contrast to traditional industrial robots, collaborative robots are developed with the intention of allowing for close-proximity physical interaction between humans and robots. Current definitions of collaborative robots provide a pragmatic starting point for establishing safety guidelines, choosing operating parameters, and implementing organisational changes, but remain predicated on technological conceptions that prioritise a conscious split between people and robots, with the surrounding world as merely a physical site for interaction. In this paper, we take a postphenomenological perspective on robots in an investigation of human-world relations that robots can give rise to. This perspective can help elucidate the nature of such relations in a design process. Our investigation is anchored in an 8-month research study that aimed to, first, identify opportunities for a robot integration within a medical manufacturing facility and, second, facilitate a design and implementation process of a proof-of-concept robotic system in collaboration with workers. The paper contributes with an empirically anchored postphenomenological analysis of how human-world relations played out in the design process of a collaborative robotic system. Finally, we elaborate on the utility and limitations of a postphenomenological lens for design research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {732},
numpages = {15},
keywords = {Robotics, Postphenomenology, Human-Robot Collaboration, Designerly HRI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714266,
author = {Shiokawa, Yoshiaki and Chen, Winnie and Nittala, Aditya Shekhar and Alexander, Jason and Sharma, Adwait},
title = {Beyond Vacuuming: How Can We Exploit Domestic Robots' Idle Time?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714266},
doi = {10.1145/3706598.3714266},
abstract = {We are increasingly adopting domestic robots (e.g., Roomba) that provide relief from mundane household tasks. However, these robots usually only spend little time executing their specific task and remain idle for long periods. They typically possess advanced mobility and sensing capabilities, and therefore have significant potential applications beyond their designed use. Our work explores this untapped potential of domestic robots in ubiquitous computing, focusing on how they can improve and support modern lifestyles. We conducted two studies: an online survey (n=50) to understand current usage patterns of these robots within homes and an exploratory study (n=12) with HCI and HRI experts. Our thematic analysis revealed 12 key dimensions for developing interactions with domestic robots and outlined over 100 use cases, illustrating how these robots can offer proactive assistance and provide privacy. Finally, we implemented a proof-of-concept prototype to demonstrate the feasibility of reappropriating domestic robots for diverse ubiquitous computing applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {733},
numpages = {17},
keywords = {domestic robots, ubiquitous, interaction, design space},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713673,
author = {Biswas, Bijetri and Powell, Emma and Nixdorf, Robert and Sewell, Richard and Roudaut, Anne},
title = {Encounter with the Giants: Understanding Interaction with Large-scale Inflatable Soft Robots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713673},
doi = {10.1145/3706598.3713673},
abstract = {Soft robots, constructed from compliant materials, offer unique flexibility and adaptability. However, most research has focused on small-scale interactions, leaving the potential of large-scale soft robots largely unexplored. This research explores how humans engage with inflatable soft robots that are large in size and created for fun and artistic expression. We conducted 22 hours of video analysis (N=30) and thematic interviews (N=20) to understand user engagement and explore their motivations. Our findings revealed a range of interactions, from delicate touches to immersive full-body engagement, driven by trust, safety, and emotional connection. Participants frequently compared the robots to peaceful creatures like plants and sea animals, fostering playful and therapeutic interactions. These insights highlight the potential of giant soft robots in enhancing emotional well-being, therapeutic applications, and immersive experiences. This paper aims to inspire future designs that leverage the unique attributes of large-scale soft robots for trust-centered, interactive human-robot relationships.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {734},
numpages = {15},
keywords = {Human-robot interaction, soft robotics, qualitative study, video analysis, large-scale robots},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713790,
author = {Yu, Xinyan and Hoggenm\"{u}ller, Marius and Tran, Tram Thi Minh and Wang, Yiyuan and Zhang, Qiuming and Tomitsch, Martin},
title = {Peek into the `White-Box': A Field Study on Bystander Engagement with Urban Robot Uncertainty},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713790},
doi = {10.1145/3706598.3713790},
abstract = {Uncertainty inherently exists in the autonomous decision-making process of robots. Involving humans in resolving this uncertainty not only helps robots mitigate it but is also crucial for improving human-robot interactions. However, in public urban spaces filled with unpredictability, robots often face heightened uncertainty without direct human collaborators. This study investigates how robots can engage bystanders for assistance in public spaces when encountering uncertainty and examines how these interactions impact bystanders’ perceptions and attitudes towards robots. We designed and tested a speculative ‘peephole’ concept that engages bystanders in resolving urban robot uncertainty. Our design is guided by considerations of non-intrusiveness and eliciting initiative in an implicit manner, considering bystanders’ unique role as non-obligated participants in relation to urban robots. Drawing from field study findings, we highlight the potential of involving bystanders to mitigate urban robots’ technological imperfections to both address operational challenges and foster public acceptance of urban robots. Furthermore, we offer design implications to encourage bystanders’ involvement in mitigating the imperfections.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {735},
numpages = {15},
keywords = {Human-robot collaboration; urban robots; robot uncertainty; field study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713237,
author = {Pelikan, Hannah R.M. and Bu, Fanjun and Ju, Wendy},
title = {The People Behind the Robots: How Wizards Wrangle Robots in Public Deployments},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713237},
doi = {10.1145/3706598.3713237},
abstract = {In the Wizard-of-Oz study paradigm, human “wizards” perform not-yet-implemented system behavior, simulating, among others, how autonomous robots could interact in public to see how unwitting bystanders respond. This paper analyzes a 60-minute video recording of two wizards in a public plaza who are operating two trash-collecting robots within their line of sight. We take an ethnomethodology and conversation analysis perspective to scrutinize interactions between the wizards and the people in the plaza, focusing on critical instances where one robot gets stuck and requires collaborative intervention by the wizards. Our analysis unpacks how the wizards deal with emergent problems by pushing one robot into the other, how they manage front and backstage interactions, and how they monitor the location of each other’s robots. We discuss how scrutinizing the work of wizards can inform explorative Wizard-of-Oz paradigms, the design of multi-agent robot systems, and the operation of urban robots from a distance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {736},
numpages = {21},
keywords = {Wizard-of-Oz, simulation, urban robotics, public robots, multi-agent systems, ethnomethodology, conversation analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714009,
author = {Franchi, Matthew and Parreira, Maria Teresa and Bu, Fanjun and Ju, Wendy},
title = {The Robotability Score: Enabling Harmonious Robot Navigation on Urban Streets},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714009},
doi = {10.1145/3706598.3714009},
abstract = {This paper introduces the Robotability Score (R), a novel metric that quantifies the suitability of urban environments for autonomous robot navigation. Through expert interviews and surveys, we identify and weigh key features contributing to R for wheeled robots on urban streets. Our findings reveal that pedestrian density, crowd dynamics and pedestrian flow are the most critical factors, collectively accounting for 28\% of the total score. Computing robotability across New York City yields significant variation; the area of highest R is 3.0 times more “robotable” than the area of lowest R. Deployments of a physical robot on high and low robotability areas show the adequacy of the score in anticipating the ease of robot navigation. This new framework for evaluating urban landscapes aims to reduce uncertainty in robot deployment while respecting established mobility patterns and urban planning principles, contributing to the discourse on harmonious human-robot environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {737},
numpages = {17},
keywords = {robotability, urban robotics, robot navigation, urban computing, human-robot interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713440,
author = {Han, Changyo and Nakagawa, Yosuke and Naemura, Takeshi},
title = {corobos: A Design for Mobile Robots Enabling Cooperative Transitions between Table and Wall Surfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713440},
doi = {10.1145/3706598.3713440},
abstract = {Swarm User Interfaces allow dynamic arrangement of user environments through the use of multiple mobile robots, but their operational range is typically confined to a single plane due to constraints imposed by their two-wheel propulsion systems. We present corobos, a proof-of-concept design that enables these robots to cooperatively transition between table (horizontal) and wall (vertical) surfaces seamlessly, without human intervention. Each robot is equipped with a uniquely designed slope structure that facilitates smooth rotation when another robot pushes it toward a target surface. Notably, this design relies solely on passive mechanical elements, eliminating the need for additional active electrical components. We investigated the design parameters of this structure and evaluated its transition success rate through experiments. Furthermore, we demonstrate various application examples to showcase the potential of corobos in enhancing user environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {738},
numpages = {16},
keywords = {swarm user interfaces, human robot interaction, surface transition},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713343,
author = {Ikeya, Yuta and Barati, Bahareh and Wensveen, Stephan},
title = {Aesthetics in Designing with the Living: A Systematic Review of Critical Perspectives and Artefacts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713343},
doi = {10.1145/3706598.3713343},
abstract = {Design aesthetics, predominantly concerned with artefact’s form and experience, has significantly shaped the evolution of design and HCI. As design practices expand to incorporate living organisms and embrace posthumanist shifts, traditional human-centered aesthetics increasingly fall short in addressing nonhuman experiences and the ethical and ecological complexities of more-than-human entanglements. Responding to the absence of overarching guidance for moving beyond traditional aesthetics, this paper systematically reviews more-than-human aesthetic perspectives within and beyond HCI and design. We first examine contemporary critical aesthetic discourse across disciplines such as art, geography, and human-animal interaction, identifying three key orientations that move away from human-centric aesthetics—phenomenologically, ontologically, and conceptually. We then review artefact-oriented publications in HCI and design venues to offer concrete examples of how these perspectives can be navigated, interpreted, combined, and applied in practice. This paper contributes a critical framework to inspire and challenge designers as they engage with aesthetics in more-than-human design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {739},
numpages = {33},
keywords = {Aesthetics; design aesthetics; more-than-human design; literature review},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713713,
author = {Yang, Yangyang and Ryokai, Kimiko},
title = {Being The Creek: Mobile Augmented Reality Experience as an Invitation for Exploring More-Than-Human Perspectives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713713},
doi = {10.1145/3706598.3713713},
abstract = {We introduce Being The Creek, a mobile augmented reality (MAR) experience that invites participants to take a “first-person” perspective of a historically-significant-creek by lying alongside her and getting attuned to her environment through embodied multisensory engagement. Individuals experience how the world might appear from the Creek’s perspective, from the pre-colonial respect she received from Indigenous peoples, through the industrial period when the Creek was used as a sewer, to a speculative future of collaborative survival despite capitalism. Fifteen participants of our study each experienced a range of emotions while “being” the Creek through temporal and spatial explorations. As participants moved between human-centered and creek-centered perspectives, they explored the Creek’s unique subjectivity and the human-nonhuman power relations, leading them to de-emphasize the stereotypical human-centric stance. We discuss designing mobile experiences that encourage movement beyond human-centric perspectives and encourage “noticing” for more-than-human worlds.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {740},
numpages = {19},
keywords = {more-than-human design, post-anthropocentric design, decentering, embodied interaction, mobile technology, augmented reality, AR, sustainable HCI, nonhuman, nature, water, creek},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713977,
author = {Cucumak, Sena and Subasi, Ozge},
title = {Designing Urban Noticing Probes for Community Animals and Cohabitation in T\"{u}rkiye},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713977},
doi = {10.1145/3706598.3713977},
abstract = {Design tools and probing, in particular, have long offered critical perspectives in HCI, broadening the understanding of who benefits from the design. Further, the designerly implementation of critical perspectives and theories using tools such as probes can support HCI designers with theoretically informed dialogical tools. However, these approaches and processes are majorly designed to understand human interactions. In this paper, we introduce urban noticing probes developed to decentre the humans in multispecies interactions by following the arts of noticing theory: noticing into, for, and through within urban relationality, focusing on the case of community animals in T\"{u}rkiye. Our goal is to create a better understanding of the functions of "urban noticing probes" for HCI designers and researchers to (1) gain relational and reflexive awareness, (2) identify intervention spaces for multispecies cohabitation, and (3) explore future design directions for urban noticing probes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {741},
numpages = {19},
keywords = {Arts of Noticing, Urban Noticing Tools, Community Animals},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713151,
author = {Altarriba Bertran, Ferran and Buruk, O\u{g}uz 'Oz' and M\'{a}rquez Puig, Jordi and Hamari, Juho},
title = {How Can Interactive Technology Help Us to Experience Joy With(in) the Forest? Towards a Taxonomy of Tech for Joyful Human-Forest Interactions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713151},
doi = {10.1145/3706598.3713151},
abstract = {This paper presents intermediate-level knowledge in the form of a taxonomy that highlights 12 different ways in which interactive tech might support forest-related experiences that are joyful for humans. It can inspire and provide direction for designs that aim to enrich the experiential texture of forests. The taxonomy stemmed from a reflexive analysis of 104 speculative ideas produced during a year-long co-design process, where we co-experienced and creatively engaged a diverse range forests and forest-related activities with 250+ forest-goers with varied backgrounds and sensitivities. Given that breadth of forests and populations involved, our work foregrounds a rich set of design directions that set an actionable early frame for creating tech that supports joyful human-forest interplays – one that we hope will be extended and consolidated in future research, ours and others'.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {742},
numpages = {21},
keywords = {Nature, celebratory tech, forests, interactive tech, joy, play, speculative design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713272,
author = {Chen, Yuning and Cachat, Elise and Pschetz, Larissa},
title = {Labour Provenance as a Lens to Reveal More-Than-Human Ecologies in Biological Design and HCI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713272},
doi = {10.1145/3706598.3713272},
abstract = {Efforts to integrate living organisms in the design of new technologies are often motivated by prospects of greater sustainability and increased connection with more-than-human worlds. In this paper, we critically discuss these motivations by analysing the vast and mostly hidden ecologies of more-than-human organisms implicated in a biodesign lab experiment. Through the lenses of labour theory, we investigate the extent to which organisms’ bodily functions and relationships can be subsumed into capitalist modes of production. In order to help reveal and map out the network of more-than-human contributors to biodesign, we develop a workshop method and a labour provenance analytical framework that identifies five types of more-than-human labourers, stretching from the centre to the periphery of biodesign. We conclude by discussing how sustainable approaches should account for wider more-than-human ecologies, and how the labour lens could help stress conflicting goals, implicit anthropocentric agendas and ways of improving organismal welfare in biological design and HCI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {743},
numpages = {22},
keywords = {Labour Theory, Provenance, More-Than-Human, Ecologies, Sustainability, Design, Ethics, Multispecies, Bio-HCI, DIY-Bio, Microbe-HCI, Biodesign, Posthumanism, Care},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713311,
author = {Wang, Jiaqi and Brewster, Stephen Anthony and Hirskyj-Douglas, Ilyena},
title = {Reshaping Human-Animal Relationships: Exploring Lemur and Human Enrichment through Smell, Sound, and Sight},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713311},
doi = {10.1145/3706598.3713311},
abstract = {Zoos aim to uphold high animal welfare standards while educating the public, yet the direct interactions that attract visitors can negatively impact the animals. Exploring technological solutions to reshape this human-animal relationship in zoos, we developed a novel device allowing lemurs to trigger olfactory, auditory, and visual stimuli in their enclosure. Over 63 days, lemurs engaged most with multimodal stimuli and with visual the least. We then created a similar device for zoo visitors to educate them about lemurs and their stimuli choices. Deploying for 20 days (no devices, lemur-only, visitor-only, and both devices), we examined the impact on visitor behaviour, education, empathy, and experience. From 968 questionnaires and 25,782 visitors, we found that using technology on the lemur and visitor sides jointly significantly enhanced all measured visitor factors, even if the visitors did not directly interact with the device or observe lemurs using theirs. This approach supports long-term conservation and visitor education efforts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {744},
numpages = {19},
keywords = {animal-computer interaction, red-ruffed lemurs, primate, multimodal, education, zoo},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714304,
author = {Wang, Guanyun and Chen, Chuang and Jin, Xiao and Chen, Yulu and Zheng, Yangweizhe and Zhen, Qianzi and Zhang, Yang and Li, Jiaji and Yang, Yue and Tao, Ye and Luo, Shijian and Sun, Lingyun},
title = {TH-Wood: Developing Thermo-Hygro-Coordinating Driven Wood Actuators to Enhance Human-Nature Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714304},
doi = {10.1145/3706598.3714304},
abstract = {Wood has become increasingly applied in shape-changing interfaces for its eco-friendly and smart responsive properties, while its applications face challenges as it remains primarily driven by humidity. We propose TH-Wood, a biodegradable actuator system composed of wood veneer and microbial polymers, driven by both temperature and humidity, and capable of functioning in complex outdoor environments. This dual-factor-driven approach enhances the sensing and response channels, allowing for more sophisticated coordinating control methods. To assist in designing and utilizing the system more effectively, we developed a structure library inspired by dynamic plant forms, conducted extensive technical evaluations, created an educational platform accessible to users, and provided a design tool for deformation adjustments and behavior previews. Finally, several ecological applications demonstrate the potential of TH-Wood to significantly enhance human interaction with natural environments and expand the boundaries of human-nature relationships.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {745},
numpages = {19},
keywords = {Shape-changing Interface, Human-nature Interaction, Bionic Design, Wooden Actuator},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714221,
author = {Kim, DaeWook and Min, Yewon and Jeong, Jae-Yeop and Han, Sehee and Hwang, JiYeon and Jeong, Jin-Woo},
title = {"Through the Looking Glass, and What We Found There": A Comprehensive Study of User Experiences with Pass-Through Devices in Everyday Activities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714221},
doi = {10.1145/3706598.3714221},
abstract = {Pass-through technologies are promising for mixed reality (MR) systems. Therefore, various MR applications operating in pass-through devices emerged in diverse domains, such as education and healthcare. However, research on the everyday use of pass-through devices remains limited, despite it blending real and virtual environments. This study explores the user experience of pass-through devices in people’s daily tasks. We conducted a field study with 16 participants and analyzed data from eight daily tasks. For in-depth analysis, we employed three measures in terms of quantitative, qualitative, and bio-signal. As a result, we found that participants felt differently in terms of immersion, collision anxiety, and workload. Findings suggest that pass-through devices are not yet fully ready for integration into daily life. However, the potential for widespread adoption exists as the technology continues to advance. Finally, we offer guidelines and considerations to improve the usability of pass-through devices for everyday use.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {746},
numpages = {30},
keywords = {Mixed reality, human-computer interaction, pass-through devices, everyday use, field study, user experience},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713914,
author = {Mackamul, Eva and Chevalier, Fanny and Casiez, G\'{e}ry and Malacria, Sylvain},
title = {Does Adding Visual Signifiers in Animated Transitions Improve Interaction Discoverability?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713914},
doi = {10.1145/3706598.3713914},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {747},
numpages = {17},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713992,
author = {Prummer, Franziska and Shereef Abdelwahab, Mohamed and Weidner, Florian and Abdrabou, Yasmeen and Gellersen, Hans},
title = {It’s Not Always the Same Eye That Dominates: Effects of Viewing Angle, Handedness and Eye Movement in 3D},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713992},
doi = {10.1145/3706598.3713992},
abstract = {Understanding eye dominance, the subconscious preference for one eye, has significant implications for 3D user interfaces in VR and AR, particularly in interface design and rendering. Although HCI recognizes eye dominance, little is known about what causes it to switch from one eye to another. To explore this, we studied eye dominance in VR, where 28 participants manually aligned a cursor with a distant target across three tasks. We manipulated the horizontal viewing angle, the hand used for alignment, and eye movement induced by target behaviour. Our results confirm the dynamic nature of eye dominance, though with fewer switches than expected and varying influences across tasks. This highlights the need for adaptive HCI techniques, which account for shifts in eye dominance in system design, such as gaze-based interaction, visual design, or rendering, and can improve accuracy, usability, and experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {748},
numpages = {10},
keywords = {Dominant Eye, Virtual Reality, Eye Movements},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713411,
author = {Kim, Jonghyun and Kim, Joongseok and Yoon, June-Seop and Moon, Hee-Seung and Kim, Sunjun and Lee, Byungjoo},
title = {Modeling User Performance in Multi-Lane Moving-Target Acquisition},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713411},
doi = {10.1145/3706598.3713411},
abstract = {Modern video games often feature moving target acquisition (MTA) tasks, where users must press a button when a moving target reaches an acquisition line. User performance models in MTA are useful for quantitative skill analysis and computational game level design, but have so far been constructed only for cases where there is a single lane for a target to appear and follow. In this study, the first user performance model is presented and validated for an MTA task with multiple lanes. The model is built as an integration of the existing MTA model and the drift-diffusion model, a model of human decision-making process under time-pressure. In a user study, we showed that the model can fit lane recognition error rates and input timing distributions with significantly higher coefficients of determination (R2) and accuracy than a baseline model.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {749},
numpages = {18},
keywords = {Moving-Target Acquisition, Temporal Pointing, Drift-Diffusion},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713152,
author = {Klass, Lina and Lammert, Anton Benjamin and Simon, Laura and Froehlich, Bernd and Hornecker, Eva and Ehlers, Jan},
title = {Perceived Asynchrony of Rhythmic Stimuli Affects Pupil Diameter and Smooth Pursuit Eye Movements},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713152},
doi = {10.1145/3706598.3713152},
abstract = {In networked applications, latency can disrupt the sense of synchrony by causing offsets e.g. between local speech and remote visual response. We investigate the influence of frequency and Stimulus Onset Asynchrony (SOA) on synchrony perception during rhythmic audiovisual experiences. Our results show that the Point of Subjective Synchrony (PSS) is influenced by frequency, whereas the Window of Subjective Synchrony (WSS) is not. Variations in SOA induce adaptive gaze behavior in response to audiovisual latencies, while pupil diameter increases with increasing SOA, suggesting a higher cognitive load for successive unisensory rather than integrated events. This has practical implications for the design of computer-mediated applications that promote a sense of community through rhythmic interaction. Eye tracking data may indicate perceived (a)synchrony in audiovisual integration. In addition, the choice of frequencies may help to mask latencies, enhance the experience of synchrony and thus support feelings of closeness and intimacy in virtual interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {750},
numpages = {14},
keywords = {Eye movement, eye tracking, smooth pursuit, gaze, pupillometry, synchrony},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713910,
author = {Saxena, Shreshth and Visram, Areez and Lobo, Neil and Mirza, Zahid and Khan, Mehak and Pirabaharan, Biranugan and Nguyen, Alexander and Fink, Lauren K},
title = {SocialEyes: Scaling Mobile Eye-tracking to Multi-person Social Settings},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713910},
doi = {10.1145/3706598.3713910},
abstract = {Eye movements provide a window into human behaviour, attention, and interaction dynamics. Challenges in real-world, multi-person environments have, however, restrained eye-tracking research predominantly to single-person, in-lab settings. We developed a system to stream, record, and analyse synchronised data from multiple mobile eye-tracking devices during collective viewing experiences (e.g., concerts, films, lectures). We implemented lightweight operator interfaces for real-time-monitoring, remote-troubleshooting, and gaze-projection from individual egocentric perspectives to a common coordinate space for shared gaze analysis. We tested the system in a live concert and a film screening with 30 simultaneous viewers during each of two public events (N=60). We observe precise time-synchronisation between devices measured through recorded clock-offsets, and accurate gaze-projection in challenging dynamic scenes. Our novel analysis metrics and visualizations illustrate the potential of collective eye-tracking data for understanding collaborative behaviour and social interaction. This advancement promotes ecological validity in eye-tracking research and paves the way for innovative interactive tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {751},
numpages = {19},
keywords = {multi-person, eye-tracking, social settings, naturalistic, visualisation, joint gaze, music, concert, film, homography},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713092,
author = {Namnakani, Omar and Abdrabou, Yasmeen and Grizou, Jonathan and Khamis, Mohamed},
title = {Stretch Gaze Targets Out: Experimenting with Target Sizes for Gaze-Enabled Interfaces on Mobile Devices},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713092},
doi = {10.1145/3706598.3713092},
abstract = {Users hold their mobile phones at varying distances depending on their posture, the application being used, and the task’s nature. Without considering such variation when designing UI target sizes limits the applicability of gaze selection for everyday interaction with mobile devices. Towards this end, we conducted a user study (N = 24) to investigate the implications of different target sizes and viewing across different screen regions. While larger targets generally improve accuracy and decrease precision, accuracy is significantly higher in the horizontal than in the vertical direction. This subsequently led us to find that increasing the tracking area in the vertical direction only, while maintaining the same visual target size, significantly improves accuracy. This suggests that visually smaller targets with larger vertical tracking areas enhance accuracy. Based on our results, we present concrete design guidelines for developers to optimise target sizes on gaze-enabled mobile devices to improve accuracy across varying user-to-screen distances.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {752},
numpages = {16},
keywords = {Eye Tracking, Gaze-enabled Interfaces, Gaze-based Interaction, Mobile Devices},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713270,
author = {Li, Zengrui and Shi, Di and Gao, Qijun and Chen, Yichen and Wang, Nanyi and Ren, Xipei},
title = {Effects of Information Widgets on Time Perception during Mentally Demanding Tasks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713270},
doi = {10.1145/3706598.3713270},
abstract = {This article examined how different time and task management information widgets affect time perception across modalities. In mentally demanding office environments, effective countdown representations are crucial for enhancing temporal awareness and productivity. We developed TickSens, a set of information widgets with different modalities, and conducted a within-subjects experiment with 30 participants to evaluate the five types of time perception modes: visual, auditory, haptic, as well as the blank and the timer modes. Our assessment focused on the technology acceptance, cognitive performance and emotional responses. Results indicated that compared to the blank and the timer modes, the use of modalities significantly improved the cognitive performance and positive emotional responses, and was better received by participants. The visual mode had the best task performance, while the auditory feedback was effective in boosting focus and the haptic mode significantly enhances user acceptance. The study revealed varied user preferences that enlightened the integration of these widgets into office.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {753},
numpages = {20},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714269,
author = {Hwang, Eugene and Lee, Jeongmi},
title = {Looking but Not Focusing: Defining Gaze-Based Indices of Attention Lapses and Classifying Attentional States},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714269},
doi = {10.1145/3706598.3714269},
abstract = {Identifying objective markers of attentional states is critical, particularly in real-world scenarios where attentional lapses have serious consequences. In this study, we identified gaze-based indices of attentional lapses and validated them by examining their impact on the performance of classification models. We designed a virtual reality visual search task that encouraged active eye movements to define dynamic gaze-based metrics of different attentional states (zone in/out). The results revealed significant differences in both reactive ocular features, such as first fixation and saccade onset latency, and global ocular features, such as saccade amplitude, depending on the attentional state. Moreover, the performance of the classification models improved significantly when trained only on the proven gaze-based and behavioral indices rather than all available features, with the highest prediction accuracy of 79.3\%. We highlight the importance of the preliminary studies before model training and provide generalizable gaze-based indices of attentional states for practical applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {754},
numpages = {14},
keywords = {Eye-tracking, Attention Lapses, Sustained Attention, Zoning out, Gaze-based Indices, Classification Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714174,
author = {Zhou, Juntao and Ding, Dian and Li, Yijie and Lu, Yu and Wang, Yida and Zhang, Yongzhao and Chen, Yi-Chao and Xue, Guangtao},
title = {M2SILENT: Enabling Multi-user Silent Speech Interactions via Multi-directional Speakers in Shared Spaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714174},
doi = {10.1145/3706598.3714174},
abstract = {We introduce M2Silent, which enables multi-user silent speech interactions in shared spaces using multi-directional speakers. Ensuring privacy during interactions with voice-controlled systems presents significant challenges, particularly in environments with multiple individuals, such as libraries, offices, or vehicles. M2Silent addresses this by allowing users to communicate silently, without producing audible speech, using acoustic sensing integrated into directional speakers. We leverage FMCW signals as audio carriers, simultaneously playing audio and sensing the user’s silent speech. To handle the challenge of multiple users interacting simultaneously, we propose time-shifted FMCW signals and blind source separation algorithms, which help isolate and accurately recognize the speech features of each user. We also present a deep-learning model for real-time silent speech recognition. M2Silent achieves Word Error Rate (WER) of (6.5\%) and Sequence Error Rate (SER) of (12.8\%) in multi-user silent speech recognition while maintaining high audio quality, offering a novel solution for privacy-preserving, multi-user silent interactions in shared spaces.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {755},
numpages = {19},
keywords = {Silent speech interaction, Multi-directional speaker, Air nonlinearity, Acoustic sensing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714263,
author = {Brade, Stephen and Anderson, Sam and Kumar, Rithesh and Jin, Zeyu and Truong, Anh},
title = {SpeakEasy: Enhancing Text-to-Speech Interactions for Expressive Content Creation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714263},
doi = {10.1145/3706598.3714263},
abstract = {Novice content creators often invest significant time recording expressive speech for social media videos. While recent advancements in text-to-speech (TTS) technology can generate highly realistic speech in various languages and accents, many struggle with unintuitive or overly granular TTS interfaces. We propose simplifying TTS generation by allowing users to specify high-level context alongside their script. Our Wizard-of-Oz system, SpeakEasy, leverages user-provided context to inform and influence TTS output, enabling iterative refinement with high-level feedback. This approach was informed by two 8-subject formative studies: one examining content creators’ experiences with TTS, and the other drawing on effective strategies from voice actors. Our evaluation shows that participants using SpeakEasy were more successful in generating performances matching their personal standards, without requiring significantly more effort than leading industry interfaces.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {756},
numpages = {19},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714186,
author = {Xie, Tianze and Zhang, Xuesong and Huang, Feiyu and Liu, Di and An, Pengcheng and Je, Seungwoo},
title = {VRCaptions: Design Captions for DHH Users in Multiplayer Communication in VR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714186},
doi = {10.1145/3706598.3714186},
abstract = {Accessing auditory information remains challenging for DHH individuals in real-world situations and multiplayer VR interactions. To improve this, we investigated caption designs that specialize in the needs of DHH users in multiplayer VR settings. First, we conducted three co-design workshops with DHH participants, social workers, and designers to gather insights into the specific needs of design directions for DHH users in the context of a room escape game in VR. We further refined our designs with 13 DHH users to determine the most preferred features. Based on this, we developed VRCaptions, a caption prototype for DHH users to better experience multiplayer conversations in VR. We lastly invited two mixed-hearing groups to participate in the VR room escape game with our VRCaptions to validate. The results demonstrate that VRCaptions can enhance the ability of DHH participants to access information and reduce the barrier to communication in VR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {757},
numpages = {18},
keywords = {Accessibility, Communication, Virtual Reality, Deaf and Hard of Hearing, Caption Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714161,
author = {Hu, Yongquan ‘Owen’ and Tang, Jingyu and Gong, Xinya and Zhou, Zhongyi and Zhang, Shuning and Elvitigala, Don Samitha and Mueller, Florian ‘Floyd’ and Hu, Wen and Quigley, Aaron J.},
title = {Vision-Based Multimodal Interfaces: A Survey and Taxonomy for Enhanced Context-Aware System Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714161},
doi = {10.1145/3706598.3714161},
abstract = {The recent surge in artificial intelligence, particularly in multimodal processing technology, has advanced human-computer interaction, by altering how intelligent systems perceive, understand, and respond to contextual information (i.e., context awareness). Despite such advancements, there is a significant gap in comprehensive reviews examining these advances, especially from a multimodal data perspective, which is crucial for refining system design. This paper addresses a key aspect of this gap by conducting a systematic survey of data modality-driven Vision-based Multimodal Interfaces (VMIs). VMIs are essential for integrating multimodal data, enabling more precise interpretation of user intentions and complex interactions across physical and digital environments. Unlike previous task- or scenario-driven surveys, this study highlights the critical role of the visual modality in processing contextual information and facilitating multimodal interaction. Adopting a design framework moving from the whole to the details and back, it classifies VMIs across dimensions, providing insights for developing effective, context-aware systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {758},
numpages = {31},
keywords = {survey; system; context aware; computer vision; vision based interface; visual data; multimodal; artificial intelligence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714102,
author = {Weinberg, Tobias M and Kadoma, Kowe and Gonzalez Penuela, Ricardo E. and Valencia, Stephanie and Roumen, Thijs},
title = {Why So Serious? Exploring Timely Humorous Comments in AAC Through AI-Powered Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714102},
doi = {10.1145/3706598.3714102},
abstract = {People with disabilities that affect their speech may use speech-generating devices (SGD), commonly referred to as Augmentative and Alternative Communication (AAC) technology. This technology enables practical conversation; however, delivering expressive and timely comments remains challenging. This paper explores how to extend AAC technology to support a subset of humorous expressions: delivering timely humorous comments -witty remarks- through AI-powered interfaces. To understand the role of humor in AAC and the challenges and experiences of delivering humor with AAC, we conducted seven qualitative interviews with AAC users. Based on these insights and the lead author’s firsthand experience as an AAC user, we designed four AI-powered interfaces to assist in delivering well-timed humorous comments during ongoing conversations. Our user study with five AAC users found that when timing is critical (e.g., delivering a humorous comment), AAC users are willing to trade agency for efficiency—contrasting prior research where they hesitated to delegate decision-making to AI. We conclude by discussing the trade-off between agency and efficiency in AI-powered interfaces, how AI can shape user intentions, and offer design recommendations for AI-powered AAC interfaces. See our project and demo at: tobiwg.github.io/research/why_so_serious},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {759},
numpages = {19},
keywords = {AAC, Accessibility, Humor, Communication, AI, large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713488,
author = {Cavez, Vincent and Letondal, Catherine and Appert, Caroline and Pietriga, Emmanuel},
title = {EuterPen: Unleashing Creative Expression in Music Score Writing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713488},
doi = {10.1145/3706598.3713488},
abstract = {Music notation programs force composers to follow the many rules of the staff notation when writing music and constantly seek to optimize symbol placement, making numerous adjustments automatically. Even though this impedes their creative process, many composers still use them throughout their workflow, for lack of a better option. We introduce EuterPen, a music notation program prototype that selectively relaxes both syntactic and structural constraints while editing a score. Composers can input and manipulate music symbols with increased flexibility, leveraging the affordances of pen and touch. They can make space on, between and around staves to insert additional content such as digital ink, pictures and audio samples. We describe the iterative design process that led to EuterPen: prototyping phases, a participatory design workshop, and a series of interviews. Feedback from the participating professional composers indicates that EuterPen offers a compelling and promising approach to music writing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {760},
numpages = {16},
keywords = {digital pen, multi-touch interaction, ink, music engraving},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713222,
author = {Mecke, Lukas and Mahmoud, Assem and Marat, Simon and Alt, Florian},
title = {Exploring the Effect of Music on User Typing and Identification through Keystroke Dynamics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713222},
doi = {10.1145/3706598.3713222},
abstract = {This paper explores the relationship between music and keyboard typing behavior. In particular, we focus on how it affects keystroke-based authentication systems. To this end, we conducted an online experiment (N=43), where participants were asked to replicate paragraphs of text while listening to music at varying tempos and loudness levels across two sessions. Our findings reveal that listening to music leads to more errors and faster typing if the music is fast. Identification through a biometric model was improved when music was played either during its training or testing. This hints at the potential of music for increasing identification performance and a tradeoff between this benefit and user distraction. Overall, our research sheds light on typing behavior and introduces music as a subtle and effective tool to influence user typing behavior in the context of keystroke-based authentication.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {761},
numpages = {10},
keywords = {security, typing, keystroke dynamics, music},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714298,
author = {Choi, Youjin and Moon, JaeYoung and Yoo, JinYoung and Hong, Jin-Hyuk},
title = {Exploring the Potential of Music Generative AI for Music-Making by Deaf and Hard of Hearing People},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714298},
doi = {10.1145/3706598.3714298},
abstract = {Recent advancements in text-to-music generative AI (GenAI) have significantly expanded access to music creation. However, deaf and hard of hearing (DHH) individuals remain largely excluded from these developments. This study explores how music GenAI could enhance the music-making experience of DHH individuals, who often rely on hearing people to translate sounds and music. We developed a multimodal music-making assistive tool informed by focus group interviews. This tool enables DHH users to create and edit music independently through language interaction with music GenAI, supported by integrated visual and tactile feedback. Our findings from the music-making study revealed that the system empowers them to engage in independent and proactive music-making activities, increasing their confidence, fostering musical expression, and positively shifting their attitudes toward music. Contributing to inclusive art by preserving the unique sensory characteristics of DHH individuals, this study demonstrates how music GenAI can benefit a marginalized community, fostering independent creative expression.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {762},
numpages = {20},
keywords = {Deaf and Hard-of-Hearing (DHH) people, Music generative AI, Music-sensory substitution system, Music-making},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713489,
author = {Zhong, Ce and Li, Xiang and Wang, Xizi and Sun, Junwei and Zhao, Jian},
title = {Investigating Composite Relation with a Data-Physicalized Thing through the Deployment of the WavData Lamp},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713489},
doi = {10.1145/3706598.3713489},
abstract = {This paper reports on a field study of the WavData Lamp: an interactive lamp that can physically visualize people’s music listening data by changing light colors and outstretching its form enclosure. We deployed five WavData Lamps to five participants’ homes for two months to investigate their composite relation with a data-physicalized thing. Findings reveal that their music-listening norms were determined by the instantiated materiality of the Lamp in the early days. With a tilted form enclosure, the WavData Lamp successfully engendered rich actions and meanings of the cohabiting participants and their family members. In the end, the participants described their experiences of entangling with and living with the Lamp as a form of collaboration. Reflecting on these empirical insights explicitly extends the intrinsic meaning of the composite relation and offers rich implications to promote further HCI explorations and practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {763},
numpages = {21},
keywords = {Data physicalization, Composite relation, Technological things, Artificial intelligence, Research through design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713876,
author = {Lee, ChungHa and Lee, DaeHo and Hong, Jin-Hyuk},
title = {MVPrompt: Building Music-Visual Prompts for AI Artists to Craft Music Video Mise-en-sc\`{e}ne},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713876},
doi = {10.1145/3706598.3713876},
abstract = {Music videos have traditionally been the domain of experts, but with text-to-video generative AI models, AI artists can now create them more easily. However, accurately reflecting the desired music-visual mise-en-sc\`{e}ne remains challenging without specialized knowledge, highlighting the need for supportive tools. To address this, we conducted a design workshop with seven music video experts, identified design goals, and developed MVPrompt—a tool for generating music-visual mise-en-sc\`{e}ne prompts. In a user study with 24 AI artists, MVPrompt outperformed the Baseline, effectively supporting the collaborative creative process. Specifically, the Visual Theme stage facilitated the exploration of tone and manner, while the Visual Scene \&amp; Grammar stage refined prompts with detailed mise-en-sc\`{e}ne elements. By enabling AI artists to specify mise-en-sc\`{e}ne creatively, MVPrompt enhances the experience of making music video scenes with text-to-video generative AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {764},
numpages = {21},
keywords = {Music Video, AI Artists, Mise-en-sc\`{e}ne, Text-to-Video, Prompt Support, Generative AI, Creativity Support Tools, Collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713601,
author = {Potapov, Kyrill and Gold, Nicolas and Olugbade, Temitayo and de C Williams, Amanda C and Overbeck, Christopher Dieter and Lynch, Danielle and Nygren, Minna and Berthouze, Nadia},
title = {Movement Sonification of Familiar Music to Support the Agency of People with Chronic Pain},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713601},
doi = {10.1145/3706598.3713601},
abstract = {FFAME (Filtering Familiar Audio for Movement Exploration) is a novel sonification framework aiming to facilitate movement in individuals with chronic back pain. Our personalised, music-based approach contrasts and extends prior work with predetermined tonal sonification. FFAME progressively filters selected music based on angles of the trunk. Through a qualitative analysis of reported experience of 15 participants with chronic pain and 5 physiotherapists, we identify how sonification parameters and musical characteristics affect movement and meaning-making. Music-based movement sonification proved impactful across multiple dimensions: (1) encouraging movement, (2) escaping pain-related rumination, (3) externalizing pain experiences, and (4) scaffolding physical activities. Drawing on enactivism and related philosophies, the study highlights how the semantic indeterminacy of music, combined with real-time movement sonification, created a rich, open-ended environment that supported user agency and exploration. Sonification for pain management can be creative and expressive, enabling people with pain to extend challenging movements and build movement confidence.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {765},
numpages = {13},
keywords = {movement sonification, chronic pain, agency, sensors, music, enactivism},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713762,
author = {Choi, Youjin and Moon, JaeYoung and Yoo, JinYoung and Hong, Jin-Hyuk},
title = {Understanding the Potentials and Limitations of Prompt-based Music Generative AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713762},
doi = {10.1145/3706598.3713762},
abstract = {Prompt-based music generative artificial intelligence (GenAI) offers an efficient way to engage in music creation through language. However, it faces limitations in conveying artistic intent with language alone, highlighting the need for more research on AI-creator interactions. This study evaluates three different interaction modes (prompt-based, preset-based, and motif-based) of commercialized music AI toots with 17 participants of varying musical expertise to examine how prompt-based GenAI can improve creative intention. Our findings revealed that user groups preferred prompt-based music GenAI for distinct purposes: experts used it to validate musical concepts, novices to generate reference samples, and nonprofessionals to transform abstract ideas into musical compositions. We identified its potential for enhancing compositional efficiency and creativity through intuitive interaction, while also noting limitations in handling temporal and musical nuances solely through prompts.  Based on these insights, we present design guidelines to ensure users can effectively engage in the creative process, considering their musical expertise.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {766},
numpages = {15},
keywords = {Music generative AI, Prompt-based music generative AI, Composition experience, Creative process},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713384,
author = {Kleinberger, Rebecca and Ashooh, Lena and Farsad, Keavan and Hirskyj-Douglas, Ilyena},
title = {Animals' Entanglement with Technology: a Scoping Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713384},
doi = {10.1145/3706598.3713384},
abstract = {Animals living alongside humans are navigating a world increasingly filled with technology, yet little is known about how they interface with these systems, whether designed for, with, or around them. Anchored in HCI and ranging across diverse fields, this scoping review analyzes nearly 800 research works to explore the diverse realities of animal-technology research, examining the who, what, why, and how of animal-technology entanglements. Our analysis revealed 11 research objectives and eight types of technologies across six animal contexts. By categorizing the literature based on authors’ aims and intended beneficiaries, we highlight trends, gaps, and ethical considerations. We find that most systems involve animals with limited potential for direct engagement or sense-making. We propose a framework to understand animals as users versus subjects of interactive systems, focusing on feedback, empirical testing, and projected animal benefits. Our findings offer a foundation to understand current and future animal technology research and the diversity of animal user experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {767},
numpages = {22},
keywords = {ACI, Animal-Computer Interaction, Scoping Review, Animal Technology, Pets, Farming, Zoo, Working Animals, Wildlife, Laboratory Animals},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713291,
author = {Wakkary, Ron and Oogjes, Doenja and Tomico, Oscar and Sakib, Nazmus and K\"{o}kel, Ege},
title = {Backyard Practices: A Liminal Approach to Designing in More-than-Human Worlds},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713291},
doi = {10.1145/3706598.3713291},
abstract = {As design researchers committed to more-than-human designing, we found we were increasingly moving our research activities outside of our institutional studios and labs into yards and balconies where we lived. In this paper, we investigate this emerging pattern through collaborative autoethnography to arrive at the notion of backyard practices. These are distinct practices that signal the value and necessity of being there in more-than-human worlds to design-with over time. We describe the features of the practice that include time as duration and intensities, liminality as more-than-human presences, and proximity. We also describe commitments that emerged that include practice decentering, consistently engage more-than-humans as participants in the process, act with not-knowing and humility, queerly design alongside, and learn to be affected.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {768},
numpages = {18},
keywords = {Design Methods, Ethnography, Home, Interaction Design, Method, Theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713916,
author = {Tomico, Oscar and Oogjes, Doenja and Wakkary, Ron},
title = {Constituency as a Matter of Practice: Moving a Plant Studio},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713916},
doi = {10.1145/3706598.3713916},
abstract = {How more-than-human gatherings configure and change to support designing is not well understood. In the more-than-human theory of designing-with, these gatherings are called constituencies. This paper aims to shed light on the practices of a constituency, by analyzing the moving of a plant studio from one city to another. The plant studio includes over 250 plants and is where living-with and designing-with plants are conceptualized. The move offered an opportunity to understand the dynamics of the plant studio as a constituency using design events, a vocabulary and analytical tool, for understanding practices and temporality. In our analysis, we surface the role of humans as speaking subjects and five repertoires or considered actions that together articulate the practice of a constituency. We also illustrate the use of design events as an analytical tool for nuance and critical reflections on more-than-human design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {769},
numpages = {17},
keywords = {Design events, More-than-human, Plant studio, Research through design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713833,
author = {Maggipinto, Beatrice and Nunes, Nuno Jardim and Hammer, Jessica and Trindade, Yanick and Nisi, Valentina},
title = {Diving into the Abyss: Exploring Deep Sea Connection and Curiosity through Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713833},
doi = {10.1145/3706598.3713833},
abstract = {This paper presents an investigation of the potential of virtual reality (VR) to bridge the gap between humans and the largely unexplored deep sea, using the immersive, playful experience of "Echo of the Abyss" (EotA). Built around the structure of a deep-sea dive experience, EotA aims to enhance users' sense of interconnectedness with underwater environments and stimulate curiosity about marine life. The qualitative analysis reveals a heightened empathy, respect for aquatic life, and a newfound interest in real-world diving experiences. Quantitative results indicate a marginal increase in positive perceptions towards the sea. From these findings, we discuss VR as an effective transformational tool to foster a deeper ecological consciousness. Our contributions can benefit HCI researchers and game designers interested in designing ocean sustainability-driven experiences and games.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {770},
numpages = {18},
keywords = {Climate Change Communications, Digital Games, Ecopsychology, More-than-human},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714067,
author = {Biggs, Heidi},
title = {Fabulating Bog Girl: Queer Entanglements of Body and Land Histories in More-than-Human AutoFiction and Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714067},
doi = {10.1145/3706598.3714067},
abstract = {The more-than-human turn in HCI has explored entanglements with non-human others that include animals, plants, and technologies. Building on this agenda, this work constructs more-than-human (MTH) entanglements through the lens of queer non-binary, human/non-human entanglements of land and body. By fabulating an autofiction (fiction based on personal experience) titled Bog Girl – this work explores the way non-binary lands of wetlands, and non-binary bodies, share similar experiences of being cut (literally and metaphorically) by bifurcating logics in medical and agricultural settings. However, these experiences allow for new human/land animations, entanglements, grieving, and healing, ultimately, imagining non-binary grounds for design. The work contributes 1) new considerations of the generative and designerly potential storytelling and fiction in more-than-human research 2) queer embodied approaches to MTH work in HCI 3) and discuss non-binary ethics for MTH design that imagine pluriversal bodily consent and paths to entangled healing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {771},
numpages = {13},
keywords = {AutoFiction, Design Research Methods, Humanities, More than Human, Sustainability, Women's Health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713207,
author = {Spors, Velvet and Buruk, O\u{g}uz 'Oz' and Hamari, Juho},
title = {Human-Nature Relationships through Video Games: An Exploration of Players' Sense-Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713207},
doi = {10.1145/3706598.3713207},
abstract = {Technology profoundly mediates how people feel, think and engage with nature. Here, video games are projected to become one of the most important mediums to facilitate digital human-nature interaction. In this paper, we explore how 16 players make sense of nature-in-games. Drawing from their own lived experiences, we 1) interviewed them, and 2) invited them to show us games that exemplify their conceptualisation of nature-in-games. We thematically analyse these “show-and-tell” conversations to construct three inductive themes: We arrive at an understanding that nature-in-games experiences are pluralistic, contested happenings. Participants positioned digital nature 1) as a relational other to respect, 2) as a space to reflect on humankind’s current practices towards nature and 3) as a tool to escape from the lack of nature in their everyday lives. Based on our insights, we sketch out design inspirations for people wishing to augment, challenge and expand nature-in-games.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {772},
numpages = {17},
keywords = {nature, ecology, climate change, sustainability, video games, player experiences, ecological distress, digital ecologies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713156,
author = {Zhu, Jingwen and Chang, Samantha and Zhao, Ruth and Kao, Cindy Hsin-Liu},
title = {LivingLoom: Investigating Human-Plant Symbiosis Through Integrating Living Plants Into (E-)Textiles},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713156},
doi = {10.1145/3706598.3713156},
abstract = {LivingLoom is a design inquiry that proposes a post-anthropocentric approach to fabrication by integrating living plants directly into textiles. Industrial textile fabrication views plants as passive resources. They are grown, harvested, and spun into yarns for textile production, mainly to serve human needs. While efficient, this approach overlooks the intrinsic value of these organisms as living beings. LivingLoom fabrication approach wet-spins biodegradable yarns with seeds that can be further integrated into textiles that can sprout and grow. We present a design space for incorporating microgreen seeds into textiles with a 10-day growth cycle, leveraging care-based fabrication and interaction. We conducted a three-day user study to understand how people wear and care for plant-integrated textiles, revealing new possibilities for living textiles and care-based interactions. LivingLoom examines the intimacy between humans and plants in textile forms, shedding light on the design potential for the care-based fabrication of (e-)textiles.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {773},
numpages = {18},
keywords = {plants, wearable, e-textiles, care-based interactions},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713420,
author = {Park, Sohyeon and Min, Aehong and Beltran, Jesus Armando and Hayes, Gillian R},
title = {"As an Autistic Person Myself:" The Bias Paradox Around Autism in LLMs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713420},
doi = {10.1145/3706598.3713420},
abstract = {Large Language Models (LLMs) like ChatGPT, used by over 200 million people monthly, are increasingly applied in disability contexts, including autism research. However, there has been limited exploration of the potential biases these models hold about autistic people. To explore what biases ChatGPT demonstrates about autistic people, we prompted GPT-3.5 to create three personas, choose one to be autistic, and explain its reasoning for this choice and any suggested changes to the persona description. Our quantitative analysis of the chosen personas indicates that gender and profession influenced GPT’s choices. Additionally, our qualitative analysis revealed ChatGPT’s tendency to highlight the importance of representation while simultaneously perpetuating mostly negative biases about autistic people, illustrating a “bias paradox,” a concept adapted from feminist studies. By applying this concept to LLMs, we provide a lens through which researchers might identify, understand, and address fundamental challenges in the development of responsible and inclusive AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {774},
numpages = {17},
keywords = {Large Language Models, Empirical Study, Autism, Bias Paradox},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714094,
author = {Kritika, Kritika and Williams, Rua Mae and Ringland, Kathryn E.},
title = {"Ultimately, it's a matter of safety, and resisting ostracization": Understanding Neurodivergent Masking with Online Communities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714094},
doi = {10.1145/3706598.3714094},
abstract = {Neurotypical modes of existence and interaction are enforced through traditional social norms, compelling individuals who diverge from these norms, such as those who are neurodivergent, to conform through “masking.” Technology research and design often also ascribe to these conventional norms, creating technology that reinforces neurodivergent people’s need to mask. In this research, we turn to neurodivergent communities online to develop an understanding of masking behaviors. We adopt a two-tiered research approach consisting of a qualitative thematic analysis of TikTok videos and a survey questionnaire. Through this work, we initiate discussion on the complexities of neurodivergent masking as a pervasive social adaptation. We urge HCI researchers to critically reframe intervention design and research practices that may either perpetuate or seek to address masking.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {775},
numpages = {14},
keywords = {Neurodivergent Masking, Critical Disability Studies, Online Communities, Inclusive Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713961,
author = {Maye, Laura and Hansen, Nicolai Brodersen},
title = {Involvement of Autistic Adults in the Participatory Design of Technology: A Scoping Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713961},
doi = {10.1145/3706598.3713961},
abstract = {Research in HCI and autism has become more focused on involving autistic adults in technological design. In this paper, we present the results of a scoping review analysis of 11 projects across 18 papers that focused on including autistic adults in the design of technology that impacts their lives. This paper contributes a deeper understanding of how autistic adults were involved in participatory design processes. Our findings reveal mixed positions on how the lived autistic perspective was harnessed to direct the application of topics and technologies chosen. Most projects employed infrastructures to enhance participation (e.g., providing multiple modes to participate or employing a tailored methodology). We pose future opportunities for autistic involvement, for example, in topics and technologies where autistic research is employed (e.g., autism diagnosis and machine learning), reviewing the importance of formal diagnosis for inclusion, and harnessing the multiple expertise of autistic adults.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {776},
numpages = {17},
keywords = {scoping review, autistic adults, participatory design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714287,
author = {Carik, Buse and Izaac, Victoria V and Ding, Xiaohan and Scarpa, Angela and Rho, Eugenia H},
title = {Reimagining Support: Exploring Autistic Individuals' Visions for AI in Coping with Negative Self-Talk},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714287},
doi = {10.1145/3706598.3714287},
abstract = {Autistic individuals often experience negative self-talk (NST), leading to increased anxiety and depression. While therapy is recommended, it presents challenges for many autistic individuals. Meanwhile, a growing number are turning to large language models (LLMs) for mental health support. To understand how autistic individuals perceive AI’s role in coping with NST, we surveyed 200 autistic adults and interviewed practitioners. We also analyzed LLM responses to participants’ hypothetical prompts about their NST. Our findings show that participants view LLMs as useful for managing NST by identifying and reframing negative thoughts. Both participants and practitioners recognize AI’s potential to support therapy and emotional expression. Participants also expressed concerns about LLMs’ understanding of neurodivergent thought patterns, particularly due to the neurotypical bias of LLMs. Practitioners critiqued LLMs’ responses as overly wordy, vague, and overwhelming. This study contributes to the growing research on AI-assisted mental health support, with specific insights for supporting the autistic community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {777},
numpages = {30},
keywords = {autism, mental health, large language models, negative self-talk, artificial intelligence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713539,
author = {Piedade, Patricia and Carter, Anna R. L. and Prada, Rui and Nicolau, Hugo},
title = {Towards Neuroqueer Spatial Justice: A Critical Literature Review of Public Space Technologies for Neurodivergent Populations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713539},
doi = {10.1145/3706598.3713539},
abstract = {Access to public spaces is of the utmost importance for social cohesion, inclusion, and civic engagement. Nevertheless, a large majority of public spaces remain incredibly uncomfortable environments for neurodivergent individuals due to, for instance, the unpredictability of such spaces and the sensory stimuli within them. Smart City technologies present an exciting opportunity to improve the accessibility and enjoyment of the spaces where they are deployed by, for instance, offering users the ability to customise a space to their specific sensory needs. However, the research topic of public space technologies for neurodivergent individuals remains scattered and sparsely documented. This critical review analyses the existing domains of inquiry, contributing a theoretical framework based on Spatial Justice and Neuroqueer Technoscience and suggests future research avenues informed by this framework. We advocate for the participatory co-creation of a neurodivergent-affirming landscape of public space technologies that both support neurodivergent needs and promote neurodivergent joy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {778},
numpages = {19},
keywords = {Public Space, Neurodivergent, Neurodiversity, Neuroqueer, Spatial Justice, Literature Review},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713344,
author = {Kong, Ha-Kyung and Lowy, Rachel and Choi, Youjin and Kim, Jennifer G},
title = {Working Together Toward Interdependence: Chatbot-Based Support for Balanced Social Interactions Between Neurodivergent and Neurotypical Individuals},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713344},
doi = {10.1145/3706598.3713344},
abstract = {While many technologies have been developed for facilitating interaction between neurodivergent and neurotypical people to bridge communication differences and reduce social exclusion, most focus on supporting and teaching neurodivergent people to adapt to neurotypical standards and norms. To promote a more balanced approach to bridging the social gap, we conducted a 5-day diary study and semi-structured interviews with 16 participants (8 neurotypical and 8 with intellectual disability) to examine the current factors and barriers to their social interactions and to explore the design of social support chatbot systems. Our findings revealed diverging views between the groups on factors they valued in their interaction, and identified social uncertainty and differing social expectations as the main barriers to successful interactions. Based on the results, we outline three pitfalls that social support chatbots can fall into if not designed mindfully, and suggest design approaches that promote bidirectional social support and interdependence.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {779},
numpages = {17},
keywords = {Neudivergence, chatbot, social support, assistive technology, interdependence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713738,
author = {Morris, Brooke and Havlucu, Hayati and Oldfield, Alison and Metatla, Oussama},
title = {“It Helps Us Express Our Feelings Without Having To Say Anything”: Exploring 'Accompanying Social Play Things' Designed With and For Neurodiverse Groups of Children},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713738},
doi = {10.1145/3706598.3713738},
abstract = {Social play is crucial for children’s well-being and development. However, many social play technologies fail to address the specific characteristics and needs of neurodiverse1 play and often overlook divergent play styles. To address this, we first conducted a co-design study with a neurodiverse group of 7 children (Age 7-8) and, based on insights from these sessions, then developed a prototype, ChromaConnect, that allowed children to express their play style to one another during play. To evaluate ChromaConnect’s ability to support neurodiverse social play in different contexts, we observed children using it in both structured and unstructured play settings. Our findings show that ChromaConnect enabled children to create a common language of play, made divergent play modes more visible, and facilitated explicit expression of social play initiation. We discuss how these findings could be used to design ‘accompanying social play things’ that are more inclusive of neurodiverse play characteristics and divergent play styles.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {780},
numpages = {21},
keywords = {Social Play, Neurodiverse Play, Autism, Double Empathy Problem, Co-design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713780,
author = {Zhang, Yan and Ratnayake, Tharaka Sachintha and Sew, Cherie and Knibbe, Jarrod and Goncalves, Jorge and Johal, Wafa},
title = {Can you pass that tool?: Implications of Indirect Speech in Physical Human-Robot Collaboration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713780},
doi = {10.1145/3706598.3713780},
abstract = {Indirect speech acts (ISAs) are a natural pragmatic feature of human communication, allowing requests to be conveyed implicitly while maintaining subtlety and flexibility. Although advancements in speech recognition have enabled natural language interactions with robots through direct, explicit commands—providing clarity in communication—the rise of large language models presents the potential for robots to interpret ISAs. However, empirical evidence on the effects of ISAs on human-robot collaboration (HRC) remains limited. To address this, we conducted a Wizard-of-Oz study (N=36), engaging a participant and a robot in collaborative physical tasks. Our findings indicate that robots capable of understanding ISAs significantly improve human’s perceived robot anthropomorphism, team performance, and trust. However, the effectiveness of ISAs is task- and context-dependent, thus requiring careful use. These results highlight the importance of appropriately integrating direct and indirect requests in HRC to enhance collaborative experiences and task performance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {781},
numpages = {18},
keywords = {Human-Robot Collaboration, Language Communication, Grounding, Lab Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713635,
author = {Faramarzian, Mohammad and Pardo, Jorge and Mandel, Ilan and Rakotonirainy, Andry and Ju, Wendy and Schroeter, Ronald},
title = {Decoding Driver Intention Cues: Exploring Non-verbal Communication for Human-Centered Automotive Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713635},
doi = {10.1145/3706598.3713635},
abstract = {In emerging "driver-less" automated vehicles (AVs), the intuitive communication that exists between human drivers and passengers no longer exists, which can lead to reduced trust and acceptance in passengers if they are unclear about what the AV intends to do. This paper contributes the foundational understanding of how passengers naturally decode drivers’ non-verbal cues about their intended action to inform intuitive Human-Machine Interface (HMI) designs that try to emulate those cues. Our study investigates what cues passengers perceive, their saliency, and interpretation through a mixed-method approach combining field observations, experience sampling, and auto-confrontation interviews with 30 driver-passenger pairs. Analysis of posture, head/eye movements, and vestibular sensations revealed four categories of intention cues: awareness, interaction, vestibular, and habitual. These findings provide empirical foundations for designing AV interfaces that mirror natural human communication patterns. We discuss implications for designing anthropomorphic HMIs that could enhance trust, predictability, and user experience in AVs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {782},
numpages = {13},
keywords = {Intention Cues, HMIs, Human-centric Design, Implicit Interaction, Anthropomorphism},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713571,
author = {Chen, Xingtong and Wang, Xia and Fang, Cong and Fang, Le and Gong, Wei and Liu, Chengzhong and Wang, Stephen Jia},
title = {Emotion-aware Design in Automobiles: Embracing Technology Advancements to Enhance Human-vehicle Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713571},
doi = {10.1145/3706598.3713571},
abstract = {The integration of emotion-aware systems in vehicles is accelerated by new technologies, including advancements in AI and ubiquitous sensing technologies. As the automotive industry shifts from technology-centred, feature-driven approaches to human-centred design, this research focuses on how to effectively incorporate emotion features into user-centred design to enhance effective human-vehicle interaction in practices. By conducting an interview study with 31 industrial design practitioners, supplemented by insights from engineers and AI experts involved in the early-stage design and development of novel in-vehicle user interfaces and systems, we examined current practices, and sampled their challenges, attitudes and expectations related to emotion-aware systems. Our findings provide critical insights to the design space of emotion-aware systems from both user and AI perspectives, inform efforts to support design practices in this evolving area, and identify opportunities for future innovation in emotion-aware in-vehicle design. Based on our findings, we propose adaptations to design practices and recommendations for further research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {783},
numpages = {18},
keywords = {Human-centred Design, Emotion, Human-vehicle Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713428,
author = {Espositi, Federico and Vetere, Maurizio and Bonarini, Andrea},
title = {From Alien to Ally: Exploring Non-Verbal Communication with Non-Anthropomorphic Avatars in a Collaborative Escape-Room},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713428},
doi = {10.1145/3706598.3713428},
abstract = {Despite the spread of technologies in the physical world and the normalization of virtual experiences, non-verbal communication with radically non-anthropomorphic avatars remains an underexplored frontier. We present an interaction system in which two participants must learn to communicate with each other non-verbally through a digital filter that morphs their appearance. In a collaborative escape room, the Visitor must teach a non-anthropomorphic physical robot to play, while the Controller, in a different location, embodies the robot with an altered perception of the environment and the Visitor’s companion in VR. This study addresses the design of the activity, the robot, and the virtual environment, with a focus on how the Visitor’s morphology is translated in VR. Results show that participants were able to develop emergent and effective communication strategies, with the Controller naturally embodying its avatar’s narrative, making this system a promising testbed for future research on human-technology interaction, entertainment, and embodiment.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {784},
numpages = {15},
keywords = {Collaboration ; Computer Mediated Communication ; Embodied Interaction ; Entertainment ; User Experience Design ; Virtual/Augmented Reality ; Robot ; Artifact or System ; Empirical study that tells us about how people use a system ; Empirical study that tells us about people ; Art ; Interaction Design ; Lab Study ; Prototyping/Implementation ; Qualitative Methods ; Quantitative Methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714078,
author = {Lee, Geonsun and Yang, Yue and Healey, Jennifer and Manocha, Dinesh},
title = {Since U Been Gone: Augmenting Context-Aware Transcriptions for Re-Engaging in Immersive VR Meetings},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714078},
doi = {10.1145/3706598.3714078},
abstract = {Maintaining engagement in immersive meetings is challenging, particularly when users must catch up on missed content after disruptions. While transcription interfaces can help, table-fixed panels have the potential to distract users from the group, diminishing social presence, while avatar-fixed captions fail to provide past context. We present EngageSync, a context-aware avatar-fixed transcription interface that adapts based on user engagement, offering live transcriptions and LLM-generated summaries to enhance catching up while preserving social presence. We implemented a live VR meeting setup for a 12-participant formative study and elicited design considerations. In two user studies with small (3 avatars) and mid-sized (7 avatars) groups, EngageSync significantly improved social presence (p &lt;.05) and time spent gazing at others in the group instead of the interface over table-fixed panels. Also, it reduced re-engagement time and increased information recall (p &lt;.05) over avatar-fixed interfaces, with stronger effects in mid-sized groups (p &lt;.01).},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {785},
numpages = {20},
keywords = {Immersive VR Meeting; Social VR; Virtual Reality; Teleconferencing; Co-presence; Re-engagement; Group Conversations; Live Transcriptions},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714306,
author = {Vazquez Gonzalez, Carlota and Neate, Timothy and Borgo, Rita},
title = {Trusting Tracking: Perceptions of Non-Verbal Communication Tracking in Videoconferencing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714306},
doi = {10.1145/3706598.3714306},
abstract = {Videoconferencing is integral to modern work and living. Recently, technologists have sought to leverage data captured – e.g. from cameras and microphones – to augment communication. This might mean capturing communication information about verbal (e.g. speech, chat messages), or non-verbal exchanges (e.g. body language, gestures, tone of voice) and using this to mediate – and potentially improve – communication. However, such tracking has implications for user experience and raises wider concerns (e.g. privacy). To design tools which account for user needs and preferences, this study investigates perspectives on communication tracking through a global survey and interviews, exploring how daily behaviours and the impact of specific features influence user perspectives. We examine user preferences on non-verbal communication tracking, preferred methods of how this information is conveyed and to whom this should be communicated. Our findings aim to guide the development of non-verbal communication tools which augment videoconferencing that prioritise user needs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {786},
numpages = {25},
keywords = {Privacy, Videoconferencing, Non-verbal Communication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714147,
author = {Dang, Minh Duc and Pulatova, Samira and Kim, Lawrence H},
title = {User-Defined Co-Speech Gesture Design with Swarm Robots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714147},
doi = {10.1145/3706598.3714147},
abstract = {Non-verbal signals, including co-speech gestures, play a vital role in human communication by conveying nuanced meanings beyond verbal discourse. While researchers have explored co-speech gestures in human-like conversational agents, limited attention has been given to non-humanoid alternatives. In this paper, we propose using swarm robotic systems as conversational agents and introduce a foundational set of swarm-based co-speech gestures, elicited from non-technical users and validated through an online study. This work outlines the key software and hardware requirements to advance research in co-speech gesture generation with swarm robots, contributing to the future development of social robotics and conversational agents.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {787},
numpages = {15},
keywords = {Swarm Robotics, Co-speech Gesture, Elicitation Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713526,
author = {Li, Haoran and Cheng, Xusen and Zhang, Xiaoping},
title = {Accurate Insights, Trustworthy Interactions: Designing a Collaborative AI-Human Multi-Agent System with Knowledge Graph for Diagnosis Prediction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713526},
doi = {10.1145/3706598.3713526},
abstract = {Healthcare question-answering (QA) systems can assist physicians in making medical decisions. However, traditional medical QA systems struggle with multi-agents interaction and domain-specific knowledge processing, thereby reducing the accuracy and credibility of clinical decision-making. We thus develop a multi-agent decision-making system by combining a fine-tuned medical model, biomedical knowledge graphs, and PubMed data. By summarizing the symptoms described by users, our system can automatically convene clinical experts from various fields, retrieve domain knowledge, and provide clinical decision support for users. We have validated the system performance using both technical and user-centric approaches in terms of information accuracy, user satisfaction, user trust, ect. We thus provide an effective tool for healthcare professionals to make accurate and timely decisions. Furthermore, this study also reveals new design and research opportunities, including (1) optimizing multi-agent collaboration mechanisms for more complex medical decision-making, (2) improving interaction design to enhance system transparency and explainability, and (3) expanding the system to support a broader range of medical issues and multimodal data.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {788},
numpages = {15},
keywords = {Human-Computer Interaction, Clinical Decision Support Systems, Large Medical Language Models, Graph-based Retrieval-Augmented Generation (Graph RAG), Multi-Agent Systems},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713773,
author = {Xu, Songlin and Wen, Hao-Ning and Pan, Hongyi and Dominguez, Dallas and Hu, Dongyin and Zhang, Xinyu},
title = {Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713773},
doi = {10.1145/3706598.3713773},
abstract = {Student simulation supports educators to improve teaching by interacting with virtual students. However, most existing approaches ignore the modulation effects of course materials because of two challenges: the lack of datasets with granularly annotated course materials, and the limitation of existing simulation models in processing extremely long textual data. To solve the challenges, we first run a 6-week education workshop from N = 60 students to collect fine-grained data using a custom built online education system, which logs students’ learning behaviors as they interact with lecture materials over time. Second, we propose a transferable iterative reflection (TIR) module that augments both prompting-based and finetuning-based large language models (LLMs) for simulating learning behaviors. Our comprehensive experiments show that TIR enables the LLMs to perform more accurate student simulation than classical deep learning models, even with limited demonstration data. Our TIR approach better captures the granular dynamism of learning performance and inter-student correlations in classrooms, paving the way towards a “digital twin” for online education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {789},
numpages = {26},
keywords = {Student Simulation, Generative Agents, Classroom Digital Twin},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713716,
author = {Wang, Jenny S and Haider, Samar and Tohidi, Amir and Gupta, Anushkaa and Zhang, Yuxuan and Callison-Burch, Chris and Rothschild, David and Watts, Duncan J},
title = {Media Bias Detector: Designing and Implementing a Tool for Real-Time Selection and Framing Bias Analysis in News Coverage},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713716},
doi = {10.1145/3706598.3713716},
abstract = {Mainstream media, through their decisions on what to cover and how to frame the stories they cover, can mislead readers without using outright falsehoods. Therefore, it is crucial to have tools that expose these editorial choices underlying media bias. In this paper, we introduce the Media Bias Detector, a tool for researchers, journalists, and news consumers. By integrating large language models, we provide near real-time granular insights into the topics, tone, political lean, and facts of news articles aggregated to the publisher level. We assessed the tool’s impact by interviewing 13 experts from journalism, communications, and political science, revealing key insights into usability and functionality, practical applications, and AI’s role in powering media bias tools. We explored this in more depth with a follow-up survey of 150 news consumers. This work highlights opportunities for AI-driven tools that empower users to critically engage with media content, particularly in politically charged environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {790},
numpages = {27},
keywords = {media bias, news analysis, large language models (LLMs), LLM-driven tools},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713618,
author = {Souza, Garrett and Lutz, Nina and Turner, Katlyn M},
title = {Mediating The Marginal: A Quantitative Analysis of Curated LGBTQ+ Content on Instagram},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713618},
doi = {10.1145/3706598.3713618},
abstract = {Control and curation of dominant visual culture – rendering who and what is visible – is central to identity formation, particularly for LGBTQ+ communities relying on digital spaces for safe self-expression. In this work, we analyze Instagram as a site of algorithmic visual curation, performing a quantitative analysis of algorithmically mediated image feeds delivered to a gay-coded user. Our persona account exclusively followed #gay and #instagay feeds, and engaged in content within these discursive spaces to seed algorithmic content promotion to a normative gay user. We present an analysis of skin tone presentations, emoji usage, and engagement metrics alongside analysis of generative outputs of dominant visual trends within the #gay search and Explore feeds. We observe content depicting darker-skinned individuals has higher engagement yet less algorithmic promotion relative to lighter skin tones, while hypermasculine and homonormative content is heavily promoted. These results suggest that, while marginalized positionalities have certainly been rendered more visible through social media platforms, this visibility is increasingly contingent on assimilation to normative ideals through algorithmically determined modes that are not necessarily consistent with user choices, preferences, or realities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {791},
numpages = {20},
keywords = {Social Networks, Recommendation Algorithms, LGBTQ+ Visual Content},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713154,
author = {Zhao, Andy and Hobbs, Will},
title = {The Effects and Non-Effects of Social Sanctions from User Jury-Based Content Moderation Decisions on Weibo},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713154},
doi = {10.1145/3706598.3713154},
abstract = {Between 2012 and 2014, Weibo used a novel crowdsourced user ‘committee’ system to make content moderation decisions. In it, user volunteers were randomly assigned to jury-like committees to vote and comment on whether reported content violated platform rules. The perceived legitimacy of similar systems has been studied in tightly controlled lab and survey experiments, but the causal effects of such jury-like moderation systems on user behavior in the real world have not been studied to the same extent. Leveraging random variation in Weibo case votes due to the assignment of more or less lenient ‘jurors’, we show that, on average, social sanctioning and norm-setting through committee votes was associated with a large but brief decline in reported users’ future posting of offensive terms. However, in line with prior work on the relative ineffectiveness of out-group sanctioning, we observe no such effect among women sanctioned by the largely male committees. This study advances our understanding of the effects of institutionalized social sanctioning on social media user behavior, and the promises and potential shortcomings of crowdsourced moderation systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {792},
numpages = {17},
keywords = {Digital Juries, Social Sanctioning, Community Norms, Content Moderation, Social Media, Weibo},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713728,
author = {Jones, Mirabelle and Griffioen, Nastasia and Neumayer, Christina and Shklovski, Irina},
title = {Artificial Intimacy: Exploring Normativity and Personalization Through Fine-tuning LLM Chatbots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713728},
doi = {10.1145/3706598.3713728},
abstract = {Fine-tuning Large Language Models (LLMs) is one response to the critique of LLMs being biased, erasing diversity, and raising ethical concerns. The Artificial Intimacy project employs artistic methods, taking personalization of chatbots to an extreme by fine-tuning LLMs on individual social media data. We find that regular GPT-3 chatbots attempt to circumvent value-laden content through flagging prompts and producing generic non-answers with variable success. While the transactional nature of such output allowed participants to make sense of responses with less personification, fine-tuned models presented value-laden, normative, and familiar personalities, resulting in strong personification as a way of making sense of the interactions. This mimicry of emotional connection resulted in a sense of artificial intimacy creating expectations for reciprocity and consideration that the models cannot express by design. As the commercialization of interactions with chatbots continues, we discuss the ethics of such emotional manipulation and its implications for personalization of LLMs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {793},
numpages = {16},
keywords = {GPT-3, chatbots, normativity, value alignment, participatory artistic research},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713962,
author = {Kamali, Negar and Nakamura, Karyn and Kumar, Aakriti and Chatzimparmpas, Angelos and Hullman, Jessica and Groh, Matthew},
title = {Characterizing Photorealism and Artifacts in Diffusion Model-Generated Images},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713962},
doi = {10.1145/3706598.3713962},
abstract = {Diffusion model-generated images can appear indistinguishable from authentic photographs, but these images often contain artifacts and implausibilities that reveal their AI-generated provenance. Given the challenge to public trust in media posed by photorealistic AI-generated images, we conducted a large-scale experiment measuring human detection accuracy on 450 diffusion-model generated images and 149 real images. Based on collecting 749,828 observations and 34,675 comments from 50,444 participants, we find that scene complexity of an image, artifact types within an image, display time of an image, and human curation of AI-generated images all play significant roles in how accurately people distinguish real from AI-generated images. Additionally, we propose a taxonomy characterizing artifacts often appearing in images generated by diffusion models. Our empirical observations and taxonomy offer nuanced insights into the capabilities and limitations of diffusion models to generate photorealistic images in 2024.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {794},
numpages = {26},
keywords = {photorealism, diffusion models, generative AI, synthetic media, deepfakes, misinformation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713603,
author = {Liao, Yi-Chi and Streli, Paul and Li, Zhipeng and Gebhardt, Christoph and Holz, Christian},
title = {Continual Human-in-the-Loop Optimization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713603},
doi = {10.1145/3706598.3713603},
abstract = {Optimal input settings vary across users due to differences in motor abilities and personal preferences, which are typically addressed by manual tuning or calibration. Although human-in-the-loop optimization has the potential to identify optimal settings during use, it is rarely applied due to its long optimization process. A more efficient approach would continually leverage data from previous users to accelerate optimization, exploiting shared traits while adapting to individual characteristics. We introduce the concept of Continual Human-in-the-Loop Optimization and a Bayesian optimization-based method that leverages a Bayesian-neural-network surrogate model to capture population-level characteristics while adapting to new users. We propose a generative replay strategy to mitigate catastrophic forgetting. We demonstrate our method by optimizing virtual reality keyboard parameters for text entry using direct touch, showing reduced adaptation times with a growing user base. Our method opens the door for next-generation personalized input systems that improve with accumulated experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {795},
numpages = {26},
keywords = {Continual learning, lifelong learning, continual optimization, Bayesian optimization, human-in-the-loop optimization, meta-learning, mid-air keyboard, typing, virtual reality.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713200,
author = {Bruun, Anders and van Berkel, Niels and Raptis, Dimitrios and Law, Effie L-C},
title = {Coordination Mechanisms in AI Development: Practitioner Experiences on Integrating UX Activities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713200},
doi = {10.1145/3706598.3713200},
abstract = {Software development relies on collaboration and alignment between a variety of roles, including software developers and user experience designers. The increasing focus on artificial intelligence in today’s development projects has given rise to new challenges in this collaboration. We extend previous work on the process of designing human-AI systems by analysing collaborative practices between UX designers and AI developers through Mintzberg’s theory on coordination mechanisms. We conducted 15 in-depth interviews with UX designers and AI developers currently working on AI projects. We contribute by identifying how coordination mechanisms impact the UX design process when developing AI systems, inter-team (a)symmetries in power relations, and a growing need for tools and cross-disciplinary knowledge to support these collaborative efforts. In particular, we outline the risks of coordinating AI development work through the standardisation of output and skills in separately organised UX and AI development teams.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {796},
numpages = {14},
keywords = {UX Integration, Artificial Intelligence, Coordination Mechanisms, Software Development, UX Design, Organisational theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714118,
author = {Kosa, Ben and Desai, Aashaka and Lu, Alex X and Ladner, Richard E. and Bragg, Danielle},
title = {Exploring Reduced Feature Sets for American Sign Language Dictionaries},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714118},
doi = {10.1145/3706598.3714118},
abstract = {There is currently no easy way to look up signs in sign language. Feature-based dictionaries help overcome this challenge by enabling users to look up a sign by inputting descriptive visual features, such as handshape and movement. However, feature-based dictionaries are typically cumbersome, including large numbers of complex features that the user must sort through. In this work, we explore simplifying the set of features used in feature-based American Sign Language (ASL) dictionaries. We present two studies: 1) a simulation study focused on lookup accuracy for various reduced feature sets, and 2) a user study focused on understanding human preferences between feature sets. Our results suggest that it is possible to dramatically reduce the number of features needed to search for signs without significantly impacting the accuracy of search results, and that smaller feature sets can improve the user experience in some cases.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {797},
numpages = {14},
keywords = {American Sign Language (ASL), Dictionary, Search, Education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713863,
author = {Tatsukawa, Yuki and Shen, I-Chao and Dogan, Mustafa Doga and Qi, Anran and Koyama, Yuki and Shamir, Ariel and Igarashi, Takeo},
title = {FontCraft: Multimodal Font Design Using Interactive Bayesian Optimization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713863},
doi = {10.1145/3706598.3713863},
abstract = {Creating new fonts requires a lot of human effort and professional typographic knowledge. Despite the rapid advancements of automatic font generation models, existing methods require users to prepare pre-designed characters with target styles using font-editing software, which poses a problem for non-expert users. To address this limitation, we propose FontCraft, a system that enables font generation without relying on pre-designed characters. Our approach integrates the exploration of a font-style latent space with human-in-the-loop preferential Bayesian optimization and multimodal references, facilitating efficient exploration and enhancing user control. Moreover, FontCraft allows users to revisit previous designs, retracting their earlier choices in the preferential Bayesian optimization process. Once users finish editing the style of a selected character, they can propagate it to the remaining characters and further refine them as needed. The system then generates a complete outline font in OpenType format. We evaluated the effectiveness of FontCraft through a user study comparing it to a baseline interface. Results from both quantitative and qualitative evaluations demonstrate that FontCraft enables non-expert users to design fonts efficiently.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {798},
numpages = {14},
keywords = {font design, outline fonts, human-in-the-loop, latent space exploration, novice user support tools, generative models, typography tools},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714199,
author = {Lee, Dawon and Choi, Jongwoo and Noh, Junyong},
title = {OptiSub: Optimizing Video Subtitle Presentation for Varied Display and Font Sizes via Speech Pause-Driven Chunking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714199},
doi = {10.1145/3706598.3714199},
abstract = {Viewers desire to watch video content with subtitles in various font sizes according to their viewing environment and personal preferences. Unfortunately, because a chunk of the subtitle—a segment of the text corpus displayed on the screen at once—is typically constructed based on one specific font size, text truncation or awkward line breaks can occur when different font sizes are utilized. While existing methods address this problem by reconstructing subtitle chunks based on maximum character counts, they overlook synchronization of the display time with the content, often causing misaligned text. We introduce OptiSub, a fully automated method that optimizes subtitle segmentation to fit any user-specified font size while ensuring synchronization with the content. Our method leverages the timing of speech pauses within the video for synchronization. Experimental results, including a user study comparing OptiSub with previous methods, demonstrate its effectiveness and practicality across diverse font sizes and input videos.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {799},
numpages = {12},
keywords = {Subtitles, Video Captions, Speech, Text Chunking, Video Editing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714060,
author = {Ko, Eunhye Grace and Landesman, Rotem and Young, Jason C and Arif, Ahmer and Davis, Katie and Smith, Angela D. R.},
title = {Domain Experts, Design Novices: How Community Practitioners Enact Participatory Design Values},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714060},
doi = {10.1145/3706598.3714060},
abstract = {There is a growing interest among researchers to define and promote equitable practices in participatory design (PD). Our work contributes to this research by exploring the values of facilitators with varying professional backgrounds. We conducted interviews with 15 facilitators who are novice in their design background but who possess a range of domain expertise and community memberships. The interviews focused on their experiences leading a series of PD sessions with rural educators, community college instructors, community organization members, and rural librarians. We identified five key values that facilitators saw as fundamental to their PD practice: community and shared culture, co-production of knowledge, respect and non-hierarchy, trust building, and creating practical and sustainable solutions. This study demonstrates how values that are core to PD are refracted through novice facilitators’ professional expertise and community membership. We offer two strategies for novice facilitators as they strive to practice more equitable PD.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {800},
numpages = {16},
keywords = {Participatory design, collaborative design, values, trust, interviews, expert knowledge},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713717,
author = {Tawde, Vinaya and Dost\'{a}lov\'{a}, Nicol and Cig\'{a}nov\'{a}, Eli\v{s}ka and Kriglstein, Simone},
title = {Exploring the Fit: Analysing Material Selection for Interactive Markers in MAR Games through Co-Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713717},
doi = {10.1145/3706598.3713717},
abstract = {Understanding how different user groups interact and perceive material selection for interactive markers in mobile augmented reality (MAR) games is essential for effective design. This study uses a qualitative approach, incorporating interviews and workshops to examine the preferences and behaviours of designers (N=6) and children (N=8). Designers highlighted the importance of using versatile and environmentally sustainable materials that can be customised for various games. Meanwhile, children’s interactions with these materials revealed challenges such as decision-making pressure and reliance on peer collaboration to navigate unfamiliar materials. The study identified five critical considerations for selecting materials: simplification, customisation, sustainability, balanced creativity, and collaboration. Our results show that while designers prioritise creative potential, user engagement is influenced by material ease and collaboration. This study provides key insights into the design considerations for MAR games, suggesting aligning designer expectations with actual user behaviour for creating successful and immersive MAR experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {801},
numpages = {19},
keywords = {Qualitative Study, Tangible Markers, Mobile Augmented Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713658,
author = {Dahl, Yngve and Sharma, Kshitij and Svan\ae{}s, Dag},
title = {Facilitation Skills in Participatory Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713658},
doi = {10.1145/3706598.3713658},
abstract = {The democratic and emancipatory principles underpinning Participatory Design (PD) set PD methodology apart from other user-oriented design methodologies associated with Human-Computer Interaction. In turning PD principles into practice, PD facilitators play a vital role. However, at present, there is a lack of understanding regarding skills relevant to enacting the role. To address this issue, we present the results from an interview study involving fourteen respondents with considerable PD facilitation experience. The analysis of the interviews uncovered six facilitation skills of perceived relevance: openness, patience, empathy, attentiveness, responsiveness, and adaptiveness. The significance of each skill, as expressed by respondents, is accounted for. We further discuss the composition of skills in the derived skill set, possible implications of missing skills, and how the findings complement relevant existing work. Drawing on the findings, the paper offers an empirically based qualitative understanding of what constitutes skillful PD facilitation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {802},
numpages = {13},
keywords = {Participation, facilitation, facilitation skills},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713165,
author = {Parker, Andrea G. and Vardoulakis, Laura M. and Alla, Jatin and Harrington, Christina N.},
title = {Participatory AI Considerations for Advancing Racial Health Equity},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713165},
doi = {10.1145/3706598.3713165},
abstract = {Health-related artificial intelligence (health AI) systems are being rapidly created, largely without input from racially minoritized communities who experience persistent health inequities and stand to be negatively affected if these systems are poorly designed. Addressing this problematic trend, we critically review prior work focused on the participatory design of health AI innovations (participatory AI research), surfacing eight gaps in this work that inhibit racial health equity and provide strategies for addressing these gaps. Our strategies emphasize that “participation” in design must go beyond typical focus areas of data collection, annotation, and application co-design, to also include co-generating overarching health AI agendas and policies. Further, participatory AI methods must prioritize community-centered design that supports collaborative learning around health equity and AI, addresses root causes of inequity and AI stakeholder power dynamics, centers relationalism and emotion, supports flourishing, and facilitates longitudinal design. These strategies will help catalyze research that advances racial health equity.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {803},
numpages = {24},
keywords = {Participatory AI, Participatory Design, Community-Centered Design, Racial Health Equity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713436,
author = {Qi, Xiang and Yu, Junnan},
title = {Participatory Design in Human-Computer Interaction: Cases, Characteristics, and Lessons},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713436},
doi = {10.1145/3706598.3713436},
abstract = {Participatory Design (PD) has become increasingly prevalent in Human-Computer Interaction (HCI) research. However, there remains a lack of comprehensive understanding of how PD has been used by HCI scholars. To bridge this gap, we sampled PD application cases (N = 185) from the SIGCHI conferences over the past decade and examined these cases through the dimensions of application features (e.g., contexts and functions of PD) and PD principles (e.g., its political commitment and mutual learning principle). Our analysis reveals the various ways PD has been applied in HCI and how its core features have been or have not been manifested in these cases. Based on these findings, we reflect on the conceptual understanding of PD within the HCI community and discuss potential misconceptions. Ultimately, we hope this work can serve as a useful reference for HCI researchers and beyond who are interested in incorporating PD into their design and research practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {804},
numpages = {26},
keywords = {Participatory Design (PD), HCI Research, PD Applications, PD Features, Content Analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713865,
author = {Kuo, Tzu-Sheng and Chen, Quan Ze and Zhang, Amy X. and Hsieh, Jane and Zhu, Haiyi and Holstein, Kenneth},
title = {PolicyCraft: Supporting Collaborative and Participatory Policy Design through Case-Grounded Deliberation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713865},
doi = {10.1145/3706598.3713865},
abstract = {Community and organizational policies are typically designed in a top-down, centralized fashion, with limited input from impacted stakeholders. This can result in policies that are misaligned with community needs or perceived as illegitimate. How can we support more collaborative, participatory approaches to policy design? In this paper, we present PolicyCraft, a system that structures collaborative policy design through case-grounded deliberation. Building on past research that highlights the value of concrete cases in establishing common ground, PolicyCraft supports users in collaboratively proposing, critiquing, and revising policies through discussion and voting on cases. A field study across two university courses showed that students using PolicyCraft reached greater consensus and developed better-supported course policies, compared with those using a baseline system that did not scaffold their use of concrete cases. Reflecting on our findings, we discuss opportunities for future HCI systems to help groups more effectively bridge between abstract policies and concrete cases.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {805},
numpages = {24},
keywords = {policy, deliberation, case-based reasoning, participatory design, AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713482,
author = {Simson, Jan and Draxler, Fiona and Mehr, Samuel and Kern, Christoph},
title = {Preventing Harmful Data Practices by using Participatory Input to Navigate the Machine Learning Multiverse},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713482},
doi = {10.1145/3706598.3713482},
abstract = {In light of inherent trade-offs regarding fairness, privacy, interpretability and performance, as well as normative questions, the machine learning (ML) pipeline needs to be made accessible for public input, critical reflection and engagement of diverse stakeholders.In this work, we introduce a participatory approach to gather input from the general public on the design of an ML pipeline. We show how people’s input can be used to navigate and constrain the multiverse of decisions during both model development and evaluation. We highlight that central design decisions should be democratized rather than “optimized” to acknowledge their critical impact on the system’s output downstream. We describe the iterative development of our approach and its exemplary implementation on a citizen science platform. Our results demonstrate how public participation can inform critical design decisions along the model-building pipeline and combat widespread lazy data practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {806},
numpages = {30},
keywords = {Participatory Design, Machine Learning, Algorithmic Fairness, Multiverse Analysis, Citizen Science, Garden of Forking Paths},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713594,
author = {Meng, Xiaru and Ju, Yulan and Kim, Christopher Changmok and He, Yan and Barbareschi, Giulia and Minamizawa, Kouta and Kunze, Kai and Hoppe, Matthias},
title = {A Placebo Concert: The Placebo Effect for Visualization of Physiological Audience Data during Experience Recreation in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713594},
doi = {10.1145/3706598.3713594},
abstract = {A core use case for Virtual Reality applications is recreating real-life scenarios for training or entertainment. Promoting physiological responses for users in VR that match those of real-life spectators can maximize engagement and contribute to more co-presence. Current research focuses on visualizations and measurements of physiological data to ensure experience accuracy. However, placebo effects are known to influence performance and self-perception in HCI studies, creating a need to investigate the effect of visualizing different types of data (real, unmatched, and fake) on user perception during event recreation in VR. We investigate these conditions through a balanced between-groups study (n=44) of uninformed and informed participants. The informed group was provided with the information that the data visualizations represented previously recorded human physiological data. Our findings reveal a placebo effect, where the informed group demonstrated enhanced engagement and co-presence. Additionally, the fake data condition in the informed group evoked a positive emotional response.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {807},
numpages = {16},
keywords = {Virtual Reality, Placebo Effect, Concert, Electrodermal Activity, Blood Volume Pulse},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713921,
author = {von Willich, Julius and Nelles, Frank and Tseng, Wen-Jie and Gugenheimer, Jan and G\"{u}nther, Sebastian and M\"{u}hlh\"{a}user, Max},
title = {A Qualitative Investigation of User Transitions and Frictions in Cross-Reality Applications},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713921},
doi = {10.1145/3706598.3713921},
abstract = {Research in Augmented Reality (AR) and Virtual Reality (VR) has mostly viewed them in isolation. Yet, when used together in practical settings, AR and VR each offer unique strengths, necessitating multiple transitions to harness their advantages. This paper investigates potential challenges in Cross-Reality (CR) transitions to inform future application design. We implemented a CR system featuring a 3D modeling task that requires users to switch between PC, AR, and VR. Using a talk-aloud study (n=12) and thematic analysis, we revealed that frictions primarily arose when transitions conflicted with users’ Spatial Mental Model (SMM). Furthermore, we found five transition archetypes employed to enhance productivity once an SMM was established. Our findings uncover that transitions have to focus on establishing and upholding the SMM of users across realities, by communicating differences between them.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {808},
numpages = {18},
keywords = {Cross-Reality Transitions, Augmented Reality, Virtual Reality, Cross-Device Interaction, Transitional Interfaces},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714110,
author = {Shi, Han and Je, Seungwoo},
title = {DobbyEar: Inducing Body Illusion of Ear Deformation with Haptic Retargeting},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714110},
doi = {10.1145/3706598.3714110},
abstract = {The use of haptic and visual stimuli to create body illusions and enhance body ownership of virtual avatars in virtual reality (VR) has been extensively studied in the fields of psychology and Human-Computer Interaction (HCI). However, previous studies have relied on mechanical devices or corresponding proxies to provide haptic feedback. In this paper, we applied haptic retargeting to induce body illusions by redirecting users’ hand movements, altering their perception of the shape of body parts when touched. Our technique allows for the realization of more precise and complex deformations. We implemented mapping of the ear’s contour, thereby creating illusions of different ear shapes, such as elf ears and dog ears. To determine the scope of retargeting, we conducted a user study to identify the maximum tolerable deviation angle for virtual ears. Subsequently, we explored the impact of haptic retargeting on body ownership of virtual avatars.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {809},
numpages = {12},
keywords = {Virtual reality, haptic retargeting, body illusion, body ownership},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713511,
author = {Cheng, Yi Fei and Lindlbauer, David},
title = {Sensing Noticeability in Ambient Information Environments},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713511},
doi = {10.1145/3706598.3713511},
abstract = {Designing notifications in Augmented Reality (AR) that are noticeable yet unobtrusive is challenging since achieving this balance heavily depends on the user’s context. However, current AR systems tend to be context-agnostic and require explicit feedback to determine whether a user has noticed a notification. This limitation restricts AR systems from providing timely notifications that are integrated with users’ activities. To address this challenge, we studied how sensors can infer users’ detection of notifications while they work in an office setting. We collected 98 hours of data from 12 users, including their gaze, head position, computer interactions, and engagement levels. Our findings showed that combining gaze and engagement data most accurately classified noticeability (AUC = 0.81). Even without engagement data, the accuracy was still high (AUC = 0.76). Our study also examines time windowing methods and compares general and personalized models.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {810},
numpages = {17},
keywords = {Ambient displays, noticeability, computational interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713455,
author = {Wilson, Graham and P\"{o}hlmann, Katharina Margareta Theresa and Al Baiaty Suarez, David and McGill, Mark and Brewster, Stephen Anthony},
title = {The Spin Doctor: Leveraging Insensitivity to Passive Rotational \&amp; Translational Gain For Unbounded Motion-Based VR Experiences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713455},
doi = {10.1145/3706598.3713455},
abstract = {Rotational gain has been studied largely under active self-motion, where users control their own movement. In multiple VR scenarios, the user is under passive self-motion: their body is moved by a training simulator, a motorised chair, or a vehicle-based VR application. Users may be less sensitive to manipulation under passive motion - especially when engaged in a secondary task - meaning motion experiences could be expanded by high gains and even opposed virtual-physical motion. We identified both the perceptible and maximum comfortable thresholds of rotational gain when passively turned in a motorised chair, with and without a task, for the first time. We then applied those thresholds to an ’unbounded’ in-car VR game where the user experiences an entirely different route to their physical movement. We provide the first guidelines for creating enhanced passive motion experiences and open the design space to new applications not restricted by physical motion.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {811},
numpages = {19},
keywords = {Virtual Reality, rotational gain, passive motion, vehicle, interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713400,
author = {Shrestha, Aayush and Malloch, Joseph},
title = {Virtual Worlds Beyond Sight: Designing and Evaluating an Audio-Haptic System for Non-Visual VR Exploration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713400},
doi = {10.1145/3706598.3713400},
abstract = {Contemporary research in Virtual Reality for users who are visually impaired often employs navigation and interaction modalities that are either non-conventional, constrained by physical spaces, or both. We designed and examined a hapto-acoustic VR system that mitigates this by enabling non-visual exploration of large virtual environments using white cane simulation and walk-in place locomotion. The system features a complex urban cityscape incorporating a physical cane prototype coupled with a virtual cane for rendering surface textures, and an omnidirectional slide mill for navigation. In addition, spatialized audio is rendered based on the progression of sound through the geometry around the user. A study involving twenty sighted participants evaluated the system through three formative tasks while blindfolded to simulate absolute blindness. Participants were highly successful in completing all the tasks while effectively navigating through the environment. Our work highlights the potential for accessible, non-visual VR experiences, achievable even with minimal training and little prior exposure to VR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {812},
numpages = {19},
keywords = {Virtual reality; white cane simulation; blindness; visual impairments; haptic feedback; auditory feedback; spatial audio; non-visual exploration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714291,
author = {Shi, Ke and Chen, Tongshu and Xiang, Yichen and Li, Ye and Zhu, Lifeng and Song, Aiguo},
title = {iGripper: A Semi-Active Handheld Haptic VR Controller Based on Variable Stiffness Mechanism},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714291},
doi = {10.1145/3706598.3714291},
abstract = {We introduce iGripper, a handheld haptic controller designed to render stiffness feedback for gripping and clamping both rigid and elastic objects in virtual reality. iGripper directly adjusts physical stiffness by using a small linear actuator to modify the spring’s position along a lever arm, with feedback force generated by the spring’s reaction to the user’s input. This enables iGripper to render stiffness from zero to any specified value, determined by the spring’s inherent stiffness. Additionally, a blocking mechanism is designed to provide fully rigid feedback to enlarge the rendering range. Compared to active controllers, iGripper offers a broad range of force and stiffness feedback without requiring high-power actuators. Unlike many passive controllers, which provide only braking force, iGripper, as a semi-active controller, delivers controllable elastic force feedback. We present the iGripper’s design, performance evaluation, and user studies, comparing its realism with a commercial impedance-type grip device.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {813},
numpages = {15},
keywords = {Virtual Reality; Haptic; Stiffness Feedback; Force Feedback; Controller Design;},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713171,
author = {Gamage, Dilrukshi and Sewwandi, Dilki and Zhang, Min and Bandara, Arosha K},
title = {Labeling Synthetic Content: User Perceptions of Label Designs for AI-Generated Content on Social Media},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713171},
doi = {10.1145/3706598.3713171},
abstract = {In this research, we explored the efficacy of various warning label designs for AI-generated content on social media platforms—e.g., deepfakes. We devised and assessed ten distinct label design samples that varied across the dimensions of sentiment, color/iconography, positioning, and level of detail. Our experimental study involved 911 participants randomly assigned to these ten label designs and a control group evaluating social media content. We explored their perceptions relating to 1) Belief in the content being AI-generated, 2) Trust in the labels and 3) Social Media engagement perceptions of the content. The results demonstrate that the presence of labels had a significant effect on the user’s belief that the content is AI-generated, deepfake, or edited by AI. However their trust in the label significantly varied based on the label design. Notably, having labels did not significantly change their engagement behaviors, such as ’like’, comment, and sharing. However, there were significant differences in engagement based on content type: political and entertainment. This investigation contributes to the field of human-computer interaction by defining a design space for label implementation and providing empirical support for the strategic use of labels to mitigate the risks associated with synthetically generated media.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {814},
numpages = {29},
keywords = {Generative AI warnings, warning label design, user perceptions, deepfake, AI content label},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713301,
author = {Ojewale, Victor and Steed, Ryan and Vecchione, Briana and Birhane, Abeba and Raji, Inioluwa Deborah},
title = {Towards AI Accountability Infrastructure: Gaps and Opportunities in AI Audit Tooling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713301},
doi = {10.1145/3706598.3713301},
abstract = {Audits are critical mechanisms for identifying the risks and limitations of deployed artificial intelligence (AI) systems. However, the effective execution of AI audits remains incredibly difficult, and practitioners often need to make use of various tools to support their efforts. Drawing on interviews with 35 AI audit practitioners and a landscape analysis of 435 tools, we compare the current ecosystem of AI audit tooling to practitioner needs. While many tools are designed to help set standards and evaluate AI systems, they often fall short in supporting accountability. We outline challenges practitioners faced in their efforts to use AI audit tools and highlight areas for future tool development beyond evaluation—from harms discovery to advocacy. We conclude that the available resources do not currently support the full scope of AI audit practitioners’ needs and recommend that the field move beyond tools for just evaluation and towards more comprehensive infrastructure for AI accountability.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {815},
numpages = {29},
keywords = {auditing, evaluation, audit tools, accountability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713887,
author = {Panicker, Yustynn and Soremekun, Ezekiel and Chattopadhyay, Sudipta and Sun, Sumei},
title = {Understanding End-User Perception of Transfer Risks in Smart Contracts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713887},
doi = {10.1145/3706598.3713887},
abstract = {Blockchain smart contracts are increasingly used in critical use cases (e.g., financial transactions). Thus, it is pertinent to ensure that their end-users understand risks in attempting token transfers. Addressing this, we investigate end-user comprehension of five transfer risks (e.g. the end-user being blacklisted) in the most popular Ethereum contract, USD Tether (USDT), and their prevalence in other top ERC-20 contracts. First, we conducted a user study investigating end-user comprehension of transfer risks in USDT with 110 participants. Second, we performed source code analysis of the next top (78) ERC-20 smart contracts to identify the prevalence of these risks. Study results show that the majority of end-users do not comprehend some real risks, and confuse real and fictitious risks. This holds regardless of participants’ self-rated programming and Web3 proficiency. Source code analysis demonstrates that examined risks are prevalent in up to 19.2\% of the top ERC-20 contracts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {816},
numpages = {21},
keywords = {smart contract, transfer risk, user perception, ethereum, erc-20},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713871,
author = {Lu, Zhuoran and Li, Patrick and Wang, Weilong and Yin, Ming},
title = {Understanding the Effects of AI-based Credibility Indicators When People Are Influenced By Both Peers and Experts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713871},
doi = {10.1145/3706598.3713871},
abstract = {In an era marked by rampant online misinformation, artificial intelligence (AI) technologies have emerged as tools to combat this issue. This paper examines the effects of AI-based credibility indicators in people’s online information processing under the social influence from both peers and “experts”. Via three pre-registered, randomized experiments, we confirm the effectiveness of accurate AI-based credibility indicators to enhance people’s capability in judging information veracity and reduce their propensity to share false information, even under the influence from both laypeople peers and experts. Notably, these effects remain consistent regardless of whether experts’ expertise is verified, with particularly significant impacts when AI predictions disagree with experts. However, the competence of AI moderates the effects, as incorrect predictions can mislead people. Furthermore, exploratory analyses suggest that under our experimental settings, the impact of the AI-based credibility indicator is larger than that of the expert’s. Additionally, AI’s influence on people is partially mediated through peer influence, although people automatically discount the opinions of their laypeople peers when seeing an agreement between AI and peers’ opinions. We conclude by discussing the implications of utilizing AI to combat misinformation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {817},
numpages = {19},
keywords = {misinformation, fake news, artificial intelligence, social influence, human-AI interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713256,
author = {West, Jack and Cagiltay, Bengisu and Zhang, Shirley and Li, Jingjie and Fawaz, Kassem and Banerjee, Suman},
title = {``Impressively Scary:' Exploring User Perceptions and Reactions to Unraveling Machine Learning Models in Social Media Applications},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713256},
doi = {10.1145/3706598.3713256},
abstract = {Machine learning models deployed locally on social media applications are used for features, such as face filters which read faces in-real time, and they expose sensitive attributes to the apps. However, the deployment of machine learning models, e.g., when, where, and how they are used, in social media applications is opaque to users. We aim to address this inconsistency and investigate how social media user perceptions and behaviors change once exposed to these models. We conducted user studies (N=21) and found that participants were unaware to both what the models output and when the models were used in Instagram and TikTok, two major social media platforms. In response to being exposed to the models’ functionality, we observed long term behavior changes in 8 participants. Our analysis uncovers the challenges and opportunities in providing transparency for machine learning models that interact with local user data.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {818},
numpages = {21},
keywords = {AI Transparency; Social Media; Privacy; Mobile AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713378,
author = {Eler, Marcelo Medeiros and Aljedaani, Wajdi},
title = {Investigating User Perceptions of Epilepsy-Related Seizure Triggers in Mobile Apps: An Analysis of User Reviews},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713378},
doi = {10.1145/3706598.3713378},
abstract = {Individuals with reflex epilepsy may have seizures caused by stimuli including flashing lights, colors, motion, and patterns. Many studies have investigated seizure-inducing content in multimedia, but studies addressing seizure triggers in mobile apps are still scarce. Hence, we examined user reviews aiming to identify and describe seizure triggers in mobile apps based on user’s reported experiences. Our findings reveal significant patterns of how apps can unintentionally harm users with epilepsy, highlighting the need for improved design practices and more comprehensive accessibility guidelines, which are mainly focused on flashy content and animation. More specifically, we present evidences indicating that users do experience seizures triggered by mobile app interaction, which are not solely limited to multimedia interaction. Most seizure triggers are associated with flashy content and less frequently by color schemes, motion, transitions, glitches, and bugs. In addition, videos and advertisements are the most seizure-inducing content reported by users.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {819},
numpages = {19},
keywords = {Accessibility, User Reviews, Seizure, Trigger, Epilepsy, Mobile App, Guidelines},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714124,
author = {Lu, Qian and Yang, Xiaoying and Wang, Xue and Sayono, Jacob and Zhang, Yang and Kim, Jeeeun},
title = {LumosX: 3D Printed Anisotropic Light-Transfer},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714124},
doi = {10.1145/3706598.3714124},
abstract = {Light’s interaction with object surfaces through anisotropic reflection–where reflected light varies with viewing angles–offers significant potential for enhancing visual capabilities and assisting informed decision-making. Such ubiquitous light transfer phenomenon supports directional information encoding in sensing and dynamic display applications.We present LumosX, a set of techniques for encoding and decoding information through light intensity changes using 3D-printed optical anisotropic properties. By optimizing directional reflection and brightness contrasts through off-the-shelf materials and precise control over processing parameters (e.g., extrusion volume, raster angles, layer height, nozzle positioning), we enable cost-effective fabrication of visually enhanced objects. Our method supports modular assembly for highly curved regular surfaces and direct printing on top of relatively flat curved surfaces, enabling flexible information encoding for diverse applications. We showcase LumosX’s effectiveness through various indoor and smart urban sensing scenarios, demonstrating significant improvements in both human interaction and autonomous machine perception.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {820},
numpages = {21},
keywords = {3D printing, light transfer, sensing, dynamic information display},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713775,
author = {Zhang, Shichen and Wang, Qijun and Song, Kunzhe and Yan, Qiben and Zeng, Huacheng},
title = {RadEye: Tracking Eye Motion Using FMCW Radar},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713775},
doi = {10.1145/3706598.3713775},
abstract = {Eye motion tracking plays a vital role in many applications such as human-computer interaction (HCI), virtual reality, and disease detection. Camera-based eye tracking, albeit accurate and easy to use, may raise privacy concerns and appear to be unreliable in poor lighting conditions. In this paper, we present RadEye, a radar system capable of detecting fine-grained human eye motions from a distance. RadEye is realized through an integrated hardware and software design. It customizes a sub-6GHz FMCW radar so as to detect millimeter-level eye movement while extending its detection range using low frequency. It further employs a deep neural network (DNN) to refine the detection accuracy through camera-guided supervisory training. We have built a prototype of RadEye. Extensive experimental results show that it achieves 90\% accuracy when detecting human eye rotation directions (up, down, left, and right) in various scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {821},
numpages = {13},
keywords = {FMCW radar, Human-Computer Interaction, Eye tracking, Deep learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713439,
author = {Thiault, Alexandre and Philippe, Telo and Parakkat, Amal Dev and Eisemann, Elmar and Muthuganapathy, Ramanathan and Igarashi, Takeo},
title = {SpineLoft: Interactive Spine-based 2D-to-3D Modeling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713439},
doi = {10.1145/3706598.3713439},
abstract = {3D artists (professionals and novices alike) often take inspiration from sketches or photos to guide their designs. Yet, existing modeling systems are not tailored to fully make use of such input. Consequently, significant effort and expertise are needed when creating model prototypes or exploring design options. In this work, we introduce a system to support the exploratory modeling process by enabling the transformation of 2D image elements into geometric 3D objects. Our solution relies on a novel d2 distance function, supporting a region-based lofting process, and delivers easily-editable 3D geometric "spine-rib" representations. The user draws a spine, and the system generates and modifies a generalized cylinder around it, considering image edges. The proposed approach, driven by simple user-defined scribble definitions, can robustly handle various image sources, ranging from photos to hand-drawn content.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {822},
numpages = {16},
keywords = {Sketch-based 3D modeling, Image-based 3D modeling, d2 function, Lofting, Interactive modeling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713679,
author = {Azim, Md Aashikur Rahman and Su, Zihao and Heo, Seongkook},
title = {Your Hands Can Tell: Detecting Redirected Hand Movements in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713679},
doi = {10.1145/3706598.3713679},
abstract = {In-air hand interactions are prevalent in Virtual Reality (VR), and prior studies have shown that manipulating the visual movement of the hand to be different from the actual hand movement, i.e., hand redirection, could create a more immersive and engaging VR experience. However, this manipulation risks degrading task performance and, if maliciously applied, poses a threat to user safety. Such manipulations may arise from VR applications developed with intentional or inadvertent perceptual manipulations that yield harmful outcomes. We advocate for a user’s prerogative to be informed of any such potential manipulations before application usage. To address this, our study introduces an Autoencoder-based anomaly detection technique that leverages users’ inherent hand movements to identify hand redirection, thereby preserving the integrity of application use. Our model is trained on regular (i.e., non-manipulated) hand movement patterns and employs a stochastic thresholding approach for anomaly detection. We validated our method through a technical evaluation involving 21 participants engaged in reaching tasks under manipulated and non-manipulated scenarios. The results demonstrated a high accuracy of hand redirection detection at (93.7\%), with an F1-score of (93.9\%).},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {823},
numpages = {14},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713744,
author = {Okoso, Ayano and Yang, Mingzhe and Baba, Yukino},
title = {Do Expressions Change Decisions? Exploring the Impact of AI's Explanation Tone on Decision-Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713744},
doi = {10.1145/3706598.3713744},
abstract = {Explanatory information helps users to evaluate the suggestions offered by AI-driven decision support systems. With large language models, adjusting explanation expressions has become much easier. However, how these expressions influence human decision-making remains largely unexplored. This study investigated the effect of explanation tone (e.g., formal or humorous) on decision-making, focusing on AI roles and user attributes. We conducted user experiments across three scenarios depending on AI roles (assistant, second-opinion provider, and expert) using datasets designed with varying tones. The results revealed that tone significantly influenced decision-making regardless of user attributes in the second-opinion scenario, whereas its impact varied by user attributes in the assistant and expert scenarios. In addition, older users were more influenced by tone, and highly extroverted users exhibited discrepancies between their perceptions and decisions. Furthermore, open-ended questionnaires highlighted that users expect tone adjustments to enhance their experience while emphasizing the importance of tone consistency and ethical considerations. Our findings provide crucial insights into the design of explanation expressions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {824},
numpages = {22},
keywords = {Decision-making Support System, Recommender System, Explanation, Expression, Tone, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713520,
author = {Koesten, Laura and Saske, Antonia and Starchenko, Sandra Maria and Gregory, Kathleen},
title = {Encountering Friction, Understanding Crises: How Do Digital Natives Make Sense of Crisis Maps?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713520},
doi = {10.1145/3706598.3713520},
abstract = {Crisis maps are regarded as crucial tools in crisis communication, as demonstrated during the COVID-19 pandemic and climate change crises. However, there is limited understanding of how public audiences engage with these maps and extract essential information. Our study investigates the sensemaking of young, digitally native viewers as they interact with crisis maps. We integrate frameworks from the learning sciences and human-data interaction to explore sensemaking through two empirical studies: a thematic analysis of online comments from a New York Times series on graph comprehension, and interviews with 18 participants from German-speaking regions. Our analysis categorizes sensemaking activities into established clusters: inspecting, engaging with content, and placing, and introduces responding personally to capture the affective dimension. We identify friction points connected to these clusters, including struggles with color concepts, responses to missing context, lack of personal connection, and distrust, offering insights for improving crisis communication to public audiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {825},
numpages = {15},
keywords = {Sensemaking, Human-Data Interaction, Data Visualization, Crisis Maps, Data Engagement, Friction Points, Crisis Communication, Public Data Understanding},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713332,
author = {Yan, Di and Bourgeois, Jacky and Hsu, Yen-Chia and Kortuem, Gerd},
title = {PAIRcolator: Pair Collaboration for Sensemaking and Reflection on Personal Data},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713332},
doi = {10.1145/3706598.3713332},
abstract = {This paper explores pair collaboration as a novel approach for making sense of personal data. Pair collaboration—characterized by dyadic comparison and structured roles for questioning and reasoning—has proven effective for co-constructing knowledge. However, current collaborative visualization tools primarily focus on group comparisons, overlooking the challenges of accommodating pair collaboration in the context of personal data. To address this gap, we propose a set of design rationales supporting subjective data analysis through dyadic comparison and mixed-focus collaboration styles for co-constructing personal narratives. We operationalize these principles in a tangible visualization toolkit, PAIRcolator. Our user study demonstrates that pairwise collaboration facilitated by the toolkit: 1) reveals detailed data insights that are effective for recalling personal experiences, and 2) fosters a structured, reciprocal sensemaking process for interpreting and reconstructing personal experiences beyond data insights. Our results shed light on the design rationales for, and the processes of pair sensemaking of personal data, and their effects to foster deep levels of reflection.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {826},
numpages = {20},
keywords = {Collaborative sensemaking, personal data visualization, self-reflection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713300,
author = {Yan, Di and Tang, Chenge and Chandrasegaran, Senthil and Kortuem, Gerd},
title = {Reciportrait: a Data Humanism Approach for Collaborative Sensemaking of Personal Data},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713300},
doi = {10.1145/3706598.3713300},
abstract = {Data Humanism has gained prominence in personal visualization and Personal Informatics, advocating for a subjective and slow approach to engage with personal data. Collaborative sensemaking has great potential for aiding the understanding of personal data, yet little is known about addressing requirements of structure and coordination when integrating Data Humanism into collaborative visualization. In this paper, we propose design principles for creating both subjective and effective collaborative visualizations, while coordinating the slow sensemaking process and promoting data awareness and communication. We operationalize these principles into a personal visualization toolkit, which we evaluate with an observational study involving 16 university students (8 pairs) analyzing each other’s screen-time data. Our findings reveal that implementing the proposed design principles: (1) facilitated data comparison from shared subjective perspectives, (2) helped coordinate sensemaking while allowing time for understanding personal data, and (3) helped the contextualization of data patterns, in turn aiding self-reflection.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {827},
numpages = {21},
keywords = {data visualization, Data Humanism, collaborative sensemaking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713664,
author = {Sivaraman, Venkatesh and Vaishampayan, Anika and Li, Xiaotong and Buck, Brian R and Ma, Ziyong and Boyce, Richard D and Perer, Adam},
title = {Tempo: Helping Data Scientists and Domain Experts Collaboratively Specify Predictive Modeling Tasks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713664},
doi = {10.1145/3706598.3713664},
abstract = {Temporal predictive models have the potential to improve decisions in health care, public services, and other domains, yet they often fail to effectively support decision-makers. Prior literature shows that many misalignments between model behavior and decision-makers’ expectations stem from issues of model specification, namely how, when, and for whom predictions are made. However, model specifications for predictive tasks are highly technical and difficult for non-data-scientist stakeholders to interpret and critique. To address this challenge we developed Tempo, an interactive system that helps data scientists and domain experts collaboratively iterate on model specifications. Using Tempo’s simple yet precise temporal query language, data scientists can quickly prototype specifications with greater transparency about pre-processing choices. Moreover, domain experts can assess performance within data subgroups to validate that models behave as expected. Through three case studies, we demonstrate how Tempo helps multidisciplinary teams quickly prune infeasible specifications and identify more promising directions to explore.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {828},
numpages = {18},
keywords = {Predictive Modeling, Temporal Data, Model Specification},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713232,
author = {Moon, Erina Seh-Young and Saxena, Devansh and Das, Dipto and Guha, Shion},
title = {The Datafication of Care in Public Homelessness Services},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713232},
doi = {10.1145/3706598.3713232},
abstract = {Homelessness systems in North America adopt coordinated data-driven approaches to efficiently match support services to clients based on their assessed needs and available resources. AI tools are increasingly being implemented to allocate resources, reduce costs and predict risks in this space. In this study, we conducted an ethnographic case study on the City of Toronto’s homelessness system’s data practices across different critical points. We show how the City’s data practices offer standardized processes for client care but frontline workers also engage in heuristic decision-making in their work to navigate uncertainties, client resistance to sharing information, and resource constraints. From these findings, we show the temporality of client data which constrain the validity of predictive AI models. Additionally, we highlight how the City adopts an iterative and holistic client assessment approach which contrasts to commonly used risk assessment tools in homelessness, providing future directions to design holistic decision-making tools for homelessness.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {829},
numpages = {16},
keywords = {algorithmic decision-making, algorithmic bias, risk assessments, homelessness, public sector},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714202,
author = {Wunder, Julia and Wash, Rick and Renaud, Karen and Oliveira, Daniela A and Benenson, Zinaida},
title = {Achieving Resilience: Data Loss and Recovery on Devices for Personal Use in Three Countries},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714202},
doi = {10.1145/3706598.3714202},
abstract = {Recovery from adverse incidents, such as accidents or cyber attacks, is a cornerstone of cyber resilience. Backups are essential in facilitating systems recovery. We have limited understanding of how devices for personal use are backed up, and of how data loss and recovery occur, including which factors might be helpful to afford resilience. To gain insights, we surveyed almost representative (in age and gender) samples of German, UK and USA populations, 1423 in total. Almost half of the participants (656, 46\%) experienced at least one data loss incident. Whereas 42\% of 656 participants recovered using backups, over half of them had outdated or incomplete backups. High levels of stress were reported, especially by those recovering without backups or with problematic backups. In the full sample, 86\% of participants created full or partial backups of at least one of their devices, the most important trigger being prior data loss experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {830},
numpages = {26},
keywords = {resilience, backup, recovery, mobile, laptop, desktop},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713546,
author = {Conwill, Louisa and Levis, Megan K. and Badillo-Urquiola, Karla and Scheirer, Walter J.},
title = {Design Patterns for the Common Good: Building Better Technologies Using the Wisdom of Virtue Ethics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713546},
doi = {10.1145/3706598.3713546},
abstract = {Virtue ethics is a philosophical tradition that emphasizes the cultivation of virtues in achieving the common good. It has been suggested to be an effective framework for envisioning more ethical technology, yet previous work on virtue ethics and technology design has remained at theoretical recommendations. Therefore, we propose an approach for identifying user experience design patterns that embody particular virtues to more concretely articulate virtuous technology designs. As a proof of concept for our approach, we documented seven design patterns for social media that uphold the virtues of Catholic Social Teaching. We interviewed 24 technology researchers and industry practitioners to evaluate these patterns. We found that overall the patterns enact the virtues they were identified to embody; our participants valued that the patterns fostered intentional conversations and personal connections. We pave a path for technology professionals to incorporate diverse virtue traditions into the development of technologies that support human flourishing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {831},
numpages = {23},
keywords = {virtue ethics, design patterns, social media, catholic social teaching, digital well-being},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713544,
author = {Stephenson, Sophie and Ramjit, Lana and Ristenpart, Thomas and Dell, Nicola},
title = {Digital Technologies and Human Trafficking: Combating Coercive Control and Navigating Digital Autonomy},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713544},
doi = {10.1145/3706598.3713544},
abstract = {This paper describes a qualitative study that interrogates the types of technology-facilitated coercive control faced by survivors of human trafficking and uncovers potential interventions to aid survivors’ recovery. Via semi-structured interviews with 21 participants, including trafficking survivors and professional advocates, we show how traffickers use technology as a lever for control, engaging in surveillance, blackmail, impersonation, and harassment as they compel survivors to stay in the trafficking situation. In recovery, digital footprints keep survivors tethered to their trafficking experience, impacting their digital autonomy, economic mobility, and feelings of safety. Nevertheless, technology can also be a valuable tool for survivors’ recovery, connecting them to essential resources and support systems. We discuss the need for interventions and services that account for the specificity of the trafficking context to help survivors attain digital safety and autonomy, including the potential to adapt existing tech safety services designed for other contexts to human trafficking.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {832},
numpages = {21},
keywords = {human trafficking, sex trafficking, labor trafficking, technology-facilitated abuse, tech abuse, technology-facilitated coercive control, clinical computer security, technology abuse clinic, digital safety, at-risk users.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713882,
author = {Li, Zisu and Li, Jiawei and Xiong, Zeyu and Zhang, Shumeng and Faruqi, Faraz and Mueller, Stefanie and Liang, Chen and Ma, Xiaojuan and Fan, Mingming},
title = {InteRecon: Towards Reconstructing Interactivity of Personal Memorable Items in Mixed Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713882},
doi = {10.1145/3706598.3713882},
abstract = {Digital capturing of memorable personal items is a key way to archive personal memories. Although current digitization methods (e.g., photos, videos, 3D scanning) can replicate the physical appearance of an item, they often cannot preserve its real-world interactivity. We present Interactive Digital Item (IDI), a concept of reconstructing both the physical appearance and, more importantly, the interactivity of an item. We first conducted a formative study to understand users’ expectations of IDI, identifying key physical interactivity features, including geometry, interfaces, and embedded content of items. Informed by these findings, we developed InteRecon, an AR prototype enabling personal reconstruction functions for IDI creation. An exploratory study was conducted to assess the feasibility of using InteRecon and explore the potential of IDI to enrich personal memory archives. Results show that InteRecon is feasible for IDI creation, and the concept of IDI brings new opportunities for augmenting personal memory archives.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {833},
numpages = {19},
keywords = {Mixed/Augmented Reality, interactive 3D reconstruction, personal memory archive, physical reconstruction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713495,
author = {Lyu, Bolin and Li, Zhuying and An, Pengcheng and Andres, Josh},
title = {LumaDreams: Designing Positive Dream Meaning-Making for Daily Empowerment},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713495},
doi = {10.1145/3706598.3713495},
abstract = {Dreams contribute to cognitive and emotional health, yet tools for everyday dream engagement remain largely underexplored outside clinical settings. In this paper, we introduce LumaDreams, a mobile application designed to foster daily empowerment through positive dream transformation using generative AI. Informed by meaning-making theories, LumaDreams enables users to journal dreams through sketches and text, which are then transformed into positive images and stories for users to revisit and reflect on. We conducted a mixed-method study with 14 participants over 14 days. Our findings show that LumaDreams strengthened participants’ daily empowerment through cognitive and emotional shifts that arise from the positive meaning-making process. Qualitative insights further revealed how users’ perceptions and trust of AI-driven dream transformation were shaped through their interactions. In conclusion, we propose an inspiring approach that enables users to co-create positive meanings in dream experiences with generative AI, promoting cognitive and emotional shifts, fostering positive mindsets, and ultimately strengthening daily empowerment.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {834},
numpages = {20},
keywords = {Dream, Empowerment, Meaning-making, Generative AI, Well-being},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714145,
author = {Elagroudy, Passant and Rzayev, Rufat and Machulla, Tonja-Katrin and Le, Huy Viet and Dingler, Tilman and Lischke, Lars and Clinch, Sarah and Ward, Geoffrey and Schmidt, Albrecht},
title = {Pixel Memories: Do Lifelog Summaries Fail to Enhance Memory but Offer Privacy-Aware Memory Assessments?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714145},
doi = {10.1145/3706598.3714145},
abstract = {We explore the metaphorical "daily memory pill" concept – a brief pictorial lifelog recap aimed at reviving and preserving memories. Leveraging psychological strategies, we explore the potential of such summaries to boost autobiographical memory. We developed an automated lifelogging memory prosthesis and a research protocol (Automated Memory Validation “AMV”) for conducting privacy-aware, in-situ evaluations. We conducted a real-world lifelogging experiment for a month (n=11). We also designed a browser “Pixel Memories’’ for browsing one-week worth of lifelogs. The results suggest that daily timelapse summaries, while not yielding significant memory augmentation effects, also do not lead to memory degradation. Participants’ confidence in recalled content remains unaltered, but the study highlights the challenge of users’ overestimation of memory accuracy. Our core contributions, the AMV protocol and "Pixel Memories" browser, advance our understanding of memory augmentations and offer a privacy-preserving method for evaluating future ubicomp systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {835},
numpages = {17},
keywords = {lifelogging, recall, memory research, privacy, case study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713365,
author = {Santana, Vagner Figueredo de and Berger, Sara E and Candello, Heloisa and Machado, Tiago and Sanctos, Cassia Sampaio and Su, Tianyu and Williams, Lemara},
title = {Responsible Prompting Recommendation: Fostering Responsible AI Practices in Prompting-Time},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713365},
doi = {10.1145/3706598.3713365},
abstract = {Human-Computer Interaction practitioners have been proposing best practices in user interface design for decades. However, generative Artificial Intelligence (GenAI) brings additional design considerations and currently lacks sufficient user guidance regarding affordances, inputs, and outputs. In this context, we developed a recommender system to promote responsible AI (RAI) practices while people prompt GenAI systems. We detail 10 interviews with IT professionals, the resulting recommender system developed, and 20 user sessions with IT professionals interacting with our prompt recommendations. Results indicate that responsible prompting recommendations have the potential to support novice prompt engineers and raise awareness about RAI in prompting-time. They also suggest that recommendations should simultaneously maximize both a prompt’s similarity to a user’s input as well as a diversity of associated social values provided. These findings contribute to RAI by offering practical ways to provide user guidance and enrich human-GenAI interaction via prompt recommendations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {836},
numpages = {30},
keywords = {Prompt Engineering, Human-AI Interaction, Responsible Computing, Responsible AI, Responsible Prompting, Recommender Systems, Proactive Value Alignment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713416,
author = {Jahn, Leonie and Engelbutzeder, Philip and Michel, Lea Katharina and Prost, Sebastian and Twidale, Michael Bernard and Randall, Dave and Wulf, Volker},
title = {Blending Code and Cause: Understanding the Dynamic Motivations of Volunteer Developers in community-driven FOSS projects},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713416},
doi = {10.1145/3706598.3713416},
abstract = {Understanding the motivations of volunteer developers is crucial for the HCI community as it seeks to design sustainable, community-driven digital platforms. This study explores the dynamics of motivation among volunteer developers in the Foodsharing.de platform, a grassroots movement focused on reducing food waste through community engagement. By investigating the evolving motivations and challenges faced by these developers, our research highlights the unique blend of personal passion, technical skill, and social commitment that sustains their long-term involvement. Through interviews, observations, and participatory research, we uncover how developers balance their commitment to Free and Open Source Software (FOSS) with the platform’s socio-ecological mission. Our findings emphasize the importance of fostering a supportive community, clear governance, and effective infrastructuring to manage motivation, frustration, and expectations. We discuss strategies to enhance volunteer retention, such as improving feedback mechanisms and recognizing contributions, which are critical for the sustainability of volunteer-driven platforms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {837},
numpages = {17},
keywords = {Volunteer Developer Motivation, Free and Open-Source Software (FOSS), Community-driven Digital Platforms, Infrastructuring in HCI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713157,
author = {Chordia, Ishita and Wolfe, Robert and Yip, Jason and Hiniker, Alexis},
title = {Building the Beloved Community: Designing Technologies for Neighborhood Safety},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713157},
doi = {10.1145/3706598.3713157},
abstract = {Neighborhood safety technologies, such as Nextdoor and Citizen, aim to enhance user safety through features like real-time alerts, interactive maps, and personalized feeds. While these platforms can support users’ sense of safety, they can also fuel a local culture of policing and lateral surveillance, which disproportionately impacts racialized and unhoused members of the community. In contrast, the theory and practice of Transformative Justice was developed to ensure the safety of those populations who are constructed to be dangerous by society. We conducted a case study of a neighborhood social work program in Jackson Grove, Atlanta to understand the design implications of a Transformative Justice-oriented approach to neighborhood safety. Our findings highlight an opportunity for designers to reconceptualize safety from merely protecting users towards: 1) meeting the basic needs of a community, and 2) building relationships to support accountability. These shifts create an opportunity for designers to reimagine neighborhood safety technologies and the associated practices for users. We surface a new wave of safety research in HCI that aims to support both safety and justice and contribute key design priorities towards this work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {838},
numpages = {18},
keywords = {crime, community safety, transformative justice, outreach, unhoused, homelessness, social work, neighborhood, safety technologies, neighborhood safety},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714246,
author = {Song, Pinyao and Hebbani, Aparna and Vyas, Dhaval},
title = {Exploring Place-Belongingness through Magic Machine Workshops in Refugee Communities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714246},
doi = {10.1145/3706598.3714246},
abstract = {Upon displacement, it becomes challenging for refugees to build a sense of home in a new environment due to the traumatic experiences they have endured. To unpack factors that are important in developing a sense of home and belonging in refugee communities, we lean on the theoretical concept of ’place-belongingness’ - we did this by conducting 6 co-design workshops involving 15 refugee participants, via the ’Magic Machine’ workshop approach. From the workshops, we uncovered how cultural identity and memory, life stability and normalcy, security and privacy, resilience and ingenuity, and social connections are central to their sense of home. This research contributes to HCI by building on the theoretical concept of place-belongingness in the context of forced displacement, proposing design implications that address refugees’ needs for home from cultural and social dimensions, and design considerations for refugees’ domestic settings.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {839},
numpages = {15},
keywords = {Refugees, Place-belongingness, Magic Machine, Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713163,
author = {Gleason, Jeffrey and Leavitt, Alex and Daly, Bridget},
title = {In Suspense About Suspensions? The Relative Effectiveness of Suspension Durations on a Popular Social Platform},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713163},
doi = {10.1145/3706598.3713163},
abstract = {It is common for digital platforms to issue consequences for behaviors that violate Community Standards policies. However, there is limited evidence about the relative effectiveness of consequences, particularly lengths of temporary suspensions. This paper analyzes two massive field experiments (N1 = 511, 304; N2 = 262, 745) on Roblox that measure the impact of suspension duration on safety- and engagement-related outcomes. The experiments show that longer suspensions are more effective than shorter ones at reducing reoffense rate, the number of consequences, and the number of user reports. Further, they suggest that the effect of longer suspensions on reoffense rate wanes over time, but persists for at least 3 weeks. Finally, they demonstrate that longer suspensions are more effective for first-time violating users. These results have significant implications for theory around digitally-enforced punishments, understanding recidivism online, and the practical implementation of product changes and policy development around consequences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {840},
numpages = {12},
keywords = {consequences, suspensions, duration, user behavior, moderation, trust \&amp; safety, social media, gaming, field experiment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713803,
author = {Preussner, Adrian and Crescenza, Anna and Sch\"{o}ning, Johannes and Mathis, Florian},
title = {UrbAI: Exploring the Possibilities of Generative AI Image Processing to Promote Citizen Participation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713803},
doi = {10.1145/3706598.3713803},
abstract = {Giving citizens a voice in urban development processes is crucial for enabling socially sustainable cities and communities. However, citizens’ opportunities to express ideas are often limited to communication channels that offer poor incentives for participation. In this paper, we conducted an in-the-wild technology probe study (N=16) using a generative AI (GenAI) tool to allow citizens to visualise and submit urban development ideas by taking pictures and manipulating them with GenAI. The results highlight the potential of GenAI to empower, engage, and inspire citizens‘ creativity. We then conducted additional expert interviews (N=6) with city representatives and community associates. They voiced GenAI’s value in early-stage citizen participation but raised concerns about excluding senior citizens. Building on these insights, we present the design and evaluation (N=10) of UrbAI, a co-creative system tailored to urban development participation and conclude with lessons learned to inform how GenAI could be embedded in future citizen participation processes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {841},
numpages = {21},
keywords = {urban planning, citizen participation, civic engagement},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714184,
author = {Laato, Samuli and Siqueira, Sara and Baer, Manuel and Papangelis, Konstantinos and Kordyaka, Bastian and Nummenmaa, Timo and Hamari, Juho},
title = {User Motivations to Participate in Crowdsourcing and Contribute User-generated Content on Location-based Media: A Literature Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714184},
doi = {10.1145/3706598.3714184},
abstract = {Location-based media applications such as Google Maps, Strava and Pok\'{e}mon GO together have more than a billion monthly active users, and popular social media such as Snapchat and Instagram now also feature map-based content. All these media products rely on user-generated content as a core element of their service, but there is a lack of synthesis on the users’ motivations to contribute this data to the platform providers. In this study, we performed a literature review to uncover users’ motivations to participate in location-based crowdsourcing and contribute shared content on these platforms. Among our findings, we show that spatial and temporal aspects, social effects, technical elements, motivational mechanisms, practical value offered to the contributors and individual differences need to be considered in motivating users to contribute shared content. We present recommendations for designers, suggest which terminology to use around this topic and propose an agenda for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {842},
numpages = {20},
keywords = {Location-based media, locative media, geographical information systems, crowdsourcing, user-generated content, motivation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713763,
author = {Liao, Junxiang and Wei, Zheng and Yang, Zeyu and Xu, Xian and Hui, Pan and He, Changyang and Zhou, Muzhi},
title = {“Even When Success Seems Impossible, I Keep Streaming”: How Do Chinese Elderly Streamers Interact with Platform Algorithmic (In)visibility},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713763},
doi = {10.1145/3706598.3713763},
abstract = {Recent research within the HCI community has illuminated the challenges faced by marginalized groups on algorithm-driven livestreaming platforms. However, there is a notable gap in understanding how elderly livestreamers interact with the platform content moderation and algorithmic (in)visibility. This study investigates the perceptions of the algorithm-moderated (in)visibility and the coping strategies of 16 elderly streamers on Douyin. We find that, contrary to stereotypes of elderly users as digitally uninformed, these streamers actively engage with the platform to facilitate their understanding about platform algorithm. This engagement involves official guidance, peer learning, and personal experimentation. The streamers adopt various strategies to align with the perceived algorithmic preferences. Despite their rich knowledge about the platform’s visibility moderation, many elderly streamers face significant challenges, such as physical and psychological strain and low viewer traffic. We conclude with design implications for livestreaming platforms to foster fairness and promote engagement among elderly streamers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {843},
numpages = {15},
keywords = {livestreaming, elderly, algorithm, social media},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713314,
author = {Jung, Yugyeong and Law, Hei Yiu and Lee, Hadong and Lee, Junmo and Lee, Bongshin and Lee, Uichin},
title = {DataSentry: Building Missing Data Management System for In-the-Wild Mobile Sensor Data Collection through Multi-Year Iterative Design Approach},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713314},
doi = {10.1145/3706598.3713314},
abstract = {Mobile sensor data collection in people’s daily lives is essential for understanding fine-grained human behaviors. However, in-the-wild data collection often results in missing data due to participant and system-related issues. While existing monitoring systems in the mobile sensing field provide an opportunity to detect missing data, they fall short in monitoring data across many participants and sensors and diagnosing the root causes of missing data, accounting for heterogeneous sensing characteristics of mobile sensor data. To address these limitations, we undertook a multi-year iterative design process to develop a system for monitoring missing data in mobile sensor data collection. Our final prototype, DataSentry, enables the detection, diagnosis, and addressing of missing data issues across many participants and sensors, considering both within- and between-person variability. Based on the iterative design process, we share our experiences, lessons learned, and design implications for developing advanced missing data management systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {844},
numpages = {18},
keywords = {mobile data, data collection, visualization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713103,
author = {Sivaraman, Venkatesh and Li, Zexuan and Perer, Adam},
title = {Divisi: Interactive Search and Visualization for Scalable Exploratory Subgroup Analysis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713103},
doi = {10.1145/3706598.3713103},
abstract = {Analyzing data subgroups is a common data science task to build intuition about a dataset and identify areas to improve model performance. However, subgroup analysis is prohibitively difficult in datasets with many features, and existing tools limit unexpected discoveries by relying on user-defined or static subgroups. We propose exploratory subgroup analysis as a set of tasks in which practitioners discover, evaluate, and curate interesting subgroups to build understanding about datasets and models. To support these tasks we introduce Divisi, an interactive notebook-based tool underpinned by a fast approximate subgroup discovery algorithm. Divisi’s interface allows data scientists to interactively re-rank and refine subgroups and to visualize their overlap and coverage in the novel Subgroup Map. Through a think-aloud study with 13 practitioners, we find that Divisi can help uncover surprising patterns in data features and their interactions, and that it encourages more thorough exploration of subtypes in complex data.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {845},
numpages = {17},
keywords = {Exploratory Data Analysis, Model Evaluation, Slice Discovery, Subgroup Analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714069,
author = {Alvarado Garcia, Adriana and Candello, Heloisa and Badillo-Urquiola, Karla and Wong-Villacres, Marisol},
title = {Emerging Data Practices: Data Work in the Era of Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714069},
doi = {10.1145/3706598.3714069},
abstract = {Data is one of the foundational aspects of making Artificial Intelligence (AI) work as intended. As large language models (LLMs) become the epicenter of AI, it is crucial to understand better how the datasets that maintain such models are created. The emergent nature of LLMs makes it critical to understand the challenges practitioners developing Gen AI technologies face to design alternatives for better responding to Gen AI’s ethical issues. In this paper, we provide such understanding by reporting on 25 interviews with practitioners who handle data in three distinct development stages of different LLMs. Our contributions are (1) empirical evidence of how uncertainty, data practices, and reliance mechanisms change across LLMs’ development cycle; (2) how the unique qualities of LLMs impact data practices and their implications for the future of Gen AI technologies; and (3) provide three opportunities for HCI researchers interested in supporting practitioners developing Gen AI technologies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {846},
numpages = {21},
keywords = {data work, data practices, AI, LLMs, synthetic data, data governance, AI practitioners, GenAI, generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713491,
author = {Yeh, Catherine and Ren, Donghao and Assogba, Yannick and Moritz, Dominik and Hohman, Fred},
title = {Exploring Empty Spaces: Human-in-the-Loop Data Augmentation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713491},
doi = {10.1145/3706598.3713491},
abstract = {Data augmentation is crucial to make machine learning models more robust and safe. However, augmenting data can be challenging as it requires generating diverse data points to rigorously evaluate model behavior on edge cases and mitigate potential harms. Creating high-quality augmentations that cover these “unknown unknowns” is a time- and creativity-intensive task. In this work, we introduce Amplio, an interactive tool to help practitioners navigate “unknown unknowns” in unstructured text datasets and improve data diversity by systematically identifying empty data spaces to explore. Amplio includes three human-in-the-loop data augmentation techniques: Augment with Concepts, Augment by Interpolation, and Augment with Large Language Model. In a user study with 18 professional red teamers, we demonstrate the utility of our augmentation methods in helping generate high-quality, diverse, and relevant model safety prompts. We find that Amplio enabled red teamers to augment data quickly and creatively, highlighting the transformative potential of interactive augmentation workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {847},
numpages = {19},
keywords = {Human-in-the-loop data augmentation, interactive visualization, data diversity, sparse autoencoders, language models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3715269,
author = {Hesenius, Marc and Krvavac, Mak and Valbj\"{o}rnsson, Valbj\"{o}rn J\'{o}n and Theresia Mita Erika and Book, Matthias},
title = {How To Draw Commands? An Elicitation Study for Sketching on Spreadsheets},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3715269},
doi = {10.1145/3706598.3715269},
abstract = {Sketching is one of the oldest techniques humans use to express themselves. We sketch to visualize concepts, externalize memory, and communicate ideas. However, we barely use sketching to interact with computers. Given how naturally sketching comes to humans, we believe untapped potential exists in being able to simply draw commands onto a user interface. In this paper, we present results of an elicitation study about expressing common operations in spreadsheets through sketching. Spreadsheets are an interesting class of applications because they are widely used, support complex data and operations, and are available on touch-enabled devices. Our results show that despite considerable variation in syntactic details, participants gravitate towards recurring patterns (e.g., enclosures and arrows, examples and cross-references, and temporal sequences of strokes). The sketch patterns we identified can be a first step towards developing interpreters of sketched commands, and thus enable new means of interacting with spreadsheets and other applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {848},
numpages = {31},
keywords = {Spreadsheets, Sketching, Interaction Techniques, Pens, Touchscreens},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714321,
author = {Xiong, Kai and Huang, Cynthia A and Wybrow, Michael and Wu, Yingcai},
title = {TableCanoniser: Interactive Grammar-Powered Transformation of Messy, Non-Relational Tables to Canonical Tables},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714321},
doi = {10.1145/3706598.3714321},
abstract = {TableCanoniser is a declarative grammar and interactive system for constructing relational tables from messy tabular inputs such as spreadsheets. We propose the concept of axis alignment to categorise input types and characterise the expanded scope of our system relative to existing tools. The declarative grammar consists of match conditions, which specify repeating patterns of input cells, and extract operations, which specify how matched values map to the output table. In the interactive interface, users can specify match and extract patterns by interacting with an input table, or author more advanced specifications in the coding panel. To refine and verify specifications, users interact with grammar-based provenance visualisations such as linked highlighting of input and output values, tree-based visualisation of matching patterns, and a mini-map overview of matched instances of patterns with annotations showing where cells are extracted to. We motivate and illustrate our work with real-world usage scenarios and workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {849},
numpages = {20},
keywords = {data transformation, data provenance, table canonicalisation, table understanding, declarative grammar, interactive visualisation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714239,
author = {Zhou, Yunfan and Cai, Xiwen and Shi, Qiming and Huang, Yanwei and Li, Haotian and Qu, Huamin and Weng, Di and Wu, Yingcai},
title = {Xavier: Toward Better Coding Assistance in Authoring Tabular Data Wrangling Scripts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714239},
doi = {10.1145/3706598.3714239},
abstract = {Data analysts frequently employ code completion tools in writing custom scripts to tackle complex tabular data wrangling tasks. However, existing tools do not sufficiently link the data contexts such as schemas and values with the code being edited. This not only leads to poor code suggestions, but also frequent interruptions in coding processes as users need additional code to locate and understand relevant data. We introduce Xavier, a tool designed to enhance data wrangling script authoring in computational notebooks. Xavier maintains users’ awareness of data contexts while providing data-aware code suggestions. It automatically highlights the most relevant data based on the user’s code, integrates both code and data contexts for more accurate suggestions, and instantly previews data transformation results for easy verification. To evaluate the effectiveness and usability of Xavier, we conducted a user study with 16 data analysts, showing its potential to streamline data wrangling scripts authoring.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {850},
numpages = {16},
keywords = {Interactive data wrangling, coding assistance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713089,
author = {Yu, Difeng and Roberts, James and Hornb\ae{}k, Kasper and Bergstr\"{o}m, Joanna},
title = {Deriving Selection Techniques for GUIs based on the Multiple Process Model},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713089},
doi = {10.1145/3706598.3713089},
abstract = {Designing efficient selection techniques for graphical user interfaces (GUIs) is fundamental in HCI research. We derive selection techniques based on the multiple process model, a theory that details the motor control processes during goal-directed movements. Specifically, we deduce three theoretical assumptions on how control processes of pre-planning, impulse control, and limb-target control could influence selection movements when adjusting GUI elements, including visual feedback, cursor position, and target position. Corresponding to our assumptions, we develop three techniques that hide the cursor when a target is highlighted, snap the cursor when selection begins, and expand clustered objects during selection movements. After that, we pre-register the assumptions and research methodology and evaluate the techniques in three crowdsourcing-based pointing studies. Our results show that all techniques improved the selection efficiency compared to established baselines. We further discuss the design implications and reflect on how we derived techniques from theory.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {851},
numpages = {16},
keywords = {Cursor, input, object selection, pointing, target selection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714076,
author = {Kim, Seonho and Kim, Munjeong and Kim, Jonghyun and Kang, Donghyeon and Kim, Sunjun and Lee, Byungjoo},
title = {Hardware-Embedded Pointing Transfer Function Capable of Canceling OS Gains},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714076},
doi = {10.1145/3706598.3714076},
abstract = {When using indirect pointing devices in modern operating systems (OS), users’ perception of the pointing transfer function is easily influenced by the device’s hardware or OS-native transfer function settings. This could hinder users from finding and fully adapting to the transfer function that is optimal for them. We propose a novel hardware-embedded transfer function technique that is expected to allow users to consistently experience the desired function even when device hardware or OS settings change. The technique (1) allows users to define the desired function within the device firmware in physical units and (2) enables the firmware to cancel out the influence of OS-native functions and hardware setting perturbations, so that the uploaded function can persist regardless of the external environment. Through technical evaluation including transfer functions of various shapes, we showed that the proposed technique has comparable robustness and accuracy to the conventional approach.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {852},
numpages = {15},
keywords = {Esports, Pointing, Gain Function, Fitts’ Law},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713530,
author = {Kim, Jinwook and Park, Sangmin and Zhou, Qiushi and Gonzalez-Franco, Mar and Lee, Jeongmi and Pfeuffer, Ken},
title = {PinchCatcher: Enabling Multi-selection for Gaze+Pinch},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713530},
doi = {10.1145/3706598.3713530},
abstract = {This paper investigates multi-selection in XR interfaces based on eye and hand interaction. We propose enabling multi-selection using different variations of techniques that combine gaze with a semi-pinch gesture, allowing users to select multiple objects, while on the way to a full-pinch. While our exploration is based on the semi-pinch mode for activating a quasi-mode, we explore four methods for confirming subselections in multi-selection mode, varying in effort and complexity: dwell-time (SemiDwell), swipe (SemiSwipe), tilt (SemiTilt), and non-dominant hand input (SemiNDH), and compare them to a baseline technique. In the user study, we evaluate their effectiveness in reducing task completion time, errors, and effort. The results indicate the strengths and weaknesses of each technique, with SemiSwipe and SemiDwell as the most preferred methods by participants. We also demonstrate their utility in file managing and RTS gaming application scenarios. This study provides valuable insights to advance 3D input systems in XR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {853},
numpages = {16},
keywords = {Extended Reality, Selection, Grouping, Gaze, Gestures, Eye-Hand interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713442,
author = {Kim, Jina and Zhang, Yang and Yoon, Sang Ho},
title = {T2IRay: Design of Thumb-to-Index based Indirect Pointing for Continuous and Robust AR/VR Input},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713442},
doi = {10.1145/3706598.3713442},
abstract = {Free-hand interactions have been widely deployed for AR/VR interfaces to promote a natural and seamless interaction experience. Among various types of hand interactions, microgestures are still limited in supporting discrete inputs and in lacking a continuous interaction theme. To this end, we propose a new pointing technique, T2IRay, which enables continuous indirect pointing through microgestures for continuous spatial input. We employ our own local coordinate system based on the thumb-to-index finger relationship to map the computed raycasting direction for indirect pointing in a virtual environment. Furthermore, we examine various mapping methodologies and collect thumb-click behaviors to formulate thumb-to-index microgesture design guidelines to foster continuous, reliable input. We evaluate the design parameters for mapping indirect pointing with acceptable speed, depth, and range. We collect and analyze the characteristics of click behaviors for future implementation. Our research demonstrates the potential and practicality of free-hand micro-finger input methods for advancing future interaction paradigms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {854},
numpages = {16},
keywords = {AR/VR, Thumb-to-Index interaction, Interaction Technique, Microgestures},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713410,
author = {Jeong, Jae-Yeop and Jeong, Jin-Woo},
title = {Understanding User Behavior in Window Selection using Dragging for Multiple Targets},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713410},
doi = {10.1145/3706598.3713410},
abstract = {Window selection is a fundamental method in desktop environments for interacting with multiple targets, typically performed by successive operations like click-drag-release (i.e., a single sequence of dragging). Although this method is common in GUI interactions, there has been limited research to understand user behavior during window selection. This study explores user behavior and performance during window selection using dragging. We empirically studied the impact of several GUI parameters — including the size, interval, number, and layout of targets — on window selection for multiple targets. Based on well-established existing motor models, we analyzed user behavior in terms of time performance and derived a more suitable model. Additionally, our new prediction model effectively predicted time performance in partially constrained scenarios. This study provides new insights into user behavior during window selection for multiple targets. We hope that our research findings will assist GUI designers, practitioners, and researchers in testing their designs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {855},
numpages = {21},
keywords = {Window selection, dragging, graphical user interface, multi-target selection, human motor performance, behavior modeling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713761,
author = {Beattie, Cameron and Gutwin, Carl and Cockburn, Andy and Redekopp, Eric},
title = {Understanding and Improving the Performance of Action Pointing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713761},
doi = {10.1145/3706598.3713761},
abstract = {Action pointing involves choosing and executing an action at a specific place in the workspace (e.g., choosing a tool and clicking to start drawing, or selecting an object and copying with a shortcut). The elements of action pointing (choosing an action, specifying a position, and triggering the action) can be carried out in many ways – and our analysis of current techniques identified limitations on performance, particularly for repeated sequences of interactions. To empirically analyse interaction alternatives for action pointing, we developed and evaluated two techniques: ModeKeys removes modifier keys from keyboard shortcuts used to choose actions; AimKeys goes further by using the shortcut (not the mouse) to trigger the action. Three studies over three tasks showed that these reconfigurations were highly effective –- in all studies, either AimKeys or ModeKeys were faster, easier, and preferred overall. Our studies show that small variations in the configuration of action pointing can have a large impact, offering opportunities to improve performance with direct-manipulation systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {856},
numpages = {23},
keywords = {Action Pointing, Pointing Performance, Bimanual Interaction, Post-WIMP Interfaces},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713083,
author = {Krau\ss{}, Veronika and McGill, Mark and Kosch, Thomas and Thiel, Yolanda Maira and Sch\"{o}n, Dominik and Gugenheimer, Jan},
title = {"Create a Fear of Missing Out" - ChatGPT Implements Unsolicited Deceptive Designs in Generated Websites Without Warning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713083},
doi = {10.1145/3706598.3713083},
abstract = {With the recent advancements in Large Language Models (LLMs), web developers increasingly apply their code-generation capabilities to website design. However, since these models are trained on existing designerly knowledge, they may inadvertently replicate bad or even illegal practices, especially deceptive designs (DD). This paper examines whether users can accidentally create DD for a fictitious webshop using GPT-4. We recruited 20 participants, asking them to use ChatGPT to generate functionalities (product overview or checkout) and then modify these using neutral prompts to meet a business goal (e.g., “increase the likelihood of us selling our product”). We found that all 20 generated websites contained at least one DD pattern (mean: 5, max: 9), with GPT-4 providing no warnings. When reflecting on the designs, only 4 participants expressed concerns, while most considered the outcomes satisfactory and not morally problematic, despite the potential ethical and legal implications for end-users and those adopting ChatGPT’s recommendations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {857},
numpages = {20},
keywords = {ChatGPT, LLM, Deceptive Design, Dark Patterns, Design Inspiration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713648,
author = {Nouwens, Midas and Kristensen, Janus Bager and Maalt, Kristjan and Bagge, Rolf},
title = {A Cross-Country Analysis of GDPR Cookie Banners and Flexible Methods For Scraping Them},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713648},
doi = {10.1145/3706598.3713648},
abstract = {Online tracking remains problematic, with compliance and ethical issues persisting despite regulatory efforts. Consent interfaces, the visible manifestation of this industry, have seen significant attention over the years. We present robust automated methods to study the presence, design, and third-party suppliers of consent interfaces at scale and the web service consent-observatory.eu to do it with. We examine the top 10,000 websites across 31 countries under the ePrivacy Directive and GDPR (n=254.148). Our findings show that 67\% of websites use consent interfaces, but only 15\% are minimally compliant, mostly because they lack a reject option. Consent management platforms (CMPs) are powerful intermediaries in this space: 67\% of interfaces are provided by CMPs, and three organisations hold 37\% of the market. There is little evidence that regulators’ guidance and fines have impacted compliance rates, but 18\% of compliance variance is explained by CMPs. Researchers should take an infrastructural perspective on online tracking and study the factual control of intermediaries to identify effective leverage points.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {858},
numpages = {28},
keywords = {Cookie, Banner, Consent Management Platform, Online Tracking, GDPR, e-Privacy Directive, Web scraping},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713779,
author = {Zhuang, Zhuoli and Lu, Cheng-You and Chang, Yu-Cheng Fred and Wang, Yu-Kai and Do, Thomas and Lin, Chin-Teng},
title = {AEGIS: Human Attention-based Explainable Guidance for Intelligent Vehicle Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713779},
doi = {10.1145/3706598.3713779},
abstract = {Improving decision-making capabilities in Autonomous Intelligent Vehicles (AIVs) has been a heated topic in recent years. Despite advancements, training machine to capture regions of interest for comprehensive scene understanding, like human perception and reasoning, remains a significant challenge. This study introduces a novel framework, Human Attention-based Explainable Guidance for Intelligent Vehicle Systems (AEGIS1). AEGIS uses a pre-trained human attention model to guide reinforcement learning (RL) models to identify critical regions of interest for decision-making. By collecting 1.2 million frames from 20 participants across six scenarios, AEGIS pre-trains a model to predict human attention patterns. The learned human attention2 guides the RL agent’s focus on task-relevant objects, prioritizes critical instances, enhances robustness in unseen environments, and leads to faster learning convergence. This approach enhances interpretability by making machine attention more comparable to human attention and thus enhancing the RL agent’s performance in diverse driving scenarios. The code is available in The code and data processing script is available in https://github.com/ALEX95GOGO/AEGIS.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {859},
numpages = {19},
keywords = {Eye-tracking, Virtual reality, Human-centered computing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713308,
author = {Theys, Tim and Van Hove, Stephanie and Mechant, Peter and Van Impe, Gill and Heerinckx, Alexander and Saldien, Jelle},
title = {Exploring Users' Perspectives on a Solid-Enabled Personal Data Store Enhanced Streaming Service},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713308},
doi = {10.1145/3706598.3713308},
abstract = {This study explores users’ perceptions of integrating a personal data store to enhance personalized recommendations within a streaming service. Using a research-through-design approach and guided by Human Data Interaction principles (legibility, agency, and negotiability), we developed an enhanced streaming service prototype. This prototype was evaluated by experts (n=5), refined, and then used in two focus groups (n=19) to gauge participants’ reactions to the personal data store integration and their willingness to share different data types for enhanced personalized streaming recommendations. The focus groups revealed mixed reactions to the personal data store, with users weighing curiosity against concerns. However, many of the implemented data transparency and control features helped to mitigate these doubts. By linking our findings to existing literature, we developed a set of design recommendations to help businesses and guide future research in building personal data store applications, further advancing the field of Human Data Interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {860},
numpages = {22},
keywords = {Personal Data Stores, Solid, Streaming Services, Personalized Recommendations, Human Data Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713897,
author = {Kadoma, Kowe and Metaxa, Dana\'{e} and Naaman, Mor},
title = {Generative AI and Perceptual Harms: Who's Suspected of using LLMs?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713897},
doi = {10.1145/3706598.3713897},
abstract = {Large language models (LLMs) are increasingly integrated into a variety of writing tasks. While these tools can help people by generating ideas or producing higher quality work, like many other AI tools, they may risk causing a variety of harms, potentially disproportionately burdening historically marginalized groups. In this work, we introduce and evaluate perceptual harms, a term for the harms caused to users when others perceive or suspect them of using AI. We examined perceptual harms in three online experiments, each of which entailed participants evaluating write-ups from mock freelance writers. We asked participants to state whether they suspected the freelancers of using AI, to rank the quality of their writing, and to evaluate whether they should be hired. We found some support for perceptual harms against certain demographic groups. At the same time, perceptions of AI use negatively impacted writing evaluations and hiring outcomes across the board.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {861},
numpages = {17},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713318,
author = {Alsos, Ole Andreas and Saghafian, Mina and Veitch, Erik and Sitompul, Taufik Akbar and Petermann, Felix and Papachristos, Eleftherios},
title = {Mind the Kayak! Informing UX Design of Autonomous Vehicles through Edge Case Testing in the Field},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713318},
doi = {10.1145/3706598.3713318},
abstract = {As autonomous vehicles are being deployed in the field for public use, passengers are interacting with traffic in new ways. In recent years, user experience related to risky traffic interactions has been studied using virtual simulations, desktop studies, and surveys—yet field tests have remained out of reach. In this paper, we present results from a field test of an autonomous urban passenger ferry open to public use. Specifically, we investigate two questions: (i) are passengers’ safety perceptions negatively affected by interactions with risky traffic? and (ii) can simulating risky behavior in the field (so-called "adversarial evaluation") present a viable way to study user experience? After repeatedly sending a kayaker on a collision course with the ferry (N&nbsp;=&nbsp;20 interventions), we sampled na\"{\i}ve passengers about their experiences (intervention group; N&nbsp;=&nbsp;37) and compared the result to those who experienced a normal crossing (control group, N&nbsp;=&nbsp;178). The results favored the intervention group, which scored higher in safety perception. However, the latter also reported that there is a need for more feedback about the ferry’s current state and future intentions to avoid surprises both for passengers and for other traffic. As autonomous vehicles are field-tested and deployed, the study reflects a growing need to test user experience in the operational environment. We discuss implications for design, emphasizing the use of external human-machine interfaces (eHMIs) and special considerations for the maritime domain.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {862},
numpages = {12},
keywords = {Autonomous vehicles, Autonomous ferry, Automation transparency, Field tests, Public Perception, Safety, Passengers},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713768,
author = {Bauske, Adrian and Fleig, Arthur},
title = {You Shall Not Pass: Warning Drivers of Unsafe Overtaking Maneuvers on Country Roads by Predicting Safe Sight Distance},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713768},
doi = {10.1145/3706598.3713768},
abstract = {Overtaking on country roads with possible opposing traffic is a dangerous maneuver and many proposed assistant systems assume car-to-car communication and sensors currently unavailable in cars. To overcome this limitation, we develop an assistant that uses simple in-car sensors to predict the required sight distance for safe overtaking. Our models predict this from vehicle speeds, accelerations, and 3D map data. In a user study with a Virtual Reality driving simulator (N=25), we compare two UI variants (monitoring-focused vs scheduling-focused). The results reveal that both UIs enable more patient driving and thus increase overall driving safety. While the monitoring-focused UI achieves higher System Usability Score and distracts drivers less, the preferred UI depends on personal preference. Driving data shows predictions were off at times. We investigate and discuss this in a comparison of our models to actual driving behavior and identify crucial model parameters and assumptions that significantly improve model predictions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {863},
numpages = {23},
keywords = {driving assistant, automotive, human-machine interaction, study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714137,
author = {Deng, Yue and He, Changyang and Zou, Yixin and Li, Bo},
title = {"Auntie, Please Don't Fall for Those Smooth Talkers": How Chinese Younger Family Members Safeguard Seniors from Online Fraud},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714137},
doi = {10.1145/3706598.3714137},
abstract = {Online fraud substantially harms individuals and seniors are disproportionately targeted. While family is crucial for seniors, little research has empirically examined how they protect seniors against fraud. To address this gap, we employed an inductive thematic analysis of 124 posts and 16,872 comments on RedNote (Xiaohongshu), exploring the family support ecosystem for senior-targeted online fraud in China. We develop a taxonomy of senior-targeted online fraud from a familial perspective, revealing younger members often spot frauds hard for seniors to detect, such as unusual charges. Younger family members fulfill multiple safeguarding roles, including preventative measures, fraud identification, fraud persuasion, loss recovery, and education. They also encounter numerous challenges, such as seniors’ refusal of help and considerable mental and financial stress. Drawing on these, we develop a conceptual framework to characterize family support in senior-targeted fraud, and outline implications for researchers and practitioners to consider the broader stakeholder ecosystem and cultural aspects.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {864},
numpages = {17},
keywords = {older adults, online fraud, family support, anti-fraud, RedNote},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713652,
author = {Yamagishi, Rei and Fujii, Shota and Yasuda, Shingo and Sato, Takayuki and Hasegawa, Ayako A.},
title = {Collaborative Work in Malware Analysis: Understanding the Roles and Challenges of Malware Analysts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713652},
doi = {10.1145/3706598.3713652},
abstract = {Malware analysis provides useful information for defending organizations against the growing number of cyberattacks. To leverage such information to enhance security, malware analysts are expected to collaborate with members of their own and other teams. However, there has been insufficient research into their actual collaboration and communication. Furthermore, given that challenges in their communication can lead to critical errors, it is imperative to understand and mitigate these challenges. We interviewed 15 malware analysts to explore their roles, collaborators, and communication means and challenges. We found that the roles within malware analysis teams are diverse and identified the roles and collaborations in which analysts leverage malware analysis knowledge effectively. We also identified several key communication challenges, including difficulties in aligning understanding in collaborative analysis and low motivation for information sharing. On the basis of our findings, we provide recommendations to address each communication challenge.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {865},
numpages = {15},
keywords = {malware analysts, communication challenges, security operations, security experts},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713257,
author = {Liu, Lanjing and Yao, Yaxing},
title = {From Knowledge to Practice: Co-Designing Privacy Controls with Children},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713257},
doi = {10.1145/3706598.3713257},
abstract = {Children born in the digital era are facing increasing privacy risks and the need to control privacy in various contexts, suggesting an urgent need to enhance their privacy literacy. While previous research focuses on developing children’s privacy literacy by delivering privacy knowledge, it remains unclear how children process the knowledge and apply it in various privacy situations. Furthermore, children’s desire for privacy controls remains understudied. To fill the gap, we conducted two five-day co-design workshops with 11 children (ages 6-11). We uncovered children’s sophisticated expectations of everyday privacy management, such as staying aware of their privacy situations, strong authentication methods, and minimal privacy exposure. We further discovered that children translated their privacy knowledge to privacy practices through an iterative reflection and action process. We discussed key considerations to support children’s privacy literacy development by leveraging this process and offered implications for children-friendly privacy design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {866},
numpages = {22},
keywords = {Privacy, Co-design, Children, Privacy Controls},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713251,
author = {Ul Haque, Ehsan and Khan, Mohammad Maifi Hasan},
title = {Investigating Users' Decision-making for Data Privacy Controls in the Context of Internet of Things (IoT) Devices Using an Incentive-compatible Lottery Study},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713251},
doi = {10.1145/3706598.3713251},
abstract = {While companies are increasingly moving towards the ‘pay for privacy’ model, it is unclear how consumers make privacy decisions under this model. Toward that, we conducted an incentive-compatible lottery study on Prolific to understand the factors behind users’ choice to have additional data privacy controls. With 265 United States participants across two device risk conditions (High-risk: camera vs. Low-risk: light bulb) and three cash conditions ($9.99 vs. $19.99 vs. $29.99), results reveal that device risk and cash offerings influence participants’ lottery choice. We further observed an interaction effect between participants’ technical literacy and cash option. Specifically, technical participants chose the data privacy controls instead of cash at a higher rate when the cash condition was $29.99. In contrast, less technical participants favored the privacy option at a higher rate when the cash condition was $9.99. Implications of our findings for user data privacy are discussed in the paper.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {867},
numpages = {22},
keywords = {Privacy, Internet of things, Incentive-compatibility, Willingness to pay for privacy, Premium data privacy controls, IoT device risk perceptions, Monetary trade-off, Technical literacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713283,
author = {Mukhopadhyay, Anirban and Luther, Kurt},
title = {OSINT Clinic: Co-designing AI-Augmented Collaborative OSINT Investigations for Vulnerability Assessment},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713283},
doi = {10.1145/3706598.3713283},
abstract = {Small businesses need vulnerability assessments to identify and mitigate cyber risks. Cybersecurity clinics provide a solution by offering students hands-on experience while delivering free vulnerability assessments to local organizations. To scale this model, we propose an Open Source Intelligence (OSINT) clinic where students conduct assessments using only publicly available data. We enhance the quality of investigations in the OSINT clinic by addressing the technical and collaborative challenges. Over the duration of the 2023-24 academic year, we conducted a three-phase co-design study with six students. Our study identified key challenges in the OSINT investigations and explored how generative AI could address these performance gaps. We developed design ideas for effective AI integration based on the use of AI probes and collaboration platform features. A pilot with three small businesses highlighted both the practical benefits of AI in streamlining investigations, and limitations, including privacy concerns and difficulty in monitoring progress.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {868},
numpages = {22},
keywords = {OSINT, Cybersecurity Vulnerability Assessment, Co-Design, Matchmaking, Generative AI, Collaborative AI Platform},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713798,
author = {Huang, Yue and Grobler, Marthie and Ferro, Lauren S. and Psaroulis, Georgia and Das, Sanchari and Wei, Jing and Janicke, Helge},
title = {Systemization of Knowledge (SoK): Goals, Coverage, and Evaluation in Cybersecurity and Privacy Games},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713798},
doi = {10.1145/3706598.3713798},
abstract = {This paper systematized existing knowledge on cybersecurity and privacy game-based approaches, exploring their goals, scope, and evaluation methods. Our review of 93 academic papers revealed that these approaches serve multiple purposes and target diverse player types. We identified 11 key aspects of cybersecurity and privacy that these approaches addressed, such as threats, defensive strategies, and data privacy. Additionally, we analyzed the effectiveness evaluation methods of these approaches, emphasizing the connections between evaluation techniques, types of data used, and their alignment with the approaches’ goals. We also summarized the aspects of user experience evaluated in the literature and the types of questions used to capture these experiences. Reflecting on these methods, we provide guidance for future research and practice in designing and evaluating game-based approaches. Finally, we identify key gaps and propose opportunities to enhance user understanding, foster adaptability, and address emerging cybersecurity and privacy challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {869},
numpages = {27},
keywords = {Cybersecurity, Privacy, Gamification, Game-based Learning, Literature Review.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713711,
author = {Wu, Y. Kelly and Sohrawardi, Saniat Javid and Gerstner, Candice R. and Wright, Matthew},
title = {Understanding and Empowering Intelligence Analysts: User-Centered Design for Deepfake Detection Tools},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713711},
doi = {10.1145/3706598.3713711},
abstract = {Intelligence analysts must quickly and accurately examine and report on information in multiple modalities, including video, audio, and images. With the rise of Generative AI and deepfakes, analysts face unprecedented challenges, and require effective, reliable, and explainable media detection and analysis tools. This work explores analysts’ requirements for deepfake detection tools and explainability features. From a study of 30 practitioners from the United States Intelligence Community, we identified the need for a comprehensive and explainable solution that incorporates a wide variety of methods and supports the production of intelligence reports. In response, we propose a design for an analyst-centered tool, and introduce a digital media forensics ontology to support analysts’ interactions with the tool and understanding of its results. We conducted a study grounded in work-related tasks as an initial evaluation of this approach, and report on its potential to assist analysts and areas for improvement in future work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {870},
numpages = {26},
keywords = {Deepfake, Intelligence Community, Qualitative Studies, Ontology, Explainability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713630,
author = {Katcher, Samantha and Mattei, James and Chandler, Jared and Votipka, Daniel},
title = {An Investigation of Interaction and Information Needs for Protocol Reverse Engineering Automation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713630},
doi = {10.1145/3706598.3713630},
abstract = {Protocol reverse engineering (ProtocolREing) consists of taking streams of network data and inferring the communication protocol. ProtocolREing is critical task in malware and system security analysis. Several ProtocolREing automation tools have been developed, however, in practice, they are not used because they offer limited interaction. Instead, reverse engineers (ProtocolREs) perform this task manually or use less complex visualization tools. To give ProtocolREs the power of more complex automation, we must first understand ProtocolREs processes and information and interaction needs to design better interfaces.We interviewed 16 ProtocolREs, presenting a paper prototype ProtocolREing automation interface, and ask them to discuss their approach to ProtocolREing while using the tool and suggest missing information and interactions. We designed our prototype based on existing ProtocolREing tool features and prior reverse engineering research’s usability guidelines. We found ProtocolREs follow a flexible, hypothesis-driven process and identified multiple information and interaction needs when validating the automation’s inferences. We provide suggestions for future interaction design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {871},
numpages = {21},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713822,
author = {Yen, Ryan and Zhao, Jian and Vogel, Daniel},
title = {Code Shaping: Iterative Code Editing with Free-form AI-Interpreted Sketching},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713822},
doi = {10.1145/3706598.3713822},
abstract = {We introduce the concept of code shaping, an interaction paradigm for editing code using free-form sketch annotations directly on top of the code and console output. To evaluate this concept, we conducted a three-stage design study with 18 different programmers to investigate how sketches can communicate intended code edits to an AI model for interpretation and execution. The results show how different sketches are used, the strategies programmers employ during iterative interactions with AI interpretations, and interaction design principles that support the reconciliation between the code editor and sketches. Finally, we demonstrate the practical application of the code shaping concept with two use case scenarios, illustrating design implications from the study.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {872},
numpages = {17},
keywords = {Ink-based Sketching, Dynamic Abstraction, Programming Interface},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714115,
author = {Ma, Jenny GuangZhen and Sreedhar, Karthik and Liu, Vivian and Perez, Pedro A. and Wang, Sitong and Sahni, Riya and Chilton, Lydia B},
title = {DynEx: Dynamic Code Synthesis with Structured Design Exploration for Accelerated Exploratory Programming},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714115},
doi = {10.1145/3706598.3714115},
abstract = {Recent advancements in large language models have significantly expedited the process of generating front-end code. This allows users to rapidly prototype user interfaces and ideate through code, a process known as exploratory programming. However, existing LLM code generation tools focus more on technical implementation details rather than finding the right design given a particular problem. We present DynEx, an LLM-based method for design exploration in accelerated exploratory programming. DynEx introduces a technique to explore the design space through a structured Design Matrix before creating the prototype with a modular, stepwise approach to LLM code generation. Code is generated sequentially, and users can test and approve each step before moving onto the next. A user study of 10 experts found that DynEx increased design exploration and enabled the creation of more complex and varied prototypes compared to a Claude Artifact baseline. We conclude with a discussion of the implications of design exploration for exploratory programming.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {873},
numpages = {27},
keywords = {code synthesis, exploratory programming, design exploration, design matrix, user interface, prototyping},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714027,
author = {Peng, Xiaohan and Koch, Janin and Mackay, Wendy E.},
title = {FusAIn: Composing Generative AI Visual Prompts Using Pen-based Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714027},
doi = {10.1145/3706598.3714027},
abstract = {Although current generative AI (GenAI) enables designers to create novel images, its focus on text-based and whole-image interaction limits expressive engagement with visual materials. Based on the design concept of deconstruction and reconstruction of digital visual attributes for visual prompts, we present FusAIn, a GenAI prompt composition tool that lets designers create personalized pens by loading them with objects or attributes such as color or texture. GenAI then fuses the pen’s contents to create new images. Extracting and reusing inspirational material matches designers’ existing work practices, making GenAI more contextualized for professional design. A study with 12 designers shows how FusAIn improves their ability to define visual details at different levels that are difficult to express with current GenAI prompts. Pen-based interaction lets them maintain fine-grained control over generated results, increasing GenAI image’s editability and reusability. We discuss the benefits of “composition as prompts” and directions for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {874},
numpages = {20},
keywords = {Creativity Support Tools, Human-AI Interaction, Design Practice, Machine Learning, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713271,
author = {Pickering, Madison and Williams, Helena and Gan, Alison and He, Weijia and Park, Hyojae and Piedrahita Velez, Francisco and Littman, Michael L. and Ur, Blase},
title = {How Humans Communicate Programming Tasks in Natural Language and Implications For End-User Programming with LLMs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713271},
doi = {10.1145/3706598.3713271},
abstract = {Large language models (LLMs) like GPT-4 can convert natural-language descriptions of a task into computer code, making them a promising interface for end-user programming. We undertake a systematic analysis of how people with and without programming experience describe information-processing tasks (IPTs) in natural language, focusing on the characteristics of successful communication. Across two online between-subjects studies, we paired crowdworkers either with one another or with an LLM, asking senders (always humans) to communicate IPTs in natural language to their receiver (either a human or LLM). Both senders and receivers tried to answer test cases, the latter based on their sender’s description. While participants with programming experience tended to communicate IPTs more successfully than non-programmers, this advantage was not overwhelming. Furthermore, a user interface that solicited example test cases from senders often, but not always, improved IPT communication. Allowing receivers to request clarification, though, was less successful at improving communication.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {875},
numpages = {34},
keywords = {Large Language Models, LLMs, End-User Programming},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713668,
author = {O'Brien, Gabrielle},
title = {How Scientists Use Large Language Models to Program},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713668},
doi = {10.1145/3706598.3713668},
abstract = {Scientists across disciplines write code for critical activities like data collection and generation, statistical modeling, and visualization. As large language models that can generate code have become widely available, scientists may increasingly use these models during research software development. We investigate the characteristics of scientists who are early-adopters of code generating models and conduct interviews with scientists at a public, research-focused university. Through interviews and reviews of user interaction logs, we see that scientists often use code generating models as an information retrieval tool for navigating unfamiliar programming languages and libraries. We present findings about their verification strategies and discuss potential vulnerabilities that may emerge from code generation practices unknowingly influencing the parameters of scientific analyses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {876},
numpages = {16},
keywords = {Code assistant, Copilot, generative AI, program synthesis, data science, data analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713905,
author = {Zhou, Zhongyi and Jin, Jing and Phadnis, Vrushank and Yuan, Xiuxiu and Jiang, Jun and Qian, Xun and Wright, Kristen and Sherwood, Mark and Mayes, Jason and Zhou, Jingtao and Huang, Yiyi and Xu, Zheng and Zhang, Yinda and Lee, Johnny and Olwal, Alex and Kim, David and Iyengar, Ram and Li, Na and Du, Ruofei},
title = {InstructPipe: Generating Visual Blocks Pipelines with Human Instructions and LLMs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713905},
doi = {10.1145/3706598.3713905},
abstract = {Visual programming has the potential of providing novice programmers with a low-code experience to build customized processing pipelines. Existing systems typically require users to build pipelines from scratch, implying that novice users are expected to set up and link appropriate nodes from a blank workspace. In this paper, we introduce InstructPipe, an AI assistant for prototyping machine learning (ML) pipelines with text instructions. We contribute two large language model (LLM) modules and a code interpreter as part of our framework. The LLM modules generate pseudocode for a target pipeline, and the interpreter renders the pipeline in the node-graph editor for further human-AI collaboration. Both technical and user evaluation (N=16) shows that InstructPipe empowers users to streamline their ML pipeline workflow, reduce their learning curve, and leverage open-ended commands to spark innovative ideas.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {877},
numpages = {22},
keywords = {Visual Programming; Large Language Models; Visual Prototyping; Node-graph Editor; Graph Compiler; Low-code Development; Deep Neural Networks; Deep Learning; Visual Analytics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713234,
author = {Andrao, Margherita and Gini, Federica and Greco, Francesco and Cappelletti, Alessandro and Desolda, Giuseppe and Treccani, Barbara and Zancanaro, Massimo},
title = {"React", "Command", or "Instruct"? Teachers Mental Models on End-User Development},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713234},
doi = {10.1145/3706598.3713234},
abstract = {This paper presents findings from a thinking-aloud protocol exploring mental models in 28 elementary school math teachers during their initial attempt at composing and testing trigger-action rules for a smart tangible educational device. In the study, two sets of event-driven primitives were implemented in an End-User Development platform for guiding teachers with no programming experience in defining new functions of the device: "concrete", based on actual actions performed on the device, and "abstract", based on general definitions of events/actions. With a thematic analysis, we identified three different metaphors that drive participants’ interaction with the device. We discuss how the metaphors influenced performance and how the order of exposition to the two primitive sets impacted their grasping of the trigger-action logic. Our findings suggest the importance of guiding teachers in assuming effective metaphors for performing End-User Development tasks, to empower them to adopt an active role toward digital devices in education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {878},
numpages = {15},
keywords = {Mental Models, End-User Development, Educational Technology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713932,
author = {Kretzer, Felix and Kolthoff, Kristian and Bartelt, Christian and Ponzetto, Simone Paolo and Maedche, Alexander},
title = {Closing the Loop between User Stories and GUI Prototypes: An LLM-Based Assistant for Cross-Functional Integration in Software Development},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713932},
doi = {10.1145/3706598.3713932},
abstract = {Graphical user interfaces (GUIs) are at the heart of almost every software we encounter. GUIs are often created through a collaborative effort involving UX designers, product owners, and software developers, constantly facing changing requirements. Historically, problems in GUI development include a fragmented, poorly integrated tool landscape and high synchronization efforts between stakeholders. Recent approaches suggest using large language models (LLMs) to recognize requirements fulfillment in GUIs and automatically propose new GUI components. Based on ten interviews with practitioners, this paper proposes an LLM-based assistant as a Figma plug-in that bridges the gap between user stories and GUI prototyping. We evaluated the prototype with 40 users and 40 crowd-workers, showing that the effectiveness of GUI creation is improved by using LLMs to detect requirements’ completion and generate new GUI components. We derive design rationales to support cross-functional integration in software development, ensuring that our plug-in integrates well into established processes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {879},
numpages = {19},
keywords = {GUI Prototypes; User Stories; Requirements; Assistance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713431,
author = {Khurana, Anjali and Su, Xiaotian and Wang, April Yi and Chilana, Parmit K},
title = {Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713431},
doi = {10.1145/3706598.3713431},
abstract = {Large Language Model (LLM)-based in-application assistants, or copilots, can automate software tasks, but users often prefer learning by doing, raising questions about the optimal level of automation for an effective user experience. We investigated two automation paradigms by designing and implementing a fully automated copilot (AutoCopilot) and a semi-automated copilot (GuidedCopilot) that automates trivial steps while offering step-by-step visual guidance. In a user study (N=20) across data analysis and visual design tasks, GuidedCopilot outperformed AutoCopilot in user control, software utility, and learnability, especially for exploratory and creative tasks, while AutoCopilot saved time for simpler visual tasks. A follow-up design exploration (N=10) enhanced GuidedCopilot with task-and state-aware features, including in-context preview clips and adaptive instructions. Our findings highlight the critical role of user control and tailored guidance in designing the next generation of copilots that enhance productivity, support diverse skill levels, and foster deeper software engagement.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {880},
numpages = {18},
keywords = {feature-rich software; large language models; software copilots; user control; semi-automation; human-AI collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714002,
author = {Chen, Valerie and Zhu, Alan and Zhao, Sebastian and Mozannar, Hussein and Sontag, David and Talwalkar, Ameet},
title = {Need Help? Designing Proactive AI Assistants for Programming},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714002},
doi = {10.1145/3706598.3714002},
abstract = {While current chat-based AI assistants primarily operate reactively, responding only when prompted by users, there is significant potential for these systems to proactively assist in tasks without explicit invocation, enabling a mixed-initiative interaction. This work explores the design and implementation of proactive AI assistants powered by large language models. We first outline the key design considerations for building effective proactive assistants. As a case study, we propose a proactive chat-based programming assistant that automatically provides suggestions and facilitates their integration into the programmer’s code. The programming context provides a shared workspace enabling the assistant to offer more relevant suggestions. We conducted a randomized experimental study examining the impact of various design elements of the proactive assistant on programmer productivity and user experience. Our findings reveal significant benefits of incorporating proactive chat assistants into coding environments, while also uncovering important nuances that influence their usage and effectiveness.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {881},
numpages = {18},
keywords = {AI-assisted Programming, Proactivity, Mixed-Initiative Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713166,
author = {Subramonyam, Hari and Thakkar, Divy and Ku, Andrew and Dieber, Juergen and Sinha, Anoop K.},
title = {Prototyping with Prompts: Emerging Approaches and Challenges in Generative AI Design for Collaborative Software Teams},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713166},
doi = {10.1145/3706598.3713166},
abstract = {Generative AI models are increasingly being integrated into human task workflows, enabling the production of expressive content across a wide range of contexts. Unlike traditional human-AI design methods, the new approach to designing generative capabilities focuses heavily on prompt engineering strategies. This shift requires a deeper understanding of how collaborative software teams establish and apply design guidelines, iteratively prototype prompts, and evaluate them to achieve specific outcomes. To explore these dynamics, we conducted design studies with 39 industry professionals, including UX designers, AI engineers, and product managers. Our findings highlight emerging practices and role shifts in AI system prototyping among multistakeholder teams. We observe various prompting and prototyping strategies, highlighting the pivotal role of to-be-generated content characteristics in enabling rapid, iterative prototyping with generative AI. By identifying associated challenges, such as the limited model interpretability and overfitting the design to specific example content, we outline considerations for generative AI prototyping.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {882},
numpages = {22},
keywords = {Generative AI, Prompt Engineering, Human-Centered AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713723,
author = {Hayatpur, Devamardeep and Hempel, Brian and Lin, Richard and Xia, Haijun},
title = {The Shapes of Abstraction in Data Structure Diagrams},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713723},
doi = {10.1145/3706598.3713723},
abstract = {Tools to inspect runtime state, like print statements and debuggers, are an essential part of programming. Yet, a major limitation is that they present data at a fixed, low level of abstraction which can overload the user with irrelevant details. In contrast, human drawings of data structures use many illustrative visual abstractions to show the most useful information. We attempt to bridge the gap by surveying 80 programmer-produced diagrams to develop a mechanical approach for capturing visual abstraction, termed abstraction moves. An abstraction move selects data objects of interest, and then revisualizes, simplifies, or annotates them. We implement these moves as a diagramming language for JavaScript code, named Chisel, and show that it can effectively reproduce 78 out of the 80 surveyed diagrams. In a preliminary study with four CS educators, we evaluate its usage and discover potential contexts of use. Our approach of mechanically moving between levels of abstraction in data displays opens the doors to new tools and workflows in programming education and software development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {883},
numpages = {12},
keywords = {programming, abstraction, graphical representations},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713621,
author = {Lakier, Matthew and Irwin, Andrew and Vogel, Daniel},
title = {Understanding Marine Scientist Software Tool Use},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713621},
doi = {10.1145/3706598.3713621},
abstract = {Marine science researchers are heavy users of software tools and systems such as statistics packages, visualization tools, and online data catalogues. Following a constructivist grounded theory approach, we conduct a semi-structured interview study of 23 marine science researchers and research supports within a North American university, to understand their perceptions of and approaches towards using both graphical and code-based software tools and systems. We propose the concept of fragmentation to represent how various factors lead to isolated pockets of views and practices concerning software tool use during the research process. These factors include informal learning of tools, preferences towards doing things from scratch, and a push towards more code-based tools. Based on our findings, we suggest design priorities for user interfaces that could more effectively help support marine scientists make and use software tools and systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {884},
numpages = {14},
keywords = {data work, data-centric science, oceanography},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713198,
author = {G\"{o}r\"{u}c\"{u}, Sinem and Morais, Luiz A. and Panagiotidou, Georgia},
title = {A Critical Analysis of Machine Learning Eco-feedback Tools through the Lens of Sustainable HCI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713198},
doi = {10.1145/3706598.3713198},
abstract = {In light of machine learning’s increasing computational needs, developers created energy and carbon-reporting tools to calculate and communicate their models’ environmental impact. These tools use modeling parameters as inputs and respond with expected or incurred energy requirements or carbon emissions. This work critically and systematically analyses them regarding their content, form, and design process. Besides their noble intentions, many of the shortcomings of early sustainable HCI eco-feedback tools are still being propagated in these tools. Moreover, their design and development have limited inclusion of potential stakeholders. We argue the need for a next generation of approaches to ML eco-feedback that (a) further support rematerialization, (b) use participatory approaches in their design and development to support collaborative team environments and go beyond individual persuasion, (c) consider complexities of ML models and processes, and more broadly, (d) re-center around sufficiency rather than only efficiency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {885},
numpages = {18},
keywords = {eco-feedback, sustainable HCI, green AI, carbon reporting, materiality of machine learning},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713665,
author = {Yan, Zeyu and Dhaygude, Mrunal Sanjay and Peng, Huaishu},
title = {Make Making Sustainable: Exploring Sustainability Practices, Challenges, and Opportunities in Making Activities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713665},
doi = {10.1145/3706598.3713665},
abstract = {The recent democratization of personal fabrication has significantly advanced the maker movement and reshaped applied research in HCI and beyond. However, this growth has also raised increasing sustainability concerns, as material waste is an inevitable byproduct of making and rapid prototyping. In this work, we examine the sustainability landscape within the modern maker community, focusing on grassroots makerspaces and maker-oriented research labs through in-depth interviews with diverse stakeholders involved in making and managing making-related activities. Our findings highlight four key themes: the various types of “waste” generated through the making process, the strategies (or lack thereof) for managing this waste, the motivations driving (un)sustainable practices, and the challenges faced. We synthesize these insights into design considerations and takeaways for technical HCI researchers and the broader community, focusing on future tools, infrastructures, and educational approaches to foster sustainable making.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {886},
numpages = {14},
keywords = {maker, material, fabrication, sustainability, reuse, unmaking, obsolescence, waste.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714276,
author = {Yan, Zeyu and Vartak, Advait and Li, Jiasheng and Zhang, Zining and Peng, Huaishu},
title = {PCB Renewal: Iterative Reuse of PCB Substrates for Sustainable Electronic Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714276},
doi = {10.1145/3706598.3714276},
abstract = {PCB (printed circuit board) substrates are often single-use, leading to material waste in electronics making. We introduce PCB Renewal, a novel technique that “erases” and “reconfigures” PCB traces by selectively depositing conductive epoxy onto outdated areas, transforming isolated paths into conductive planes that support new traces. We present the PCB Renewal workflow, evaluate its electrical performance and mechanical durability, and model its sustainability impact, including material usage, cost, energy consumption, and time savings. We develop a software plug-in that guides epoxy deposition, generates updated PCB profiles, and calculates resource usage. To demonstrate PCB Renewal ’s effectiveness and versatility, we repurpose a single PCB across four design iterations spanning three projects: a camera roller, a WiFi radio, and an ESPboy game console. We also show how an outsourced double-layer PCB can be reconfigured, transforming it from an LED watch to an interactive cat toy. The paper concludes with limitations and future directions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {887},
numpages = {18},
keywords = {PCB Prototyping, Sustainability, Reuse, Renewal, Fabrication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714095,
author = {Lu, Jasmine and Boddu, Sai Rishitha and Lopes, Pedro},
title = {ProtoPCB: Reclaiming Printed Circuit Board E-waste as Prototyping Material},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714095},
doi = {10.1145/3706598.3714095},
abstract = {We propose an interactive tool that enables reusing printed circuit boards (PCB) as prototyping materials to implement new circuits—this extends the utility of PCBs rather than discards them as e-waste. To enable this, our tool takes a user's desired circuit schematic and analyzes its components and connections to find methods of creating the user's circuit on discarded PCBs (e.g., e-waste, old prototypes). In our technical evaluation, we utilized our tool across a diverse set of PCBs and input circuits to characterize how often circuits could be implemented on a different board, implemented with minor interventions (trace-cutting or bodge-wiring), or implemented on a combination of multiple boards—demonstrating how our tool assists with exhaustive matching tasks that a user would not likely perform manually. We believe our tool offers: (1) a new approach to prototyping with electronics beyond the limitations of breadboards and (2) a new approach to reducing e-waste during electronics prototyping.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {888},
numpages = {12},
keywords = {Printed circuit boards, electronic waste, electronics prototyping, reuse},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713663,
author = {Sharma, Vishal and Kumar, Neha},
title = {Sustainability, Development, and Human–Computer Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713663},
doi = {10.1145/3706598.3713663},
abstract = {Researchers in Human–Computer Interaction (HCI) have studied the design and use of technologies for sustainability and development, contributing to the subfields of Sustainable HCI and HCI for Development. Increasingly, there have been calls within and outside HCI for a more integrated approach to sustainable development. To identify the potential of such an approach, we present a comprehensive review of HCI scholarship on sustainability and development, combined with an analysis of interviews with researchers working in and across both subfields. Using the lens of political economy, we uncover understandings, critiques, tensions, and considerations toward advancing scholarship at the intersections of sustainability, development, and HCI. We conclude by inviting the larger Special Interest Group on Computer-Human Interaction (SIGCHI) community to join us in collectively devising pathways for technology-mediated sustainable development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {889},
numpages = {21},
keywords = {Sustainability; Development; Sustainable Development; SHCI; HCI4D},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713948,
author = {Smith, Miana and Forman, Jack and Abdel-Rahman, Amira and Wang, Sophia and Gershenfeld, Neil},
title = {Voxel Invention Kit: Reconfigurable Building Blocks for Prototyping Interactive Electronic Structures},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713948},
doi = {10.1145/3706598.3713948},
abstract = {Prototyping large, electronically integrated structures is challenging and often results in unwieldy wiring, weak mechanical properties, expensive iterations, or limited reusability. While many electronics prototyping kits exist for small-scale objects, relatively few methods exist to freely iterate large and sturdy structures with integrated electronics. To address this gap, we present the Voxel Invention Kit (VIK), which uses reconfigurable blocks that assemble into high-stiffness, lightweight structures with integrated electronics. We do this by creating cubic blocks composed of PCBs that carry electrical routing and components and can be (re)configured with simple tools into a variety of structures. To ensure structural stability without expertise, we created a tool to configure structures and simulate applied loads, which we validated with mechanical testing data. Using VIK, we produced devices reconfigured from a shared set of voxels: multiple iterations of a customizable AV lounge seat, a dance floor game, and a force-sensing bridge.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {890},
numpages = {15},
keywords = {Personal fabrication, interactive structures, modular electromechanical systems},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713239,
author = {Mackey, Angella and McCallum, David NG and Tomico, Oscar and de Waal, Martijn},
title = {What Comes After Noticing?: Reflections on Noticing Solar Energy and What Came Next},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713239},
doi = {10.1145/3706598.3713239},
abstract = {Many design researchers have been exploring what it means to take a more-than-human design approach in their practice. In particular, the technique of “noticing” has been explored as a way of intentionally opening a designer's awareness to more-than-human worlds. In this paper we present autoethnographic accounts of our own efforts to notice solar energy. Through two studies we reflect on the transformative potential of noticing the more-than-human, and the difficulties in trying to sustain this change in oneself and one's practice. We propose that noticing can lead to activating exiled capacities within the noticer, relational abilities that lie dormant in each of us. We also propose that emphasising sense-fullness in and through design can be helpful in the face of broader psychological or societal boundaries that block paths towards more relational ways of living with non-humans.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {891},
numpages = {14},
keywords = {autoethnography, ecological thinking, more-than-human design, noticing, solar energy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713791,
author = {Pan, Ziqi and Zhang, Xiucheng and Li, Zisu and Peng, Zhenhui and Fan, Mingming and Ma, Xiaojuan},
title = {ACKnowledge: A Computational Framework for Human Compatible Affordance-based Interaction Planning in Real-world Contexts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713791},
doi = {10.1145/3706598.3713791},
abstract = {Intelligent agents coexisting with humans often need to interact with human-shared objects in environments. Thus, agents should plan their interactions based on objects’ affordances and the current situation to achieve acceptable outcomes. How to support intelligent agents’ planning of affordance-based interactions compatible with human perception and values in real-world contexts remains under-explored. We conducted a formative study identifying the physical, intrapersonal, and interpersonal contexts that count to household human-agent interaction. We then proposed ACKnowledge, a computational framework integrating a dynamic knowledge graph, a large language model, and a vision language model for affordance-based interaction planning in dynamic human environments. In evaluations, ACKnowledge generated acceptable planning results with an understandable process. In real-world simulation tasks, ACKnowledge achieved a high execution success rate and overall acceptability, significantly enhancing usage-rights respectfulness and social appropriateness over baselines. The case study’s feedback demonstrated ACKnowledge’s negotiation and personalization capabilities toward an understandable planning process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {892},
numpages = {20},
keywords = {Affordance-based Interaction Planning, Real-world Context, Human Compatible},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713241,
author = {Li, Wenqi and Kuo, Jui-Ching and Sheng, Manyu and Zhang, Pengyi and Wu, Qunfang},
title = {Beyond Explicit and Implicit: How Users Provide Feedback to Shape Personalized Recommendation Content},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713241},
doi = {10.1145/3706598.3713241},
abstract = {As personalized recommendation algorithms become integral to social media platforms, users are increasingly aware of their ability to influence recommendation content. However, limited research has explored how users provide feedback through their behaviors and platform mechanisms to shape the recommendation content. We conducted semi-structured interviews with 34 active users of algorithmic-driven social media platforms (e.g., Xiaohongshu, Douyin). In addition to explicit and implicit feedback, this study introduced intentional implicit feedback, highlighting the actions users intentionally took to refine recommendation content through perceived feedback mechanisms. Additionally, choices of feedback behaviors were found to align with specific purposes. Explicit feedback was primarily used for feed customization, while unintentional implicit feedback was more linked to content consumption. Intentional implicit feedback was employed for multiple purposes, particularly in increasing content diversity and improving recommendation relevance. This work underscores the user intention dimension in the explicit-implicit feedback dichotomy and offers insights for designing personalized recommendation feedback that better responds to users’ needs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {893},
numpages = {17},
keywords = {Personalized recommendation algorithm, Explicit feedback, Implicit feedback, User purpose, Semi-structured interview, Xiaohongshu, RedNote, Douyin, TikTok},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714106,
author = {Zhou, Xiaofei and Zhang, Yi and Jiang, Yufei and Gong, Yunfan and Zhang, Chi and Antle, Alissa N. and Bai, Zhen},
title = {Briteller: Shining a Light on AI Recommendations for Children},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714106},
doi = {10.1145/3706598.3714106},
abstract = {Understanding how AI recommendations work can help the younger generation become more informed and critical consumers of the vast amount of information they encounter daily. However, young learners with limited math and computing knowledge often find AI concepts too abstract. To address this, we developed Briteller, a light-based recommendation system that makes learning tangible. By exploring and manipulating light beams, Briteller enables children to understand an AI recommender system’s core algorithmic building block, the dot product, through hands-on interactions. Initial evaluations with ten middle school students demonstrated the effectiveness of this approach, using embodied metaphors, such as "merging light" to represent addition. To overcome the limitations of the physical optical setup, we further explored how AR could embody multiplication, expand data vectors with more attributes, and enhance contextual understanding. Our findings provide valuable insights for designing embodied and tangible learning experiences that make AI concepts more accessible to young learners.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {894},
numpages = {30},
keywords = {Tangible User Interface, Augmented Reality, Embodied Learning, AI Literacy, Optical Computing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713379,
author = {Wan, Ruyuan and Tong, Lingbo and Knearem, Tiffany and Li, Toby Jia-Jun and Huang, Ting-Hao 'Kenneth' and Wu, Qunfang},
title = {Hashtag Re-Appropriation for Audience Control on Recommendation-Driven Social Media Xiaohongshu (rednote)},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713379},
doi = {10.1145/3706598.3713379},
abstract = {Algorithms have played a central role in personalized recommendations on social media. However, they also present significant obstacles for content creators trying to predict and manage their audience reach. This issue is particularly challenging for marginalized groups seeking to maintain safe spaces. Our study explores how women on Xiaohongshu (rednote), a recommendation-driven social platform, proactively re-appropriate hashtags (e.g., #宝宝辅食, Baby Supplemental Food) by using them in posts unrelated to their literal meaning. The hashtags were strategically chosen from topics that would be uninteresting to the male audience they wanted to block. Through a mixed-methods approach, we analyzed the practice of hashtag re-appropriation based on 5,800 collected posts and interviewed 24 active users from diverse backgrounds to uncover users’ motivations and reactions towards the re-appropriation. This practice highlights how users can reclaim agency over content distribution on recommendation-driven platforms, offering insights into self-governance within algorithmic-centered power structures.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {895},
numpages = {25},
keywords = {Social Media Governance, Content Moderation, Feminist HCI, Hashtag Activism, Platform Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713460,
author = {Do, Tiffany D. and Shafqat, Usama Bin and Ling, Elsie and Sarda, Nikhil},
title = {PAIGE: Examining Learning Outcomes and Experiences with Personalized AI-Generated Educational Podcasts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713460},
doi = {10.1145/3706598.3713460},
abstract = {Generative AI is revolutionizing content creation and has the potential to enable real-time, personalized educational experiences. We investigated the effectiveness of converting textbook chapters into AI-generated podcasts and explored the impact of personalizing these podcasts for individual learner profiles. We conducted a 3x3 user study with 180 college students in the United States, comparing traditional textbook reading with both generalized and personalized AI-generated podcasts across three textbook subjects. The personalized podcasts were tailored to students’ majors, interests, and self-described instructional preferences. Our findings show that students found the AI-generated podcast format to be more enjoyable than textbooks and that personalized podcasts led to significantly improved learning outcomes, although this was subject-specific. These results highlight that AI-generated podcasts can offer an engaging and effective modality transformation of textbook material, with personalization enhancing content relevance. We conclude with design recommendations for leveraging AI in education, informed by student feedback.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {896},
numpages = {12},
keywords = {artificial intelligence in education, personalized learning, large language models, content transformation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713569,
author = {Qin, Hua Xuan and Zhu, Guangzhi and Fan, Mingming and Hui, Pan},
title = {Toward Personalizable AI Node Graph Creative Writing Support: Insights on Preferences for Generative AI Features and Information Presentation Across Story Writing Processes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713569},
doi = {10.1145/3706598.3713569},
abstract = {As story writing requires diverse resources, a single system combining these resources could improve personalization. We leverage the broad capabilities of generative AI to support both more general story writing needs and an understudied but essential aspect: reflection on the moral (lesson) conveyed. Through a formative study (N=12), a user study (N=14), and external evaluation (N=19), we designed, implemented, then studied a prototype plugin for FigJam supporting visualization of the story structure through customizable node graph editing, LLM audience impersonation (chatbot and non-chatbot interfaces), and image and audio generative AI features. Our findings support writers’ preference for leveraging unique interplays of our breadth of features to satisfy shifting needs across writing processes, from conveying a moral across audience groups to story writing in general. We discuss how our tool design and findings can inform model bias, personalized writing support, and visualization research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {897},
numpages = {30},
keywords = {Creativity Support, Writing Assistants, Visualization, Human-AI Collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713347,
author = {Yun, Sojeong and Lim, Youn-kyung},
title = {User Experience with LLM-powered Conversational Recommendation Systems: A Case of Music Recommendation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713347},
doi = {10.1145/3706598.3713347},
abstract = {The advancement of large language models (LLMs) now allows users to actively interact with conversational recommendation systems (CRS) and build their own personalized recommendation services tailored to their unique needs and goals. This experience offers users a significantly higher level of controllability compared to traditional RS, enabling an entirely new dimension of recommendation experiences. Building on this context, this study explored the unique experiences that LLM-powered CRS can provide compared to traditional RS. Through a three-week diary study with 12 participants using custom GPTs for music recommendations, we found that LLM-powered CRS can (1) help users clarify implicit needs, (2) support unique exploration, and (3) facilitate a deeper understanding of musical preferences. Based on these findings, we discuss the new design space enabled by LLM-powered CRS and highlight its potential to support more personalized, user-driven recommendation experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {898},
numpages = {15},
keywords = {CRS, LLM, user experience, music recommendation, self-discovery, explorative search, sense-making, designability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713826,
author = {Niu, Yuqi and Meng-Schneider, Nicole and Qiu, Weidong and Kokciyan, Nadin},
title = {``I am not the primary focus" - Understanding the Perspectives of Bystanders in Photos Shared Online},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713826},
doi = {10.1145/3706598.3713826},
abstract = {When taking photos in a crowd, unintended individuals, such as bystanders, are often captured alongside the main subject(s). In an effort to protect bystanders’ privacy, existing methods have been developed to automatically detect bystanders. However, inconsistent definitions of who qualifies as a bystander limit their effectiveness. To better understand bystanders’ perceptions, we conducted an online survey with 486 participants, analyzing their responses to 864 image-based scenarios and their comfort with sharing these images online. Our results revealed no significant correlation between comfort with public photo sharing and bystander status. We identified limitations in current bystander detection methodologies, as they often fail to recognize bystanders who are not clearly in the background, hence missing individuals with privacy concerns. Moreover, comfort with public sharing varied significantly depending on the image context. Our findings highlight the importance of considering the context of captured images to address privacy concerns in image sharing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {899},
numpages = {23},
keywords = {Bystander, Privacy, Social media, Online photo, Sharing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714245,
author = {Tiefenau, Eva and Grohs, Julia Angelika and H\"{a}ring, Maximilian and Smith, Matthew and Tiefenau, Christian},
title = {"They are responsible for ensuring that I can continue to use the service." Investigating Users' Expectations Towards 2FA Recovery in Germany},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714245},
doi = {10.1145/3706598.3714245},
abstract = {Two-factor authentication is often recommended for increasing online security, and users often follow this by using their phones. If physical items become unavailable, there is a risk of losing access to the account due to missing authentication requirements. In such cases, users need a backup or help from the service. Previous work found no standardized approach to how services address this issue, assist users, or offer backup options. Until now, it is unclear how users handle backups and account recovery and what their expectations towards service providers are. To shed light on this, we conducted 16 interviews and a survey with 95 participants. We found that most had never considered how to access their accounts if the second factor was lost, and only a few had a backup plan. Instead, users often rely on website support, assuming that personal data will help them regain access. We give recommendations for services.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {900},
numpages = {17},
keywords = {Authentication, 2FA, Account recovery, backups, user-centered research, interview, survey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713334,
author = {Qiwei, Li and Zhang, Shihui and Pratt, Samantha Paige and Kasper, Andrew Timothy and Gilbert, Eric and Schoenebeck, Sarita},
title = {A Law of One's Own: The Inefficacy of the DMCA for Non-Consensual Intimate Media},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713334},
doi = {10.1145/3706598.3713334},
abstract = {Non-consensual intimate media (NCIM) presents internet-scale harm to individuals who are depicted. One of the most powerful tools for requesting its removal is the Digital Millennium Copyright Act (DMCA). However, the DMCA was designed to protect copyright holders rather than to address the problem of NCIM. Using a dataset of more than 54,000 DMCA reports and over 85 million infringing URLs spanning over a decade, this paper evaluates the efficacy of the DMCA for NCIM takedown. Results show that for non-commercial requests, while more than half of URLs are de-indexed from Google Search within 48 hours, the actual removal of content from website hosts is much slower. The median infringing URL takes more than 45 days to be removed from website hosts, and only 5.39\% URLs are removed within the first 48 hours. Additionally, the most frequently reported domains for non-commercial NCIM are smaller websites, not large platforms. We stress the need for new laws that ensure a shorter time to takedown that are enforceable across big and small platforms alike.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {901},
numpages = {17},
keywords = {Online sexual abuse, Content moderation, Image-based sexual abuse, IBSA, Non-consensual intimate imagery, NCII, DMCA, Digital copyright, Survival analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713391,
author = {Liao, Si and He, Hanwei and Chen, Huangxun and Yang, Zhice},
title = {Bystander Privacy in Video Sharing Era: Automated Consent Compliance through Platform Censorship},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713391},
doi = {10.1145/3706598.3713391},
abstract = {Bystander privacy has become a critical concern amidst the widespread activities of video sharing, engaging billions of users daily. Concerns arise when individuals inadvertently appear in public videos without consent. Existing methods for determining bystander permissions require significant adaptation and modifications by videographers and video sharing platforms, potentially limiting their adoption. This study explores leveraging platform censorship capabilities to enforce bystander privacy. We introduce SelfFlag, a type of violative media signal designed to trigger automatic content flagging. Bystanders exhibiting such signals, captured in public videos, can be automatically identified and removed by platforms, thereby indirectly enforcing privacy preferences, primarily through the efforts of bystanders themselves. We conduct thorough measurements on current censorship practices, propose music-based triggering content, and develop an auxiliary tool for videographers to produce high-quality content with privacy compliance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {902},
numpages = {16},
keywords = {Bystander Privacy, Copyright, Censorship, Music},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713795,
author = {Kaufhold, Marc-Andr\'{e} and B\"{a}umler, Julian and Bajorski, Marius and Reuter, Christian},
title = {Cyber Threat Awareness, Protective Measures and Communication Preferences in Germany: Implications from Three Representative Surveys (2021-2024)},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713795},
doi = {10.1145/3706598.3713795},
abstract = {In light of the increasing vulnerability of citizens against cyberattacks, we conducted three representative surveys with German citizens in 2021 (N=1,093), 2023 (N=1,011), and 2024 (N=1,004) to examine their cyber threat awareness, use of protective security measures, and preferred information channels. While our findings attest large proportions of the German population a high level of cyber threat awareness, many citizens feel inadequately informed about coping with cyberattacks and show little confidence in German security authorities to protect citizens and infrastructures. While age correlated with citizens’ awareness and behavior, we only saw minor temporal differences between datasets. Finally, we provide design and policy implications for enhancing citizens’ awareness of cyber threats and implementing security measures.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {903},
numpages = {20},
keywords = {Cyber Threat Awareness, Security Measures, Communication Strategies, Human-Computer Interaction, Representative Citizen Survey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714136,
author = {Godwin, Alex and Foriest, Jasmine C and Bottcher, Mia and Baas, Gretchen and Tsai, Michael and Wu, Daniel T},
title = {Interaction Techniques for Providing Sensitive Location Data of Interpersonal Violence with User-Defined Privacy Preservation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714136},
doi = {10.1145/3706598.3714136},
abstract = {Violence is a significant public health issue. Interventions to reduce violence rely on data about where incidents occur. Cities have historically used incomplete law enforcement crime data, but many are shifting toward data collected from hospital patients via the Cardiff Model to form a more complete understanding of violence. Still, location data is wrought with issues related to completeness, quality, and privacy. For example, if a patient feels that sharing a detailed location may present them with additional risks, such as undesired police involvement or retaliatory violence, they may be unwilling or unable to share. Consequently, survivors of violence who are the most vulnerable may remain the most at risk. We have designed a user interface and mapping algorithm to confront these challenges and conducted an experiment with emergency department patients. The results indicate a significant improvement in location data obtained using the interface compared to the existing screening interview.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {904},
numpages = {18},
keywords = {health care systems, field studies, visualization, geographic data},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714097,
author = {Bo, Jessica Y and Wan, Sophia and Anderson, Ashton},
title = {To Rely or Not to Rely? Evaluating Interventions for Appropriate Reliance on Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714097},
doi = {10.1145/3706598.3714097},
abstract = {As Large Language Models become integral to decision-making, optimism about their power is tempered with concern over their errors. Users may over-rely on LLM advice that is confidently stated but wrong, or under-rely due to mistrust. Reliance interventions have been developed to help users of LLMs, but they lack rigorous evaluation for appropriate reliance. We benchmark the performance of three relevant interventions by conducting a randomized online experiment with 400 participants attempting two challenging tasks: LSAT logical reasoning and image-based numerical estimation. For each question, participants first answered independently, then received LLM advice modified by one of three reliance interventions and answered the question again. Our findings indicate that while interventions reduce over-reliance, they generally fail to improve appropriate reliance. Furthermore, people became more confident after making wrong reliance decisions in certain contexts, demonstrating poor calibration. Based on our findings, we discuss implications for designing effective reliance interventions in human-LLM collaboration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {905},
numpages = {23},
keywords = {Large Language Models, Human-LLM Collaboration, Appropriate Reliance, Over-Reliance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713812,
author = {Ghimire, Amit and Hou, Anova and Kim, Ig-Jae and Yoon, Dongwook},
title = {AvatARoid: A Motion-Mapped AR Overlay to Bridge the Embodiment Gap Between Robots and Teleoperators in Robot-Mediated Telepresence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713812},
doi = {10.1145/3706598.3713812},
abstract = {Robot-mediated telepresence promises to facilitate effective social interaction between remote teleoperators and on-site users. However, disparities between the robot’s form and the teleoperator’s representation cause perceptual conflict in on-site users, degrading interaction quality. We introduce AvatARoid, a novel design that bridges this embodiment gap by superimposing the teleoperator’s motion-mapped AR avatar overlay on a humanoid. We evaluated our design in a mixed-method study (n=48) using an immersive simulation where participants interacted with a confederate teleoperator, presented in either (a) a humanoid robot, (b) a humanoid robot with video, or (c) AvatARoid. Results suggest AvatARoid significantly improved teleoperator embodiment for on-site users, particularly enhancing co-location, and control perceptions, and providing richer non-verbal gestures. In contrast, video and baseline conditions often resulted in a pronounced disconnect between the teleoperator and the robot for on-site users. Our study offers new insights into designing novel teleoperator representations to promote social interaction in robot-mediated telepresence.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {906},
numpages = {26},
keywords = {AvatARoid, telepresence, robot, humanoid, embodiment, avatar, AR overlay},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713457,
author = {Chen, XinHui and Yuan, Xiang and Zhang, Hui and Zheng, Ruixiao and Wei, Wanyi},
title = {Maintaining "Balanced" Conflict: Proactive Intervention Strategies of AI Voice Agents in Online Collaboration of Temporary Design Teams},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713457},
doi = {10.1145/3706598.3713457},
abstract = {Temporary teams are important in modern work but often struggle with interpersonal factors that hinder consensus-driven tasks, especially in design teams where effective discussion and execution are critical. Integrating AI into these teams provides a promising solution. While some studies have explored AI’s role in enhancing teamwork, they often ignore the bidirectional impact of team dynamics: teams need to maintain a moderate level of disagreement, which must be effectively managed. To explore the mechanisms regulating conflict escalation and de-escalation in online collaboration of temporary design teams, we conducted exploratory research and an expert workshop (N=6) to propose proactive intervention strategies for AI voice agents. A controlled experiment (N=36) showed that teams with AI voice agent intervention performed better in improving interpersonal relationships, communication-related collaboration quality, and collaboration experience. This work suggests that AI voice agents can support team conflict dynamics by fostering constructive discussions and managing disagreements arising positively.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {907},
numpages = {19},
keywords = {Team Collaboration, Conflict Management, Intelligent voice interaction, Proactivity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713889,
author = {Hostettler, Damian and Mayer, Simon and Albert, Jan Liam and Jenss, Kay Erik and Hildebrand, Christian},
title = {Real-Time Adaptive Industrial Robots: Improving Safety And Comfort In Human-Robot Collaboration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713889},
doi = {10.1145/3706598.3713889},
abstract = {Industrial robots become increasingly prevalent, resulting in a growing need for intuitive, comforting human-robot collaboration. We present a user-aware robotic system that adapts to operator behavior in real time while non-intrusively monitoring physiological signals to create a more responsive and empathetic environment. Our prototype dynamically adjusts robot speed and movement patterns to proxemics while measuring operator pupil dilation. Our user study compares this adaptive system to a non-adaptive counterpart, and demonstrates that the adaptive system significantly reduces both perceived and physiologically measured cognitive load while enhancing usability. Participants reported increased feelings of comfort, safety, trust, and a stronger sense of collaboration when working with the adaptive robot. This highlights the potential of integrating real-time physiological data into human-robot interaction paradigms. This novel approach creates more intuitive and collaborative industrial environments where robots effectively ’read’ and respond to human cognitive states, and we feature all data and code for future use.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {908},
numpages = {16},
keywords = {Adaptive Robot, Industrial Robot, User Study, Pupillometry, Proxemics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713113,
author = {Kassem, Khaled and Gietl, Patrick and Michahelles, Florian and Matviienko, Andrii},
title = {RoboTeach: How Student Robots' Preexisting Proficiency and Learning Rate Affect Human Teachers Demonstrating Object Placement},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713113},
doi = {10.1145/3706598.3713113},
abstract = {Social robots are employed as companions, helping in industrial and domestic environments. Adapting robots’ capabilities to user needs can be achieved through teaching from human demonstrations. However, the influence of robots’ preexisting proficiency and learning rate on human teachers’ self-efficacy and perception of the robots is underexplored. In this paper, we simulated four robot performance types that combine: (1) preexisting proficiency (low/high) and (2) learning rate (slow/fast). We conducted a controlled lab experiment studying the impact of robots’ performance type on teachers’ self-efficacy, willingness to teach the robot, and perception of the robot (N=24), in which robots placed objects in suitable locations. Fast learners were perceived as more intelligent, anthropomorphic, and likable, and this caused higher teaching self-efficacy regardless of preexisting skills. Slow learners caused frustration while teaching. Moreover, participants stopped teaching robots with low preexisting skills sooner, regardless of the learning rate, indicating potential bias caused by expectations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {909},
numpages = {12},
keywords = {teaching robots, object placement, learning rate, existing proficiency, self-efficacy, robot perception},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713477,
author = {Fan, Xianzhe and Xiao, Qing and Zhou, Xuhui and Pei, Jiaxin and Sap, Maarten and Lu, Zhicong and Shen, Hong},
title = {User-Driven Value Alignment: Understanding Users' Perceptions and Strategies for Addressing Biased and Discriminatory Statements in AI Companions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713477},
doi = {10.1145/3706598.3713477},
abstract = {Content Warning: This paper presents textual examples that may be offensive or upsetting.Large language model-based AI companions are increasingly viewed by users as friends or romantic partners, leading to deep emotional bonds. However, they can generate biased, discriminatory, and harmful outputs. Recently, users are taking the initiative to address these harms and re-align AI companions. We introduce the concept of user-driven value alignment, where users actively identify, challenge, and attempt to correct AI outputs they perceive as harmful, aiming to guide the AI to better align with their values. We analyzed 77 social media posts about discriminatory AI statements and conducted semi-structured interviews with 20 experienced users. Our analysis revealed six common types of discriminatory statements perceived by users, how users make sense of those AI behaviors, and seven user-driven alignment strategies, such as gentle persuasion and anger expression. We discuss implications for supporting user-driven value alignment in future AI systems, where users and their communities have greater agency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {910},
numpages = {19},
keywords = {User-Driven Value Alignment, Value Alignment, Human-AI Alignment, Discrimination, LLM-Based AI Companion, User-Driven Algorithm Auditing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713983,
author = {Reichmann, Felix and Buckmann, Annalina and Fischer, Konstantin and Sasse, M. Angela and Naiakshina, Alena},
title = {Bridging the Gap Between Usable Security Research and Open-Source Practice - Lessons From a Long-Term Engagement With VeraCrypt},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713983},
doi = {10.1145/3706598.3713983},
abstract = {VeraCrypt is a freely available open-source encryption tool popular with tech-savvy users. In a 4-year effort to improve VeraCrypt’s usability to reach less tech-savvy users, we conducted 3 user studies (N=77) and found that participants struggled to successfully encrypt their devices with VeraCrypt. We iteratively redesigned the UI and instructions and suggested significant usability improvements to the VeraCrypt community. Since 7 professional developers struggled to compile the project, we created a step-by-step compilation guide and contributed 5 pull requests for bug fixes and interface improvements. However, our efforts to translate academic findings into practical applications were unsuccessful. In this work, we explore why our usability improvements failed. Due to code complexity and a lack of transparency, the OS community was concerned our changes could undermine security. Based on our findings, we provide recommendations for researchers collaborating with open-source communities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {911},
numpages = {21},
keywords = {VeraCrypt, Open-Source Software, Usable Security, Community Engagement, User Studies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713966,
author = {Sigg, Dorothee and Hardt, Moritz and Mendler-D\"{u}nner, Celestine},
title = {Decline Now: A Combinatorial Model for Algorithmic Collective Action},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713966},
doi = {10.1145/3706598.3713966},
abstract = {Drivers on food delivery platforms often run a loss on low-paying orders. In response, workers on DoorDash started a campaign, #DeclineNow, to purposefully decline orders below a certain pay threshold. For each declined order, the platform returns the request to other available drivers with slightly increased pay. While contributing to overall pay increase the implementation of the strategy comes with the risk of missing out on orders for each individual driver. In this work, we propose a first combinatorial model to study the strategic interaction between workers and the platform. Within our model, we formalize key quantities such as the collective benefit of the strategy, the benefit of freeriding, as well as the benefit of participation. We extend our theoretical results with simulations. Our key insights show that the collective benefit of the strategy is always positive, while the benefit of participation is positive only for small degrees of labor oversupply. Beyond this point, the utility of participants decreases faster with increasing degree of oversupply, compared to the return of freeriding. Our work highlights the significance of labor supply levels for the effectiveness of collective action on gig platforms. We discuss organizing in shifts as a means to reduce oversupply and empower collectives.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {912},
numpages = {17},
keywords = {Gig economy, collective action, digital platforms, algorithmic resistance, data leverage},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713959,
author = {Hassan, Waseem and Da, Liyue and Elizondo, Sonia and Hornb\ae{}k, Kasper},
title = {Heartbeat Resonance: Inducing Non-contact Heartbeat Sensations in the Chest},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713959},
doi = {10.1145/3706598.3713959},
abstract = {Perceiving and altering the sensation of internal physiological states, such as heartbeats, is key for biofeedback and interoception. Yet, wearable devices used for this purpose can feel intrusive and typically fail to deliver stimuli aligned with the heart’s location in the chest. To address this, we introduce Heartbeat Resonance, which uses low-frequency sound waves to create non-contact haptic sensations in the chest cavity, mimicking heartbeats. We conduct two experiments to evaluate the system’s effectiveness. The first experiment shows that the system created realistic heartbeat sensations in the chest, with 78.05 Hz being the most effective frequency. In the second experiment, we evaluate the effects of entrainment by simulating faster and slower heart rates. Participants perceived the intended changes and reported high confidence in their perceptions for +15\% and -30\% heart rates. This system offers a non-intrusive solution for biofeedback while creating new possibilities for immersive VR environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {913},
numpages = {22},
keywords = {Vibrotactile feedback; non-contact haptics; psychophysics; heartbeat modulation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713097,
author = {Dolata, Mateusz and Lange, Norbert and Schwabe, Gerhard},
title = {More Attention, Transformation, Acceleration, and Exploration: Freelance Developers' Take on Hypes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713097},
doi = {10.1145/3706598.3713097},
abstract = {Despite growing economic importance, freelance software developers face unfavorable conditions on freelance platforms. Among others, they need to deal with the consequences of elevated expectations emerging during technology hypes. Despite this, the impact of hype on freelancers remains underexplored, limiting our ability to guide them through these intense periods and inform the design of freelance platforms. Through interviews with 52 freelance developers pursuing projects involving generative AI (GenAI), we identify technology hypes as a significant force shaping freelancers’ careers. Based on the interviews, we offer a multifaceted perspective on hype as a phenomenon. We reveal that technological hypes negatively impact the career prospects and well-being of some freelancers while empowering others to advance their careers or transition into new areas. We identify four clusters of freelance developers based on their experiences with and reactions to the GenAI hype. This study positions technology hype as a critical factor shaping the freelance economy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {914},
numpages = {21},
keywords = {GenAI, freelancing, gig workers, hype, independent developers, knowledge workers, technology trends, upwork},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713931,
author = {Asadi, Raha and Biering, Bodil and van Dijk, Vincent and Kulyk, Oksana and Paja, Elda},
title = {No Silver Bullet: Towards Demonstrating Secure Software Development for Small and Medium Enterprises in a Business-to-Business Model},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713931},
doi = {10.1145/3706598.3713931},
abstract = {Software developing small and medium enterprises (SMEs) play a crucial role as suppliers to larger corporations and public administration. It is therefore necessary for them to be able to demonstrate that their products meet certain security criteria, both to gain trust of their customers and to comply to standards that demand such a demonstration. In this study we have investigated ways for SMEs to demonstrate their security when operating in a business-to-business model, conducting semi-structured interviews (N = 16) with practitioners from different SMEs in Denmark and validating our findings in a follow-up workshop (N = 6). Our findings indicate five distinctive security demonstration approaches, namely: Certifications, Reports, Questionnaires, Interactive Sessions and Social Proof. We discuss the challenges, benefits, and recommendations related to these approaches, concluding that none of them is a one-size-fits all solution and that more research into relative advantages of these approaches and their combinations is needed.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {915},
numpages = {17},
keywords = {Security; Commerce/Business; Qualitative methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713980,
author = {Reichmann, Felix and Opdenbusch, Jens Christian and Marky, Karola and Gutfleisch, Marco},
title = {Security Knight in Shining Armor: What and Who VPN Providers Claim to Shield Consumers Against},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713980},
doi = {10.1145/3706598.3713980},
abstract = {Consumer virtual private network (VPN) providers promise online security and privacy by tunneling user traffic through their servers. However, there is a growing disparity between the users’ perceptions of achievable security and privacy and the actual limitations of such services. In a large-scale, multi-step mixed methods study, we holistically investigated the degree to which 78 consumer VPN providers support or undermine proper mental models for their products and services. We collected search queries from 300 participants - coming from five countries across four continents - to identify suitable VPN providers and, subsequently their security and privacy promises. Among VPN providers’ statements, a large share contains misleading or false information, and more than half do not mention any threat agent at all. Our results extend the current research on consumer VPNs and provide a more realistic, holistic, and accurate overview of information on VPN provider websites.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {916},
numpages = {21},
keywords = {VPN Security and Privacy, Threat Agents, Assets, VPN Perceptions, Web Analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713104,
author = {Jianu, Radu and Slingsby, Aidan and Laksono, Dany and Okoe, Mershack},
title = {VisUnit: Literate Visualisation Studies Assembled from Reusable Test-Suites},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713104},
doi = {10.1145/3706598.3713104},
abstract = {We make four contributions to lower the overhead of conducting visualisation user studies and promote the reuse and extension of their materials. (i) A declarative Javascript specification lets experimenters describe how studies are assembled from tested visualisations, datasets, tasks and chosen evaluation strategies. (ii) A VisUnit library translates these into sequences of visual stimuli and delivers them to participants. We move away from monolithic evaluation stimuli typical of previous work and construct studies around three ingredients – visual encodings, datasets, and tasks – that can be developed independently and recombined flexibly. (iii) This paves the way for developing benchmark data+tasks test-suites as independent, reusable resources to support multiple studies. (iv) Structuring user studies as “literate” visualisation notebooks brings together in the open all ingredients necessary for replication and scrutiny: formal design specification; underlying materials; participant-facing views; and narratives justifying design and supporting reuse.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {917},
numpages = {15},
keywords = {visualisation evaluation, user studies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713895,
author = {Ruth, Kimberly and Rivera, Veronica A. and Akiwate, Gautam and Fass, Aurore and Kelley, Patrick Gage and Thomas, Kurt and Durumeric, Zakir},
title = {"Perfect is the Enemy of Good": The CISO's Role in Enterprise Security as a Business Enabler},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713895},
doi = {10.1145/3706598.3713895},
abstract = {Chief Information Security Officers (CISOs) are responsible for setting and executing organizations’ information security strategies. This role has only grown in importance as a result of today’s increasingly high-stakes threat landscape. To understand these key decision-makers, we interviewed 16&nbsp;current and former CISOs to understand how they build a security strategy and the day-to-day obstacles that they face. Throughout, we find that the CISO role is strongly shaped by a business enablement perspective, driven by broad organizational goals beyond solely technical protection. Within that framing, we describe the most salient concerns for CISOs, isolate key decision-making factors they use when prioritizing security investments, and surface practical complexities and pain points that they face in executing their strategy. Our results surface opportunities to help CISOs better navigate the complex task of managing organizational risk, as well as lessons for how security tools can be made more deployable in practice.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {918},
numpages = {19},
keywords = {CISO, security, enterprise, business},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713122,
author = {Chen, Xiaowei and Sch\"{o}ni, Lorin and Distler, Verena and Zimmermann, Verena},
title = {Beyond Deterrence: A Systematic Review of the Role of Autonomous Motivation in Organizational Security Behavior Studies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713122},
doi = {10.1145/3706598.3713122},
abstract = {What drives employees to ensure security when handling information assets in organizations? There is growing interest from the security behavior community in how autonomous motivators shape employees’ security-related behaviors. To reconcile the scattered viewpoints on autonomous motivation and synthesize findings from studies utilizing various theoretical frameworks, we systematically reviewed relevant publications. We present a preregistered literature review that investigated (a) what forms of autonomous motivation have been examined in organizational security contexts, (b) which behaviors/behavioral intentions are related to autonomous motivators, and (c) how autonomous motivation affects employees’ security behaviors. Based on an initial set of 432 papers, filtered down to 45 studies, we identified 17 unique autonomous motivators and three types of related security behaviors. This review not only develops a refined taxonomy of autonomous motivation related to security behaviors but also charts a path forward for future research on autonomous motivation in human-centered security.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {919},
numpages = {28},
keywords = {Information security behavior, Autonomous motivation, Motivation theory, Intrinsic motivation, Self-Determination Theory, Systematic review, Expectancy-Value Theory, Human-centered security},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713616,
author = {He, Shijing and Zhan, Xiao and Lei, Yaxiong and Liu, Yueyan and Abu-Salma, Ruba and Such, Jose},
title = {Exploring the Privacy and Security Challenges Faced by Migrant Domestic Workers in Chinese Smart Homes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713616},
doi = {10.1145/3706598.3713616},
abstract = {The growing use of smart home devices poses considerable privacy and security challenges, especially for individuals like migrant domestic workers (MDWs) who may be surveilled by their employers. This paper explores the privacy and security challenges experienced by MDWs in multi-user smart homes through in-depth semi-structured interviews with 26 MDWs and 5 staff members of agencies that recruit and/or train domestic workers in China. Our findings reveal that the relationships between MDWs, their employers, and agencies are characterized by significant power imbalances, influenced by Chinese cultural and social factors (such as Confucianism and collectivism), as well as legal ones. Furthermore, the widespread and normalized use of surveillance technologies in China, particularly in public spaces, exacerbates these power imbalances, reinforcing a sense of constant monitoring and control. Drawing on our findings, we provide recommendations to domestic worker agencies and policymakers to address the privacy and security challenges facing MDWs in Chinese smart homes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {920},
numpages = {18},
keywords = {Internet of Things (IoT), smart homes, migrant domestic workers, multi-user privacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713209,
author = {Eleshin, Farida and Sun, Qi and Ye, Mengzhe and Das, Sauvik and Hong, Jason I.},
title = {Of Secrets and Seedphrases: Conceptual Misunderstandings and Security Challenges for Seed Phrase Management among Cryptocurrency Users},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713209},
doi = {10.1145/3706598.3713209},
abstract = {Cryptocurrency adoption has surged dramatically, with over 500 million global users. Despite the appeal of self-custodial wallets, which grant users control over their assets, these users often struggle with the complexities of securing seed phrases, leading to substantial financial losses. This paper investigates the behaviors, challenges, and security practices of cryptocurrency users regarding seed phrase management. We conducted a mixed-methods study comprising semi-structured interviews with 20 participants and a comprehensive survey of 643 respondents. Our findings reveal significant gaps in users’ understanding and practices around seed phrase security and the circumstances under which users share their seed phrases. We also explore users’ mental models of shared accounts and strategies for handling cryptocurrency assets in the event of death. We found that the majority of our participants harbored significant misconceptions about seed phrases that could expose them to significant security risks — e.g., only 43\% could correctly identify an image of a seed phrase, many believed they could reset their seed phrase if they lost them. Moreover, only a minority have engaged in any estate planning for their crypto assets. By identifying these challenges and behaviors, we provide actionable insights for the design of more secure and user-friendly cryptocurrency wallets, ultimately aiming to enhance user confidence in managing their crypto assets reduce their exposure to scams and accidental loss of assets, and simplify the creation of bequeathment plans.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {921},
numpages = {19},
keywords = {seedphrase, private key, cryptocurrency wallets, backups, custodial, non-custodial, usability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713547,
author = {Elbitar, Yusra and Khodayari, Soheil and Harbach, Marian and De Stefano, Gianluca and Engedy, Balazs Csaba and Pellegrino, Giancarlo and Bugiel, Sven},
title = {Permission Rationales in the Web Ecosystem: An Exploration of Rationale Text and Design Patterns},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713547},
doi = {10.1145/3706598.3713547},
abstract = {Modern web applications use features like camera and geolocation for personalized experiences, requiring user permission via browser prompts. To explain these requests, applications provide rationales—contextual information on why permissions are needed. Despite their importance, little is known about how often rationales appear on the web or their influence on user decisions.This paper presents the first large-scale study of how the web ecosystem handles permission rationales, covering three areas: (i) identifying webpages that use permissions, (ii) detecting and classifying permission rationales, and (iii) analyzing their attributes to understand their impact on user decisions. We examined over 770K webpages from Chrome telemetry, finding 3.6K unique rationale texts and 749 rationale UIs across 85K pages. We extracted key rationale attributes and assessed their effect on user behavior by cross-referencing them with Chrome telemetry data. Our findings reveal nine key insights, providing the first evidence of how different rationales affect user decisions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {922},
numpages = {25},
keywords = {Web Measurement, Exploratory Analysis, Permissions, Rationales},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713968,
author = {Delgado Rodriguez, Sarah and Windl, Maximiliane and Alt, Florian and Marky, Karola},
title = {The TaPSI Research Framework - A Systematization of Knowledge on Tangible Privacy and Security Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713968},
doi = {10.1145/3706598.3713968},
abstract = {This paper presents a comprehensive Systematization of Knowledge on tangible privacy and security interfaces (TaPSI). Tangible interfaces provide physical forms for digital interactions. They can offer significant benefits for privacy and security applications by making complex and abstract security concepts more intuitive, comprehensible, and engaging. Through a literature survey, we collected and analyzed 80 publications. We identified terminology used in these publications and addressed usable privacy and security domains, contributions, applied methods, implementation details, and opportunities or challenges inherent to TaPSI. Based on our findings, we define TaPSI and propose the TaPSI Research Framework, which guides future research by offering insights into when and how to conduct research on privacy and security involving TaPSI as well as a design space of TaPSI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {923},
numpages = {28},
keywords = {tangible privacy, tangible security, tangible interface, TaPSI, framework},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713290,
author = {Jenkins, Eve and Abdulgalimov, Dinislam and Briggs, Pamela and Olivier, Patrick and Nicholson, James},
title = {Using Anonymous Discussion Platforms to Support Open Conversations about Cybersecurity in Organisations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713290},
doi = {10.1145/3706598.3713290},
abstract = {People-centred security is critical for the security of an organisation, but we know that it comes at a cost. Recently the academic literature base has started to focus on how security might be understood and promoted as a facet of the overall culture of an organisation. This work sets out to understand the experiences of employees and management when using an anonymous online discussion platform to discuss cybersecurity policies. Following a 2-week deployment in a large UK educational institution, we found that anonymity helped individuals share their experiences, and that these experiences helped others understand more about the rationale for security policies. However, we also found that anonymity negatively impacted on individuals’ ability to discuss specific problems and follow up on incidents. We discuss the opportunities and challenges of using anonymous discussion platforms in organisations for improving the security culture through social participation and a more transparent listening culture.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {924},
numpages = {14},
keywords = {Organisational security culture, anonymity, employee voice, security policies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714030,
author = {Cai, Zhaochong and Abbink, David and Wiertlewski, Micha\"{e}l},
title = {Attracting Fingers with Waves: Potential Fields Using Active Lateral Forces Enhance Touch Interactions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714030},
doi = {10.1145/3706598.3714030},
abstract = {Touchscreens and touchpads offer intuitive interfaces but provide limited tactile feedback, usually just mechanical vibrations. These devices lack continuous feedback to guide users’ fingers toward specific directions. Recent innovations in surface haptic devices, however, leverage ultrasonic traveling waves to create active lateral forces on a bare fingertip. This paper investigates the effects and design possibilities of active forces feedback in touch interactions by rendering artificial potential fields on a touchpad. Three user studies revealed that: (1) users perceived attractive and repulsive fields as bumps and holes with similar detection thresholds; (2) step-wise force fields improved targeting by 22.9\% compared to friction-only methods; and (3) active force fields effectively communicated directional cues to the users. Several applications were tested, with user feedback favoring this approach for its enhanced tactile experience, added enjoyment, realism, and ease of use.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {925},
numpages = {13},
keywords = {Haptic feedback, surface haptics, active force, targeting task},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713100,
author = {Xu, Weiye and Li, Tony and Wang, Yuntao and Yang, Xing-Dong and Wu, Te-Yen},
title = {BIT: Battery-free, IC-less and Wireless Smart Textile Interface and Sensing System},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713100},
doi = {10.1145/3706598.3713100},
abstract = {The development of smart textile interfaces is hindered by the inclusion of rigid hardware components and batteries within the fabric, which pose challenges in terms of manufacturability, usability, and environmental concerns related to electronic waste. To mitigate these issues, we propose a smart textile interface and its wireless sensing system to eliminate the need for ICs, batteries, and connectors embedded into textiles. Our technique is established on the integration of multi-resonant circuits in smart textile interfaces, and utilizing near-field electromagnetic coupling between two coils to facilitate wireless power transfer and data acquisition from smart textile interface. A key aspect of our system is the development of a mathematical model that accurately represents the equivalent circuit of the sensing system. Using this model, we developed a novel algorithm to accurately estimate sensor signals based on changes in system impedance. Through simulation-based experiments and a user study, we demonstrate that our technique effectively supports multiple textile sensors of various types.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {926},
numpages = {18},
keywords = {battery-less, IC-less, wireless, smart textile, sensing interface, relay},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714140,
author = {Zheng, Ruonan and Fang, Jiawei and Yao, Yuan and Gao, Xiaoxia and Zuo, Chengxu and Guo, Shihui and Luo, Yiyue},
title = {FIP: Endowing Robust Motion Capture on Daily Garment by Fusing Flex and Inertial Sensors},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714140},
doi = {10.1145/3706598.3714140},
abstract = {What if our clothes could capture our body motion accurately? This paper introduces Flexible Inertial Poser (FIP), a novel motion-capturing system using daily garments with two elbow-attached flex sensors and four Inertial Measurement Units (IMUs). To address the inevitable sensor displacements in loose wearables which degrade joint tracking accuracy significantly, we identify the distinct characteristics of the flex and inertial sensor displacements and develop a Displacement Latent Diffusion Model and a Physics-informed Calibrator to compensate for sensor displacements based on such observations, resulting in a substantial improvement in motion capture accuracy. We also introduce a Pose Fusion Predictor to enhance multimodal sensor fusion. Extensive experiments demonstrate that our method achieves robust performance across varying body shapes and motions, significantly outperforming SOTA IMU approaches with a 19.5\% improvement in angular error, a 26.4\% improvement in elbow angular error, and a 30.1\% improvement in positional error. FIP opens up opportunities for ubiquitous human-computer interactions and diverse interactive applications such as Metaverse, rehabilitation, and fitness analysis. Our project page can be seen at Flexible Inertial Poser.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {927},
numpages = {21},
keywords = {Motion Capture, Wearable Computers, Sensor Fusion},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713835,
author = {Vuong, Hoang and Torres, Cesar},
title = {RheoMap: Mapping Inks, Gels, Pastes, and Slurries within a Rheological Embedding Space using Retraction-Extrusion Pressure Sensor Vectors},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713835},
doi = {10.1145/3706598.3713835},
abstract = {Viscous materials such as inks, gels, pastes, and slurries are ubiquitous across domains like food science, smart materials, digital fabrication, and the arts. However, their dynamic and unpredictable behavior—shifting over time and in response to environmental factors—poses challenges, often requiring costly equipment for accurate rheological analysis. This paper presents a low-cost, accessible sensing routine that retracts and extrudes viscous materials through an air tube, generating sensor vectors rich in rheological data. By embedding data from 26 rheologically diverse materials into a two-dimensional space, we create RheoMaps that allow for tracking material changes over time, distinguishing concentrations, and tuning rheological behaviors. These maps offer practical benefits for detecting preparation errors, guiding material design and documentation, and providing tutorial waypoints. We further discuss how this approach can be extended to extract relational insights from sensor data, improving material literacy and manipulation across a range of applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {928},
numpages = {24},
keywords = {rheology, viscosity, material sensing, digital fabrication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713419,
author = {Teng, Shan-Yuan and Kim, Gene S-H and Liu, Xuanyou and Lopes, Pedro},
title = {Seeing with the Hands: A Sensory Substitution That Supports Manual Interactions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713419},
doi = {10.1145/3706598.3713419},
abstract = {Sensory-substitution devices enable perceiving objects by translating one modality (e.g., vision) into another (e.g., tactile). While many explored the placement of the haptic-output (e.g., torso, forehead), the camera's location remains largely unexplored—typically seeing from the eyes’ perspective. Instead, we propose that seeing \&amp; feeling information from the hands’ perspective could enhance flexibility \&amp; expressivity of sensory-substitution devices to support manual interactions with physical objects. To this end, we engineered a back-of-the-hand electrotactile-display that renders tactile images from a wrist-mounted camera, allowing the user's hand to feel objects while reaching \&amp; hovering. We conducted a study with sighted/Blind-or-Low-Vision participants who used our eyes vs. hand tactile-perspectives to manipulate bottles and soldering-irons, etc. We found that while both tactile perspectives provided comparable performance, when offered the opportunity to choose, all participants found value in also using the hands’ perspective. Moreover, we observed behaviors when “seeing with the hands” that suggest a more ergonomic object-manipulation. We believe these insights extend the landscape of sensory-substitution devices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {929},
numpages = {15},
keywords = {Blind, Electrotactile, Haptics, Sensory substitution, Wearable},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713369,
author = {Preindl, Thomas and Pointner, Andreas and Kumar, Nimal Jagadeesh and Cohen, Nitzan and M\"{u}nzenrieder, Niko and Haller, Michael},
title = {SqueezeMe: Creating Soft Inductive Pressure Sensors with Ferromagnetic Elastomers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713369},
doi = {10.1145/3706598.3713369},
abstract = {We introduce SqueezeMe, a soft and flexible inductive pressure sensor with high sensitivity made from ferromagnetic elastomers for wearable and embedded applications. Constructed with silicone polymers and ferromagnetic particles, this biocompatible sensor responds to pressure and deformation by varying inductance through ferromagnetic particle density changes, enabling precise measurements. We detail the fabrication process and demonstrate how silicones with varying Shore hardness and different ferromagnetic fillers affect the sensor’s sensitivity. Applications like weight, air pressure, and pulse measurements showcase the sensor’s versatility for integration into soft robotics and flexible electronics.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {930},
numpages = {13},
keywords = {Fabrication, Sensors, Tangible, Artifact or System, Prototyping/ Implementation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714132,
author = {Chen, Mengzhu (Katie) and Pedraza Pineros, Isabella and Satyanarayan, Arvind and Zong, Jonathan},
title = {Tactile Vega-Lite: Rapidly Prototyping Tactile Charts with Smart Defaults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714132},
doi = {10.1145/3706598.3714132},
abstract = {Tactile charts are essential for conveying data to blind and low vision (BLV) readers but are difficult for designers to construct. Non-expert designers face barriers to entry due to complex guidelines, while experts struggle with fragmented and time-consuming workflows that involve extensive customization. Inspired by formative interviews with expert tactile graphics designers, we created Tactile Vega-Lite (TVL): an extension of Vega-Lite that offers tactile-specific abstractions and synthesizes existing guidelines into a series of smart defaults. Predefined stylistic choices enable non-experts to produce guideline-compliant tactile charts quickly. Expert users can override defaults to tailor customizations for their intended audience. In a user study with 12 tactile graphics creators, we show that Tactile Vega-Lite enhances flexibility and consistency by automating tasks like adjusting spacing and translating braille while accelerating iterations through pre-defined textures and line styles. Through expert critique, we also learn more about tactile chart design best practices and design decisions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {931},
numpages = {23},
keywords = {Tactile Graphics, Accessible Data Visualization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713139,
author = {Feng, K. J. Kevin and Liao, Q. Vera and Xiao, Ziang and Wortman Vaughan, Jennifer and Zhang, Amy X. and McDonald, David W.},
title = {Canvil: Designerly Adaptation for LLM-Powered User Experiences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713139},
doi = {10.1145/3706598.3713139},
abstract = {Advancements in large language models (LLMs) are sparking a proliferation of LLM-powered user experiences (UX). In product teams, designers often craft UX to meet user needs, but it is unclear how they engage with LLMs as a novel design material. Through a formative study with 12 designers, we find that designers seek a translational process that enables design requirements to shape and be shaped by LLM behavior, motivating a need for designerly adaptation to facilitate this translation. We then built Canvil, a Figma widget that operationalizes designerly adaptation. We used Canvil as a probe to study designerly adaptation in a group-based design study (6 groups, N = 17), finding that designers constructively iterated on both adaptation approaches and interface designs to enhance end-user interaction with LLMs. Furthermore, designers identified promising collaborative workflows for designerly adaptation. Our work opens new avenues for processes and tools that foreground designers’ human-centered expertise when developing LLM-powered applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {932},
numpages = {22},
keywords = {large language models, user experience, design practice},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713408,
author = {Danry, Valdemar and Pataranutaporn, Pat and Groh, Matthew and Epstein, Ziv},
title = {Deceptive Explanations by Large Language Models Lead People to Change their Beliefs About Misinformation More Often than Honest Explanations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713408},
doi = {10.1145/3706598.3713408},
abstract = {Advanced Artificial Intelligence (AI) systems, specifically large language models (LLMs), have the capability to generate not just misinformation, but also deceptive explanations that can justify and propagate false information and discredit true information. We examined the impact of deceptive AI generated explanations on individuals’ beliefs in a pre-registered online experiment with 11,780 observations from 589 participants. We found that in addition to being more persuasive than accurate and honest explanations, AI-generated deceptive explanations can significantly amplify belief in false news headlines and undermine true ones as compared to AI systems that simply classify the headline incorrectly as being true/false. Moreover, our results show that logically invalid explanations are deemed less credible - diminishing the effects of deception. This underscores the importance of teaching logical reasoning and critical thinking skills to identify logically invalid arguments, fostering greater resilience against advanced AI-driven misinformation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {933},
numpages = {31},
keywords = {Deceptive Explanations, Explainable AI, Misinformation, Generative AI, Large Language Models, LLMs, Human-AI Interaction, Chatbot, Deception},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713327,
author = {Qin, Yigang and Li, Yanheng and Cheon, EunJeong},
title = {Encountering Robotic Art: The Social, Material, and Temporal Processes of Creation with Machines},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713327},
doi = {10.1145/3706598.3713327},
abstract = {Robots extend beyond the tools of productivity; they also contribute to creativity. While typically defined as utility-driven technologies designed for productive or social settings, the role of robots in creative settings remains underexplored. This paper examines how robots participate in artistic creation. Through semi-structured interviews with robotic artists, we analyze the impact of robots on artistic processes and outcomes. We identify the critical roles of social interaction, material properties, and temporal dynamics in facilitating creativity. Our findings reveal that creativity emerges from the co-constitution of artists, robots, and audiences within spatial-temporal dimensions. Based on these insights, we propose several implications for socially informed, material-attentive, and process-oriented approaches to creation with computing systems. These approaches can inform the domains of HCI, including media and art creation, craft, digital fabrication, and tangible computing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {934},
numpages = {18},
keywords = {Robotic Art, Robot, Art, Artist, Audience, Creativity, Sociality, Materiality, Temporality, Human-robot interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714316,
author = {Zhang, Chao and Ju, Kexin and Bidoshi, Peter and Yen, Yu-Chun Grace and Rzeszotarski, Jeffrey M.},
title = {Friction: Deciphering Writing Feedback into Writing Revisions through LLM-Assisted Reflection},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714316},
doi = {10.1145/3706598.3714316},
abstract = {This paper introduces Friction, a novel interface designed to scaffold novice writers in reflective feedback-driven revisions. Effective revision requires mindful reflection upon feedback, but the scale and variability of feedback can make it challenging for novice writers to decipher it into actionable, meaningful changes. Friction leverages large language models to break down large feedback collections into manageable units, visualizes their distribution across sentences and issues through a co-located heatmap, and guides users through structured reflection and revision with adaptive hints and real-time evaluation. Our user study (N = 16) showed that Friction helped users allocate more time to reflective planning, attend to more critical issues, develop more actionable and satisfactory revision plans, iterate more frequently, and ultimately produce higher-quality revisions, compared to the baseline system. These findings highlight the potential of human-AI collaboration to foster a balanced approach between maximum efficiency and deliberate reflection, supporting the development of creative mastery.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {935},
numpages = {27},
keywords = {Feedback, Reflection, Sensemaking, Writing, Revision, Creativity, Large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714327,
author = {Yang, Jackie (Junrui) and Shi, Yingtian and Gu, Chris and Zheng, Zhang and Jain, Anisha and Li, Tianshi and Lam, Monica S. and Landay, James A.},
title = {GenieWizard: Multimodal App Feature Discovery with Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714327},
doi = {10.1145/3706598.3714327},
abstract = {Multimodal interactions are more flexible, efficient, and adaptable than graphical interactions, allowing users to execute commands beyond simply tapping GUI buttons. However, the flexibility of multimodal commands makes it hard for designers to prototype and provide design specifications for developers. It is also hard for developers to anticipate what actions users may want. We present GenieWizard, a tool to aid developers in discovering potential features to implement in multimodal interfaces. GenieWizard supports user-desired command discovery early in the implementation process, streamlining the development process. GenieWizard uses an LLM to generate potential user interactions and parse these interactions into a form that can be used to discover the missing features for developers. Our evaluations showed that GenieWizard can reliably simulate user interactions and identify missing features. Also, in a study (N = 12), we demonstrated that developers using GenieWizard can identify and implement 42\% of the missing features of multimodal apps compared to only 10\% without GenieWizard.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {936},
numpages = {17},
keywords = {Multimodal interfaces, developer tools, large language models, feature discovery, interaction simulation, voice interfaces, touch interfaces, semantic parsing, multimodal app development},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713201,
author = {Biswas, Shreyan and Erlei, Alexander and Gadiraju, Ujwal},
title = {Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713201},
doi = {10.1145/3706598.3713201},
abstract = {Recent advances in generative AI have precipitated a proliferation of novel writing assistants. These systems typically rely on multilingual large language models (LLMs), providing globalized workers the ability to revise or create diverse forms of content in different languages. However, there is substantial evidence indicating that the performance of multilingual LLMs varies between languages. Users who employ writing assistance for multiple languages are therefore susceptible to disparate output quality. Importantly, recent research has shown that people tend to generalize algorithmic errors across independent tasks, violating the behavioral axiom of choice independence. In this paper, we analyze whether user utilization of novel writing assistants in a charity advertisement writing task is affected by the AI’s performance in a second language. Furthermore, we quantify the extent to which these patterns translate into the persuasiveness of generated charity advertisements, as well as the role of peoples’ beliefs about LLM utilization for their donation choices. Our results provide evidence that writers who engage with an LLM-based writing assistant violate choice independence, as prior exposure to a Spanish LLM reduces subsequent utilization of an English LLM. While these patterns do not affect the aggregate persuasiveness of the generated advertisements, people’s beliefs about the source of an advertisement (human versus AI) do. In particular, Spanish-speaking female participants who believed that they read an AI-generated advertisement strongly adjusted their donation behavior downwards. Furthermore, people are generally not able to adequately differentiate between human-generated and LLM-generated ads. Our work has important implications on the design, development, integration, and adoption of multilingual LLMs as assistive agents—particularly in writing tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {937},
numpages = {20},
keywords = {Human-AI interaction, Choice Independence, Multilingual LLMs, User Reliance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714068,
author = {Li, Isabel and Chen, Ace S. and Rawn, Eric and Almeda, Shm Garanganao and Hartmann, Bjoern and Li, Jingyi},
title = {Reimagining Misuse as Creative Practice: Impressions and Implications of Usage Norms on Digital Artists},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714068},
doi = {10.1145/3706598.3714068},
abstract = {Digital artists use creativity support tools guided by their ideas of “intended use” and therefore “misuse”—but what does misuse mean in creative practice? To discover what constitutes misuse and what creative contexts call for misuse, we interviewed 20 expert creative practitioners across eight visual art disciplines. We identify five sources of normativity which form conventions of misuse: traditional practices, educational institutions, industry norms, online communities, and tools themselves. We surface why artists defy norms and misuse creative software by exploring how software apathy affects tool engagement, how tool genealogies and personal histories impact artists’ practices, and how artists prioritize practical and professional needs during the creative process. Alongside traditional definitions, we offer artists’ individual perspectives on what misuse means and its relevance to their creative practice. By understanding artists as “mis-users,” we present an opportunity to revise how we design for using and misusing creativity support tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {938},
numpages = {14},
keywords = {misuse, interpretive frameworks, creativity support tools, visual art},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713138,
author = {Cila, Nazli and Lupetti, Maria Luce and Cavalcante Siebert, Luciano and van Grunsven, Janna},
title = {Dramatic Things: Investigating Value Conflicts in Smart Home through Enactment and Co-speculation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713138},
doi = {10.1145/3706598.3713138},
abstract = {Smart home technologies embed values such as sustainability, comfort, privacy, and security, which can sometimes conflict with one another, considering the complexities of domestic environments. This paper investigates the potential implications of these value conflicts and the corresponding design challenges. Through an enactment session and co-speculations with professional actors, we explored what it means to navigate multiple values simultaneously, live with products that impose their own values, and manage value conflicts both with and among smart products. The findings challenge the seamless and harmonious vision of smart homes conceived by technologists, proposing shifts in the common narrative: from value alignment to value transparency, from service provision to mutual care, and from autonomy to responsiveness. We discuss that acknowledging value conflicts, rather than eliminating them, is an opportunity to gain a deeper understanding of users and home environments and guide the design of smart home technologies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {939},
numpages = {17},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713494,
author = {Wang, Ge and Zhao, Jun and Van Kleek, Max and Pea, Roy and Shadbolt, Nigel},
title = {FamiData Hub: A Speculative Design Exploration with Families on Smart Home Datafication},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713494},
doi = {10.1145/3706598.3713494},
abstract = {Smart home technologies are becoming increasingly common in households with children. While privacy and security concerns have been widely discussed, a critical issue often overlooked is the extensive data harvesting embedded in these smart homes and its manipulative impact on children through algorithmic decision-making. In this paper, we introduce FamiData Hub, a speculative prototype designed to empower families to navigate the datafication of smart homes. Through 17 study sessions—including speculative interviews followed by co-design activities—with 30 children and 25 parents, we found that families face challenges related to smart home datafication, such as the erosion of boundaries in family spaces, loss of control over family norms, and diminished autonomy in data-driven decision-making processes. Our findings offer key design recommendations for rethinking smart home technologies to better safeguard children’s data, advocating for respectful, family-centered approaches that challenge the normalization of datafication in domestic life.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {940},
numpages = {17},
keywords = {Children, Smart Home, Datafication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713712,
author = {Zhang-Kennedy, Leah and Valiquette, Michaela and Chen, An Bella and Hadan, Hilda and Suh, Sangho},
title = {Folk Tales of IoT: Understanding the Impact of Stories on Users' Positive and Negative Perceptions of Smart Home IoT Devices},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713712},
doi = {10.1145/3706598.3713712},
abstract = {This study examines how anecdotal stories from friends, peers, and online sources influence non-experts’ perceptions and behaviors toward smart home IoT devices. We surveyed 263 participants, collecting narratives that either positively or negatively influenced their perception of IoT devices, which they retold in text and comic formats to encourage deeper reflection. Thematic analysis of the narratives, combined with quantitative survey data, reveals that stories significantly impact trust and willingness to use and adopt IoT devices. Negative stories, particularly those concerning security, privacy, and device unreliability, reduced trust and usage, while positive stories about home safety through monitoring and improved quality of life increased interest in IoT devices. Perceptions of different IoT devices varied based on the themes associated with the stories. The findings highlight the powerful role of storytelling in driving consumer acceptance of technology.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {941},
numpages = {18},
keywords = {Smart Home, Internet of Things, Privacy and Security, Stories, Technology Acceptance, Mental Models, Folk Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713517,
author = {Windl, Maximiliane and Thalhammer, Philipp and M\"{u}ller, David and Schmidt, Albrecht and Feger, Sebastian S.},
title = {PrivacyHub: A Functional Tangible and Digital Ecosystem for Interoperable Smart Home Privacy Awareness and Control},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713517},
doi = {10.1145/3706598.3713517},
abstract = {Hubs are at the core of most smart homes. Modern cross-ecosystem protocols and standards enable smart home hubs to achieve interoperability across devices, offering the unique opportunity to integrate universally available smart home privacy awareness and control features. To date, such privacy features mainly focus on individual products or prototypical research artifacts. We developed a cross-ecosystem hub featuring a tangible dashboard and a digital web application to deepen our understanding of how smart home users interact with functional privacy features. The ecosystem allows users to control the connectivity states of their devices and raises awareness by visualizing device positions, states, and data flows. We deployed the ecosystem in six households for one week and found that it increased participants’ perceived control, awareness, and understanding of smart home privacy. We further found distinct differences between tangible and digital mechanisms. Our findings highlight the value of cross-ecosystem hubs for effective privacy management.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {942},
numpages = {15},
keywords = {human-computer interaction, smart home privacy, tangible privacy, smart home dashboard, privacy awareness, privacy control},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714231,
author = {Ye, Junjian and de Carn\'{e} de Carnavalet, Xavier and Zhao, Lianying and Wu, Lifa and Zhang, Mengyuan},
title = {Understanding Home Router Configuration Habits \&amp; Attitudes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714231},
doi = {10.1145/3706598.3714231},
abstract = {Home routers serve as a gateway to the Internet and configuration issues such as weak passwords can simply be introduced by users that configured them, potentially leading to severe consequences. The most critical phase in the lifecycle of a home router is perhaps the initial setup intended for users to complete. Yet, the mindset and behavior of users during this process remain under-explored. In a comprehensive online survey of 392 participants across several regions, we find that router settings and user behavior vary significantly between China and English-speaking countries, influenced by factors like IT background, age, gender, and education. A majority of participants go through the configuration of their own routers, but many also admit keeping the default settings and are not actively maintaining their router firmware up-to-date, leaving security vulnerabilities unfixed. We estimate that 91\% of participant routers run with default settings, which should push router manufacturers to focus on safe defaults. Moreover, while default passwords are often changed, some participants report coping strategies. With noteworthy differences that we have observed across user backgrounds, we believe that our takeaways can shed some light on advancing the area of home network security.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {943},
numpages = {12},
keywords = {Home router security, configuration habits, password selection, automatic updates},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713903,
author = {Rao, Shruti and Rogers, Katja and Good, Judith and Alavi, Hamed},
title = {What Do We Design for When We Design "Smart Buildings"? - A Scoping Review of Human Experience Design Research in Buildings},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713903},
doi = {10.1145/3706598.3713903},
abstract = {Built environments increasingly incorporate new forms of intelligence, creating opportunities for enhancing human interactive experiences with and within building spaces. This scoping review examines design interventions and discourses within the domain of “Smart Buildings”. The goal is to identify and characterise the type of human experiences that research in this domain aims to address. Using a hybrid deductive-inductive coding approach, we analysed 192 papers related to human experiences and smart buildings from ACM Digital Library and Scopus published between 1996 and 2024. Our analysis revealed 11 distinct “targeted human experiences”, 20 commonly used “design mechanisms” to achieve those design goals, as well as two typologies of “technological interventions”. Our findings create a foundation for understanding building design research and the range of human experience they entail.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {944},
numpages = {23},
keywords = {scoping review, smart building, human experience, user experience, interaction design, interactive technologies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713265,
author = {Yun, Sojeong and Lim, Youn-kyung},
title = {What If Smart Homes Could See Our Homes?: Exploring DIY Smart Home Building Experiences with VLM-Based Camera Sensors},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713265},
doi = {10.1145/3706598.3713265},
abstract = {The advancement of Vision-Language Model (VLM) camera sensors, which enable autonomous understanding of household situations without user intervention, has the potential to completely transform the DIY smart home building experience. Will this simplify or complicate the DIY smart home process? Additionally, what features do users want to create using these sensors? To explore this, we conducted a three-week diary-based experience prototyping study with 12 participants. Participants recorded their daily activities, used GPT to analyze the images, and manually customized and tested smart home features based on the analysis. The study revealed three key findings: (1) participants’ expectations for VLM camera-based smart homes, (2) the impact of VLM camera sensor characteristics on the DIY process, and (3) users’ concerns. Through the findings of this study, we propose design implications to support the DIY smart home building process with VLM camera sensors, and discuss living with intelligence.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {945},
numpages = {22},
keywords = {DIY, smart home, home sensor, VLM, vision sensing, camera sensor, user experience},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713645,
author = {Smith, Garrett and Chapman, Kirsten and Weng, Tzu-Yu and Hao, Haijing and Mondal, Mainack and Smith, Staci and Chen, Yunan and Page, Xinru},
title = {A House Divided: How U.S. Politics Could Shape Contact-Tracing Adoption in Future Pandemics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713645},
doi = {10.1145/3706598.3713645},
abstract = {Contact tracing has shown to be an effective tool in limiting the spread of transmittable diseases in countries where it is widely adopted. During the COVID-19 pandemic, contact tracing app adoption in the United States was low despite having the highest number of  recorded cases worldwide. To better understand why, we conducted a survey (N=302, matched to U.S. census demographics) and found that political orientation overwhelmingly predicted attitudes towards COVID-19 and the adoption of contact tracing apps. These attitudes also overwhelmingly shaped people’s willingness to participate in contact tracing for diseases in future pandemics. Our findings suggest that the politically charged environment surrounding COVID-19 in the U.S. may have a long-term impact on American’s willingness to utilize contact tracing for diseases in future pandemics. We conclude with recommendations for technology designers and policymakers on how to overcome the sharp divide that has been driven by the political discourse in the U.S.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {946},
numpages = {20},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713266,
author = {Thuppilikkat, Ashique Ali and Dhar, Dipsita and Raval, Noopur and Chandra, Priyank},
title = {Generative Politics and Labour Markets: Unions and Collective Life in a City in Crisis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713266},
doi = {10.1145/3706598.3713266},
abstract = {The COVID-19 pandemic temporarily disrupted the operations of on-demand ride-sourcing digital labour platforms like Uber and Ola, severely impacting gig workers’ labour opportunities. In response, the Kolkata Ola-Uber App-Cab Operator and Drivers Union in West Bengal, India, mobilised an alternate socio-technical infrastructure by operating emergency transport and taxi ambulance services. Our ethnographic study explores how this initiative leveraged technologies to structure and coordinate hybrid sites of action and ‘generate’ a labour market without profit motive to support the public health infrastructure. Our paper highlights the significance of what we call the gig worker union’s ‘generative politics’ in creating resources to support workers and citizens, facilitating political action beyond protest politics, contributing to new counter-hegemonic formations, and shaping collective action centered around regeneration and care for the city and life under capitalism. We contribute to the HCI literature by offering insights to design alternate and participatory socio-technical infrastructures that challenge the hegemony of digital labour platforms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {947},
numpages = {18},
keywords = {Digital labour, Gig work, Urban HCI, Crisis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714299,
author = {Breda, Joseph and Campos Zamora, Daniel and Patel, Shwetak and Froehlich, Jon E.},
title = {NightLight: Passively Mapping Nighttime Sidewalk Light Data for Improved Pedestrian Routing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714299},
doi = {10.1145/3706598.3714299},
abstract = {Nighttime sidewalk illumination has a significant and unequal influence on where and whether pedestrians walk at night. Despite the importance of pedestrian lighting, there is currently no approach for measuring and communicating how humans experience nighttime sidewalk light levels at scale. We introduce NightLight, a new sensing approach that leverages the ubiquity of smartphones by re-appropriating the built-in light sensor—traditionally used to adapt screen brightness—to sense pedestrian nighttime lighting conditions. We validated our technique through in-lab and street-based evaluations characterizing performance across phone orientation, phone model, and varying light levels demonstrating the ability to aggregate and map pedestrian-oriented light levels with unaltered smartphones. Additionally, to examine the impact of light level data on pedestrian route choice, we conducted a qualitative user study with 13 participants using a standard map vs. one with pedestrian lighting data from NightLight. Our findings demonstrate that people changed their routes in preference of well-light routes during nighttime walking. Our work has implications for improving personalized navigation, understanding pedestrian route choice, and expanding passive urban sensing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {948},
numpages = {13},
keywords = {Ambient Light, Pedestrian, Urban Informatics, Navigation, Mobile Sensing, Passive Sensing, Middleware},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713643,
author = {Chaudhary, Akash and Escobar, Stefany Arevalo and Zayas, Dulce and Su, Norman Makoto},
title = {Normalizing Grit: The Futility of Personal Informatics for Farm Workers and Climate Change},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713643},
doi = {10.1145/3706598.3713643},
abstract = {California’s agricultural workers are a vulnerable population due to their undocumented status and poor working conditions. This paper describes community engagement with NGO workers, farm laborers, and farm owners to identify and address the effects of climate change, namely heat stress, on, strawberry field workers. We deployed personal informatics devices in a longitudinal study with three field workers for a month and a half and presented the collected statistics back to them, asking them to reflect on their personal health (e.g., exposure to heat stress) and work data. We found that field workers normalized grit - the irregularity, adversity, competitiveness, and helplessness of their labor - thereby limiting the promise of personal informatics to help users lead healthier lives. Implicitly, personal informatics supports white collar workers such as information workers; overall, however, our study suggests a mismatch between current designs and front-line work which involve intensive physical work requirements.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {949},
numpages = {17},
keywords = {Farm work, Front-line workers, Personal informatics, Reflective design, Climate change, Heat stress},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713261,
author = {Razaq, Lubna and Ghoshal, Sucheta},
title = {The Role of ICTs in the Maintenance and Reproduction of Digital Border Assemblages},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713261},
doi = {10.1145/3706598.3713261},
abstract = {In this paper, we extend the Digital Border Assemblages framework (DBA) by locating the role of ICTs in enabling means of racialized control at geographical boundaries or borders. Applying a critical-interpretive approach, we identify key features of DBA that contribute to such racial formations. We analyze three case studies of border technologies deployed at and beyond physical sites of border control: electronic device inspections, electronic location monitoring, and restricted transactions in financial technologies. Although a framework of DBA exists in the current paradigm of border studies, we argue that a close examination of the entanglements between borders and ICTs offers us key insights into how migrant bodies are subjected to racialized control at/by the border. Implications for HCI researchers include studying the experiences of those impacted by this assemblage and developing methods inspired by the legal field for studying these obscure systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {950},
numpages = {17},
keywords = {migration, surveillance, ICTs, digital border assemblages, case studies, digital borders, race and privacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713593,
author = {Jo, Eunkyung and Kim, Young-Ho and Ok, Sang-Houn and Epstein, Daniel A.},
title = {Understanding Public Agencies' Expectations and Realities of AI-Driven Chatbots for Public Health Monitoring},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713593},
doi = {10.1145/3706598.3713593},
abstract = {Advances in artificial intelligence (AI) offer the potential for chatbots to support public health monitoring by automating tasks traditionally performed by frontline workers. While introducing AI impacts public agency workers across decision-making, administration, and monitoring roles, the perceptions of workers regarding these technologies and their actual impact on labor are underexplored. We examine the case of CareCall, a large language model (LLM)-driven chatbot used to monitor socially isolated individuals, by interviewing 21 public agency workers across 13 sites involved in its adoption and rollout. We find that CareCall helped expand public reach but increased burdens on frontline workers due to insufficient resources and new labor demands, such as handling lapses in user engagement. We discuss how implementing LLM-driven chatbots in public health contexts can complicate decision-makers’ articulation work and impose additional maintenance work on frontline workers. We recommend AI chatbots in this space leverage public infrastructure and incorporate fallback mechanisms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {951},
numpages = {17},
keywords = {Chatbot, Large language models, Public sector AI, Public health monitoring, Social isolation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714250,
author = {Singh, Anubha and Garcia, Patricia and Chandra, Priyank},
title = {What's in a Place? On Platformization of Traditional Agricultural Marketplaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714250},
doi = {10.1145/3706598.3714250},
abstract = {In this paper, we pay ethnographic attention to the failed attempts at platformization of agricultural trade in one of Asia’s largest onion markets, located in rural western Maharashtra. We focus on e-NAM, or the electronic National Agricultural Market, a state-sponsored digital trading platform intended to create a transparent, efficient, and frictionless online national agricultural market by collapsing geographical barriers of traditional marketplaces, commonly known as mandis. We found that despite e-NAM’s intended benefits, mandis continue to be the preferred mode of transaction for trading agricultural commodities. We demonstrate that these two agricultural marketplaces foster different meanings of information transparency, efficiency, and participation among stakeholders. In agrarian societies dominated by smallholder farmers, such as India, social collectives and non-economic relationships are crucial for providing safety and risk mitigation when dealing with perishable commodities like onions. We argue that e-NAM fails because its digital intermediation prioritizes an ahistorical and depoliticized free-market approach, which treats farmers (and traders) as independent units driven solely by the economic logic of demand and supply, disconnecting them from their historical and political agrarian social class.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {952},
numpages = {16},
keywords = {Agricultural Marketplaces, Platforms, Auctions, Digital Agriculture},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713901,
author = {Fischer, Katrin and Xie, Louise and Arnold, Lauren Jade and Stevens, Robin},
title = {Building a Better Social Media Platform: Can We Codesign With Equity in Mind?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713901},
doi = {10.1145/3706598.3713901},
abstract = {Adolescents are frequent users of social media, with research suggesting both potential harms and positive impacts from use. Black and Hispanic/Latinx youth in particular are both early adopters and high users of social media platforms. However, adolescents–and youth of color in particular–have relatively little say in the design of such platforms. We propose youth participatory action research (YPAR) as a model for informing co-design sessions with representatives of a social networking platform to develop community-building solutions and improve youth developmental outcomes. In a four-months-long study with Black and Hispanic/Latinx teens aged 14-17 (n = 14), we examined how their sense of engagement and efficacy were altered by actively leading, participating in and contributing to design exercises facilitated by Instagram, one of the world’s largest social media sites. Results of pre- and post- surveys indicated a significant increase in teens’ civic engagement as well as leadership efficacy. Our results contribute to the understanding of teenagers’ expectations and attitudes toward social media and how participatory methods for achieving equity in design can affect change. Theoretical and practical implications are discussed.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {953},
numpages = {10},
keywords = {co-design, social media, efficacy, teens, youth participatory action research, community-based participatory research, digital organizing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713592,
author = {Steeds, Madeleine and Clinch, Sarah and Are, Carolina and Brown, Genavee and Dalton, Ben and Webster, Lexi and Wilson, Alice and Woolley, Dawn},
title = {Queer Joy on Social Media: Exploring the Expression and Facilitation of Queer Joy in Online Platforms},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713592},
doi = {10.1145/3706598.3713592},
abstract = {Queer Joy is conceptualised as a form of resistance to oppression by celebrating queerness in the face of adversity. This research aimed to centre queer joy and understand how it is expressed and may be facilitated in online spaces. To do this we conducted a survey with 100 UK participants who indicated they identified as LGBTQ+ on the online recruitment platform Prolific. We asked a series of open and closed questions in an online survey to investigate 1) what queer joy looks like on social media 2) how queer joy content is engaged with on social media 3) which platforms are perceived to facilitate queer joy and 4) how queer people protect their privacy online. The results suggested that to facilitate queer joy online, platforms should allow flexible self expression and community engagement, while allowing for granular control over privacy and the audience such content is shown to.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {954},
numpages = {19},
keywords = {queer, joy, social media, lgbtq+},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713136,
author = {Kender, Kay and Spiel, Katta},
title = {Social Media as Marginalisation Machine: The Trans Desire for Solidarity Spaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713136},
doi = {10.1145/3706598.3713136},
abstract = {As a marginalised group at increased risk of violence, trans people’s perspectives on social media aid us in a nuanced understanding of current issues and consideration of more just futures. We conducted in-depth design interviews along participatory speculative activities around a utopian social media application with seven young trans participants to explore desirable and meaningful social media. Participants reported experiences of algorithmic and other forms of violence, and discussed frictions between safety and freedom as they described their embodied experiences of shifting spaces. We identify scale, commercialisation and automation as core issues, and challenge the potential of large-public, profile-centric social media spaces to support human flourishing. Drawing from aspects of social media participants consider desirable and meaningful, we discuss the idea of a shift towards interest-centric, community-oriented spaces that prioritise interactions based on solidarity over those based on identity.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {955},
numpages = {17},
keywords = {Social media, third places, transgender, LGBTQ, neurodivergence, speculative participatory design, design interviews.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713351,
author = {Luther, Anna Ricarda and Heuer, Hendrik and Geise, Stephanie and Haunss, Sebastian and Breiter, Andreas},
title = {Social Media for Activists: Reimagining Safety, Content Presentation, and Workflows},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713351},
doi = {10.1145/3706598.3713351},
abstract = {Social media is central to activists, who use it internally for coordination and externally to reach supporters and the public. To date, the HCI community has not explored activists’ perspectives on future social media platforms. In interviews with 14 activists from an environmental and a queer-feminist movement in Germany, we identify activists’ needs and feature requests for future social media platforms. The key finding is that on- and offline safety is their main need. Based on this, we make concrete proposals to improve safety measures. Increased control over content presentation and tools to streamline activist workflows are also central to activists. We make concrete design and research recommendations on how social media platforms and the HCI community can contribute to improved safety and content presentation, and how activists themselves can reduce their workload.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {956},
numpages = {18},
keywords = {Social Media, Activism, Safety, Algorithmic Curation, User Agency, Artificial Intelligence, Qualitative Methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713813,
author = {Jungselius, Beata and Weilenmann, Alexandra},
title = {Tracing Change in Social Media Use: A Qualitative Longitudinal Study},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713813},
doi = {10.1145/3706598.3713813},
abstract = {This study reveals a significant shift in how users perceive and engage with social media over time. Our analysis is based on qualitative longitudinal research carried out over ten years, involving a small group of participants in 2012, 2017, and 2022. Semi-structured, in-depth interviews were conducted using stimulated recall allowing for retrospection and reflection. Through this methodology, we trace the shifting perceptions of social media users, from initially embracing these platforms for quick, fun, and social activities, to later recognizing their potential intrusiveness and seeking strategies to manage their use. We outline three central trajectories that illustrate shifts in social media use across time: from public performance to private interaction, from producing to consuming and from fun to problematic. For HCI and social media studies, these findings underscore the need to prioritize user agency, ethical design practices, and longitudinal research endeavors to understand the evolving impacts of social media.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {957},
numpages = {14},
keywords = {Longitudinal, QLR, Qualitative methods, Social media, Social media use, Understanding people},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713263,
author = {Guan, Maggie Yongqi and Yu, Yaman and Wang, Kanye Ye},
title = {Using Affordance to Understand Usability of Web3 Social Media},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713263},
doi = {10.1145/3706598.3713263},
abstract = {Web3 social media refers to a new generation of platforms built on decentralized technologies, particularly blockchain. Although academia has investigated the newly emerging Web3 social media, it is not clear how users perceive the usability of such platforms and how these perceptions are influenced by the inherent characteristics of Web3. To address this gap, we utilize affordance theory to explore the unique usability of Web3 social media compared with Web2 social media. We conducted interviews with 32 participants who are experienced with Web3 social media and examined the affordances of Web3 social media from the perspectives of content creation, content consumption, and community interaction. We further discuss the correlation between the usability of Web3 social media and the underlying decentralized technology, and provide design implications for enhancing the usability of this new type of social interaction platform.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {958},
numpages = {19},
keywords = {Social media, affordance, usability, Web3, blockchain},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714126,
author = {Wang, Chun-Han Ariel and Kaziunas, Elizabeth and Chung, Chia-Fang},
title = {“It's Too Much On Top of Your Own Food Drama”: Exploring Food Allergy Identity and Experience Through Social Media},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714126},
doi = {10.1145/3706598.3714126},
abstract = {This paper provides an in-depth view of people’s experiences with food allergies, focusing on their social media use and its influences on healthy habits and identities. Through 18 interviews, our study examined how information and identity work on social media influences health behaviors, social interactions, self-expression, and navigation of algorithms for those with food allergies. Social media functions as both a source of empowerment and community and a platform for stigma and emotional distress. Our findings highlight how individuals manage their food allergy identity and online visibility on algorithm-driven platforms. The concept of “on-and-off identities” is introduced to capture this complex identity work. Design considerations for HCI include: 1) creating mindful social media experiences that support agency while addressing vulnerability in identity and information work, and 2) reflections on the challenges of evolving health contexts and social media ecologies. We urge HCI researchers and designers to adopt a holistic perspective on identity and information work to better support marginalized populations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {959},
numpages = {18},
keywords = {food allergies; social media; health; food; identity work},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713094,
author = {Bennett, Dan and Feng, Feng and Mekler, Elisa D.},
title = {Autonomous Regulation of Social Media Use: Implications for Self-control, Well-Being, and UX},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713094},
doi = {10.1145/3706598.3713094},
abstract = {Much work in HCI has investigated strategies for supporting autonomous self-regulation in social media use (SMU): helping users to control their time online and ensure it serves personally valued outcomes. However, results suggest that the effectiveness and acceptability of these strategies may vary based on individual needs. Recent work has attributed this variation to motivational factors, though we currently lack data to understand how these factors influence self-regulation, user experience and well-being. We draw on Self-Determination Theory to analyse autonomous and non-autonomous patterns of motivation in 521 users of social media. Using latent profile analysis, we identify 4 “motivational profiles” associated with significant differences in need satisfaction, affect, and compulsive engagement. Our results clarify distinct aspects of autonomy in SMU and identify opportunities to target and personalise design interventions; they suggest autonomous regulation can be associated with better experience and well-being, though not necessarily less time online.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {960},
numpages = {22},
keywords = {motivation, self-regulation, social-media, self-control, autonomy, self-determination theory, organismic integration theory, internalisation, amotivation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714243,
author = {Tanaka, Yuko and Arai, Hiromi and Inuzuka, Miwa and Takahashi, Yoichi and Kukita, Minao and Iseki, Ryuta and Inui, Kentaro},
title = {Beyond Click to Cognition: Effective Interventions for Promoting Examination of False Beliefs in Misinformation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714243},
doi = {10.1145/3706598.3714243},
abstract = {In the digital information ecosystem, clicks serve as a crucial gateway to fact-checking, yet the essential challenge extends beyond this to fostering cognitive shifts that update entrenched false beliefs. This study investigates effective interventions aimed at encouraging users vulnerable to misinformation, particularly those who tend to avoid incongruent facts, to examine their false beliefs. We conducted an online experiment with 627 participants, comparing metacognitive and ranking interventions. Both interventions successfully improved click behavior, with the metacognitive intervention increasing belief-examining clicks by 14 percentage points and the ranking intervention by 33 percentage points. However, only the metacognitive intervention significantly promoted users’ examination of misinformation. This finding underscores the importance of interventions that go beyond merely influencing easily measurable clicks to facilitating thoughtful engagement with fact-checking content. We discuss implications for designing strategies to enhance online fact-checking engagement and mitigate misinformation’s societal impact.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {961},
numpages = {18},
keywords = {Misinformation, Click Behavior, Fact-checking, Cognitive Change, Metacognition},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713909,
author = {Chuai, Yuwei and Sergeeva, Anastasia and Lenzini, Gabriele and Pr\"{o}llochs, Nicolas},
title = {Community Fact-Checks Trigger Moral Outrage in Replies to Misleading Posts on Social Media},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713909},
doi = {10.1145/3706598.3713909},
abstract = {Displaying community fact-checks is a promising approach to reduce engagement with misinformation on social media. However, how users respond to misleading content emotionally after community fact-checks are displayed on posts is unclear. Here, we employ quasi-experimental methods to causally analyze changes in sentiments and (moral) emotions in replies to misleading posts following the display of community fact-checks. Our evaluation is based on a large-scale panel dataset comprising N = 2225260 replies across 1841 source posts from X’s Community Notes platform. We find that informing users about falsehoods through community fact-checks significantly increases negativity (by 7.3\%), anger (by 13.2\%), disgust (by 4.7\%), and moral outrage (by 16.0\%) in the corresponding replies. These results indicate that users perceive spreading misinformation as a violation of social norms and that those who spread misinformation should expect negative reactions once their content is debunked. We derive important implications for the design of community-based fact-checking systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {962},
numpages = {23},
keywords = {Misinformation, fact-checking, social media, crowdsourcing, online emotions, moral outrage},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713131,
author = {Devasia, Nisha and Zhao, Runhua and Lee, Jin Ha},
title = {Does the Story Matter? Applying Narrative Theory to an Educational Misinformation Escape Room Game},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713131},
doi = {10.1145/3706598.3713131},
abstract = {Rapid spread of harmful misinformation has led to a dire need for effective media literacy interventions, to which educational games have been suggested as a possible solution. Researchers and educators have created several games that increase media literacy and resilience to misinformation. However, the existing body of misinformation education games rarely focus upon the socio-emotional influences that factor into misinformation belief. Misinformation correction and serious games have both explored narrative as a method to engage with people on an emotional basis. To this end, we investigated how 123 young adults (mean age = 22.98) experienced narrative transportation and identification in two narrative-centered misinformation escape room games developed for library settings. We found that propensity for certain misinformation contexts, such as engagement with fan culture and likelihood to share on social media platforms, significantly affected how participants experienced specific measures of narrative immersion within the games. We discuss design implications for tailoring educational interventions to specific misinformation contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {963},
numpages = {15},
keywords = {Misinformation, Education, Escape room game, Narrative theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713187,
author = {Meinhardt, Luca-Maxim and Elhaidary, Maryam and Colley, Mark and Rietzler, Michael and Rixen, Jan Ole and Purohit, Aditya Kumar and Rukzio, Enrico},
title = {Scrolling in the Deep: Analysing Contextual Influences on Intervention Effectiveness during Infinite Scrolling on Social Media},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713187},
doi = {10.1145/3706598.3713187},
abstract = {Infinite scrolling on social media platforms is designed to encourage prolonged engagement, leading users to spend more time than desired, which can provoke negative emotions. Interventions to mitigate infinite scrolling have shown initial success, yet users become desensitized due to the lack of contextual relevance. Understanding how contextual factors influence intervention effectiveness remains underexplored. We conducted a 7-day user study (N=72) investigating how these contextual factors affect users’ reactance and responsiveness to interventions during infinite scrolling. Our study revealed an interplay, with contextual factors such as being at home, sleepiness, and valence playing significant roles in the intervention’s effectiveness. Low valence coupled with being at home slows down the responsiveness to interventions, and sleepiness lowers reactance towards interventions, increasing user acceptance of the intervention. Overall, our work contributes to a deeper understanding of user responses toward interventions and paves the way for developing more effective interventions during infinite scrolling.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {964},
numpages = {17},
keywords = {infinite scrolling, digital interventions, context-aware, field study, longitudinal study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713098,
author = {Gunasekara, Suwani and Pareek, Saumya and Kelly, Ryan M. and Goncalves, Jorge},
title = {The Influence of Content Modality on Perceptions of Online Misinformation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713098},
doi = {10.1145/3706598.3713098},
abstract = {Social media has become a primary information source, with platforms evolving from text-based to multi-modal environments that include images and videos. While richer media modalities enhance user engagement, they also increase the spread and perceived credibility of misinformation. Most interventions to counter misinformation on social media are text-based, which may lack the persuasive power of richer modalities. This study explores whether the effectiveness of misinformation correction varies by modality, and if certain modalities of misinformation are better countered by a specific correction modality. We conducted a survey-based experiment where participants rated the credibility of misinformation tweets before and after exposure to corrections, across all combinations of text, images and video modalities. Our findings suggest that corrections are most effective when their modality richness matches that of the original misinformation. We discuss factors affecting the perceived credibility of corrections and offer strategies to optimise misinformation correction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {965},
numpages = {10},
keywords = {Misinformation, Content Modality, Corrections, Social Media},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713516,
author = {Sharevski, Filipo and Vander Loop, Jennifer and Jachim, Peter and Devine, Amy and Pieroni, Emma},
title = {User Experiences with Abortion Misinformation on TikTok: Encounters, Assessment Strategies, and Response},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713516},
doi = {10.1145/3706598.3713516},
abstract = {Studying health-related misinformation, so far, has mostly focused on general “fearmongering” content spread on social media. The Supreme Court’s overturn of Roe v. Wade highlighted the need to study abortion misinformation as health-related content that could have criminal implications for users. In response to this need, we conducted a study with 60 TikTok users about the way they conceptualize, assess, and respond to misleading abortion videos. Half of our participants saw political intent behind the spread of health-related misinformation driven towards a “fear of criminalization.” Prior to Roe v. Wade, our participants encountered videos discussing the legal ramifications of abortion, but post-Roe v. Wade, they saw videos suggesting herbal alternative treatments for pregnancy termination. Roughly 30\% of our participants believed in the safety and efficacy of these otherwise scientifically debunked “alternative abortion treatments,” even in the presence of a debunking label attached to a self-administering abortion video.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {966},
numpages = {18},
keywords = {Misinformation, Mental Health, TikTok, Moderation, Labels, Stigmatization, Politicization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713988,
author = {De, Ankolika},
title = {"Business on WhatsApp is tough now-- but am I really a businesswoman?" Exploring Challenges with Adapting to Changes in WhatsApp Business},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713988},
doi = {10.1145/3706598.3713988},
abstract = {This study examines how WhatsApp has evolved from a personal communication tool to a professional platform, focusing on its use by small business owners in India. Initially embraced in smaller, rural communities for its ease of use and familiarity, WhatsApp played a crucial role in local economies. However, as Meta introduced WhatsApp Business with new, formalized features, users encountered challenges in adapting to the more complex and costly platform. Interviews with 14 small business owners revealed that while they adapted creatively, they felt marginalized by the advanced tools. This research contributes to HCI literature by exploring the transition from personal to professional use and introduces the concept of Coercive Professionalization. It highlights how standardization by large tech companies affects marginalized users, exacerbating power imbalances and reinforcing digital colonialism, concluding with design implications for supporting community-based appropriations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {967},
numpages = {18},
keywords = {Infrastructure, Appropriation, Global South, Mobile Phones, Decoliniality, WhatsApp},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713119,
author = {Lee, Yeuk Yu and Bellini, Rosanna},
title = {In the Balance: Insights from Collaborative Financial Technologies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713119},
doi = {10.1145/3706598.3713119},
abstract = {Financial technologies have reshaped how many individuals manage daily financial activities, introducing new ways to interact with traditional financial products. Given the swift adoption of these technologies, shared language and conceptual frameworks are needed to better represent emerging methods of financial collaboration, hopefully leading to informed design and research. We provide the first in-depth analysis of 31 consumer-facing financial applications that provide support for budgeting, payments, and long-term planning to identify how sharing is mechanized at the system level. Our analysis offers sharing dimensions and patterns that depict the diversity of how existing applications support, or actively hinder, participation in financial sharing. Reflecting on our analysis, we highlight the need for more granular information for consumers and advocates to promote healthy financial sharing practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {968},
numpages = {19},
keywords = {financial account sharing; intimate partnerships; money work},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713178,
author = {Joshi, Kartik and Mudliar, Preeti},
title = {Reselling Practices in a Textile Bazaar: Translating E-Commerce Platforms to WhatsApp},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713178},
doi = {10.1145/3706598.3713178},
abstract = {We examine WhatsApp-based reselling practices adopted by small garment sellers in Surat, a textile city in India, as a response to the challenges posed by high commission costs, confusing dashboards, and restrictive rules of global e-commerce platforms. Through interviews and observations, we show how sellers use WhatsApp’s popularity to collaborate with women resellers and customers, enabling participation in online commerce bypassing e-commerce platforms. Using the lens of translation, we argue that WhatsApp functions as a tool and site of praxis for sellers who translate the complicated, standardized, and expensive processes of e-commerce platforms that are in English into multimodal, idiomatic, collaborative reselling practices. These are undertaken in regional languages on WhatsApp with the help of traders and women resellers economically benefiting everyone while delivering a personalized online shopping experience for customers. We discuss the politics of this translation, examining its impact on the design of e-commerce platforms while also shaping the discourse of reselling as an empowering pathway for women.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {969},
numpages = {18},
keywords = {Social Commerce, Technology Translation, WhatsApp Reselling, Algorithmic Platforms, Gendered Labor, Social Computing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713583,
author = {Puerta, Eduardo and Spivak, Shani Claire and Correll, Michael},
title = {The Many Tendrils of the Octopus Map},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713583},
doi = {10.1145/3706598.3713583},
abstract = {Conspiratorial thinking can connect many distinct or distant ills to a central cause. This belief has visual form in the octopus map: a map where a central force (for instance a nation, an ideology, or an ethnicity) is depicted as a literal or figurative octopus, with extending tendrils. In this paper, we explore how octopus maps function as visual arguments through an analysis of historical examples as well as a through a crowd-sourced study on how the underlying data and the use of visual metaphors contribute to specific negative or conspiratorial interpretations. We find that many features of the data or visual style can lead to “octopus-like” thinking in visualizations, even without the use of an explicit octopus motif. We conclude with a call for a deeper analysis of visual rhetoric, and an acknowledgment of the potential for the design of data visualizations to contribute to harmful or conspiratorial thinking.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {970},
numpages = {20},
keywords = {visual rhetoric, persuasive cartography, critical cartography},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3715270,
author = {Bhatti, Neelma and Mushtaque, Qurba and Qadir, Aisha Abdul and Riaz, Muhammad Huzaifah},
title = {Understanding Pakistani Mothers' Use and Non-Use of Screen Media-based Devices: Gratifications, Strategies, and Design Implications},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3715270},
doi = {10.1145/3706598.3715270},
abstract = {This study explores how Pakistani mothers, as primary caregivers, navigate the use and non-use of screen media-based devices (SMDs) in their parenting practices. Grounded in the uses and gratifications theory, we explore how mothers seek specific gratifications through their children’s use of SMDs, and how unmet needs prompt them to adopt strategies for limiting SMD use. Through an analysis of interview and survey data, we present and discuss different patterns of SMD use among mothers, emphasizing their needs for religious education, cultural enrichment, family bonding, and early learning. These findings reveal a trend toward value-driven SMD use. We further compare these strategies with global digital parenting practices and identify opportunities for designing culturally relevant technological solutions to support digital parenting in this space.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {971},
numpages = {13},
keywords = {digital childcare, digital parenting, screen media-based devices, uses and gratifications, child-computer interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713724,
author = {Guo, Longjie and Fu, Yue and Lin, Xiran and Xu, Xuhai and Chang, Yung-Ju and Hiniker, Alexis},
title = {What Social Media Use Do People Regret? An Analysis of 34K Smartphone Screenshots with Multimodal LLM},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713724},
doi = {10.1145/3706598.3713724},
abstract = {Smartphone users often regret aspects of their phone use, especially social media use. However, pinpointing specific ways in which the design of an interface contributes to regrettable use can be challenging due to the complexity of social media app features and user intentions. We conducted a one-week study with 17 Android users, using a novel method where we passively collected screenshots every five seconds, which we analyzed via a multimodal large language model to understand participants’ usage activity at a fine-grained level. Triangulating this data with data from experience sampling, surveys, and interviews, we found that regret varies based on user intention, with non-intentional and social media use being especially regrettable. Regret also varies by social media activity; participants were most likely to regret viewing algorithmically recommended content and comments. Additionally, participants frequently deviated to browsing social media when their intention was direct communication, which slightly increased their regret. Our findings provide guidance to designers and policy-makers seeking to improve users’ experience and autonomy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {972},
numpages = {23},
keywords = {screenshots, regret, digital well-being, multimodal large language model, social media},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713672,
author = {Gathani, Sneha and Liu, Zhicheng and Haas, Peter J. and Demiralp, \c{C}a\u{g}atay},
title = {What-if Analysis for Business Professionals: Current Practices and Future Opportunities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713672},
doi = {10.1145/3706598.3713672},
abstract = {What-if analysis (WIA) is essential for data-driven decision-making, allowing users to assess how changes in variables impact outcomes and explore alternative scenarios. Existing WIA research primarily supports the workflows of data scientists and analysts, and largely overlooks business professionals who engage in WIA through non-technical means. To bridge this gap, we conduct a two-part user study with 22 business professionals across marketing, sales, product, and operations roles. The first study examines their existing WIA practices, tools, and challenges. Findings reveal that business professionals perform many WIA techniques independently using rudimentary tools due to various constraints. We then implement representative WIA techniques in a visual analytics prototype and use it as a probe to conduct a follow-up study evaluating business professionals’ practical use of the techniques. Results show that these techniques improve decision-making efficiency and confidence while underscoring the need for better support in data preparation, risk assessment, and domain knowledge integration. Finally, we offer design recommendations to enhance future business analytics systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {973},
numpages = {17},
keywords = {Business Intelligence, What-if Analysis, Predictive and Prescriptive Analytics, Interview Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714125,
author = {Chheda-Kothary, Arnavi and Sharif, Ather and Rios, David Angel and Smith, Brian A.},
title = {"It Brought Me Joy": Opportunities for Spatial Browsing in Desktop Screen Readers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714125},
doi = {10.1145/3706598.3714125},
abstract = {Blind or low-vision (BLV) screen-reader users have a significantly limited experience interacting with desktop websites compared to non-BLV, i.e., sighted users. This digital divide is exacerbated by the incapability to browse the web spatially—an affordance that leverages spatial reasoning, which sighted users often rely on. In this work, we investigate the value of and opportunities for BLV screen-reader users to browse websites spatially (e.g., understanding page layouts). We additionally explore at-scale website layout understanding as a feature of desktop screen readers. We created a technology probe, WebNExt, to facilitate our investigation. Specifically, we conducted a lab study with eight participants and a five-day field study with four participants to evaluate spatial browsing using WebNExt. Our findings show that participants found spatial browsing intuitive and fulfilling, strengthening their connection to the design of web pages. Furthermore, participants envisioned spatial browsing as a step toward reducing the digital divide.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {974},
numpages = {18},
keywords = {Blind or low-vision users; accessibility; desktop web applications; spatial awareness},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713102,
author = {Chen, Jennie J.Y. and Fels, Sidney S.},
title = {Curves Ahead: Enhancing the Steering Law for Complex Curved Trajectories},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713102},
doi = {10.1145/3706598.3713102},
abstract = {The Steering Law has long been a fundamental model in predicting movement time for tasks involving navigating through constrained paths, such as in selecting sub-menu options, particularly for straight and circular arc trajectories. However, this does not reflect the complexities of real-world tasks where curvatures can vary arbitrarily, limiting its applications. This study aims to address this gap by introducing the total curvature parameter K into the equation to account for the overall curviness characteristic of a path. To validate this extension, we conducted a mouse-steering experiment on fixed-width paths with varying lengths and curviness levels. Our results demonstrate that the introduction of K significantly improves model fitness for movement time prediction over traditional models. These findings advance our understanding of movement in complex environments and support potential applications in fields like speech motor control and virtual navigation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {975},
numpages = {12},
keywords = {Human performance modeling, Steering Law, Trajectory-based tasks, Curved path steering},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713849,
author = {Lu, Tao and Zhu, Qian and Ma, Tiffany and Kam-Kwai, Wong and Xie, Anlan and Endert, Alex and Yang, Yalong},
title = {Ego vs. Exo and Active vs. Passive: Investigating the Individual and Combined Effects of Viewpoint and Navigation on Spatial Immersion and Understanding in Immersive Storytelling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713849},
doi = {10.1145/3706598.3713849},
abstract = {Visual storytelling combines visuals and narratives to communicate important insights. While web-based visual storytelling is well-established, leveraging the next generation of digital technologies for visual storytelling, specifically immersive technologies, remains underexplored. We investigated the impact of the story viewpoint (from the audience’s perspective) and navigation (when progressing through the story) on spatial immersion and understanding. First, we collected web-based 3D stories and elicited design considerations from three VR developers. We then adapted four selected web-based stories to an immersive format. Finally, we conducted a user study (N=24) to examine egocentric and exocentric viewpoints, active and passive navigation, and the combinations they form. Our results indicated significantly higher preferences for egocentric+active (higher agency and engagement) and exocentric+passive (higher focus on content). We also found a marginal significance of viewpoints on story understanding and a strong significance of navigation on spatial immersion.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {976},
numpages = {19},
keywords = {Immersive storytelling, Story navigation, Story viewpoint in immersive environments},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714315,
author = {Bouzbib, Elodie and Sarasate, Iosune and Fern\'{a}ndez, Unai Javier and Fern\'{a}ndez, Ivan and Lopez-Amo, Manuel and Ezcurdia, I\~{n}igo and Marzo, Asier},
title = {FlexiVol: a Volumetric Display with an Elastic Diffuser to Enable Reach-Through Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714315},
doi = {10.1145/3706598.3714315},
abstract = {Volumetric displays render true 3D graphics without forcing users to wear headsets or glasses. However, the optical diffusers that volumetric displays employ are rigid and thus do not allow for direct interaction. FlexiVol employs elastic diffusers to allow users to reach inside the display volume to have direct interaction with true 3D content. We explored various diffuser materials in terms of visual and mechanical properties. We correct the distortions of the volumetric graphics projected on elastic oscillating diffusers and propose a design space for FlexiVol, enabling various gestures and actions through direct interaction techniques. A user study suggests that selection, docking and tracing tasks can be performed faster and more precisely using direct interaction when compared to indirect interaction with a 3D mouse. Finally, applications such as a virtual pet or landscape edition highlight the advantages of a volumetric display that supports direct interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {977},
numpages = {16},
keywords = {Volumetric Displays, Direct Interaction, True 3D graphics, Flexible Diffuser, Projection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713747,
author = {Han, Seung Hyeon and Han, Yeeun and Park, Kyeongho and Lee, Sangjun and Lee, Woohun},
title = {SpatIO: Spatial Physical Computing Toolkit Based on Extended Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713747},
doi = {10.1145/3706598.3713747},
abstract = {Proper placement of sensors and actuators is one of the key factors when designing spatial and proxemic interactions. However, current physical computing tools do not effectively support placing components in three-dimensional space, often forcing designers to build and test prototypes without precise spatial configuration. To address this, we propose the concept of spatial physical computing and present SpatIO, an XR-based physical computing toolkit that supports a continuous end-to-end workflow. SpatIO consists of three interconnected subsystems: SpatIO Environment for composing and testing prototypes with virtual sensors and actuators, SpatIO Module for converting virtually placed components into physical ones, and SpatIO Code for authoring interactions with spatial visualization of data flow. Through a comparative user study with 20 designers, we found that SpatIO significantly altered workflow order, encouraged broader exploration of component placement, enhanced spatial correlation between code and components, and promoted in-situ bodily testing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {978},
numpages = {22},
keywords = {Spatial Physical Computing, Prototyping, Extended Reality, Digital Fabrication, Visual Computing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714083,
author = {Wald, Iddo Yehoshua and Degraen⁎, Donald and Maimon⁎, Amber and Keppel, Jonas and Schneegass, Stefan and Malaka, Rainer},
title = {Spatial Haptics: A Sensory Substitution Method for Distal Object Detection Using Tactile Cues},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714083},
doi = {10.1145/3706598.3714083},
abstract = {We present a sensory substitution-based method for representing locations of remote objects in 3D space via haptics. By imitating auditory localization processes, we enable vibrotactile localization abilities similar to those of some spiders, elephants, and other species. We evaluated this concept in virtual reality by modulating the vibration amplitude of two controllers depending on relative locations to a target. We developed two implementations applying this method using either ear or hand locations. A proof-of-concept study assessed localization performance and user experience, achieving under 30° differentiation between horizontal targets with no prior training. This unique approach enables localization by using only two actuators, requires low computational power, and could potentially assist users in gaining spatial awareness in challenging environments. We compare the implementations and discuss the use of hands as ears in motion, a novel technique not previously explored in the sensory substitution literature.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {979},
numpages = {12},
keywords = {Haptic, Tactile, Sensory substitution, Spatial perception, Localization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714033,
author = {Wong, Emily and Genay, Ad\'{e}la\"{\i}de and Gr\o{}nb\ae{}k, Jens Emil Sloth and Velloso, Eduardo},
title = {Spatial Heterogeneity in Distributed Mixed Reality Collaboration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714033},
doi = {10.1145/3706598.3714033},
abstract = {Collaborative Mixed Reality (MR) enables embodied meetings for distributed collaborators working across a variety of locations. However, providing a coherent experience for all users regardless of the spatial configurations of their respective physical environments is a central challenge. We present the Spatial Heterogeneity Framework, which breaks the problem into four core components: the activity zones, heterogeneity ladder, blended proxemics, and MR solutions matrix. We explain the interplay between these components, demonstrating their interconnectivity via a case study. Our framework enables researchers to navigate differences and trade-offs between solutions for distributed MR collaboration. It also supports designers to think about the role of space, technology, and social behaviours in MR collaboration. Ultimately, our contributions advance the field by conceptualising the challenges of spatial heterogeneity and strategies to overcome them.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {980},
numpages = {19},
keywords = {Mixed Reality, Distributed Collaboration, Proxemics, Spatial Heterogeneity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713933,
author = {Lei, Ying and Ma, Shuai and Sun, Yuling and Ma, Xiaojuan},
title = {"AI Afterlife" as Digital Legacy: Perceptions, Expectations, and Concerns},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713933},
doi = {10.1145/3706598.3713933},
abstract = {The rise of generative AI technology has sparked interest in using digital information to create AI-generated agents as digital legacy. These agents, often referred to as “AI Afterlives”, present unique challenges compared to traditional digital legacy. Yet, there is limited human-centered research on “AI Afterlife” as digital legacy, especially from the perspectives of the individuals being represented by these agents. This paper presents a qualitative study examining users’ perceptions, expectations, and concerns regarding AI-generated agents as digital legacy. We identify factors shaping people’s attitudes, their perceived differences compared with the traditional digital legacy, and concerns they might have in real practices. We also examine the design aspects throughout the life cycle and interaction process. Based on these findings, we situate “AI Afterlife” in digital legacy, and delve into design implications for maintaining identity consistency and balancing intrusiveness and support in “AI Afterlife” as digital legacy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {981},
numpages = {18},
keywords = {Generative AI, Agent, Afterlife, Digital Legacy, Perception, Expectation, Concern, Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713111,
author = {Kolb, Daniel and Maiolo, Simona and Maier, Patricia and Genz, Fabio and M\"{u}ller, Simone and Kranzlm\"{u}ller, Dieter August},
title = {Effects of Visual Modality on Conversations with Interactive Digital Testimonies: Preparing for the Post-Witness Era},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713111},
doi = {10.1145/3706598.3713111},
abstract = {Interactive Digital Testimonies (IDTs) allow users to learn virtually about the life stories of contemporary witnesses as recounted by the witnesses themselves. Although several IDTs have been created in recent years, there is little empirical research on their effects on users. We investigated how different levels of visual modality (audio-only, audio-visual 2D, audio-visual stereoscopic 3D) affect user perception by conducting two separate mixed-methods studies: A 2 \texttimes{} 2 between-subjects study comparing audio-only with audio-visual 2D in in-person and online settings (n = 82) and a within-subjects study comparing audio-visual 2D with audio-visual stereoscopic 3D (n = 51). We found that audio-visual 2D improves user experience, immersion, and perceived authenticity over audio-only versions. Audio-visual 3D IDTs are more authentic and immersive than audio-visual 2D IDTs, however, this is diminished by a less comfortable interaction. Our findings broaden empirical research on user perception of realistic Embodied Conversational Agents and help guide future thanatosensitive designs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {982},
numpages = {25},
keywords = {Modality; Presence; Immersion; Learning; Embodied Conversational Agent; Interactive Digital Testimony; Oral History},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713215,
author = {Jang, Sangsu and Kim, Nari and Kim, Nanum and Moon, Jin-young and Woo, Choong-Wan and Park, Young-Woo},
title = {Journey to My Past: Exploring and Journaling Past Memories Evoked by Questions Framed as Proud Moments},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713215},
doi = {10.1145/3706598.3713215},
abstract = {Accumulating a life history is a valuable resource for understanding self and reflecting on personal historical experience, which could be developed through diary writing. To facilitate the recording of past events in a diary, we designed and implemented Rebulb, a system that enables users to engage with reflective questions about proud moments and document memories evoked for accumulating one's life history. Our four-month field study with three participants showed that users intentionally and spontaneously recalled vague and wide memories during their daily activity and then concretized these memories by writing them down in a journal. The study also revealed that regardless of whether the memories were positive or negative, the current state of the user played a crucial role in how these memories were processed and reflected upon. Our finding imply consideration in designing a tool for supporting the recall and documentation of past experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {983},
numpages = {19},
keywords = {Diary, Life history, Self-explorative retrospection, Self-journaling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713172,
author = {Liu, Lika Haizhou and Lu, Xi and Chiang, Pei-Chun and Epstein, Daniel A. and Squire, Kurt},
title = {Meditating Together: Practices, Benefits and Challenges of Meditation on Social Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713172},
doi = {10.1145/3706598.3713172},
abstract = {Meditation and mind-body practices offer many benefits for both mental and physical well-being. Recently, social virtual reality (VR) has emerged as a promising platform to support well-being activities. While Human-Computer Interaction (HCI) research has explored technologies for meditation, little is known about how users appropriate social VR for meditation, particularly group practice, and how it shapes their experiences. To bridge this gap, we interviewed 13 regular social VR meditators to explore their practices, perceived benefits, and challenges. We found that meditators utilized platform features to engage in community-driven group practices, manage session flow, employ avatars and body tracking for kinetic practices, and experiment with novel forms of meditation. Participants reported benefits and challenges related to the individual and social aspects of their meditation experiences. Based on these findings, we discuss the implications of using social VR for meditation, including how avatars and virtual others positively affect the practice, as well as emerging tensions and opportunities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {984},
numpages = {20},
keywords = {Virtual Reality; Meditation; Group meditation; Embodiment; Social VR; Mindfulness},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714297,
author = {Cho, Hyungjun and Seo, Jiyeon Amy and Lee, Jiwon and Kim, Chang-Min and Nam, Tek-Jin},
title = {ShamAIn: Designing Superior Conversational AI Inspired by Shamanism},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714297},
doi = {10.1145/3706598.3714297},
abstract = {This paper presents the design process, outcomes, and installation of ShamAIn, a multi-modal embodiment of conversational AI inspired by the beliefs and symbols of Korean shamanism. Adopting a research through design approach, we offer an alternative perspective on conversational AI design, emphasizing perceived superiority. ShamAIn was developed based on strategies derived from investigating people’s experiences with shamanistic counseling and rituals. We deployed the system in an exhibition room for six weeks, during which 20 participants made multiple visits to engage with ShamAIn. Through subsequent in-depth interviews, we found that participants felt a sense of awe toward ShamAIn and engaged in interactions with humility and respect. Our participants disclosed personal and profound concerns, reflecting deeply on the responses they received. Consequently, they relied on ShamAIn and formed relationships in which they received support. In the discussion, we present the design implications of conversational AI perceived as superior to humans, along with the ethical considerations involved in designing such AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {985},
numpages = {18},
keywords = {conversational AI, superior AI, shamanism, speculative design, research through design (RtD)},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713552,
author = {Saito, Shun and Sugihara, Taro},
title = {Unintended, Percolated Work: Overlooked Opportunities for Collaboration Between Informal Caregivers and Healthcare Professionals During the End-Of-Life Care Process},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713552},
doi = {10.1145/3706598.3713552},
abstract = {Bereavement often places a psychological burden on families and should be addressed appropriately. Although end-of-life care is a collaborative activity with interaction between family caregivers and medical professionals, further research is needed to explore family caregivers’ support needs as collaborative workers and the challenges they face. This study examined the collaboration during the end-of-life process between family caregivers and medical professionals to understand the cooperative activities and factors surrounding them based on unrealized or regrettable experiences during end-of-life care. Semi-structured interviews with bereaved family caregivers who provided end-of-life care and medical professionals who provided support revealed that family caregivers’ aspirations and medical professionals’ support for family caregivers crossed paths, steering end-of-life caregiving in an unintended direction. Characteristic work carried out by each actor in this situation is defined as "unintended, percolated work" and considered an overlooked collaboration opportunity, proposing support suggestions for handling family caregivers’ original intentions and needs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {986},
numpages = {16},
keywords = {informal caregivers, healthcare professional, cooperative work, end-of-life care, unintended work},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713557,
author = {Song, Xiaran and Wang, Anqi and Lucero, Andr\'{e}s},
title = {Walking in My Shoes: An Autoethnography of Techno-Spiritual Practices},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713557},
doi = {10.1145/3706598.3713557},
abstract = {Technology has become deeply woven into the practices of faith communities who engage in shared prayer, online worship, or meditation. Despite a growing body of research on religious/spiritual practices, the Human-Computer Interaction (HCI) community has yet to fully investigate Techno-Spirituality, especially through a first-person approach. We explored prayer experiences to understand which elements evoke such experiences from a Christian perspective. We present results from an eight-month autoethnographic study of private prayer by the first author, also a community member, while incorporating both technological (e.g., a Muse 2 electroencephalogram headband) and non-technological (e.g., religious iconography) media. We reflect on emerging practices and limitations of integrating technology during Christian prayer. This paper provides empirical insights on spiritual practices with technologies, and contributes to discourses on Techno-Spirituality in HCI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {987},
numpages = {14},
keywords = {techno-spirituality; Christianity; first-person methods; self-tracking; lived experience; spiritual informatics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714178,
author = {Kim, Kyusik and Song, Hyungwoo and Ryu, Jeongwoo and Oh, Changhoon and Suh, Bongwon},
title = {BleacherBot: AI Agent as a Sports Co-Viewing Partner},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714178},
doi = {10.1145/3706598.3714178},
abstract = {Co-viewing, traditionally defined as watching content together in the same physical space, enhances emotional connections through shared experiences. With the rise of remote viewing during the COVID-19 pandemic, existing solutions, such as second-screen platforms and rule-based AI companions, struggle to facilitate meaningful social interactions. This study explores the potential of Large Language Models, which offer human-like interactions and personalization. Our formative study with ten participants revealed the importance of managing arousal levels, highlighting the need to balance between high- and low-arousal levels across different viewing contexts. Based on these insights, we developed ‘BleacherBot’, a sports co-viewing agent with distinct interaction styles that vary in arousal levels. Our main study with 27 participants demonstrated that matching users’ preferred arousal levels with the agent’s interaction style significantly enhanced their engagement and overall enjoyment. We propose design guidelines for AI co-viewing agents that consider their role as complements to human social interactions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {988},
numpages = {31},
keywords = {Co-viewing, AI Agents, Large Language Models (LLMs), Sports Communication, Human-AI Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713324,
author = {Weng, Jian-Jia and Ku, Calvin and Wang, Jo Chien and Cheng, Chih-Jen and Lin, Tica and Su, Yu-An and Tsai, Tsung-Hsun and Lin, You-Yi and Ku, Lun-Wei and Chu, Hung-Kuo and Hu, Min-Chun},
title = {Bridging Coaching Knowledge and AI Feedback to Enhance Motor Learning in Basketball Shooting Mechanics Through a Knowledge-Based SOP Framework},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713324},
doi = {10.1145/3706598.3713324},
abstract = {We present a methodology for designing an AI feedback system aimed at assisting basketball beginners in refining their shooting techniques during independent practice sessions. Mastering shooting mechanics requires consistent, precise repetition, which traditionally depends on coaching feedback and the breakdown of movements into steps during the early stages. However, due to limited coaching resources, this guidance is often unavailable, leading to ineffective and even detrimental motor learning. To bridge this gap, we propose a Standard Operating Procedure (SOP) framework grounded in expert human knowledge, or knowledge-based SOP, which allows our AI-driven system to verify and guide players’ movements in real-time. Through a formative study involving interviews with 13 coaches and players, we identified key challenges faced by beginners, such as uncertainty in movement correctness and lack of guidance during unsupervised practice. Our AI system addresses these issues by providing immediate, actionable feedback using SOP tailored to individual players. In a study with 28 participants, we confirmed that our system improves shooting form, increases confidence in adjustments, and enhances self-awareness during practice. This work highlights the potential of integrating coaching expertise with AI to empower athletes with more effective tools for self-directed practice.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {989},
numpages = {20},
keywords = {Sports/Exercise, Visualization, Empirical study that tells us about how people use a system},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714026,
author = {Brewer, Mollie and Childs, Kevin and Thomas, Spencer and Wilkins, Celeste and Boyer, Kristy Elizabeth and Nichols, Jennifer A. and Butler, Kevin R.B. and Beatty, Garrett F. and Ferris, Daniel P.},
title = {Coach, Data Analyst, and Protector: Exploring Data Practices of Collegiate Coaching Staff},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714026},
doi = {10.1145/3706598.3714026},
abstract = {A rapidly emerging research community at the intersection of sport and human-computer interaction (SportsHCI) explores how technology can support physically active humans, such as athletes. At highly competitive levels, coaching staff play a central role in the athlete experience by using data to enhance performance, reduce injuries, and foster team success. However, little is known about the practices and needs of these coaching staff. We conducted five focus groups with 17 collegiate coaching staff across three women’s teams and two men’s teams at an elite U.S. university. Our findings show that coaching staff selectively use data with the goal of balancing performance goals, athlete emotional well-being, and privacy. This paper contributes design recommendations to support coaching staff in operating across the data life cycle through gathering, sharing, deciding, acting, and assessing data as they aim to support team success and foster the well-being of student-athletes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {990},
numpages = {13},
keywords = {SportsHCI, sports technology, coaching technology, collegiate sports, human-data interaction, sports performance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713141,
author = {Lee, Hanbyeol and Kleinman, Erica and Kim, Namsub and Park, Sangbeom and Harteveld, Casper and Lee, Byungjoo},
title = {Crafting Champions: An Observation Study of Esports Coaching Processes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713141},
doi = {10.1145/3706598.3713141},
abstract = {As esports grows into a multi-million dollar industry of professional players and competitions, so too grows the interest in and need for professional coaching. Accordingly, there are increased demands and attempts to support and improve coaching for esports. A more comprehensive, granular understanding of the esports coaching process would provide a valuable foundation to inform opportunities to advance the domain via HCI theories and practices. However, in-depth studies of coaching practice, from the lens of HCI, are far less common in existing literature. In this paper, we take the first steps to provide such a foundation through an observation study conducted at an elite, award-winning League of Legends training academy. By analyzing 112 hours of dialogue and footage from coaching sessions, we identify pertinent activities and events that occur within the coaching process, which enable us to consider how esports coaching can be improved via theory, practice, and technology from HCI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {991},
numpages = {20},
keywords = {Esports, Coaching, Observation Study, League of Legends},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713606,
author = {G\"{o}ldi, Andreas and Rietsche, Roman and Ungar, Lyle},
title = {Efficient Management of LLM-Based Coaching Agents' Reasoning While Maintaining Interaction Quality and Speed},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713606},
doi = {10.1145/3706598.3713606},
abstract = {LLM-based agents improve upon standalone LLMs, which are optimized for immediate intent-satisfaction, by allowing the pursuit of more extended objectives, such as helping users over the long term. To do so, LLM-based agents need to reason before responding. For complex tasks like personalized coaching, this reasoning can be informed by adding relevant information at key moments, shifting it in the desired direction. However, the pursuit of objectives beyond interaction quality may compromise this very quality. Moreover, as the depth and informativeness of reasoning increase, so do the number of tokens required, leading to higher latency and cost. This study investigates how an LLM-based coaching agent can adjust its reasoning depth using a discrepancy mechanism that signals how much reasoning effort to allocate based on how well the objective is being met. Our discrepancy-based mechanism constrains reasoning to better align with alternative objectives, reducing cost roughly tenfold while minimally impacting interaction quality.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {992},
numpages = {18},
keywords = {Behavior Change, Education/Learning, Text/Speech/Language, Artifact or System, Quantitative Methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713819,
author = {J\"{o}rke, Matthew and Sapkota, Shardul and Warkenthien, Lyndsea and Vainio, Niklas and Schmiedmayer, Paul and Brunskill, Emma and Landay, James A.},
title = {GPTCoach: Towards LLM-Based Physical Activity Coaching},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713819},
doi = {10.1145/3706598.3713819},
abstract = {Mobile health applications show promise for scalable physical activity promotion but are often insufficiently personalized. In contrast, health coaching offers highly personalized support but can be prohibitively expensive and inaccessible. This study draws inspiration from health coaching to explore how large language models (LLMs) might address personalization challenges in mobile health. We conduct formative interviews with 12 health professionals and 10 potential coaching recipients to develop design principles for an LLM-based health coach. We then built GPTCoach, a chatbot that implements the onboarding conversation from an evidence-based coaching program, uses conversational strategies from motivational interviewing, and incorporates wearable data to create personalized physical activity plans. In a lab study with 16 participants using three months of historical data, we find promising evidence that GPTCoach gathers rich qualitative information to offer personalized support, with users feeling comfortable sharing concerns. We conclude with implications for future research on LLM-based physical activity support.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {993},
numpages = {46},
keywords = {Physical activity, health coaching, large language models (LLMs), personal informatics, conversational agents},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713627,
author = {Motahar, Tamanna and Kim, YeonJae and Fisher, Eden and Wiese, Jason},
title = {Understanding the Training Experiences of Competitive Skiers with Tetraplegia},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713627},
doi = {10.1145/3706598.3713627},
abstract = {Adaptive sports are crucial for the psychological well-being of individuals with tetraplegia—limited motor function in both arms and legs. TetraSki provides these individuals access to extreme adaptive sports through a power-assisted ski instrument, which an athlete can control independently. While athletes in other sporting contexts commonly use technology to improve their performance, no studies have explored how technology might benefit athletes with tetraplegia when training for adaptive competitive sports like TetraSki. We conducted semi-structured interviews with six TetraSki athletes and four tethers who participated in TetraSki Express 2022, the world’s first and only adaptive alpine ski competition for athletes with tetraplegia. Our study provides an in-depth understanding of athletes’ and tethers’ current practices and challenges while working to improve their performance in this competitive environment, and points to opportunities for self-tracking technologies to support their athletic endeavors better.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {994},
numpages = {16},
keywords = {Adaptive Sports, TetraSki, Tetraplegia},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713093,
author = {Duan, Wen and Li, Lingyuan and Freeman, Guo and McNeese, Nathan},
title = {A Scoping Review of Gender Stereotypes in Artificial Intelligence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713093},
doi = {10.1145/3706598.3713093},
abstract = {People often apply gender stereotypes to Artificial Intelligence (AI), and AI design frequently reinforces these stereotypes, perpetuating traditional gender ideologies in state-of-the-art technology. Despite growing interests in investigating this phenomenon, there is little conceptual clarity or consistency regarding what actually constitutes a "gender stereotype" in AI. Therefore, it is critical to provide a more comprehensive image of existing understandings and ongoing discussions of gender stereotypes of AI to guide AI design that reduces the harmful effects of these stereotypes. In doing so, this paper presents a scoping review of over 20 years of research across HCI, HRI and various social science disciplines on how gender stereotypes are applied to AI. We outline the methods and contexts of this growing body of work, develop a typology to clarify these stereotypes, highlight under-explored approaches for future research, and offer guidelines to improve rigor and consistency in this field that may inform responsible AI design in the future.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {995},
numpages = {20},
keywords = {Artificial Intelligence, Gender stereotypes, Anthropomorphism},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713430,
author = {Povinelli, Kassie C and Zhu, Hanxiu 'Hazel' and Zhao, Yuhang},
title = {Beyond the “Industry Standard”: Focusing Gender-Affirming Voice Training Technologies on Individualized Goal Exploration.},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713430},
doi = {10.1145/3706598.3713430},
abstract = {Gender-affirming voice training is critical for the transition process for many transgender individuals, enabling their voice to align with their gender identity. Individualized voice goals guide and motivate the voice training journey, but existing voice training technologies fail to define clear goals. We interviewed six voice experts and ten transgender individuals with voice training experience (voice trainees), focusing on how they defined, triangulated, and used voice goals. We found that goal voice exploration involves navigation between descriptive and technical goals, and continuous reevaluation throughout the voice training journey. Our study reveals how goal descriptions, subjective satisfaction, voice examples, and voice modification and training technologies inform goal exploration, and identifies risks of overemphasizing goals. We identified technological implications informed by existing expert and trainee strategies, and provide guidelines for supporting individualized goals throughout the voice training journey based on brainstorming with trainees and experts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {996},
numpages = {21},
keywords = {Transgender, Voice training, Voice changers, Qualitative research, Interview},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713608,
author = {De Cet, Martina and Obaid, Mohammad and Torre, Ilaria},
title = {Breaking the Binary: A Systematic Review of Gender-Ambiguous Voices in Human-Computer Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713608},
doi = {10.1145/3706598.3713608},
abstract = {Voice interfaces come in many forms in Human-Computer Interaction (HCI), such as voice assistants and robots. These are often gendered, i.e. they sound masculine or feminine. Recently, there has been a surge in creating gender-ambiguous voices, aiming to make voice interfaces more inclusive and less prone to stereotyping. In this paper, we present the first systematic review of research on gender-ambiguous voices in HCI literature, with an in-depth analysis of 36 articles. We report on the definition and availability of gender-ambiguous voices, creation methods, user perception and evaluation techniques. We conclude with several concrete action points: clarifying key terminology and definitions for terms such as gender-ambiguous, gender-neutral, and non-binary; conducting an initial acoustic analysis of gender-ambiguous voices; taking initial steps toward standardising evaluation metrics for these voices; establishing an open-source repository of gender-ambiguous voices; and developing a framework for their creation and use. These recommendations provide important insights for fostering the development and adoption of inclusive voice technologies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {997},
numpages = {17},
keywords = {gender-ambiguous, gender, ambiguous, gender-neutral, robot, agent, assistant, computer voice, Conversational User Interfaces},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713681,
author = {Ciolfi Felice, Marianela and Feldfeber, Ivana and Glasserman Apicella, Carolina and Quiroga, Yasm\'{\i}n Bel\'{e}n and Ansaldo, Juli\'{a}n and Lapenna, Luciano and Bezchinsky, Santiago and Barriga Rubio, Raul and Garc\'{\i}a, Mail\'{e}n},
title = {Doing the Feminist Work in AI: Reflections from an AI Project in Latin America},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713681},
doi = {10.1145/3706598.3713681},
abstract = {The contemporary AI development landscape is dominated by big corporations, lacks diversity, and mostly centres the Global North, or applies extractivist logics in the South. This paper showcases a feminist process of AI development from Latin America, where we created an interactive, AI-powered tool that helps criminal court officers open justice data, addressing a data gap on gender-based violence. Through a collaborative autoethnography, drawing from Latin American feminisms, we unpack and visibilize the feminist work that was required, as a crucial step to counter hegemonic narratives. Foregrounding the subjugated knowledges of our experiences, we offer a concrete example of a feminist approach to AI development grounded in practice. With this, we aim to critically inspire those who consider building technology in service of social justice causes, or who choose to build AI systems otherwise.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {998},
numpages = {18},
keywords = {Global South, NGO, activism, critical HCI, critical computing, duoethnography, feminist AI, feminist research},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713709,
author = {Mandai, Yuto and Seaborn, Katie and Nakano, Tomoyasu and Sun, Xin and Wang, Yijia and Kato, Jun},
title = {Super Kawaii Vocalics: Amplifying the "Cute" Factor in Computer Voice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713709},
doi = {10.1145/3706598.3713709},
abstract = {“Kawaii” is the Japanese concept of cute, which carries sociocultural connotations related to social identities and emotional responses. Yet, virtually all work to date has focused on the visual side of kawaii, including in studies of computer agents and social robots. In pursuit of formalizing the new science of kawaii vocalics, we explored what elements of voice relate to kawaii and how they might be manipulated, manually and automatically. We conducted a four-phase study (grand N = 512) with two varieties of computer voices: text-to-speech (TTS) and game character voices. We found kawaii “sweet spots” through manipulation of fundamental and formant frequencies, but only for certain voices and to a certain extent. Findings also suggest a ceiling effect for the kawaii vocalics of certain voices. We offer empirical validation of the preliminary kawaii vocalics model and an elementary method for manipulating kawaii perceptions of computer voice.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {999},
numpages = {19},
keywords = {Computer Voice, Kawaii Computing, Voice Interaction, Voice Assistants, Speech Signal Processing, Video Games, Character Design, Kawaii, Japan},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713155,
author = {Krause, Thorsten and G\"{o}ritz, Lorena and Gratz, Robin},
title = {The Effect of Gender De-biased Recommendations — A User Study on Gender-specific Preferences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713155},
doi = {10.1145/3706598.3713155},
abstract = {Recommender systems treat users inherently differently. Sometimes, however, personalization turns into discrimination. Gender bias occurs when a system treats users differently based on gender. While most research discusses measures and countermeasures for gender bias, one recent study explored whether users enjoy gender de-biased recommendations. However, its methodology has significant shortcomings; It fails to validate its de-biasing method appropriately and compares biased and unbiased models that differ in key properties. We reproduce the study in a 2x2 between-subjects design with n = 800 participants. Moreover, we examine the authors’ hypothesis that educating users on gender bias improves their attitude towards de-biasing. We find that the genders perceive de-biasing differently. The female users —the majority group— rate biased recommendations significantly higher while the male users —the minority group— indicate no preference. Educating users on gender bias increased acceptance non-significantly. We consider our contribution vital towards understanding how gender de-biasing affects different user groups.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1000},
numpages = {16},
keywords = {Gender Bias, Recommender Systems, Fairness, User Study, Reproducibility},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713235,
author = {Brooke, Si\^{a}n},
title = {“Python is for girls!”: Masculinity, Femininity, and Queering Inclusion at Hackathons},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713235},
doi = {10.1145/3706598.3713235},
abstract = {This paper explores how queerness intersects with hackathon culture, reinforcing or challenging its masculine norms. By utilizing autoethnographic insights from seven UK hackathons, it reveals that while queerness is visibly celebrated, inclusion remains conditional—accepted only when it aligns with masculine-coded technical authority. Femininity, regardless of the queer identities of those who embody it, is devalued and associated with lesser technical competence. Beyond social dynamics, gendered hierarchies influence programming tools, roles, and physical environments, embedding exclusion within technical culture. Although gender-fluid expressions like cosplay provide moments of subversion, they remain limited by the masculine framework of hackathons. This study contributes to human-computer interaction and feminist technology studies by showing that queerness alone does not dismantle gendered hierarchies. It advocates for moving beyond visibility to actively challenge masculinized definitions of technical legitimacy, promoting alternative, non-exclusionary models of expertise.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1001},
numpages = {13},
keywords = {gender, hackathons, inclusion, queerness},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713275,
author = {Chen, Jiaju and Tang, Minglong and Lu, Yuxuan and Yao, Bingsheng and Fan, Elissa and Ma, Xiaojuan and Xu, Ying and Wang, Dakuo and Sun, Yuling and He, Liang},
title = {Characterizing LLM-Empowered Personalized Story Reading and Interaction for Children: Insights From Multi-Stakeholder Perspectives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713275},
doi = {10.1145/3706598.3713275},
abstract = {Personalized interaction is highly valued by parents in their story-reading activities with children. While AI-empowered story-reading tools have been increasingly used, their abilities to support personalized interaction with children are still limited. Recent advances in large language models (LLMs) show promise in facilitating personalized interactions, but little is known about how to effectively and appropriately use LLMs to enhance children’s personalized story-reading experiences. This work explores this question through a design-based study. Drawing on a formative study, we designed and developed StoryMate, an LLM-empowered personalized interactive story-reading tool for children, following an empirical study with children, parents, and education experts. Our participants valued the personalized features in StoryMate, and also highlighted the need to support personalized content, guiding mechanisms, reading context variations, and interactive interfaces. Based on these findings, we propose a series of design recommendations for better using LLMs to empower children’s personalized story reading and interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1002},
numpages = {24},
keywords = {Children, AI, Large Language Model, Story-Reading, Interaction, Personalization, Guided Conversation, Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713715,
author = {D\"{u}ck, Moritz and Holter, Steffen and Chan, Robin Shing Moon and Sevastjanova, Rita and El-Assady, Mennatallah},
title = {Finding Needles in Document Haystacks: Augmenting Serendipitous Claim Retrieval Workflows},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713715},
doi = {10.1145/3706598.3713715},
abstract = {Preliminary exploration of vast text corpora for generating and validating hypotheses, typical in academic inquiry, requires flexible navigation and rapid validation of claims. Navigating the corpus by titles, summaries, and abstracts might neglect information, whereas identifying the relevant context-specific claims through in-depth reading is unfeasible with rapidly increasing publication numbers. Our paper identifies three typical user pathways for hypothesis exploration and operationalizes sentence-based retrieval combined with effective contextualization and provenance tracking in a unified workflow. We contribute an interface that augments the previously laborious tasks of claim identification and consistency checking using NLP techniques while balancing user control and serendipity. Use cases, expert interviews, and a user study with 10 participants demonstrate how the proposed workflow enables users to traverse literature corpora in novel and efficient ways. For the evaluation, we instantiate the tool within two independent domains, providing novel insights into the analysis of political discourse and medical research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1003},
numpages = {17},
keywords = {human-AI interaction, natural language processing, provenance, serendipity, text data},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713309,
author = {Liu, Xuye and Sun, Annie and An, Pengcheng and Ma, Tengfei and Zhao, Jian},
title = {Influencer: Empowering Everyday Users in Creating Promotional Posts via AI-infused Exploration and Customization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713309},
doi = {10.1145/3706598.3713309},
abstract = {Creating promotional posts on social platforms enables everyday users to disseminate their creative outcomes, engage in community exchanges, or generate additional income from micro-businesses. However, crafting eye-catching posts with appealing images and effective captions can be challenging and time-consuming for everyday users since they are mostly design novices. We propose Influencer, an interactive tool that helps novice creators quickly generate ideas and create high-quality promotional post designs through AI. Influencer offers a multi-dimensional recommendation system for ideation through example-based image and caption suggestions. Further, Influencer implements a holistic promotional post-design system supporting context-aware exploration considering brand messages and user-specified design constraints, flexible fusion of content, and a mind-map-like layout for idea tracking. Our user study, comparing the system with industry-standard tools, along with two real-life case studies, indicates that Influencer is effective in assisting design novices to generate ideas as well as creative and diverse promotional posts with user-friendly interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1004},
numpages = {19},
keywords = {Promotional post, mindmap, caption, image, exploration, customization, ideation.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713913,
author = {Wang, Huichen Will and Birnbaum, Larry and Setlur, Vidya},
title = {Jupybara: Operationalizing a Design Space for Actionable Data Analysis and Storytelling with LLMs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713913},
doi = {10.1145/3706598.3713913},
abstract = {Mining and conveying actionable insights from complex data is a key challenge of exploratory data analysis (EDA) and storytelling. To address this challenge, we present a design space for actionable EDA and storytelling. Synthesizing theory and expert interviews, we highlight how semantic precision, rhetorical persuasion, and pragmatic relevance underpin effective EDA and storytelling. We also show how this design space subsumes common challenges in actionable EDA and storytelling, such as identifying appropriate analytical strategies and leveraging relevant domain knowledge. Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension. Jupybara employs two strategies—design-space-aware prompting and multi-agent architectures—to operationalize our design space. An expert evaluation confirms Jupybara’s usability, steerability, explainability, and reparability, as well as the effectiveness of our strategies in operationalizing the design space framework with LLMs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1005},
numpages = {24},
keywords = {Actionable Insights, Human-AI Collaboration, Multi-Agent System, Large Language Model, Exploratory Data Analysis, Data Storytelling, Data Science, Semantics, Rhetoric, Pragmatics.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713132,
author = {Jain, Radhika Pankaj and Drogemuller, Adam and Satriadi, Kadek Ananta and Smith, Ross and Cunningham, Andrew},
title = {Strollytelling: Coupling Animation with Physical Locomotion to Explore Immersive Data Stories},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713132},
doi = {10.1145/3706598.3713132},
abstract = {With a growing interest in immersive data storytelling, there is an opportunity to explore story presentation and navigation techniques in virtual reality (VR) that can engage audiences as much as data story techniques have on conventional displays. We propose and explore “strolly”telling, a novel data storytelling technique that maps the story progression with the user/audience’s physical locomotion. Inspired by the conventional web-based technique for scrolling-based stories (i.e. scrollytelling), our technique tightly couples the user’s position in physical space to the animation frame of the data story. This technique leverages the natural tendency of humans to "walk and talk" while telling a story and requires users to engage with the content actively. This work defines strollytelling, design considerations, and a preliminary process for designing a strollytelling experience. A user study comparing strollytelling with virtual locomotion found that strollytelling was preferred by most participants and had higher self-reported immersion. We conclude with opportunities for strollytelling within the immersive data storytelling landscape.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1006},
numpages = {17},
keywords = {Immersive Data Storytelling, Strollytelling, Narrative Visualisation, Design Considerations},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713367,
author = {Kong, Junhan and Wobbrock, Jacob O. and Cai, Tianyuan and Bylinskii, Zoya},
title = {Supporting Mobile Reading While Walking with Automatic and Customized Font Size Adaptations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713367},
doi = {10.1145/3706598.3713367},
abstract = {The pervasive use of mobile devices for information consumption makes reading on-the-go an unavoidable daily occurrence, whereby walking creates a natural situational impairment for reading. In this work, we quantify the impact of walking on reading performance and compare automatic system adaptations with user customizations for mitigating these impacts. We collected user interactions and mobile sensor data of reading while walking in a controlled lab study with 45 participants. We found that automatic font size adjustment by viewing distance mitigated the performance degradation from walking, yielding faster reading speed and increased comfort. Furthermore, exposure to the automatic adaptation functionality influences user customization behavior and preferences for reading while walking. We discuss implications and provide design suggestions for personalizing interfaces when reading on-the-go, including blending system recommendation with user customization, offering multiple points of customization through appropriately-timed prompts, and refining recommendations based on observed preferences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1007},
numpages = {13},
keywords = {Situational impairments, mobile readability, personalization, adaptivity, adaptability, customization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713240,
author = {Ben chaaben, Eya and Koch, Janin and Mackay, Wendy E.},
title = {"Should I choose a smaller model?': Understanding ML Model Selection and Its Impact on Sustainability},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713240},
doi = {10.1145/3706598.3713240},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1008},
numpages = {13},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713118,
author = {Wieczorek, Catherine and Biggs, Heidi and Payyapilly Thiruvenkatanathan, Kamala and Bardzell, Shaowen},
title = {Architecting Utopias: How AI in Healthcare Envisions Societal Ideals and Human Flourishing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713118},
doi = {10.1145/3706598.3713118},
abstract = {Many narratives around AI systems promise a utopian vision of empowerment, inclusivity, and democratization, yet there remains a gap in how to concretely pursue such a promise. In this paper, we review and analyze a curated set of AI-driven healthcare products, leveraging sociologist Ruth Levitas’ three distinct but interrelated forms of utopian thinking—archaeology, ontology, and architecture. We contribute to HCI’s Human-AI Interaction agenda by applying this theory to critically examine how AI technologies embed societal ideals, shape user identities, and project alternative futures. This allows us to consider the values and users these systems illustrate as images of the “good society.” In doing so, we also make visible the normativity and repetitive nature of technology hype cycles and raise important questions about the future these technologies are shaping.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1009},
numpages = {15},
keywords = {utopian thinking, speculation, health, assemblages},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713990,
author = {Homewood, Sarah and Hinkle, Claudia A and Kaklopoulou, Irene},
title = {Cripping the Co-Design of Pacing Technologies For Energy-Limiting Conditions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713990},
doi = {10.1145/3706598.3713990},
abstract = {People with energy-limiting conditions, such as chronic fatigue syndrome (ME/CFS) and Long COVID, need to limit their activity levels and balance exertion with rest and restorative activities. This practice is known as “pacing”. There is an opportunity for technology to help people with this process, but conducting research with this population can be difficult given their limited and unpredictable energy levels. This research explores how we can use crip theory to inform the development of co-design methods suitable for this cohort, and as an analytical lens to explore how these tools should be designed outside of normative and abelist assumptions about fatigue and productivity. This is done through a 5 week Asynchronous Remote Community study utilising various co-design techniques. These findings point to future designs of pacing technologies and contribute insights about developing more accessible approaches to conducting research with people with energy-limiting conditions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1010},
numpages = {16},
keywords = {chronic fatigue syndrome, ME/CFS, long COVID, post-COVID syndrome, pacing, self-tracking technologies, crip theory, co-design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713101,
author = {Bakhshoudeh, Fatemeh and Comber, Rob},
title = {Designing with the Solar Internet: Towards Constraint-Based Design for Sustainable Consumption},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713101},
doi = {10.1145/3706598.3713101},
abstract = {In response to the escalating impact of mindless consumption in the fashion and IT industry, we began to think of and with a constraint-based approach to interaction design. This paper describes a research through design investigation into a paradigm of constraint-based design, founded on the practical and perceived constraints of solar-powered internet. Our intention is not to examine individual consumer as a site for sustainable transition, but the industries and industry practitioners at the interface with consumers. We employed strategies that included optimisation as a form of minimisation, visibility as a means to mark existing absence, offloading from automation, and the design of dead-ends. We discuss the challenges in learning to design against the cornucopian paradigm. While the overall vision of an internet powered by the sun seems at once desirable and achievable, the pursuit of a constraints-based interaction design highlights the desire to confirm the dominant paradigm of abundance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1011},
numpages = {18},
keywords = {Solar Internet, Sustainable fashion, Constraint-based design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714001,
author = {Laurell Thorslund, Minna and Leifler, Ola},
title = {Exploring Assumptions about Sustainability: Towards a Constructive Framework for Action in Sustainable HCI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714001},
doi = {10.1145/3706598.3714001},
abstract = {The global environmental crises continue to get worse, fast approaching various irreversible thresholds. While a vast array of approaches to solving sustainability problems are found under the umbrella of Sustainable HCI, their contributions are sometimes hard to compare. In this essay, we describe a set of assumptions that influence what is considered meaningful and important areas of sustainability research, along four dimensions of sustainability: 1) the depth and nature of the sustainability challenges; 2) the role of technological innovation in sustainability; 3) what gets defined as "externalities" to a design or system; and 4) the time perspective used to consider sustainability. We argue that what one assumes within each of these dimensions directly influences what one means by the term "sustainability", which is then reflected in the questions that are asked, the methods chosen, the proposed solutions and the developed systems. By describing these assumptions and some of their commensurate actions, we offer a framework that may enable members of the SHCI community to reflect on and better position their own work and that of others in the field. Our intention is for the framework to lead to better transparency and more constructive conversations about where we might collectively direct our efforts moving forward.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1012},
numpages = {13},
keywords = {sustainability, climate change, predicament, theories of change},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713299,
author = {Englhardt, Zachary and H\"{a}hnlein, Felix and Mei, Yuxuan and Lin, Tong and Sun, Connor Masahiro and Zhang, Zhihan and Patel, Shwetak and Schulz, Adriana and Iyer, Vikram},
title = {Incorporating Sustainability in Electronics Design: Obstacles and Opportunities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713299},
doi = {10.1145/3706598.3713299},
abstract = {Life cycle assessment (LCA) is a methodology for holistically measuring the environmental impact of a product from initial manufacturing to end-of-life disposal. However, the extent to which LCA informs the design of computing devices remains unclear. To understand how this information is collected and applied, we interviewed 17 industry professionals with experience in LCA or electronics design, systematically coded the interviews, and investigated common themes. These themes highlight the challenge of LCA data collection and reveal distributed decision-making processes where responsibility for sustainable design choices—and their associated costs—is often ambiguous. Our analysis identifies opportunities for HCI technologies to support LCA computation and its integration into the design process to facilitate sustainability-oriented decision-making. While this work provides a nuanced discussion about sustainable design in the information and communication technologies (ICT) hardware industry, we hope our insights will also be valuable to other sectors.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1013},
numpages = {17},
keywords = {Environmental Impact, Life Cycle Assessment (LCA), Sustainability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713754,
author = {Bremer, Christina and Knowles, Bran and Friday, Adrian},
title = {Of Ironies and Agency: Energy Professionals' Views on Digital Interventions and Their Users},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713754},
doi = {10.1145/3706598.3713754},
abstract = {The efficacy of digital solutions to increase energy efficiency, including technical optimisations and behavioural influence, has long been a subject of debate within sustainable HCI (SHCI). While the viewpoints of policymakers and academics are frequently published (and often contradictory), less is known about the views of those on the ground. In this paper we ask: What are energy professionals’ views of digital energy-saving interventions and their users? What are the challenges they face implementing these interventions? Based on a university campus case study with twelve semi-structured interviews and a focus group with energy and facilities’ professionals, we illustrate how they strongly advocate digital efficiency as a pathway to sustainability; yet, this optimism is in apparent tension with key barriers they identify to realising ‘their seamless visions’, particularly the complexities of the human behaviour they are seeking to optimise. These findings underscore the seductiveness of techno-optimism and the need for more systemic change.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1014},
numpages = {14},
keywords = {Sustainable HCI, Energy Systems, Climate Change, Efficiency, Automation, Energy Professionals, Buildings, Occupants},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713714,
author = {Prabhudesai, Snehal and Kasi, Ananya Prashant and Mansingh, Anmol and Das Antar, Anindya and Shen, Hua and Banovic, Nikola},
title = {"Here the GPT made a choice, and every choice can be biased": How Students Critically Engage with LLMs through End-User Auditing Activity},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713714},
doi = {10.1145/3706598.3713714},
abstract = {Despite recognizing that Large Language Models (LLMs) can generate inaccurate or unacceptable responses, universities are increasingly making such models available to their students. Existing university policies defer the responsibility of checking for correctness and appropriateness of LLM responses to students and assume that they will have the required knowledge and skills to do so on their own. In this work, we conducted a series of user studies with students (N=47) from a large North American public research university to understand if and how they critically engage with LLMs. Our participants evaluated an LLM provided by the university in a quasi-experimental setup; first by themselves, and then with a scaffolded design probe that guided them through an end-user auditing exercise. Qualitative analysis of participant think-aloud and LLM interaction data showed that students without basic AI literacy skills struggle to conceptualize and evaluate LLM biases on their own. However, they transition to focused thinking and purposeful interactions when provided with structured guidance. We highlight areas where current university policies may fall short and offer policy and design recommendations to better support students.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1015},
numpages = {23},
keywords = {End-user Audit, End-user Algorithmic Audit, User-Driven Algorithm Auditing, Algorithmic Audit, Auditing Algorithms, Algorithmic Bias, Algorithmic Harm, Large Language Models, LLMs, AI Literacy, AI Education, Responsible AI.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713148,
author = {Neubaum, German and Chounta, Irene-Angelica and Gredel, Eva and Wiesche, David},
title = {A Pandemic for the Good of Digital Literacy? An Empirical Investigation of Newly Improved Digital Skills during COVID-19 Lockdowns},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713148},
doi = {10.1145/3706598.3713148},
abstract = {This research explores whether the rapid digital transformation due to COVID-19 managed to close or exacerbate the digital divide concerning users’ digital skills. We conducted a pre-registered survey with N = 1,143 German Internet users. Our findings suggest the latter: younger, male, and higher educated users were more likely to improve their digital skills than older, female, and less educated ones. According to their accounts, the pandemic helped Internet users improve their skills in communicating with others by using video conference software and reflecting critically upon information they found online. These improved digital skills exacerbated not only positive (e.g., feeling informed and safe) but also negative (e.g., feeling lonely) effects of digital media use during the pandemic. We discuss this research’s theoretical and practical implications regarding the impact of challenges, such as technological disruption and health crises, on humans’ digital skills, capabilities, and future potential, focusing on the second-level digital divide.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1016},
numpages = {11},
keywords = {second-level digital divide, digital skills, digital literacy, COVID-19, pandemic},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713173,
author = {Cao, Huajie Jay and Choi, Kahyun and Park, Claire and Lee, Hee Rin},
title = {AI Literacy for Underserved Students: Leveraging Cultural Capital from Underserved Communities for AI Education Research},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713173},
doi = {10.1145/3706598.3713173},
abstract = {As Artificial Intelligence (AI) continues to influence various aspects of society, the need for AI literacy education for K-12 students has grown. An increasing number of AI literacy studies aim to enhance students’ competencies in understanding, using, and critically evaluating AI systems. However, despite the vulnerabilities faced by students from underserved communities—due to factors such as socioeconomic status, gender, and race—these students remain underrepresented in existing research. To address this gap, this study focuses on leveraging the cultural capital that students acquire from their communities’ unique history and culture for AI literacy education. Education researchers have demonstrated that identifying and mobilizing cultural capital is an effective strategy for educating these populations. Through collaboration with 26 students from underserved communities—including those who are socioeconomically disadvantaged, female, or people of color—this paper identifies three types of cultural capital relevant to AI literacy education: 1) resistant capital, 2) communal capital, and 3) creative capital. The study also emphasizes that collaborative relationships between researchers and students are crucial for mobilizing cultural capital in AI literacy education research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1017},
numpages = {15},
keywords = {Culturl Capital; Artificial Intelligence; AI; AI Literacy; Underserved Communities; Racism, Sexism, Critical Padagogy, Education; K-12},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713841,
author = {Xie, Shixian and Zimmerman, John and Eslami, Motahhare},
title = {Exploring What People Need to Know to be AI Literate: Tailoring for a Diversity of AI Roles and Responsibilities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713841},
doi = {10.1145/3706598.3713841},
abstract = {AI literacy research has had great success in offering competencies that capture the knowledge and skills users and developers of AI need to have for a world full of AI, helping them maximize its benefits and minimize its harms. However, recent years have witnessed other roles beyond users and developers whose responsibilities have been complicated by AI. In this work, we apply a service design approach to identify such roles and their responsibilities across various AI applications. By mapping the responsibilities to current AI literacy competencies, we exposed gaps suggesting unmet learning needs in current AI literacy research: identifying and assessing AI benefits, strategizing about AI’s benefits and risks, and monitoring and refining deployed AI to understand their changing impact. We discuss implications for future AI literacy research and its connection to Responsible AI research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1018},
numpages = {16},
keywords = {AI Literacy, Service Design, Competencies, Responsible AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713667,
author = {Horvath, Anca-Simona and Raptis, Dimitrios},
title = {How Students in Creative Educations Appropriate Technology: A phenomenological analysis.},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713667},
doi = {10.1145/3706598.3713667},
abstract = {Building technological literacy is an important topic in education today while at the same time, creativity is seen as a desirable skill for professional practice and education alike as it is considered a catalyst for innovation. In this paper, we present a case study where we aim to understand how students in a creative education appropriate technology. We analyze qualitative data collected from students in a STEAM higher education undergraduate program called Art&amp;Technology: a program where students are introduced to an assortment of technological tools including software, programming, digital fabrication and physical prototyping which they employ in creating a variety of artifacts. We analyze how students learn and interact with these technologies by analyzing the collected data through a phenomenological lens of technology appropriation. We contribute with understandings on how technology is appropriated as it transforms from an object, to a tool until it finally becomes equipment.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1019},
numpages = {11},
keywords = {creativity, art, design, technology, appropriation, phenomenology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713126,
author = {Brailsford, Joe and Vetere, Frank and Velloso, Eduardo},
title = {Responsibility Attribution in Human Interactions with Everyday AI Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713126},
doi = {10.1145/3706598.3713126},
abstract = {How do individuals perceive AI systems as responsible entities in everyday collaborations between humans and AI? Drawing on psychological literature from attribution theory, praise-blame asymmetries and negativity bias, this study investigated the effects of perspective (actor vs observer) and outcome favorability (positive vs negative) on how participants (N=321) attributed responsibility for outcomes resulting from shared human-AI decision-making. Both Bayesian modelling and reflexive thematic analysis of results revealed that, overall, participants were more likely to attribute greater responsibility to the AI systems. When the outcome was positive, participants were more likely to ascribe shared responsibility to both Human and AI systems, rather than either separately. When the outcome was negative, participants were more likely to attribute responsibility to a single entity, but not consistently towards the human or the AI. These results build on the understanding of how individuals cast blame and praise for shared interactions involving AI systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1020},
numpages = {17},
keywords = {Artificial Intelligence, Praise, Blame, Responsibility Attribution, Responsible AI, Algorithmic Decision-Making, Human-AI Teams},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713297,
author = {Hashmi, Sumair Ijaz and Sarfaraz, Rimsha and Gr\"{o}ber, Lea and Javed, Mobin and Krombholz, Katharina},
title = {Understanding the Security Advice Mechanisms of Low Socioeconomic Pakistanis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713297},
doi = {10.1145/3706598.3713297},
abstract = {Low socioeconomic populations face severe security challenges while being unable to access traditional written advice resources. We present the first study to explore the security advice landscape of low socioeconomic people in Pakistan. With 20 semi-structured interviews, we uncover how they learn and share security advice and what factors enable or limit their advice sharing. Our findings highlight that they heavily rely on community advice and intermediation to establish and maintain security-related practices (such as passwords). We uncover how shifting social environments shape advice dissemination, e.g., across different workplaces. Participants leverage their social structures to protect each other against threats that exploit their financial vulnerability and lack of digital literacy. However, we uncover barriers to social advice mechanisms, limiting their effectiveness, which may lead to increased security and privacy risks. Our results lay the foundation for rethinking security paradigms and advice for this vulnerable population.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1021},
numpages = {25},
keywords = {Security Advice, Intermediation, Passwords, Threats, Global South, Low Socioeconomic},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713772,
author = {Xu, Yuansong and Shao, Yuheng and Dong, Jiahe and Shi, Shaohan and Jiang, Chang and Li, Quan},
title = {Advancing Problem-Based Learning with Clinical Reasoning for Improved Differential Diagnosis in Medical Education},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713772},
doi = {10.1145/3706598.3713772},
abstract = {Medical education increasingly emphasizes students’ ability to apply knowledge in real-world clinical settings, focusing on evidence-based clinical reasoning and differential diagnoses. Problem-based learning (PBL) addresses traditional teaching limitations by embedding learning into meaningful contexts and promoting active participation. However, current PBL practices are often confined to medical instructional settings, limiting students’ ability to self-direct and refine their approaches based on targeted improvements. Additionally, the unstructured nature of information organization during analysis poses challenges for record-keeping and subsequent review. Existing research enhances PBL realism and immersion but overlooks the construction of logic chains and evidence-based reasoning. To address these gaps, we designed e-MedLearn, a learner-centered PBL system that supports more efficient application and practice of evidence-based clinical reasoning. Through controlled study (N=19) and testing interviews (N=13), we gathered data to assess the system’s impact. The findings demonstrate that e-MedLearn improves PBL experiences and provides valuable insights for advancing clinical reasoning-based learning.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1022},
numpages = {32},
keywords = {Problem-Based Learning, Medical Education, Differential Diagnosis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714024,
author = {M\"{o}rth, Eric and Kostic, Zona and Gehlenborg, Nils and Pfister, Hanspeter and Beyer, Johanna and Nobre, Carolina},
title = {Beyond Time and Accuracy: Strategies in Visual Problem-Solving},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714024},
doi = {10.1145/3706598.3714024},
abstract = {In this paper, we explore viewers’ strategies in visual problem-solving tasks. We build on the traditional metrics of accuracy and time to better understand the learning that occurs as individuals interact with visualizations. We conducted an in-lab eye-tracking user study with 53 participants from diverse demographic backgrounds. Using questions from the Visualization Literacy Assessment Test (VLAT), we examined participants’ problem-solving strategies. We employed a mixed-methods approach capturing quantitative data on performance and gaze patterns, as well as qualitative data through think-alouds and sketches by participants as they reported on their problem-solving approach. Our analysis reveals not only the various cognitive strategies leading to correct answers but also the nature of mistakes and the conceptual misunderstandings that underlie them. This research contributes to the enhancement of visualization design guidelines by incorporating insights into the diverse strategies and cognitive processes employed by users.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1023},
numpages = {22},
keywords = {Visualization, visualization literacy, problem-solving strategies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713229,
author = {Bu\c{c}inca, Zana and Swaroop, Siddharth and Paluch, Amanda E. and Doshi-Velez, Finale and Gajos, Krzysztof Z.},
title = {Contrastive Explanations That Anticipate Human Misconceptions Can Improve Human Decision-Making Skills},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713229},
doi = {10.1145/3706598.3713229},
abstract = {People’s decision-making abilities often fail to improve or may even erode when they rely on AI for decision-support, even when the AI provides informative explanations. We argue this is partly because people intuitively seek contrastive explanations, which clarify the difference between the AI’s decision and their own reasoning, while most AI systems offer “unilateral” explanations that justify the AI’s decision but do not account for users’ knowledge and thinking. To address potential human knowledge gaps, we introduce a framework for generating human-centered contrastive explanations which explain the difference between AI’s choice and a predicted, likely human choice about the same task. Results from a large-scale experiment (N = 628) demonstrate that contrastive explanations significantly enhance users’ independent decision-making skills compared to unilateral explanations, without sacrificing decision accuracy. As concerns about deskilling in AI-supported tasks grow, our research demonstrates that integrating human reasoning into AI design can promote human skill development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1024},
numpages = {25},
keywords = {AI-assisted decision-making, human-AI interaction, explainable AI, human skills, contrastive explanations},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714082,
author = {Spatharioti, Sofia Eleni and Rothschild, David and Goldstein, Daniel G and Hofman, Jake M},
title = {Effects of LLM-based Search on Decision Making: Speed, Accuracy, and Overreliance},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714082},
doi = {10.1145/3706598.3714082},
abstract = {Recent advances in large language models (LLMs) are transforming online applications, including search tools that accommodate complex natural language queries and provide direct responses. There are, however, concerns about the veracity of LLM-generated content due to potential for LLMs to "hallucinate". In two online experiments, we examined how LLM-based search affects behavior compared to traditional search and explored ways to reduce overreliance on incorrect LLM-based output. Participants assigned to LLM-based search completed tasks more quickly, with fewer but more complex queries, and reported a more satisfying experience. While decision accuracy was comparable when the LLM was correct, users overrelied on incorrect information when the model erred. In a second experiment, a color-coded highlighting system helped users detect errors, improving decision accuracy without affecting other outcomes. These findings suggest that LLM-based search tools have promise as decision aids but also highlight the importance of effectively communicating uncertainty to mitigate overreliance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1025},
numpages = {15},
keywords = {large language models, information retrieval, search, uncertainty, hallucination, decision making},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713462,
author = {van Arum, Sterre and Gen\c{c}, H\"{u}seyin U\u{g}ur and Reidsma, Dennis and Karahano\u{g}lu, Arma\u{g}an},
title = {Selective Trust: Understanding Human-AI Partnerships in Personal Health Decision-Making Process},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713462},
doi = {10.1145/3706598.3713462},
abstract = {As artificial intelligence (AI) becomes more embedded in personal health technology, its potential to transform health decision-making through personalised recommendations is becoming significant. However, there is limited understanding of how individuals perceive AI-assisted decision-making in the context of personal health. This study investigates the impact of AI-assisted decision-making on trust in physical activity-related health decisions. By employing MoveAI, a GPT-4.0-based physical activity decision-making tool, we conducted a mixed-methods study and conducted an online survey (N=184) and semi-structured interviews (N=24) to explore this dynamic. Our findings emphasise the role of nuanced personal health recommendations and individual decision-making styles in shaping trust in AI-assisted personal health decision-making. This paper contributes to the HCI literature by elucidating the relationship between decision-making styles and trust in the AI-assisted personal health decision-making process and showing the challenges of aligning AI recommendations with individual decision-making preferences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1026},
numpages = {21},
keywords = {AI-assisted decision-making, decision-making styles, personal health technology, physical activity decisions, trust},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713508,
author = {Orii, Lisa and Harrington, Elizabeth K and Gitome, Serah and Cheruiyot, Nelson Kiprotich and Bukusi, Elizabeth Anne and Cheng, Sandy and Fu, Ariel and Khandelwal, Khushi and Narasimhan, Shrimayee and Anderson, Richard},
title = {Supporting Contraceptive Decision-Making in the Intermediated Pharmacy Setting in Kenya},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713508},
doi = {10.1145/3706598.3713508},
abstract = {Adolescent girls and young women (AGYW) in sub-Saharan Africa face unique barriers to contraceptive access and lack AGYW-centered contraceptive decision-support resources. To empower AGYW to make informed choices and improve reproductive health outcomes, we developed a tablet-based application to provide contraceptive education and decision-making support in the pharmacy setting - a key source of contraceptive services for AGYW - in Kenya. We conducted workshops with AGYW and pharmacy providers in Kenya to gather app feedback and understand how to integrate the intervention into the pharmacy setting. Our analysis highlights how intermediated interactions - a multiuser, cooperative effort to enable technology use and information access - could inform a successful contraceptive intervention in Kenya. The potential strengths of intermediation in our setting inform implications for technological health interventions in intermediated scenarios in low- and middle-income countries, including challenges and opportunities for extending impact to different populations and integrating technology into resource-constrained healthcare settings.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1027},
numpages = {23},
keywords = {HCI4D, intermediation, health, contraception},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713145,
author = {Yurrita, Mireia and Verma, Himanshu and Balayn, Agathe and Gadiraju, Ujwal and Pont, Sylvia C. and Bozzon, Alessandro},
title = {Towards Effective Human Intervention in Algorithmic Decision-Making: Understanding the Effect of Decision-Makers' Configuration on Decision-Subjects' Fairness Perceptions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713145},
doi = {10.1145/3706598.3713145},
abstract = {Human intervention is claimed to safeguard decision-subjects’ rights in algorithmic decision-making and contribute to their fairness perceptions. However, how decision-subjects perceive hybrid decision-maker configurations (i.e., combining humans and algorithms) is unclear. We address this gap through a mixed-methods study in an algorithmic policy enforcement context. Through qualitative interviews (Study&nbsp;1; N1 = 21), we identify three characteristics (i.e., decision-maker’s profile, model type, input data provenance) that affect how decision-subjects perceive decision-makers’ ability, benevolence, and integrity (ABI). Through a quantitative study (Study&nbsp;2; N2 = 223), we then systematically evaluate the individual and combined effects of these characteristics on decision-subjects’ perceptions towards decision-makers, and fairness perceptions. We found that only decision-maker’s profile contributes to perceived ability, benevolence, and integrity. Interestingly, the effect of decision-maker’s profile on fairness perceptions was mediated by perceived ability and integrity. Our findings have design implications for ensuring effective human intervention as a protection against harmful algorithmic decisions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1028},
numpages = {21},
keywords = {human intervention, fairness perceptions, decision-maker, ability, benevolence, integrity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714280,
author = {Rashik, Mashrur and Sweth, Shilpa and Agrawal, Nishtha and Kochar, Saiyyam and Smith, Kara M and Rajabiyazdi, Fateme and Setlur, Vidya and Mahyar, Narges and Sarvghad, Ali},
title = {AI-Enabled Conversational Journaling for Advancing Parkinson's Disease Symptom Tracking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714280},
doi = {10.1145/3706598.3714280},
abstract = {Journaling plays a crucial role in managing chronic conditions by allowing patients to document symptoms and medication intake, providing essential data for long-term care. While valuable, traditional journaling methods often rely on static, self-directed entries, lacking interactive feedback and real-time guidance. This gap can result in incomplete or imprecise information, limiting its usefulness for effective treatment. To address this gap, we introduce Patrika, an AI-enabled prototype designed specifically for people with Parkinson’s disease (PwPD). The system incorporates cooperative conversation principles, clinical interview simulations, and personalization to create a more effective and user-friendly journaling experience. Through two user studies with PwPD and iterative refinement of Patrika, we demonstrate conversational journaling’s significant potential in patient engagement and collecting clinically valuable information. Our results showed that generating probing questions Patrika turned journaling into a bi-directional interaction. Additionally, we offer insights for designing journaling systems for healthcare and future directions for promoting sustained journaling.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1029},
numpages = {23},
keywords = {Conversational implicature, Gricean maxims, context, journaling, healthcare.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714256,
author = {Hsu, Long-Jing and Swaminathan, Manasi and Khoo, Weslie and Amon, Kyrie Jig and Sato, Hiroki and Dobbala, Sathvika and Tsui, Kate and Crandall, David and Sabanovic, Selma},
title = {Bittersweet Snapshots of Life: Designing to Address Complex Emotions in a Reminiscence Interaction between Older Adults and a Robot},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714256},
doi = {10.1145/3706598.3714256},
abstract = {Human-Computer Interaction and Human-Robot Interaction researchers have developed various reminiscence technologies for older adults, but the focus of such work has mostly been on making the technology usable and improving older adults’ memory recall. Our study of a robot facilitating reminiscence through conversations about personal photographs with 20 older adults uncovered a less discussed aspect of such interactions: reminiscence can evoke both bitter and sweet emotions. Without adequate emotional sensitivity, the robot sometimes responded inappropriately, requiring researchers to intervene in the interaction to address misunderstandings. To understand how to better address these challenges, we conducted a follow-up co-design workshop with 7 older adults to explore how the robot could better support managing bittersweet emotions. Through reflexive thematic analysis of the two studies, this paper identifies factors that trigger bittersweet emotions during reminiscence with a robot and provides strategies for technology to manage these emotions during such interactions. This research highlights the importance of addressing emotional experiences in the design of reminiscence technology. It also raises ethical concerns about the emotional vulnerability of deploying one-on-one AI technologies for older adults.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1030},
numpages = {18},
keywords = {Bittersweet, HRI, Human-Robot Interaction, older adults, photographs, reminiscence, emotions},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713810,
author = {Sun, Jingwei and Zhang, Zhongyue and Wang, Mengyang and Li, Nianlong and Lu, Zhangwei and Xiang, Yan and Zhang, Liuxin and Zhang, Yu and Wang, Qianying and Fan, Mingming},
title = {Chorus of the Past: Toward Designing a Multi-agent Conversational Reminiscence System with Digital Artifacts for Older Adults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713810},
doi = {10.1145/3706598.3713810},
abstract = {Reminiscence has been shown to provide benefits for older adults, but traditionally relies on personal photos as memory cues and interactions with real people who may not always be available. We present ReminiBuddy, a novel LLM-powered multi-agent conversational system, which allows older adults to engage with two distinct agents—one embodying an older identity and the other a younger identity—while using not only personal photos but also 3D models of generic nostalgic objects as memory cues. Our study, with older adult participants, found that the conversational approach both enjoyable and beneficial for reminiscence. While the younger agent was perceived as more emotionally engaging, the older one fostered greater resonance in content. Personal photos prompted autobiographical memories, whereas 3D generic nostalgic objects evoked shared memories of an era, contributing to a more multifaceted reminiscence experience. We further present design implications for better supporting older adults in reminiscing with LLM-powered conversational agents.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1031},
numpages = {22},
keywords = {Multi-agent Conversational System, Conversational agents, Glasses-free 3D Monitor, Reminiscence, Human-AI Interaction, Older Adults},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713135,
author = {Ghaiumy Anaraky, Reza and Schuster, Amy M and Van Fossen, Jenna and Nov, Oded and Cotten, Shelia},
title = {Increased Use of Asocial Technologies Is Associated with Reduced Well-being Among Older Adults},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713135},
doi = {10.1145/3706598.3713135},
abstract = {In this paper, we introduce the concept of asocial technologies (e.g., online purchases), which digitize activities that traditionally would have been carried out in person (e.g., in-person shopping). We argue that using asocial technologies limits users’ opportunities for face-to-face interactions, which can be particularly detrimental to older adults (65+) who are more prone to social isolation and loneliness. Analyzing longitudinal survey data from the U.S. National Health and Aging Trends Study (N = 1925), we identified the adverse effects of asocial technologies on older adults’ well-being. Using a within-between-level analytical framework, we found that an increased use of asocial technologies in a given year is associated with higher levels of anxiety and depression, and lower levels of overall health experienced by older adults in the following year. This work highlights the negative consequences of asocial technology use, emphasizing the need for more systematic designs in digital innovations that target seniors.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1032},
numpages = {10},
keywords = {Older adults, technology use and well-being, asocial technologies, depression and anxiety, face-to-face interactions},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713920,
author = {Wen, Tianyang and Zhang, Xucheng and Wan, Zhirong and Zhao, Jing and Zhu, Yicheng and Su, Ning and Peng, Xiaolan and Huang, Jin and Sun, Wei and Tian, Feng and Li, Franklin Mingzhe},
title = {PANDA: Parkinson's Assistance and Notification Driving Aid},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713920},
doi = {10.1145/3706598.3713920},
abstract = {Parkinson’s Disease (PD) significantly impacts driving abilities, often leading to early driving cessation or accidents due to reduced motor control and increasing reaction times. To diminish the impact of these symptoms, we developed PANDA (Parkinson’s Assistance and Notification Driving Aid), a multi-modality real-time alert system designed to monitor driving patterns continuously and provide immediate alerts for irregular driving behaviors, enhancing driver safety of individuals with PD. The system was developed through a participatory design process with 9 people with PD and 13 non-PD individuals using a driving simulator, which allowed us to identify critical design characteristics and collect detailed data on driving behavior. A user study involving individuals with PD evaluated the effectiveness of PANDA, exploring optimal strategies for delivering alerts and ensuring they are timely and helpful. Our findings demonstrate that PANDA has the potential to enhance the driving safety of individuals with PD, offering a valuable tool for maintaining independence and confidence behind the wheel.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1033},
numpages = {23},
keywords = {Parkinson’s disease, driving assistance system, real-time alert},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714277,
author = {Zhang, Xuechen and He, Changyang and Zhang, Peng and Gu, Hansu and Gu, Ning and Shen, Qi and Hu, Zhan and Lu, Tun},
title = {RemiHaven: Integrating "In-Town" and "Out-of-Town" Peers to Provide Personalized Reminiscence Support for Older Drifters},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714277},
doi = {10.1145/3706598.3714277},
abstract = {With increasing social mobility and an aging society, more older adults in China are migrating to new cities, known as “older drifters”. Due to fewer social connections and cultural adaptation, they face negative emotions such as loneliness and depression. While reminiscence-based interventions have been used to improve older adults’ psychological well-being, challenges such as the lack of tangible materials and limited social resources constrain the feasibility of traditional reminiscence approaches for older drifters. To address this challenge, we designed RemiHaven, a personalized reminiscence support tool based on a two-phase formative study. It integrates “In-Town” and “Out-of-Town” peer agents to enhance personalization, engagement, and emotional resonance in the reminiscence process powered by Multimodal Large Language Models (MLLMs). Our evaluations show RemiHaven’s strengths in supporting reminiscence while identifying potential challenges. We conclude by offering insights for the future design of reminiscence support tools for older migrants.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1034},
numpages = {20},
keywords = {Older Drifters, Reminiscence Support, Reminiscence-Based Intervention, Multimodal Large Language Models, Human-AI Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714093,
author = {Short, Amelia and Su, Norman Makoto and Hu, Ruipu and Choe, Eun Kyoung and Kacorri, Hernisa and Danilovich, Margaret and Conroy, David E. and Jette, Shannon and Barnett, Beth and Lazar, Amanda},
title = {Tracking and its Potential for Older Adults with Memory Concerns},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714093},
doi = {10.1145/3706598.3714093},
abstract = {Much research on older people with memory concerns is focused on tracking and informed by the priorities of others. In this paper, we seek to understand the potential that people with memory concerns see in tracking. We conducted interviews with 29 participants with concerns about their memory and engaged in an affective writing approach. We find a range of potentials that can be traced to how participants are already self-tracking. Emotions associated with these potentials vary: from acceptance to resistance, and positive anticipation to aversion. Participants are emotionally motivated to foreclose possibilities in some instances and keep them open in others. While individual and unique, potential is structured by forces that include individual routines, relationships with others, and macro-level institutions and cultural contexts. We reflect on these findings in the context of research on self-tracking with older adults, designing with ambiguity, and forces that structure the experience of living with memory concerns.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1035},
numpages = {15},
keywords = {Older adults, cognitive impairment, dementia, memory concerns, affect, stigma, tracking, self-tracking, ambiguity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713614,
author = {Winter, Lauren and Zendle, David I and Helsby, Laura},
title = {"Leave our kids alone!": Exploring Concerns Reported by Parents in 1-star Reviews},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713614},
doi = {10.1145/3706598.3713614},
abstract = {Children are playing games from a young age and, despite their best efforts, parents often lack the support to fully understand what their children are playing. Ratings systems like PEGI are designed to allow informed parental decisions, but it is currently largely unknown if they capture what parents care about. In this study, we analysed 821 1-star reviews of 40 top-grossing mobile games on the Google Play store focused on parental concerns. We used content analysis to identify the key concerns that parents were expressing with regards to the games their children were playing. The reviews found that parents often reported technical issues, issues surrounding in-game purchases and concerns around player-to-player interaction. This research has implications for the way games are sold to parents and the way children play games, as well as presenting some suggestions for future research and innovation in this area.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1036},
numpages = {16},
keywords = {video games, children, reviews, qualitative research},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713192,
author = {Xu, Wenjie and Yu, Zhoutong and Liu, Yikun and Ying, Fangtian},
title = {Accompany Sleep: Using GenAI to Create Bedtime Stories for Mediating Parent-Child Relationships in LBC Families},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713192},
doi = {10.1145/3706598.3713192},
abstract = {Left-Behind Children (LBC) refers to children who lack daily companionship due to their parents working away from home, accounting for approximately one-fifth of all children in China. Due to the lack of communication and emotional support from their parents, LBCs often experience physical and mental health issues. Effective communication is usually limited by time and topics, and the format of mobile devices and video calls is not always suitable. To address this issue, we developed the Accompany Sleep system. Parents upload daily life content through the app, and the system uses ChatGPT4o to create bedtime stories projected to the LBC. To explore the role of Accompany Sleep in family mediation, we conducted a one-month user study involving four families. The results of the study indicated that both parents and children exhibited positive behaviors, the parent-child relationship was effectively strengthened, and GenAI played a crucial role in this process. Based on these findings, this paper discusses how Accompany Sleep facilitated behavioral changes and improved parent-child relationships while expanding the application of GenAI in the family domain.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1037},
numpages = {19},
keywords = {Parent-child relationship, left-behind children, bedtime stories, generative artificial intelligence, emotional connection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713596,
author = {Cha, Yoon Jeong and Chen, Jiongyu and Gunal, Yasemin and Zhu, Qiying and Newman, Mark W and Park, Sun Young},
title = {Collaborative Health-Tracking Technologies for Children and Parents: A Review of Current Studies and Directions for Future Research},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713596},
doi = {10.1145/3706598.3713596},
abstract = {Collaborative health-tracking technologies for children and parents have gained significant attention in recent years in HCI. This review examines the current state of these technologies by analyzing 29 studies screened from 15,973 search results across three databases. Our findings revealed three primary goals in these technologies: promoting family health, improving children’s health through child-parent co-tracking, and fostering children’s independence in self-tracking. For each goal, we examined child-parent roles, data types collected, and features that facilitate or hinder collaboration. Our findings highlight key directions for future research, including designing adaptable technologies to reflect evolving child-parent roles, exploring different technologies and tracking topics that impact child-parent dynamics, involving children in the system design stage to enhance collaborative features, and studying diverse populations with varied family characteristics. These insights aim to guide the creation of more effective and inclusive collaborative health-tracking technologies for children and parents.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1038},
numpages = {13},
keywords = {child, parent, family, health tracking, child-parent collaboration, collaborative tracking, collaborative healthcare technology, literature review, systematic review, review},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713548,
author = {Dumaru, Prakriti and Al-Ameen, Mahdi Nasrullah},
title = {One Size Doesn't Fit All: Towards Design and Evaluation of Developmentally Appropriate Parental Control Tool},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713548},
doi = {10.1145/3706598.3713548},
abstract = {As children progress through developmental stages, they undergo substantial biological, cognitive, and social changes, creating unique needs for online safety across different age groups (e.g., young children, tweens, teens). The existing parental control tools fail to account for these differences, leaving a notable gap in the literature on parental mediation. To this end, we conducted 10 focus group sessions with a total of 20 parents to understand their preferences for age-appropriate design components that promote self-regulation and open communication, followed by an ideation workshop with four UX design experts to translate these preferences into customized features. We then evaluated these designs (presented as storyboards) through semi-structured interviews with 25 parents. Our study joins the body of work on parental mediation, providing valuable insights into customizing parental control settings as children transition through the developmental stages. Based on our findings, we offer guidelines for future research in these directions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1039},
numpages = {22},
keywords = {parental mediation, open communication, self-regulation, focus groups, ideation workshop, storyboarding, interviews, developmental parenting},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713330,
author = {Ho, Hui-Ru and Kargeti, Nitigya and Liu, Ziqi and Mutlu, Bilge},
title = {SET-PAiREd: Designing for Parental Involvement in Learning with an AI-Assisted Educational Robot},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713330},
doi = {10.1145/3706598.3713330},
abstract = {AI-assisted learning companion robots are increasingly used in early education. Many parents express concerns about content appropriateness, while they also value how AI and robots could supplement their limited skill, time, and energy to support their children’s learning. We designed a card-based kit, SET, to systematically capture scenarios that have different extents of parental involvement. We developed a prototype interface, PAiREd, with a learning companion robot to deliver LLM-generated educational content that can be reviewed and revised by parents. Parents can flexibly adjust their involvement in the activity by determining what they want the robot to help with. We conducted an in-home field study involving 20 families with children aged 3–5. Our work contributes to an empirical understanding of the level of support parents with different expectations may need from AI and robots and a prototype that demonstrates an innovative interaction paradigm for flexibly including parents in supporting their children.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1040},
numpages = {20},
keywords = {Human-robot interaction, human-AI interaction, large language model (LLM), flexible parental involvment, parent-child dyads, informal learning, young children, home, field study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713422,
author = {Ma, Renkai and Li, Yao and Bai, Sunhye and Kou, Yubo and Gui, Xinning},
title = {Weighing Benefits and Harms: Parental Mediation on Social Video Platforms},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713422},
doi = {10.1145/3706598.3713422},
abstract = {Children’s increasing use of social video platforms like YouTube and TikTok raises safety concerns for parents, yet little research explores how they mediate their children’s social video consumption. Previous studies often treat online harms and benefits as outcomes of parental mediation, overlooking how these factors affect parental mediation or how these effects vary with parents’ self-efficacy. To address these gaps, we surveyed 285 parents and found that perceived content informativeness value and content-inherent harm increase mediation, while entertainment value and creator trustworthiness decrease it. Parents’ self-efficacy—digital literacy and confidence in understanding their children’s consumption—and children’s consumption frequency significantly moderate these effects. These findings lead us to discuss how parental mediation differs between traditional media and social video platforms, where parents perform a more complex benefit-harm analysis due to competing effects of perceived harms and benefits. We propose strategies for enhancing parents’ self-efficacy and platform-parent collaboration in children’s online safety.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1041},
numpages = {26},
keywords = {parental mediation, children’s online safety, social video platform},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713360,
author = {Zhao, Wenxin and Yu, Fangyu and Zhang, Peng and Gu, Hansu and Wang, Lin and Qiao, Siyuan and Lu, Tun and Gu, Ning},
title = {YouthCare: Building a Personalized Collaborative Video Censorship Tool to Support Parent-Child Joint Media Engagement},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713360},
doi = {10.1145/3706598.3713360},
abstract = {To mitigate the negative impacts of online videos on teenagers, existing research and platforms have implemented various parental mediation mechanisms, such as Parent-Child Joint Media Engagement (JME). However, JME generally relies heavily on parents’ time, knowledge, and experience. To fill this gap, we aim to design an automatic tool to help parents/children censor videos more effectively and efficiently in JME. For this goal, we first conducted a formative study to identify the needs and expectations of teenagers and parents for such a system. Based on the findings, we designed YouthCare, a personalized collaborative video censorship tool that supports parents and children to collaboratively filter out inappropriate content and select appropriate content in JME. An evaluation with 10 parent-child pairs demonstrated YouthCare’s several strengths in supporting video censorship, while also highlighting some potential problems. These findings inspire us to propose several insights for the future design of parent-child collaborative JME systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1042},
numpages = {20},
keywords = {Children/Parents, Video Censorship, Joint Media Engagement, Personalization, Chatbot},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713655,
author = {Sun, Yuling and Tang, Minglong and Lu, Zhicong and He, Liang},
title = { 'Douyin is My Nourishment of the Mind': Exploring the Infrastructuralization Process of Short Video Sharing Platforms From Rural People’s Perspective},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713655},
doi = {10.1145/3706598.3713655},
abstract = {Infrastructure is a common topic in rural areas around the world. While most existing research attention has been paid to the difficulties with Internet access and the fragile infrastructure of rural areas, our study contributes an empirical understanding of digital platform-as-infrastructure - short video sharing platforms (SVSPs) in rural China. Through semi-structured interviews with 26 rural users including content creator and regular users, we elaborate on their practices, experiences, and perceptions of SVSPs. We foreground that SVSPs have reshaped rural people’s daily routines and enhanced their self-worth and identity, which in turn led to deeper and more sustained engagement with these platforms. We then situate our findings within the broader context of platform-as-infrastructure, discussing how rural people’s adoption and usage intertwine with the infrastructuralization process of SVSPs. We end by discussing how to make future platform-as-infrastructure more engaged and beneficial to rural populations, meeting their practical usage and well-being requirements.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1043},
numpages = {16},
keywords = {Rural, Short-form video sharing platforms (SVSPs), Infrastructure, Infrastructuralization, Platform-as-infrastructure, Practice, Routine, Identity, Social Network},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713661,
author = {Zhang, Qinshi and Wen, Ruoyu and Hendra, Latisha Besariani and Ding, Zijian and LC, Ray},
title = {Can AI Prompt Humans? Multimodal Agents Prompt Players? Game Actions and Show Consequences to Raise Sustainability Awareness},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713661},
doi = {10.1145/3706598.3713661},
abstract = {Unsustainable behaviors are challenging to prevent due to their long-term, often unclear consequences. Serious games offer a promising solution by creating artificial environments where players can immediately experience the outcomes of their actions. To explore this potential, we developed EcoEcho, a GenAI-powered game leveraging multimodal agents to raise sustainability awareness. These agents engage players in natural conversations, prompting them to take in-game actions that lead to visible environmental impacts. We evaluated EcoEcho using a mixed-methods approach with 23 participants. Results show a significant increase in intended sustainable behaviors post-game, although attitudes towards sustainability had only marginal effects, suggesting that in-game actions likely can motivate intended real world behaviors despite similar opinions on sustainability. This finding highlights multimodal agents and action-consequence mechanics to effectively raising sustainability awareness and the potential of motivating real-world behavioral change.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1044},
numpages = {29},
keywords = {Multimodal Agents, Sustainability Awareness, Generative AI, In-Game Action},
location = {
},
series = {CHI '25}
}

@inbook{10.1145/3706598.3713782,
author = {Chen, Zhanming and Ghaju, Alisha and Hang, May and Maestre, Juan Fernando and Shin, Ji Youn},
title = {Designing Health Technologies for Immigrant Communities: Exploring Healthcare Providers' Communication Strategies with Patients},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713782},
abstract = {Patient-provider communication is an important aspect of successful healthcare, as it can directly lead to positive health outcomes. Previous studies examined factors that facilitate communication between healthcare providers and patients in socially marginalized communities, especially developing countries, and applied identified factors to technology development. However, there is limited understanding of how providers work with patients from immigrant populations in a developed country. By conducting semi-structured interviews with 15 providers working with patients from an immigrant community with unique cultural characteristics, we identified providers’ effective communication strategies, including acknowledgment, community involvement, gradual care, and adaptive communication practices (i.e., adjusting the communication style). Based on our findings, we highlight cultural competence and discuss design implications for technologies to support health communication in immigrant communities. Our suggestions propose approaches for HCI researchers to identify practical, contextualized cultural competence for their health technology design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1045},
numpages = {19}
}

@inproceedings{10.1145/3706598.3714232,
author = {Sun, Yuling and Chen, Jiaju and Zhou, Xiaomu and Ma, Xiaojuan and Yao, Bingsheng and Zhang, Kai and He, Liang and Wang, Dakuo},
title = {Live-Streaming-Based Dual-Teacher Classes for Equitable Education: Insights and Challenges From Local Teachers' Perspective in Disadvantaged Areas},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714232},
doi = {10.1145/3706598.3714232},
abstract = {Educational inequalities in disadvantaged areas have long been a global concern. While Information and Communication Technologies (ICTs) have shown great potential in addressing this issue, the unique challenges in disadvantaged areas often hinder the practical effectiveness of such technologies. This paper examines live-streaming-based dual-teacher classes (LSDC) through a qualitative study in disadvantaged regions of China. Our findings indicate that, although LSDC offers students in these regions access to high-quality educational resources, its practical implementation is fraught with challenges. Specifically, we foreground the pivotal role of local teachers in mitigating these challenges. Through a series of situated efforts, local teachers contextualize high-quality lectures to the local classroom environment, ensuring the expected educational outcomes. Based on our findings, we argue that greater recognition and support for the situational practices of local teachers is essential for fostering a more equitable, sustainable, and scalable technology-driven educational model in disadvantaged areas.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1046},
numpages = {18},
keywords = {Education, Remote Education, Technology, Live-streaming, China, Teachers, Disadvantaged Area, Education Equality, Education Equity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713817,
author = {Salehzadeh Niksirat, Kavous and Munyendo, Collins W. and Batista Leal Neto, Onicio and Katya, Muswagha and Kouassi, Cyrille and Ochieng, Kevin and Georgina, Angoa and Olayo, Bernard and Barras, Jean-Philippe and Cattuto, Ciro and Aviv, Adam J. and Troncoso, Carmela},
title = {Reimagining Wearable-Based Digital Contact Tracing: Insights from Kenya and C\^{o}te d'Ivoire},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713817},
doi = {10.1145/3706598.3713817},
abstract = {While digital contact tracing has been extensively studied in Western contexts, its relevance and application in Africa remain largely unexplored. This study focuses on Kenya and C\^{o}te&nbsp;d’Ivoire to uncover user perceptions and inform the design of culturally resonant contact tracing technologies. Utilizing a wearable proximity sensor as a technology probe, we conducted field studies with healthcare workers and community members in rural areas through interviews (N = 19) and participatory design workshops (N = 72). Our findings identify critical barriers to adoption, including low awareness, widespread misconceptions, and social stigma. The study emphasizes the need for culturally sensitive and discreet wearables and advocates for awareness campaigns over mandates to foster adoption. Our work addresses the unique needs of Kenyan and Ivorian populations, offering vital design recommendations and insights to guide designers and policymakers in enhancing digital contact tracing adoption across Africa.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1047},
numpages = {23},
keywords = {HCI4D, Africa, contact tracing, wearables, social acceptability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713315,
author = {Chan, Ka I and Hu, Siying and Wang, Yuntao and Xu, Xuhai and Lu, Zhicong and Shi, Yuanchun},
title = {The Odyssey Journey: Top-Tier Medical Resource Seeking for Specialized Disorder in China},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713315},
doi = {10.1145/3706598.3713315},
abstract = {It is pivotal for patients to receive accurate health information, diagnoses, and timely treatments. However, in China, the significant imbalanced doctor-to-patient ratio intensifies the information and power asymmetries in doctor-patient relationships. Health information-seeking, which enables patients to collect information from sources beyond doctors, is a potential approach to mitigate these asymmetries. While HCI research predominantly focuses on common chronic conditions, our study focuses on specialized disorders, which are often familiar to specialists but not to general practitioners and the public. With Hemifacial Spasm (HFS) as an example, we aim to understand patients’ health information and top-tier1 medical resource seeking journeys in China. Through interviews with three neurosurgeons and 12 HFS patients from rural and urban areas, and applying Actor-Network Theory, we provide empirical insights into the roles, interactions, and workflows of various actors in the health information-seeking network. We also identified five strategies patients adopted to mitigate asymmetries and access top-tier medical resources, illustrating these strategies as subnetworks within the broader health information-seeking network and outlining their advantages and challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1048},
numpages = {18},
keywords = {Health Information Seeking, Hemifacial Spasm, Actor-Network Theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714324,
author = {Janzen, Leon and Putz, Florentin and Kaufhold, Marc-Andr\'{e} and Straub, Kolja and Hollick, Matthias},
title = {The User Perspective on Island-Ready 6G Communication: A Survey of Future Smartphone Usage in Crisis-Struck Areas with Local Cellular Connectivity},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714324},
doi = {10.1145/3706598.3714324},
abstract = {Using smartphone apps during crises is well-established, proving critical for efficient crisis response. However, such apps become futile without an Internet connection, which is a common issue during crises. The ongoing 6G standardization explores the capability to provide local cellular connectivity for areas cut off from the Internet in crises. This paper introduces to the HCI community the concept of cellular island connectivity in isolated areas, promising a seamless transition from normal operation to island operation with local-only cellular connectivity. It presents findings from a survey (N = 857) among adult smartphone users from major German cities regarding their smartphone usage preferences in this model. Results show a shift in app demand, with users favoring general-purpose apps over dedicated crisis apps in specific scenarios. We prioritize smartphone services based on their criticality, distinguishing between apps essential for crisis response and those supporting routines. Our findings provide operators, developers, and authorities insights into making user-centric design decisions for implementing island-ready 6G communication.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1049},
numpages = {22},
keywords = {User-Centric, Smartphone Interaction, Island-Ready, 6G Communication, Smartphone Usage, Island Connectivity, Local Communication, Island Networking, Local-First, Decentralized 6G, Distributed Core Network, Crisis, Resilience},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713249,
author = {Upreti, Divesh and Maheshwari, Aditi and Tabb, Taylor and Polykretis, Ioannis and Gallo, Eric M and Stewart, Kenneth Michael and LaToza, Thomas D. and Danielescu, Andreea},
title = {Advancing HCI with Neuromorphic Technology: Guidelines for Designing User-Friendly Developer Tools for Neuromorphic Development},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713249},
doi = {10.1145/3706598.3713249},
abstract = {Neuromorphic technology offers advantages such as low-power processing, low latency, adaptive learning, and noise tolerance, making it ideal for edge computing applications. However, developers face significant hurdles due to the nascent nature of the field, including limited access to hardware and software, lack of benchmarks, and the need for deep interdisciplinary knowledge. Through interviews with 12 practitioners from both industry and academia, we conducted a thematic analysis to understand the current landscape of neuromorphic programming and identified key challenges, workflows, and potential solutions for enhancing accessibility and adoption. Our findings led to a set of guidelines for creating more accessible software development tools and platforms for those looking to create neuromorphic applications. Through this work, we aim to bridge the gap between neuromorphic computing and the HCI community, promoting the design of more intuitive and effective interfaces for neuromorphic development, and ultimately facilitating the creation of edge intelligent systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1050},
numpages = {18},
keywords = {neuromorphic computing, developer experience, developer tools, neural networks},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714045,
author = {Zheng, Qingxiao and Chen, Minrui and Sharma, Pranav and Tang, Yiliu and Oswal, Mehul and Liu, Yiren and Huang, Yun},
title = {EvAlignUX: Advancing UX Evaluation through LLM-Supported Metrics Exploration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714045},
doi = {10.1145/3706598.3714045},
abstract = {Evaluating UX in the context of AI’s complexity, unpredictability, and generative nature presents unique challenges. How can we support HCI researchers to create comprehensive UX evaluation plans? In this paper, we introduce EvAlignUX&nbsp;, a system powered by large language models and grounded in scientific literature, designed to help HCI researchers explore evaluation metrics and their relationship to research outcomes. A user study with 19 HCI scholars showed that EvAlignUX&nbsp;improved the perceived quality and confidence in UX evaluation plans while prompting deeper consideration of research impact and risks. The system enhanced participants’ thought processes, leading to the creation of a “UX Question Bank” to guide UX evaluation development. Findings also highlight how researchers’ backgrounds influence their inspiration and concerns about AI over-reliance, pointing to future research on AI’s role in fostering critical thinking. In a world where experience defines impact, we discuss the importance of shifting UX evaluation from a “method-centric” to a “mindset-centric” approach as the key to meaningful and lasting design evaluation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1051},
numpages = {25},
keywords = {User experience, Evaluation, Human-AI Interaction, Large Language Models, Usability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713678,
author = {Luna, Sanzida Mojib and Xu, Jiangnan and Tigwell, Garreth W. and LaLone, Nicolas and Saker, Michael and Chamberlain, Alan and Schwartz, David I and Papangelis, Konstantinos},
title = {Exploring Deaf And Hard of Hearing Peoples' Perspectives On Tasks In Augmented Reality: Interacting With 3D Objects And Instructional Comprehension},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713678},
doi = {10.1145/3706598.3713678},
abstract = {Tasks in augmented reality (AR), such as 3D interaction and instructional comprehension, are often designed for users with uniform sensory abilities. Such an approach, however, can overlook the more nuanced needs of Deaf and Hard of Hearing (DHH) users who might have reduced auditory perception. To better understand these challenges, our study utilized the single-player AR game Angry Birds AR&nbsp;as a probe to explore how 11 DHH participants and 15 hearing participants experienced AR interactions. Our findings highlight that DHH users prefer interaction based on context, effective haptic cues, audio cue substitutes, and clear instructional design. We, therefore, propose the following design recommendations to enhance the accessibility of AR for DHH users. This includes customizable UI options, modular feedback systems, and virtual avatars for sign language instructions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1052},
numpages = {14},
keywords = {Deaf and Hard of Hearing; Augmented Reality; Accessibility; Accessible AR},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713900,
author = {Balkaya, Melike and Baykal, G\"{o}k\c{c}e Elif},
title = {Exploring the Nexus of Technology and Food Practices in Young Adults: A Value-Sensitive Design Perspective towards Human-Food Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713900},
doi = {10.1145/3706598.3713900},
abstract = {This study aims to investigate the dynamics of young adults’ food practices within the interplay between technology and tradition by employing a Value-Sensitive Design (VSD) approach as an analytical lens. We conducted surveys and interviews with young adults. This is complemented by a workshop involving design and gastronomy experts. Grounded in Value-Sensitive Design (VSD) and encompassing 38 core values and resulting in five value conflicts. Our analysis highlights five prominent themes: “Preservation of Culinary Heritage and Relationships”, “Technological Convenience”, “Uniqueness and Personalisation”, “Globalised Nature of Food”, and “Sustainable Choices and Trustworthiness”. By bridging between Human-Food Interaction (HFI) and VSD realms, this study provides insights for researchers, designers, and practitioners. The value-laden analytical perspective of the findings sheds light on the food practices of the young generation, for future HFI design studies blending traditional and technological elements.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1053},
numpages = {16},
keywords = {Human-Food Interaction, Value-Sensitive Design, Food Practices, Young Adults},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714224,
author = {Tang, Yiliu and Situ, Jason and Cui, Andrea Yaoyun and Wu, Mengke and Huang, Yun},
title = {LLM Integration in Extended Reality: A Comprehensive Review of Current Trends, Challenges, and Future Perspectives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714224},
doi = {10.1145/3706598.3714224},
abstract = {The rapid evolution of Extended Reality (XR) technologies—encompassing Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR)—has paved the way for richer and more immersive user experiences. Concurrently, the emergence of Large Language Models (LLMs), such as GPT-4, has unlocked new opportunities to enhance interactions within XR environments. This paper presents the first comprehensive review addressing the underexplored synergy between XR and LLMs, examining how the integration of these technologies can augment various aspects of human awareness: spatial, situational, social, and self-awareness. By systematically analyzing 135 papers, we synthesize and categorize the research field into seven dimensions: 1) diverse application domains, 2) types of human awareness expanded, 3) interaction paradigms between users and systems, 4) effects of LLMs in XR, 5) practices for effectively integrating LLMs into XR environments, and 6) evaluation metrics. We also discuss remaining challenges and propose future research focusing on ethical awareness.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1054},
numpages = {24},
keywords = {Extended Reality, Large Language Models, Scoping Review},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714096,
author = {Li, Chaoyu and Padmanabhuni, Sid and Cheema, Maryam S and Seifi, Hasti and Fazli, Pooyan},
title = {VideoA11y: Method and Dataset for Accessible Video Description},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714096},
doi = {10.1145/3706598.3714096},
abstract = {Video descriptions are crucial for blind and low vision (BLV) users to access visual content. However, current artificial intelligence models for generating descriptions often fall short due to limitations in the quality of human annotations within training datasets, resulting in descriptions that do not fully meet BLV users’ needs. To address this gap, we introduce VideoA11y, an approach that leverages multimodal large language models (MLLMs) and video accessibility guidelines to generate descriptions tailored for BLV individuals. Using this method, we have curated VideoA11y-40K, the largest and most comprehensive dataset of 40,000 videos described for BLV users. Rigorous experiments across 15 video categories, involving 347 sighted participants, 40 BLV participants, and seven professional describers, showed that VideoA11y descriptions outperform novice human annotations and are comparable to trained human annotations in clarity, accuracy, objectivity, descriptiveness, and user satisfaction. We evaluated models on VideoA11y-40K using both standard and custom metrics, demonstrating that MLLMs fine-tuned on this dataset produce high-quality accessible descriptions. Code and dataset are available at https://people-robots.github.io/VideoA11y/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1055},
numpages = {29},
keywords = {Video Accessibility, Video Description, Video Understanding, Blind and Low Vision Users, Multimodal Large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713877,
author = {Zhao, Ruijing and Diep, Brian and Pei, Jiaxin and Yoon, Dongwook and Jurgens, David and Zhu, Jian},
title = {Who Reaps All the Superchats? A Large-Scale Analysis of Income Inequality in Virtual YouTuber Livestreaming},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713877},
doi = {10.1145/3706598.3713877},
abstract = {The explosive growth of Virtual YouTubers (VTubers)—streamers who perform behind virtual anime avatars—has created a unique digital economy with profound implications for content creators, platforms, and viewers. Understanding the economic landscape of VTubers is crucial for designing equitable platforms, supporting content creator livelihoods, and fostering sustainable digital communities. To this end, we conducted a large-scale study of over 1 million hours of publicly available streaming records from 1,923 VTubers on YouTube, covering tens of millions of dollars in actual profits. Our analysis reveals stark inequality within the VTuber community and characterizes the sources of income for VTubers from multiple perspectives. Furthermore, we also found that the VTuber community is increasingly monopolized by two agencies, driving the financial disparity. This research illuminates the financial dynamics of VTuber communities, informing the design of equitable platforms and sustainable support systems for digital content creators.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1056},
numpages = {18},
keywords = {virtual YouTuber, livestreaming, social media, monetization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713390,
author = {Zhang, Fan and Li, Molin and Chang, Xiaoyu and Fu, Kexue and Allen, Richard William and LC, RAY},
title = {"Becoming My Own Audience": How Dancers React to Avatars Unlike Themselves in Motion Capture-Supported Live Improvisational Performance.},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713390},
doi = {10.1145/3706598.3713390},
abstract = {The use of motion capture in live dance performances has created an emerging discipline enabling dancers to play different avatars on the digital stage. Unlike classical workflows, avatars enable performers to act as different characters in customized narratives, but research has yet to address how movement, improvisation, and perception change when dancers act as avatars. We created five avatars representing differing genders, shapes, and body limitations, and invited 15 dancers to improvise with each in practice and performance settings. Results show that dancers used avatars to distance themselves from their own habitual movements, exploring new ways of moving through differing physical constraints. Dancers explored using gender-stereotyped movements like powerful or feminine actions, experimenting with gender identity. However, focusing on avatars can coincide with a lack of continuity in improvisation. This work shows how emerging practices with performance technology enable dancers to improvise with new constraints, stepping outside the classical stage.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1057},
numpages = {24},
keywords = {Dance; Motion Capture; Avatar; Improvisation; Movement},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714176,
author = {Gong, Xinya and Tao, Wenhui and Ma, Yuxin},
title = {CalliSense: An Interactive Educational Tool for Process-based Learning in Chinese Calligraphy},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714176},
doi = {10.1145/3706598.3714176},
abstract = {Process-based learning is crucial for the transmission of intangible cultural heritage, especially in complex arts like Chinese calligraphy, where mastering techniques cannot be achieved by merely observing the final work. To explore the challenges faced in calligraphy heritage transmission, we conducted semi-structured interviews (N=8) as a formative study. Our findings indicate that the lack of calligraphy instructors and tools makes it difficult for students to master brush techniques, and teachers struggle to convey the intricate details and rhythm of brushwork. To address this, we collaborated with calligraphy instructors to develop an educational tool that integrates writing process capture and visualization, showcasing the writing rhythm, hand force, and brush posture. Through empirical studies conducted in multiple teaching workshops, we evaluated the system’s effectiveness with teachers (N=4) and students (N=12). The results show that the tool significantly enhances teaching efficiency and aids learners in better understanding brush techniques.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1058},
numpages = {20},
keywords = {Chinese Calligraphy, learning system, visualization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714220,
author = {Han, Hyunyoung and Jung, Kyungeun and Yoon, Sang Ho},
title = {ChoreoCraft: In-situ Crafting of Choreography in Virtual Reality through Creativity Support Tool},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714220},
doi = {10.1145/3706598.3714220},
abstract = {Choreographers face increasing pressure to create content rapidly, driven by growing demand in social media, entertainment, and commercial sectors, often compromising creativity. This study introduces ChoreoCraft, a novel in-situ virtual reality (VR) choreographic system designed to enhance the creation process of choreography. Through contextual inquiries with professional choreographers, we identified key challenges such as memory dependency, creative plateaus, and abstract feedback to formulate design implications. Then, we propose a VR choreography creation system embedded with a context-aware choreography suggestion system and a choreography analysis system, all grounded in choreographers’ creative processes and mental models. Our study results demonstrated that ChoreoCraft fosters creativity, reduces memory dependency, and improves efficiency in choreography creation. Participants reported high satisfaction with the system’s ability to overcome creative plateaus and provide objective feedback. Our work advances creativity support tools by providing digital assistance in dance composition that values artistic autonomy while fostering innovation and efficiency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1059},
numpages = {21},
keywords = {Creativity Support, Entertainment, Virtual/Augmented Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713432,
author = {Chicau, Joana and Fdili Alaoui, Sarah and Fass, John and Fiebrink, Rebecca},
title = {Human-Computer Counter-Choreographies: Raising Awareness of Data Tracking through Live Coding},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713432},
doi = {10.1145/3706598.3713432},
abstract = {In this paper we describe how we designed the performance Human-Computer Counter-Choreographies (HCCC) using a methodology that borrows from artistic research, critical design, choreography, and embodied sense-making. HCCC is a live-coding performance in which I (the first author) manipulate JavaScript code and use a modified version of the open-source DuckDuckGo privacy extension to unveil online tracking algorithms on stage. Throughout the performance, the audience is encouraged to participate in a sequence of choreographic prompts where they embody aspects of online tracking such as fingerprinting and profiling. We analysed audience responses to questionnaires after three performances of HCCC and found that it allows audience members to gain awareness and engage their bodies to critically reflect on online tracking. We contribute a new approach to live-coding that bridges choreography with online tracking, and we present empirical findings on the efficacy of this approach to engage audiences in reflecting on data tracking.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1060},
numpages = {14},
keywords = {live-coding, performance, online tracking algorithms, user-data, extractivist technology, algorithmic awareness, choreography, embodiment, critical reflection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714190,
author = {Zhang, Ying and Li, Zejian and Zhang, Jiesi and Hu, Fang and Zhu, Kewen and Liu, Qi and Deng, Huanghuang and Chen, Xiaoyu and Sun, Lingyun},
title = {Ink Restorer: Virtual Restoration of Ancient Chinese Paintings Inheriting Traditional Restoration Processes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714190},
doi = {10.1145/3706598.3714190},
abstract = {The restoration of ancient Chinese paintings plays an essential role in protection and inheritance of Asian culture. A traditional restoration process consists of four stages: Xi (washing), Jie (separating), Bu (mending), and Quan (completing). However, it is difficult for the public to experience this process due to high professional requirement and time consumption. We conduct a questionnaire survey and interview experts in our formative study. The questionnaire result shows the public express strong interest in virtual restoration. Experts believe virtual restoration is an experience valuable for the public. We introduce Ink-Restorer, a tool designed for experiencing virtual restoration for ancient paintings. Its design follows the traditional restoration process, and it adopts image segmentation and generation techniques to simplify detailed restoration for users. We recruit 60 users to evaluate Ink-Restorer and invite experts to evaluate restoration results. Ink-Restorer significantly improves user experience, cultural understanding, and restoration quality.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1061},
numpages = {16},
keywords = {Ancient Chinese painting, Culture heritage, Human-AI cocreation, Virtual restoration.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714156,
author = {Wang, Che Wei and Lu, Pin Chun and Cheng, Yun Chen and Chen, Mike Y.},
title = {MR.Drum: Designing Mixed Reality Interfaces to Support Structured Learning Micro-Progression in Drumming},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714156},
doi = {10.1145/3706598.3714156},
abstract = {Learning drumming is challenging because multiple rhythms must be performed independently and simultaneously using both hands and feet. We conducted two formative studies to understand: 1) professional drumming instructors’ teaching methods, and 2) drummers’ current self-learning practices and pain points. All instructors deconstructed complex rhythms and limb movements and then used structured progression to teach drumming, which has not been explored by HCI research to date. Based on these findings, we developed a novel micro-progression learning framework for novice drummers that divides and structures comprehension progression (drum sequence and rhythm) and limb coordination progression into 16 stages. We also designed MR-Drum, a mixed-reality system that provides a first-person view of virtual limbs to demonstrate rhythm, limb, and drum surface dynamics, with adjustable tempo and automatic error detection. A summative user study vs. instructional videos showed that MR-Drum significantly improved error rate and timing accuracy, was significantly preferred for comprehension, skill development, and user experience, and was preferred overall by all participants.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1062},
numpages = {17},
keywords = {Education/Learning, User Experience Design, Virtual/Augmented Reality, Prototyping/Implementation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714325,
author = {De Silva, Madhuka Thisuri and Smiley, Jim and Goodwin, Sarah and Holloway, Leona M and Butler, Matthew},
title = {Sensing Movement: Contemporary Dance Workshops with People who are Blind or have Low Vision and Dance Teachers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714325},
doi = {10.1145/3706598.3714325},
abstract = {Dance teachers rely primarily on verbal instructions and visual demonstrations to convey key dance concepts and movement. These techniques, however, have limitations in supporting students who are blind or have low vision (BLV). This work explores the role technology can play in supporting instruction for BLV students, as well as improvisation with their instructor. Through a series of design workshops with dance instructors and BLV students, ideas were generated by physically engaging with probes featuring diverse modalities including tactile objects, a body tracked sound and musical probe, and a body tracked controller with vibrational feedback. Implications for the design of supporting technologies were discovered for four contemporary dance learning goals: learning a phrase; improvising; collaborating through movement; and awareness of body and movement qualities. We discuss the potential of numerous multi-sensory methods and artefacts, and present design considerations for technologies to support meaningful dance instruction and participation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1063},
numpages = {19},
keywords = {blind, low vision, dance, education, design considerations, Contemporary dance, improvisation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713210,
author = {Harvey, Emma and Koenecke, Allison and Kizilcec, Rene F.},
title = {"Don't Forget the Teachers": Towards an Educator-Centered Understanding of Harms from Large Language Models in Education},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713210},
doi = {10.1145/3706598.3713210},
abstract = {Education technologies (edtech) are increasingly incorporating new features built on large language models (LLMs), with the goals of enriching the processes of teaching and learning and ultimately improving learning outcomes. However, the potential downstream impacts of LLM-based edtech remain understudied. Prior attempts to map the risks of LLMs have not been tailored to education specifically, even though it is a unique domain in many respects: from its population (students are often children, who can be especially impacted by technology) to its goals (providing the correct answer may be less important for learners than understanding how to arrive at an answer) to its implications for higher-order skills that generalize across contexts (e.g., critical thinking and collaboration). We conducted semi-structured interviews with six edtech providers representing leaders in the K-12 space, as well as a diverse group of 23 educators with varying levels of experience with LLM-based edtech. Through a thematic analysis, we explored how each group is anticipating, observing, and accounting for potential harms from LLMs in education. We find that, while edtech providers focus primarily on mitigating technical harms, i.e., those that can be measured based solely on LLM outputs themselves, educators are more concerned about harms that result from the broader impacts of LLMs, i.e., those that require observation of interactions between students, educators, school systems, and edtech to measure. Overall, we (1) develop an education-specific overview of potential harms from LLMs, (2) highlight gaps between conceptions of harm by edtech providers and those by educators, and (3) make recommendations to facilitate the centering of educators in the design and development of edtech tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1064},
numpages = {19},
keywords = {education, edtech, large language models, LLMs, interviews, harms},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713646,
author = {Ahn, Dakyeom and Lim, Hajin},
title = {Exploring K-12 Physical Education Teachers’ Perspectives on Opportunities and Challenges of AI Integration through Ideation Workshops},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713646},
doi = {10.1145/3706598.3713646},
abstract = {While AI’s potential in education and professional sports is widely recognized, its application in K-12 physical education (PE) remains underexplored with significant opportunities for innovation. This study aims to address this gap by engaging 17 in-service secondary school PE teachers in group ideation workshops to explore potential AI applications and challenges in PE classes. Participants envisioned AI playing multidimensional roles, such as an operational assistant, personal trainer, group coach, and evaluator, as solutions to address unique instructional and operational challenges in K-12 PE classes. These roles reflected participants’ perspectives on how AI could enhance class management, deliver personalized feedback, promote balanced team activities, and streamline performance assessments. Participants also highlighted critical considerations for AI integration, including the need to ensure robust student data security and privacy measures, minimize the risk of over-reliance on AI for instructional decisions, and accommodate the varying levels of technological proficiency among PE teachers. Our findings provide valuable insights and practical guidance for AI developers, educators, and policymakers, offering a foundation for the effective integration of AI into K-12 PE curricula to enhance teaching practices and student outcomes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1065},
numpages = {16},
keywords = {Physical education, PE, artificial intelligence, AI, K-12},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713109,
author = {Zhu, Zihao and Yu, Ao and Tong, Xin and Hui, Pan},
title = {Exploring LLM-Powered Role and Action-Switching Pedagogical Agents for History Education in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713109},
doi = {10.1145/3706598.3713109},
abstract = {Multi-role pedagogical agents can create engaging and immersive learning experiences, helping learners better understand knowledge in history learning. However, existing pedagogical agents often struggle with multi-role interactions due to complex controls, limited feedback forms, and difficulty dynamically adapting to user inputs. In this study, we developed a VR prototype with LLM-powered adaptive role-switching and action-switching pedagogical agents to help users learn about the history of the Pavilion of Prince Teng. A 2 x 2 between-subjects study was conducted with 84 participants to assess how adaptive role-switching and action-switching affect participants’ learning outcomes and experiences. The results suggest that adaptive role-switching enhances participants’ perception of the pedagogical agent’s trustworthiness and expertise but may lead to inconsistent learning experiences. Adaptive action-switching increases participants’ perceived social presence, expertise, and humanness. The study did not uncover any effects of role-switching and action-switching on usability, learning motivation and cognitive load. Based on the findings, we proposed five design implications for incorporating adaptive role-switching and action-switching into future VR history education tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1066},
numpages = {19},
keywords = {Pedagogical agents, Virtual reality, Large language models, History education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714402,
author = {Atabey, Ay\c{c}a and Wilson, Cara and Urquhart, Lachlan D and Schafer, Burkhard},
title = {Fairness by Design: Cross-Cultural Perspectives from Children on AI and Fair Data Processing in their Education Futures},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714402},
doi = {10.1145/3706598.3714402},
abstract = {AI-driven educational technologies (AI-EdTech) process extensive data, raising concerns about commercial exploitation of children's data and risks to their privacy, wellbeing, agency, and legal rights. The ‘fairness principle’ in data protection law requires fair data processing that meets children's expectations and avoids unexpected, detrimental, discriminatory, or misleading practices. However, children's own perspectives on what fairness means in AI-EdTech are underexplored in design. This study bridges the gap between law and design research to contextualize what fairness means through co-design workshops with 72 children (aged 10–12) and 4 teachers (N=76) in Scotland and T\"{u}rkiye. We examine how children's perspectives can inform the operationalization of ‘fairness by design’ for AI-EdTech. Our contributions include: (1) an understanding of children's perspectives on how fairness manifests (or does not) in AI-EdTech and (2) recommendations for both design and legal communities to align AI-EdTech design and data practices with children's values and rights.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1067},
numpages = {20},
keywords = {AI for children, age appropriate design, data protection, fairness},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713995,
author = {Yarmand, Matin and Li, Haowei and Weibel, Nadir},
title = {Interactions Beyond the Pandemic: Lessons Learned from Large-scale Emergency Remote Teaching in Higher Education},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713995},
doi = {10.1145/3706598.3713995},
abstract = {Online education — given the enhanced access for diverse populations and flexible participation — has been a topic of interest for many computer science and learning science researchers. The sudden shift to online settings during the COVID-19 Emergency Remote Teaching (ERT) provided a valuable opportunity to examine the use of educational technologies on a global scale with various digital readiness skills, beyond many past works that relied on small lab studies. Following a PRISMA-inspired methodology grounded on Moore’s three types of classroom interaction, this descriptive review investigates 22 empirical research papers published during the COVID-19 ERT era focused on higher-education online classrooms. We explore the empirical evidence reported in the collected corpus, and given how ERT remains a likely future occurrence, we suggest key directions for future research, including a new learning paradigm that centralizes and augments Learner-Content interaction to balance between flexibility and structure of online learning.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1068},
numpages = {15},
keywords = {Online Classroom, Higher Education, Learning Interactions, Emergency Remote Education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713698,
author = {Yarmand, Matin and Reed, Courtney N. and Tandon, Udayan and Hekler, Eric B. and Weibel, Nadir and Wang, April Yi},
title = {Towards Dialogic and On-Demand Metaphors for Interdisciplinary Reading},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713698},
doi = {10.1145/3706598.3713698},
abstract = {The interdisciplinary field of Human-Computer Interaction (HCI) thrives on productive engagement with different domains, yet this engagement often breaks due to idiosyncratic writing styles and unfamiliar concepts. Inspired by the dialogic model of abstract metaphors, as well as the potential of Large Language Models (LLMs) to produce on-demand support, we investigate the use of metaphors to facilitate engagement between Science and Technology Studies (STS) and System HCI. Our reflective-style survey with early-career HCI researchers (N=48) reported that limited prior exposure to STS research can hinder perceived openness of the work, and ultimately interest in reading. The survey also revealed that metaphors enhance likelihood to continue reading STS papers, and alternative perspectives can build critical thinking skills to mitigate potential risks of LLM-generated metaphors. We lastly offer a specified model of metaphor exchange (within this generative context) that incorporates alternative perspectives to construct shared understanding in interdisciplinary engagement.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1069},
numpages = {19},
keywords = {Metaphor Exchange, Large Language Models, Reflective Survey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713310,
author = {Lee, Jungmin and Yoon, Seoyoung and Shim, Hwajin and Yoo, Youngjae},
title = {Development of an LLM-Based Chatbot to Support Learnability in Stardew Valley: A Diary Study Approach},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713310},
doi = {10.1145/3706598.3713310},
abstract = {The video gaming industry offers richer experiences through increasingly complex game mechanics, often hindering learnability. This research explores integrating an LLM-based chatbot, “Daisy,” in Stardew Valley, a narrative-rich role-playing game where learnability is critical. Over three weeks, 24 participants—14 new and 10 experienced players—engaged in a diary study and post-interviews. Analysis of diaries, chat logs, gameplay videos, and interviews revealed three themes: seeking information support, playing with chatbots, and addressing practical challenges. Findings show Daisy's potential to enhance learnability through natural conversations, fostering immersion and emotional engagement, though issues like hallucinations and context awareness require improvement. This work highlights preliminary insights for integrating LLMs into narrative-rich games.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1070},
numpages = {19},
keywords = {Human-centered artificial intelligence, Large language model, Learnability, Video games},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713393,
author = {Adnin, Rudaiba and Pandkar, Atharva and Yao, Bingsheng and Wang, Dakuo and Das, Maitraye},
title = {Examining Student and Teacher Perspectives on Undisclosed Use of Generative AI in Academic Work},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713393},
doi = {10.1145/3706598.3713393},
abstract = {With the widespread adoption of Generative Artificial Intelligence (GenAI) tools, ethical issues are being raised around the disclosure of their use in publishing, journalism, or artwork. Recent research has found that college students are increasingly using GenAI tools; however, we know less about when, why, and how they choose to hide or disclose their use of GenAI in academic work. To address this gap, we conducted an online survey (n=97) and interviews with fifteen college students followed by interviews with nine teachers who had experience with students’ undisclosed use of GenAI. Our findings elucidate the strategies students employ to hide their GenAI use and their justifications for doing so, alongside the strategies teachers follow to manage such non-disclosure. We unpack students’ non-disclosure of GenAI through the lens of cognitive dissonance and discuss practical considerations for teachers and students regarding ways to promote transparency in GenAI use in higher education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1071},
numpages = {17},
keywords = {Generative AI, undisclosed use, college students, AI in education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713456,
author = {Tan, Chek Tien and Atmosukarto, Indriyati and Tandianus, Budianto and Shen, Songjia and Wong, Steven},
title = {Exploring the Impact of Avatar Representations in AI Chatbot Tutors on Learning Experiences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713456},
doi = {10.1145/3706598.3713456},
abstract = {Despite the growing prominence of Artificial Intelligence (AI) chatbots used in education, there remains a significant gap in our understanding of how interface design elements, particularly avatar representations, influence learning experiences. This paper explores the impact of different AI chatbot avatar representations on students’ learning experiences through a mixed-methods within-subjects study, where participants interacted with three distinct types of AI chatbot interfaces with a common large language model (LLM) over a 14-week university course. Our findings reveal that preferences vary according to factors such as learning habits and learning activities. Avatar design also exhibits affordances for specific prompting behaviors, while the perceived human touch influenced learning experiences in nuanced ways. Additionally, real-world relationships with the individuals behind deepfakes influence these experiences. These insights suggest that the thoughtful integration of diverse avatar representations in AI chatbot systems for different learners and settings can greatly enhance learning experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1072},
numpages = {12},
keywords = {Chatbots, conversational agents, large language models, avatars},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714054,
author = {Jin, Hyoungwook and Yoo, Minju and Park, Jeongeon and Lee, Yokyung and Wang, Xu and Kim, Juho},
title = {TeachTune: Reviewing Pedagogical Agents Against Diverse Student Profiles with Simulated Students},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714054},
doi = {10.1145/3706598.3714054},
abstract = {Large language models (LLMs) can empower teachers to build pedagogical conversational agents (PCAs) customized for their students. As students have different prior knowledge and motivation levels, teachers must review the adaptivity of their PCAs to diverse students. Existing chatbot reviewing methods (e.g., direct chat and benchmarks) are either manually intensive for multiple iterations or limited to testing only single-turn interactions. We present TeachTune, where teachers can create simulated students and review PCAs by observing automated chats between PCAs and simulated students. Our technical pipeline instructs an LLM-based student to simulate prescribed knowledge levels and traits, helping teachers explore diverse conversation patterns. Our pipeline could produce simulated students whose behaviors correlate highly to their input knowledge and motivation levels within 5\% and 10\% accuracy gaps. Thirty science teachers designed PCAs in a between-subjects study, and using TeachTune resulted in a lower task load and higher student profile coverage over a baseline.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1073},
numpages = {28},
keywords = {LLM-assisted evaluation, Simulated students, Pedagogical conversational agents},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713919,
author = {Lord, Carolynne and Friday, Adrian and Jackson, Adrian and Bird, Caroline and Preist, Chris and Lambert, Simon and Kayumbi, Gabin and Widdicks, Kelly},
title = {The World is Not Enough: Growing Waste in HPC-enabled Academic Practice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713919},
doi = {10.1145/3706598.3713919},
abstract = {Most research depends to some extent on technologies and computational infrastructures including, and perhaps especially, HCI. Despite the noted environmental impacts associated with information communication technology (ICT) globally, to date little consideration has been given as to how to limit the impact of research and innovation processes themselves. Working to understand the technical and cultural drivers of this impact within the specific but resource-intensive domain of High Performance Computing (HPC), we conducted 25 interviews with academic researchers, providers, funders, and commissioners of HPC. We find intersecting socio-cultural and technical dimensions that link to research institutions like conferences, funders, and universities that reinforce and embed, rather than challenge, expectations of growth and waste. At a time when large scale cloud systems, generative AI and ever larger models are multiplying, we argue to de-escalate demand for computing, aiming for more moderate, responsible and meaningful use of computational infrastructures—including within HCI itself.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1074},
numpages = {14},
keywords = {sustainable HCI, HPC, growth, waste, socio-cultural drivers},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714047,
author = {Fok, Raymond and Siu, Alexa and Weld, Daniel S.},
title = {Toward Living Narrative Reviews: An Empirical Study of the Processes and Challenges in Updating Survey Articles in Computing Research},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714047},
doi = {10.1145/3706598.3714047},
abstract = {Surveying prior literature to establish a foundation for new knowledge is essential for scholarly progress. However, survey articles are resource-intensive and challenging to create, and can quickly become outdated as new research is published, risking information staleness and inaccuracy. Keeping survey articles current with the latest evidence is therefore desirable, though there is a limited understanding of why, when, and how these surveys should be updated. Toward this end, through a series of in-depth retrospective interviews with 11 researchers, we present an empirical examination of the work practices in authoring and updating survey articles in computing research. We find that while computing researchers acknowledge the value in maintaining an updated survey, continuous updating remains unmanageable and misaligned with academic incentives. Our findings suggest key leverage points within current workflows that present opportunities for enabling technologies to facilitate more efficient and effective updates.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1075},
numpages = {10},
keywords = {Living literature reviews, narrative reviews, scholarly research},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713731,
author = {Kang, Wenhui and Zhang, Lin and Peng, Xiaolan and Zhang, Hao and Li, Anchi and Wang, Mengyao and Huang, Jin and Tian, Feng and Dai, Guozhong},
title = {TutorCraftEase: Enhancing Pedagogical Question Creation with Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713731},
doi = {10.1145/3706598.3713731},
abstract = {Pedagogical questions are crucial for fostering student engagement and learning. In daily teaching, teachers pose hundreds of questions to assess understanding, enhance learning outcomes, and facilitate the transfer of theory-rich content. However, even experienced teachers often struggle to generate a large volume of effective pedagogical questions. To address this, we introduce TutorCraftEase, an interactive generation system that leverages large language models (LLMs) to assist teachers in creating pedagogical questions. TutorCraftEase enables the rapid generation of questions at varying difficulty levels with a single click, while also allowing for manual review and refinement. In a comparative user study with 39 participants, we evaluated TutorCraftEase against a traditional manual authoring tool and a basic LLM tool. The results show that TutorCraftEase can generate pedagogical questions comparable in quality to those created by experienced teachers, while significantly reducing their workload and time.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1076},
numpages = {22},
keywords = {large language models, intelligent tutoring systems, human-AI collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713718,
author = {Kim, Callie Y. and Sato, Arissa J. and White, Nathan Thomas and Ho, Hui-Ru and Lee, Christine P. and Hwang, Yuna and Mutlu, Bilge},
title = {Bridging Generations using AI-Supported Co-Creative Activities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713718},
doi = {10.1145/3706598.3713718},
abstract = {Intergenerational co-creation using technology between grandparents and grandchildren can be challenging due to differences in technological familiarity. AI has emerged as a promising tool to support co-creative activities, offering flexibility and creative assistance, but its role in facilitating intergenerational connection remains underexplored. In this study, we conducted a user study with 29 grandparent-grandchild groups engaged in AI-supported story creation to examine how AI-assisted co-creation can foster meaningful intergenerational bonds. Our findings show that grandchildren managed the technical aspects, while grandparents contributed creative ideas and guided the storytelling. AI played a key role in structuring the activity, facilitating brainstorming, enhancing storytelling, and balancing the contributions of both generations. The process fostered mutual appreciation, with each generation recognizing the strengths of the other, leading to an engaging and cohesive co-creation process. We offer design implications for integrating AI into intergenerational co-creative activities, emphasizing how AI can enhance connection across skill levels and technological familiarity.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1077},
numpages = {15},
keywords = {Intergenerational interaction, co-creation with AI, generational gap, grandparents, grandchildren},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713746,
author = {Hunt, Casey Lee and Sun, Kaiwen and Dhuliawala, Zahra and Tsukiyama, Fumi and Druin, Allison and Huynh, Amanda and Leithinger, Daniel and Yip, Jason},
title = {Children using Tabletop Telepresence Robots for Collaboration: A Longitudinal Case Study of Hybrid and Online Intergenerational Participatory Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713746},
doi = {10.1145/3706598.3713746},
abstract = {Improving telepresence for children expands educational opportunities and connects faraway family. Yet, research about child-centered physical telepresence systems (tangible interfaces for telepresence) remains sparse, despite established benefits of tangible interaction for children. To address this gap, we collaborated with child designers (ages 8-12) over 2-years of online/1-year of hybrid participatory design. Together, we adapted one approach to physical telepresence (tabletop robots) for child users. Using a case study methodology, we explore how our tabletop telepresence robot platform influenced children’s connections with one another over the 3-year study. In our analysis, we compare four vignettes representing cooperation/conflict between children while using the platform; centering theories of ownership, collaboration, and co-design roles. Through this exploration of children’s interpersonal dynamics while using the platform, we uncover four key features of tabletop telepresence robots for children: (1) Anonymous Robot Control (2) Robot/Material Distribution, (3) Robot Form/Size, and (4) Robot Stewardship.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1078},
numpages = {16},
keywords = {Physical telepresence; Actuated tangible user interfaces; Hybrid collaboration; Online Collaboration; Participatory design; Children},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713134,
author = {Seo, Woosuk and Kim, Young-Ho and Kim, Ji Eun and Fan, Megan Tao and Ackerman, Mark S. and Choi, Sung Won and Park, Sun Young},
title = {Enhancing Pediatric Communication: The Role of an AI-Driven Chatbot in Facilitating Child-Parent-Provider Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713134},
doi = {10.1145/3706598.3713134},
abstract = {Communication with child patients is challenging due to their developing ability to express emotions and symptoms. Additionally, healthcare providers often have limited time to offer resources to parents. By leveraging AI to facilitate free-form conversations, our study aims to design an AI-driven chatbot to bridge these gaps in child-parent-provider communication. We conducted two studies: 1) design sessions with 12 children with cancer and their parents, which informed the development of our chatbot, ARCH, and 2) an interview study with 15 pediatric care experts to identify potential challenges and refine ARCH’s role in pediatric communication. Our findings highlight three key roles for ARCH: providing an expressive outlet for children, offering reassurance to parents, and serving as an assessment tool for providers. We conclude by discussing design considerations for AI-driven chatbots in pediatric communication, such as creating communication spaces, balancing the expectations of children and parents, and addressing potential cultural differences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1079},
numpages = {16},
keywords = {Chatbots, Child Patients, Parents, Healthcare, Communication},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714018,
author = {Graf, Linda and Scholemann, Leslie and Sykownik, Philipp and Fuss, Johannes and Masuch, Maic},
title = {Virtual Visits, Real Emotions: Designing Social VR Experiences for Imprisoned Fathers and their Children},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714018},
doi = {10.1145/3706598.3714018},
abstract = {The imprisonment of parents has severe consequences for their relationship to their children. Thus, ensuring valuable contact between them is crucial for parent’s social rehabilitation and children’s development and well-being. However, visits are often not child-friendly and lack interaction. We see social VR as a means to address these issues. In this paper, we share findings of a user-centered design process of a virtual reality application that allows imprisoned parents to meet their children. Our pilot study with four dyads of children and imprisoned fathers revealed that both appreciated the virtual visits, felt close to each other, and had a positive emotional experience, although fathers missed physical contact. Children preferred VR’s playful and interactive nature compared to regular visits. Our research presents virtual visits as a suitable alternative to ensure valuable social interaction between prisoners and their children and contribute to the potential of immersive virtual social experiences for sensitive use cases.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1080},
numpages = {23},
keywords = {Social VR, Social Connectedness, Social Richness, Emotional Experience, Playful Interaction, sensitive use cases, Prison, Social Rehabilitation, Well-Being, Parent-Child Bond},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714039,
author = {Richards, Olivia K. and Veinot, Tiffany},
title = {`I don't want to watch grown-up stuff': Children's and Parents' Perspectives and Recommendations for Health-Centered Digital Media Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714039},
doi = {10.1145/3706598.3714039},
abstract = {Screen time is ubiquitous in children’s lives and has both positive and negative health impacts. Calls for developmentally appropriate design and restrictions on manipulative design are ongoing, yet children’s and parents’ perspectives to inform interventions are lacking. This research uses design workshops with children (n=16) and focus groups with their parents (n=17) to understand whether and how digital media could be more health-centered. Participants shared concerns that manipulative design may inhibit screen time limits and transitions, and present age-inappropriate content. Participants expressed strong interest in health-centered designs incorporating nudges, moderation, and controls. Children’s self-generated designs aimed to reduce negative impacts by limiting screen time (e.g., time-related feedback, changed defaults), facilitating transitions (e.g., pause capabilities), minimizing age-inappropriate content (e.g., expanded shared controls), and reducing hurtful experiences (e.g., online video game moderation). To increase positive health impacts, participants suggested promoting physical activity (e.g., suggested screen breaks) within and away from digital media.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1081},
numpages = {18},
keywords = {Design, Nudges, Manipulative Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713405,
author = {Shen, Jocelyn J and King Chen, Jennifer and Findlater, Leah and Dietz Smith, Griffin},
title = {eaSEL: Promoting Social-Emotional Learning and Parent-Child Interaction through AI-Mediated Content Consumption},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713405},
doi = {10.1145/3706598.3713405},
abstract = {As children increasingly consume media on devices, parents look for ways this usage can support learning and growth, especially in domains like social-emotional learning. We introduce eaSEL, a system that (a) integrates social-emotional learning (SEL) curricula into children’s video consumption by generating reflection activities and (b) facilitates parent-child discussions around digital media without requiring co-consumption of videos. We present a technical evaluation of our system’s ability to detect social-emotional moments within a transcript and to generate high-quality SEL-based activities for both children and parents. Through a user study with N = 20 parent-child dyads, we find that after completing an eaSEL activity, children reflect more on the emotional content of videos. Furthermore, parents find that the tool promotes meaningful active engagement and could scaffold deeper conversations around content. Our work paves directions in how AI can support children’s social-emotional reflection of media and family connections in the digital age.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1082},
numpages = {18},
keywords = {parent-child interaction, child-computer interaction, social-emotional learning, human connection, large language models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714278,
author = {Li, Chentao and Xi, Ziheng and Feng, Jianjiang and Zhou, Jie},
title = {FineType: Fine-grained Tapping Gesture Recognition for Text Entry},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714278},
doi = {10.1145/3706598.3714278},
abstract = {With the rise of mixed reality (MR) and augmented reality (AR) applications, efficient text input in AR/MR environments remains challenging. We propose FineType, a text entry system using tapping gestures with finger combinations and postures on any flat surface. Using a wristband with an IMU and an infrared camera, we detect tapping events and employ a multi-task convolutional neural network to predict these gestures, enabling nearly full keyboard mapping (including letters, symbols, numbers, etc.) with one hand. We collected gestures from participants (N=28) with 10 finger combinations and 3 finger postures for training. Cross-user validation showed accuracies of 98.26\% for combinations, 95.53\% for postures, and 94.19\% for all categories. For 8 newly defined finger combinations and their postures, classification accuracies were 91.27\% and 93.86\%. Using user-adaptive few-shot learning, we improved the finger combination accuracy to 97.05\%. The results demonstrate our potential to map tapping gestures composed of all finger combinations and three postures. Our user study (N=10) demonstrated an average typing speed of 35.1 WPM with a character error rate of 5.1\% after two hours of practice.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1083},
numpages = {20},
keywords = {text entry; deep nerual network; finger posture; finger combination; interaction techniques},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713944,
author = {Chen, Weihao and Shi, Yuanchun and Wang, Yukun and Shi, Weinan and Chen, Meizhu and Gao, Cheng and Mei, Yu and Zhu, Yeshuang and Zhang, Jinchao and Yu, Chun},
title = {Investigating Context-Aware Collaborative Text Entry on Smartphones using Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713944},
doi = {10.1145/3706598.3713944},
abstract = {Text entry is a fundamental and ubiquitous task, but users often face challenges such as situational impairments or difficulties in sentence formulation. Motivated by this, we explore the potential of large language models (LLMs) to assist with text entry in real-world contexts. We propose a collaborative smartphone-based text entry system, CATIA, that leverages LLMs to provide text suggestions based on contextual factors, including screen content, time, location, activity, and more. In a 7-day in-the-wild study with 36 participants, the system offered appropriate text suggestions in over 80\% of cases. Users exhibited different collaborative behaviors depending on whether they were composing text for interpersonal communication or information services. Additionally, the relevance of contextual factors beyond screen content varied across scenarios. We identified two distinct mental models: AI as a supportive facilitator or as a more equal collaborator. These findings outline the design space for human-AI collaborative text entry on smartphones.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1084},
numpages = {20},
keywords = {Human-AI Collaboration, Text Entry, Context-aware Computing, Smartphones, Large Language Models, In-the-wild Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713580,
author = {Lisnic, Maxim and Setlur, Vidya and Sultanum, Nicole},
title = {Plume: Scaffolding Text Composition in Dashboards},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713580},
doi = {10.1145/3706598.3713580},
abstract = {Text in dashboards plays multiple critical roles, including providing context, offering insights, guiding interactions, and summarizing key information. Despite its importance, most dashboarding tools focus on visualizations and offer limited support for text authoring. To address this gap, we developed Plume, a system to help authors craft effective dashboard text. Through a formative review of exemplar dashboards, we created a typology of text parameters and articulated the relationship between visual placement and semantic connections, which informed Plume’s design. Plume&nbsp;employs large language models (LLMs) to generate contextually appropriate content and provides guidelines for writing clear, readable text. A preliminary evaluation with 12 dashboard authors explored how assisted text authoring integrates into workflows, revealing strengths and limitations of LLM-generated text and the value of our human-in-the-loop approach. Our findings suggest opportunities to improve dashboard authoring tools by better supporting the diverse roles that text plays in conveying insights.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1085},
numpages = {18},
keywords = {Visualization, dashboards, text authoring, large language models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713153,
author = {Shi, Danqing and Zhu, Yujun and Fernandes Junior, Francisco Erivaldo and Zhai, Shumin and Oulasvirta, Antti},
title = {Simulating Errors in Touchscreen Typing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713153},
doi = {10.1145/3706598.3713153},
abstract = {Empirical evidence shows that typing on touchscreen devices is prone to errors and that correcting them poses a major detriment to users’ performance. Design of text entry systems that better serve users, across their broad capability range, necessitates understanding the cognitive mechanisms that underpin these errors. However, prior models of typing cover only motor slips. The paper reports on extending the scope of computational modeling of typing to cover the cognitive mechanisms behind the three main types of error: slips (inaccurate execution), lapses (forgetting), and mistakes (incorrect knowledge). Given a phrase, a keyboard, and user parameters, &nbsp;Typoist simulates eye and finger movements while making human-like insertion, omission, substitution, and transposition errors. Its main technical contribution is the formulation of a supervisory control problem wherein the controller allocates cognitive resources to detect and fix errors generated by the various mechanisms. The model generates predictions of typing performance that can inform design, for better text entry systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1086},
numpages = {13},
keywords = {Human errors; User simulation; Mobile typing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713862,
author = {Masson, Damien and Kim, Young-Ho and Chevalier, Fanny},
title = {Textoshop: Interactions Inspired by Drawing Software to Facilitate Text Editing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713862},
doi = {10.1145/3706598.3713862},
abstract = {We explore how interactions inspired by drawing software can help edit text. Making an analogy between visual and text editing, we consider words as pixels, sentences as regions, and tones as colours. For instance, direct manipulations move, shorten, expand, and reorder text; tools change number, tense, and grammar; colours map to tones explored along three dimensions in a tone picker; and layers help organize and version text. This analogy also leads to new workflows, such as boolean operations on text fragments to construct more elaborated text. A study shows participants were more successful at editing text and preferred using the proposed interface over existing solutions. Broadly, our work highlights the potential of interaction analogies to rethink existing workflows, while capitalizing on familiar features.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1087},
numpages = {14},
keywords = {writing, interface metaphors, drawing interaction, LLM, AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713781,
author = {Mutasim, Aunnoy K and Bashar, Mohammad Raihanul and Lutteroth, Christof and Batmaz, Anil Ufuk and Stuerzlinger, Wolfgang},
title = {There Is More to Dwell Than Meets the Eye: Toward Better Gaze-Based Text Entry Systems With Multi-Threshold Dwell},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713781},
doi = {10.1145/3706598.3713781},
abstract = {Dwell-based text entry seems to peak at 20 words per minute (WPM). Yet, little is known about the factors contributing to this limit, except that it requires extensive training. Thus, we conducted a longitudinal study, broke the overall dwell-based selection time into six different components, and identified several design challenges and opportunities. Subsequently, we designed two novel dwell keyboards that use multiple yet much shorter dwell thresholds: Dual-Threshold Dwell (DTD) and Multi-Threshold Dwell (MTD). The performance analysis showed that MTD (18.3 WPM) outperformed both DTD (15.3 WPM) and the conventional Constant-Threshold Dwell (12.9 WPM). Notably, absolute novices achieved these speeds within just 30 phrases. Moreover, MTD’s performance is also the fastest-ever reported average text entry speed for gaze-based keyboards. Finally, we discuss how our chosen parameters can be further optimized to pave the way toward more efficient dwell-based text entry.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1088},
numpages = {18},
keywords = {Text Entry, Eye Gaze, Eye-Tracking, Dwell Thresholds, Learnability, QWERTY},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713181,
author = {Chu, Seong Yeub and Kim, Jong Woo and Yi, Mun Yong},
title = {Think Together and Work Better: Combining Humans' and LLMs' Think-Aloud Outcomes for Effective Text Evaluation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713181},
doi = {10.1145/3706598.3713181},
abstract = {This study introduces InteractEval, a framework that integrates the outcomes of Think-Aloud (TA) conducted by humans and LLMs to generate attributes for checklist-based text evaluation. By combining humans’ flexibility and high-level reasoning with LLMs’ consistency and extensive knowledge, InteractEval outperforms text evaluation baselines on a text summarization benchmark (SummEval) and an essay scoring benchmark (ELLIPSE). Furthermore, an in-depth analysis shows that it promotes divergent thinking in both humans and LLMs, leading to the generation of a wider range of relevant attributes and enhancement of text evaluation performance. A subsequent comparative analysis reveals that humans excel at identifying attributes related to internal quality (Coherence and Fluency), but LLMs perform better at those attributes related to external alignment (Consistency and Relevance). Consequently, leveraging both humans and LLMs together produces the best evaluation outcomes, highlighting the necessity of effectively combining humans and LLMs in an automated checklist-based text evaluation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1089},
numpages = {23},
keywords = {Large Language Model, Think-Aloud, Human-LLM Combination, Text Evaluation, Checklist},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713252,
author = {Holtgrave, Jan-Ulrich and Klivan, Sabrina and Marky, Karola and Fahl, Sascha},
title = {A Qualitative Study of Adoption Barriers and Challenges for Passwordless Authentication in German Public Administrations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713252},
doi = {10.1145/3706598.3713252},
abstract = {Public administrations provide critical services and manage sensitive data for a country’s citizens. Recent phishing campaigns targeting public sector employees highlight their attractiveness as targets. Deploying state-of-the-art authentication technologies, such as FIDO2, can improve overall security. We conducted a mixed-methods study in Germany to understand better the practices and challenges of deploying passwordless authentication in the public sector. First, we conducted an online survey (N=108) among German public sector employees to gain insights into their experiences and challenges. Next, we partnered with an e-government vendor and performed an in-situ experiment. We let 11 employees from the public sector experience FIDO2 under real-world conditions. Our results show that only a minority of our participants were aware of current passwordless authentication procedures. In our experiment, FIDO2-based methods left an overall positive impression. Hierarchical and heterogeneous public sector structures and the need for more technical expertise and equipment were barriers to adoption.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1090},
numpages = {16},
keywords = {Authentication, Public Administration, E-Government},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713538,
author = {von Preuschen, Alexandra and Benda, Carolin and Schuhmacher, Monika Christine and Zimmermann, Verena},
title = {Fear, Fun or None: A Qualitative Quest Towards Unlocking Cybersecurity Attitudes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713538},
doi = {10.1145/3706598.3713538},
abstract = {Employees, once seen as the weakest link in organizational cybersecurity, are now recognized as crucial defenders against malicious attacks. Thus, understanding employee attitudes towards cybersecurity, a major factor driving security behavior, is essential for protecting organizations. Using semi-structured interviews and focus groups, this study holistically explores attitudes toward cybersecurity, its influencing factors, and the employees’ needs for fostering positive attitudes. The study offers in-depth insights into affective, cognitive, and behavioral components of attitudes, ranging from annoyance and fear to appreciation for cybersecurity measures. Influencing key factors include (in)direct cybersecurity experiences and individual perceptions - both highlighting social influences. For developing positive attitudes, employees express needs related to the company’s social and cultural framework, communication styles, educational contents and formats. The study contributes to developing effective security strategies that address the individual, social, and organizational factors that shape cybersecurity attitudes, ultimately promoting a stronger organizational security.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1091},
numpages = {24},
keywords = {Attitude, Cybersecurity, Interview, Focus Group, Organization, Employee},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714143,
author = {Zhuo, Sijie and Biddle, Robert and Russello, Giovanni and Lottridge, Danielle},
title = {Precision Email Simulator for Research on Safety-Critical Phishing Behaviour},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714143},
doi = {10.1145/3706598.3714143},
abstract = {Email is ubiquitous, and in the context of phishing, it becomes critical, as risky behaviours like clicking on phishing links or downloading malicious files can lead to severe consequences. While much research exists on phishing susceptibility, there is still a gap in understanding factors that influence user micro-behaviour when interacting with phishing emails. To address this, we offer a tool, the Precision Email Simulator, to support phishing researchers, as well as considerations in conceptualising controlled ‘experimental simulation’ studies, which are currently underutilised in phishing research. The Precision Email Simulator simulates real-world email inboxes and tracks precision user data, such as time spent on messages and eye-tracking for key areas like URLs and sender addresses. We discuss the practical uses of our simulator, and provide recommendations and guidelines of using our email simulator.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1092},
numpages = {12},
keywords = {phishing susceptibility, Precision Email Interaction Study, Precision Email Simulator, email interactions},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714117,
author = {Moreira, Gustavo and Bogucka, Edyta Paulina and Constantinides, Marios and Quercia, Daniele},
title = {The Hall of AI Fears and Hopes: Comparing the Views of AI Influencers and those of Members of the U.S. Public Through an Interactive Platform},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714117},
doi = {10.1145/3706598.3714117},
abstract = {AI development is shaped by academics and industry leaders—let us call them “influencers”—but it is unclear how their views align with those of the public. To address this gap, we developed an interactive platform that served as a data collection tool for exploring public views on AI, including their fears, hopes, and overall sense of hopefulness. We made the platform available to 330 participants representative of the U.S. population in terms of age, sex, ethnicity, and political leaning, and compared their views with those of 100 AI influencers identified by Time magazine. The public fears AI getting out of control, while influencers emphasize regulation, seemingly to deflect attention from their alleged focus on monetizing AI’s potential. Interestingly, the views of AI influencers from underrepresented groups such as women and people of color often differ from the views of underrepresented groups in the public.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1093},
numpages = {27},
keywords = {responsible AI, ethical AI, AI governance, empirical ethics, value alignment, AI fears, AI hopes, AI influencers, participatory AI ethics, crowdsourcing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713824,
author = {McKinley, Oen G and Pandey, Saugat and Ottley, Alvitta},
title = {Trustworthy by Design: The Viewer's Perspective on Trust in Data Visualization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713824},
doi = {10.1145/3706598.3713824},
abstract = {Despite the importance of viewers’ trust in data visualization, there is a lack of research on the viewers’ own perspective on their trust. In addition, much of the research on trust remains relatively theoretical and inaccessible for designers. This work aims to address this gap by conducting a qualitative study to explore how viewers perceive different data visualizations and how their perceptions impact their trust. Three dominant themes emerged from the data. First, users appeared to be consistent, listing similar rationale for their trust across different stimuli. Second, there were diverse opinions about what factors were most important to trust perception and about why the factors matter. Third, despite this disagreement, there were important trends to the factors that users reported as impactful. Finally, we leverage these themes to give specific and actionable guidelines for visualization designers to make more trustworthy visualizations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1094},
numpages = {17},
keywords = {Data Visualization, Trust, Qualitative Methods, Survey, Design Guidelines, Visualization Design, Designer},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713972,
author = {Pe\~{n}a-Araya, Vanessa and Mart\'{\i}nez Fontaine, Consuelo and Wei, Xiang and Delpech, Guillaume and Bezerianos, Anastasia},
title = {Uncertainty in Science is Malleable. Advocating for User-Agency in Defining Uncertainty in Visualizations: a Case Study in Geology},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713972},
doi = {10.1145/3706598.3713972},
abstract = {Uncertainty is inherent in science built on previous results. In geoscience, for instance, researchers analyzing volcanic deposits assess the uncertainty around past deposit classifications. To aid this assessment, we followed a design by immersion approach to co-design uncertainty visualizations. We observed that besides visualizing it, it is challenging even to define what constitutes uncertainty, as how researchers understand and process uncertainty evolves. This motivated us to reach other members of the community to better understand how they integrate uncertainty in their work. Informed by a series of interviews, we first redesigned our visualization system and then introduced it as a technology probe to a broader community of geoscientists. Our results highlight that uncertainty in science is malleable and that visualization systems should be designed with this malleability in mind. Through a set of design implications, we advocate for visualizations that promote user agency and flexibility in defining and processing uncertainty.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1095},
numpages = {18},
keywords = {Visualization, Uncertainty, Qualitative Methods, Working with Domain Experts, Design Study, Geology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713463,
author = {Caven, Peter and Gurjar, Ambarish and Zhang, Zitao and Ma, Xinyao and Camp, LJean},
title = {Usability, Efficacy, and Acceptability of the U.S. Cyber Trust Mark},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713463},
doi = {10.1145/3706598.3713463},
abstract = {The U.S. Cyber Trust Mark is intended to empower consumers and enable security by demand. But is there such a demand? To explore this, we recruited 599 participants and asked them to select their desired smart device using a simulated online marketplace. Participants were informed they would receive their selected light bulbs, and they were divided into five experimental groups based on different versions of the Mark. After the product selections, we surveyed them about their priorities and preferences. We found no significant differences between the groups as a whole. However, the subset of consumers who identified cybersecurity as most important were significantly more likely to select labeled products, spending 16.5\% more. We detail these differences and preferences, then argue that an awareness program is needed to assist consumers in better understanding the long-term economic benefits of the U.S. Cyber Trust Mark.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1096},
numpages = {35},
keywords = {labels, security, privacy, trust, interaction, IoT, icons},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713468,
author = {Pareek, Saumya and Sch\"{o}mbs, Sarah and Velloso, Eduardo and Goncalves, Jorge},
title = {"It's Not the AI's Fault Because It Relies Purely on Data": How Causal Attributions of AI Decisions Shape Trust in AI Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713468},
doi = {10.1145/3706598.3713468},
abstract = {Humans naturally seek to identify causes behind outcomes through causal attribution, yet Human-AI research often overlooks how users perceive causality behind AI decisions. We examine how this perceived locus of causality—internal or external to the AI—influences trust, and how decision stakes and outcome favourability moderate this relationship. Participants (N=192) engaged with AI-based decision-making scenarios operationalising varying loci of causality, stakes, and favourability, evaluating their trust in each AI. We find that internal attributions foster lower trust as participants perceive the AI to have high autonomy and decision-making responsibility. Conversely, external attributions portray the AI as merely “a tool” processing data, reducing its perceived agency and distributing responsibility, thereby boosting trust. Moreover, stakes moderate this relationship—external attributions foster even more trust in lower-risk, low-stakes scenarios. Our findings establish causal attribution as a crucial yet underexplored determinant of trust in AI, highlighting the importance of accounting for it when researching trust dynamics.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1097},
numpages = {18},
keywords = {causal attribution, locus of causality, trust, human-AI interaction, human-AI decision-making, decision stakes, outcome favourability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713184,
author = {Bhatnagar, Tigmanshu and Omar, Maarya and Orlic, Davor and Smith, James and Holloway, Catherine and Kett, Maria},
title = {Bridging AI and Humanitarianism: An HCI-Informed Framework for Responsible AI Adoption},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713184},
doi = {10.1145/3706598.3713184},
abstract = {Advances in artificial intelligence (AI) hold transformative potential for humanitarian practice. Yet aligning this potential with the demands of humanitarian practice in dynamic and often resource-austere contexts remains a challenge. While research on Responsible AI provides high-level guidance, humanitarian practice demands nuanced approaches for which human-computer interaction (HCI) can provide a strong foundation. However, existing literature lacks a comprehensive examination of how HCI principles can inform responsible AI adoption in humanitarian practice. To address this gap, we conducted a reflexive thematic analysis of 34 interviews with AI technology experts, humanitarian practitioners, and humanitarian policy developers. Our contributions are twofold. First, we empirically identify three cross-cutting themes—AI risks in humanitarian practice, organisational readiness, and collaboration—that highlight common tensions in adopting AI for humanitarian practice. Second, by analysing their interconnectivities, we reveal intertwined obstacles and propose a conceptual HCI-informed framework.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1098},
numpages = {17},
keywords = {AI Ethics, Crisis/Disaster, Interview, Qualitative Methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713570,
author = {Aly, Heba and Volonte, Matias and Byrne, Kaileigh Angela and Knijnenburg, Bart Piet},
title = {Bridging the Trust Gap: Investigating the Role of Trust Transfer in the Adoption of AI Instructors for Digital Privacy Education},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713570},
doi = {10.1145/3706598.3713570},
abstract = {Recent studies have demonstrated how AI instructors can be used for digital privacy education. However, these studies also highlights the lack of trust that certain individuals—particularly older adults—have in such AI instructors as a major obstacle to their adoption. The current paper introduces “trust transfer” as a means to enhance appropriate trust in AI instructors and improve learning experiences. A between-subjects experiment (N = 217) was conducted to test the effect of a human introducing an AI instructor on users’ trust and learning experiences. Our findings reveal that this trust transfer positively impacts the perceived trustworthiness of the instructor, as well as users’ perception of learning and their enjoyment of the educational material, regardless of age. Based on our findings, we discuss how trust transfer can help calibrate users’ trust in AI instructors, thereby fostering AI use in digital privacy education, with potential extensions to other domains.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1099},
numpages = {22},
keywords = {Digital privacy education, AI instructors, Trust transfer, Older adults, AI use in education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713099,
author = {Kahr, Patricia and Rooks, Gerrit and Snijders, Chris and Willemsen, Martijn C.},
title = {Good Performance Isn't Enough to Trust AI: Lessons from Logistics Experts on their Long-Term Collaboration with an AI Planning System},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713099},
doi = {10.1145/3706598.3713099},
abstract = {While research on trust in human-AI interactions is gaining recognition, much work is conducted in lab settings that, therefore, lack ecological validity and often omit the trust development perspective. We investigated a real-world case in which logistics experts had worked with an AI system for several years (in some cases since its introduction). Through thematic analysis, three key themes emerged: First, although experts clearly point out AI system imperfections, they still showed to develop trust over time. Second, however, inconsistencies and frequent efforts to improve the AI system disrupted trust development, hindering control, transparency, and understanding of the system. Finally, despite the overall trustworthiness, experts overrode correct AI decisions to protect their colleagues’ well-being. By comparing our results with the latest trust research, we can confirm empirical work and contribute new perspectives, such as understanding the importance of human elements for trust development in human-AI scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1100},
numpages = {16},
keywords = {Trust (development) in human-AI-interactions; AI-supported decision-making},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713130,
author = {Ladak, Ali and Wilks, Matti and Loughnan, Steve and Anthis, Jacy Reese},
title = {Robots, Chatbots, Self-Driving Cars: Perceptions of Mind and Morality Across Artificial Intelligences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713130},
doi = {10.1145/3706598.3713130},
abstract = {AI systems have rapidly advanced, diversified, and proliferated, but our knowledge of people’s perceptions of mind and morality in them is limited, despite its importance for outcomes such as whether people trust AIs and how they assign responsibility for AI-caused harms. In a preregistered online study, 975 participants rated 26 AI and non-AI entities. Overall, AIs were perceived to have low-to-moderate agency (e.g., planning, acting), between inanimate objects and ants, and low experience (e.g., sensing, feeling). For example, ChatGPT was rated only as capable of feeling pleasure and pain as a rock. The analogous moral faculties, moral agency (doing right or wrong) and moral patiency (being treated rightly or wrongly) were higher and more varied, particularly moral agency: The highest-rated AI, a Tesla Full Self-Driving car, was rated as morally responsible for harm as a chimpanzee. We discuss how design choices can help manage perceptions, particularly in high-stakes moral contexts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1101},
numpages = {19},
keywords = {Human-AI Interaction, Mind Perception, Mind Attribution, Anthropomorphism, Morality, Agency},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713527,
author = {Duan, Wen and Flathmann, Christopher and McNeese, Nathan and Scalia, Matthew J and Zhang, Ruihao and Gorman, Jamie and Freeman, Guo and Zhou, Shiwen and Hauptman, Allyson Ivy and Yin, Xiaoyun},
title = {Trusting Autonomous Teammates in Human-AI Teams - A Literature Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713527},
doi = {10.1145/3706598.3713527},
abstract = {As autonomous AI agents become increasingly integrated into human teams, the level of trust humans place in these agents - both as a piece of technology and increasingly viewed as teammates - significantly impacts the success of human-AI teams (HATs). This work presents a literature review of the HAT research that investigates humans’ trust in their AI teammates. In this review, we first identify the ways in which trust was conceptualized and operationalized, which underscores the pressing need for clear definitions and consistent measurements. Then, we categorize and quantify the factors found to influence trust in an AI teammate, highlighting that agent-related factors (such as transparency, reliability) have the strongest impacts on trust in HAT research. We also identify under-explored factors related to humans, teams, and environments, and gaps for future HAT research and design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1102},
numpages = {23},
keywords = {Artificial Intelligence, Human-Autonomy Teaming, Human-AI Teaming, Human-Agent Teaming, Trust, Trust in Autonomous Teammates},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713787,
author = {Balayn, Agathe and Yurrita, Mireia and Rancourt, Fanny and Casati, Fabio and Gadiraju, Ujwal},
title = {Unpacking Trust Dynamics in the LLM Supply Chain: An Empirical Exploration to Foster Trustworthy LLM Production \&amp; Use},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713787},
doi = {10.1145/3706598.3713787},
abstract = {Research on trust in AI is limited to several trustors (e.g., end-users) and trustees (especially AI systems), and empirical explorations remain in laboratory settings, overlooking factors that impact trust relations in the real world. Here, we broaden the scope of research by accounting for the supply chains that AI systems are part of. To this end, we present insights from an in-situ, empirical, study of LLM supply chains. We conducted interviews with 71 practitioners, and analyzed their (collaborative) practices using the lens of trust drawing from literature in organizational psychology. Our work reveals complex trust dynamics at the junctions of the chains, with interactions between diverse technical artifacts, individuals, or organizations. These junctions might constitute terrain for uncalibrated reliance when trustors lack supply chain knowledge or power dynamics are at play. Our findings bear implications for AI researchers and policymakers to promote AI governance that fosters calibrated trust.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1103},
numpages = {20},
keywords = {trust in AI, large language models, collaborations, AI supply chain, calibrated trust},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714259,
author = {Riche, Nathalie and Offenwanger, Anna and Gmeiner, Frederic and Brown, David and Romat, Hugo and Pahud, Michel and Marquardt, Nicolai and Inkpen, Kori and Hinckley, Ken},
title = {AI-Instruments: Embodying Prompts as Instruments to Abstract \&amp; Reflect Graphical Interface Commands as General-Purpose Tools},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714259},
doi = {10.1145/3706598.3714259},
abstract = {Chat-based prompts respond with verbose linear-sequential texts, making it difficult to explore and refine ambiguous intents, back up and reinterpret, or shift directions in creative AI-assisted design work. &nbsp;AI-Instruments instead embody “prompts” as interface objects via three key principles: (1)&nbsp;Reification of user-intent as reusable direct-manipulation instruments; (2)&nbsp;Reflection of multiple interpretations of ambiguous user-intents (Reflection-in-intent) as well as the range of AI-model responses (Reflection-in-response) to inform design "moves" towards a desired result; and (3)&nbsp;Grounding to instantiate an instrument from an example, result, or extrapolation directly from another instrument. Further, AI-Instruments leverage LLM’s to suggest, vary, and refine new instruments, enabling a system that goes beyond hard-coded functionality by generating its own instrumental controls from content. We demonstrate four technology probes, applied to image generation, and qualitative insights from twelve participants, showing how AI-Instruments address challenges of intent formulation, steering via direct manipulation, and non-linear iterative workflows to reflect and resolve ambiguous intents.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1104},
numpages = {18},
keywords = {instrumental interaction, generative AI interfaces},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713500,
author = {Khan, Abidullah and Shokrizadeh, َAtefeh and Cheng, Jinghui},
title = {Beyond Automation: How Designers Perceive AI as a Creative Partner in the Divergent Thinking Stages of UI/UX Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713500},
doi = {10.1145/3706598.3713500},
abstract = {Divergent thinking activities, like research and ideation, are key drivers of innovation in UI/UX design. Existing research has explored AI’s role in automating design tasks, but leaves a critical gap in understanding how AI specifically influences divergent thinking. To address this, we conducted interviews with 19 professional UI/UX designers, examining their use and perception of AI in these creative activities. We found that in this context, participants valued AI tools that offer greater control over ideation, facilitate collaboration, enhance efficiency to liberate creativity, and align with their visual habits. Our results indicated four key roles AI plays in supporting divergent thinking: aiding research, kick-starting creativity, generating design alternatives, and facilitating prototype exploration. Through this study, we provide insights into the evolving role of AI in the less-investigated area of divergent thinking in UI/UX design, offering recommendations for future AI tools that better support design innovation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1105},
numpages = {12},
keywords = {UI/UX Design, Divergent Thinking, AI Tools, Human-AI Interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713785,
author = {Shokrizadeh, َAtefeh and Bahati Tadjuidje, Boniface and Kumar, Shivam and Kamble, Sohan and Cheng, Jinghui},
title = {Dancing With Chains: Ideating Under Constraints With UIDEC in UI/UX Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713785},
doi = {10.1145/3706598.3713785},
abstract = {UI/UX designers often work under constraints like brand identity, design norms, and industry guidelines. How these constraints impact designers’ ideation and exploration processes should be addressed in creativity-support tools for design. Through an exploratory interview study, we identified three designer personas with varying views on having constraints in the ideation process, which guided the creation of UIDEC, a GenAI-powered tool for supporting creativity under constraints. UIDEC allows designers to specify project details, such as purpose, target audience, industry, and design styles, based on which it generates diverse design examples that adhere to these constraints, with minimal need to write prompts. In a user evaluation involving designers representing the identified personas, participants found UIDEC compatible with their existing ideation process and useful for creative inspiration, especially when starting new projects. Our work provides design implications to AI-powered tools that integrate constraints during UI/UX design ideation to support creativity.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1106},
numpages = {23},
keywords = {User Interface Design, Constraint, Inspiration, Ideation, Creativity Support},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713739,
author = {Cai, Zhuojiang and Hong, Jingkai and Wang, Zhimin and Lu, Feng},
title = {GazeSwipe: Enhancing Mobile Touchscreen Reachability through Seamless Gaze and Finger-Swipe Integration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713739},
doi = {10.1145/3706598.3713739},
abstract = {Smartphones with large screens provide users with increased display and interaction space but pose challenges in reaching certain areas with the thumb when using the device with one hand. To address this, we introduce GazeSwipe, a multimodal interaction technique that combines eye gaze with finger-swipe gestures, enabling intuitive and low-friction reach on mobile touchscreens. Specifically, we design a gaze estimation method that eliminates the need for explicit gaze calibration. Our approach also avoids the use of additional eye-tracking hardware by leveraging the smartphone’s built-in front-facing camera. Considering the potential decrease in gaze accuracy without dedicated eye trackers, we use finger-swipe gestures to compensate for any inaccuracies in gaze estimation. Additionally, we introduce a user-unaware auto-calibration method that improves gaze accuracy during interaction. Through extensive experiments on smartphones and tablets, we compare our technique with various methods for touchscreen reachability and evaluate the performance of our auto-calibration strategy. The results demonstrate that our method achieves high success rates and is preferred by users. The findings also validate the effectiveness of the auto-calibration strategy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1107},
numpages = {14},
keywords = {Interaction Technique, Eye Tracking, Reachability, Mobile Devices},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713924,
author = {Lu, Yuwen and Leung, Alan and Swearngin, Amanda and Nichols, Jeffrey and Barik, Titus},
title = {Misty: UI Prototyping Through Interactive Conceptual Blending},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713924},
doi = {10.1145/3706598.3713924},
abstract = {UI prototyping often involves iterating and blending elements from examples such as screenshots and sketches, but current tools offer limited support for incorporating these examples. Inspired by the cognitive process of conceptual blending, we introduce a novel UI workflow that allows developers to rapidly incorporate diverse aspects from design examples into work-in-progress UIs. We prototyped this workflow as Misty. Through a exploratory first-use study with 14 frontend developers, we assessed Misty’s effectiveness and gathered feedback on this workflow. Our findings suggest that Misty’s conceptual blending workflow helps developers kickstart creative explorations, flexibly specify intent in different stages of prototyping, and inspires developers through serendipitous UI blends. Misty demonstrates the potential for tools that blur the boundaries between developers and designers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1108},
numpages = {17},
keywords = {UI prototyping, UX design, conceptual blending, artificial intelligence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713445,
author = {Sun, Lipeipei and Qin, Tianzi and Hu, Anran and Zhang, Jiale and Lin, Shuojia and Chen, Jianyan and Ali, Mona and Prpa, Mirjana},
title = {Persona-L has Entered the Chat: Leveraging LLMs and Ability-based Framework for Personas of People with Complex Needs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713445},
doi = {10.1145/3706598.3713445},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1109},
numpages = {31},
keywords = {Persona, UX Design, Context, Ability-based Framework},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713140,
author = {Cha, Inha and Wong, Richmond Y.},
title = {Understanding Socio-technical Factors Configuring AI Non-Use in UX Work Practices},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713140},
doi = {10.1145/3706598.3713140},
abstract = {AI tools are often promoted as revolutionary for streamlining labor- and cost-intensive UX workflows. Although their actual adoption and usage are more complex and nuanced than often portrayed, instances, where AI may be unnecessary or even undesirable are frequently overlooked. Therefore, we aim to gain deeper insights into technology non-use—viewed not merely as a binary opposite to use but as a spectrum of practices. Through semi-structured interviews with 15 UX practitioners, we identified factors influencing non-use across individual, professional, organizational, and societal dimensions. We use a sociotechnical assemblage lens to explore how multiple layers of an individual’s context interact within professional settings, how diverse politics intersect within individuals or organizations, and how these interactions evolve over time. We propose implications for rethinking AI application design and evaluation, for considering policy frameworks and AI design together and deliberating about where AI should and should not be used.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1110},
numpages = {17},
keywords = {AI, UX Practices, Non-use, Tech Practitioners, Assemblages, Sociotechnical Systems},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713336,
author = {Li, Jingshu and Yang, Yitian and Liao, Q. Vera and Zhang, Junti and Lee, Yi-Chieh},
title = {As Confidence Aligns: Understanding the Effect of AI Confidence on Human Self-confidence in Human-AI Decision Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713336},
doi = {10.1145/3706598.3713336},
abstract = {Complementary collaboration between humans and AI is essential for human-AI decision making. One feasible approach to achieving it involves accounting for the calibrated confidence levels of both AI and users. However, this process would likely be made more difficult by the fact that AI confidence may influence users’ self-confidence and its calibration. To explore these dynamics, we conducted a randomized behavioral experiment. Our results indicate that in human-AI decision-making, users’ self-confidence aligns with AI confidence and such alignment can persist even after AI ceases to be involved. This alignment then affects users’ self-confidence calibration. We also found the presence of real-time correctness feedback of decisions reduced the degree of alignment. These findings suggest that users’ self-confidence is not independent of AI confidence, which practitioners aiming to achieve better human-AI collaboration need to be aware of. We call for research focusing on the alignment of human cognition and behavior with AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1111},
numpages = {16},
keywords = {Human-AI Decision Making, Human-AI Alignment, Uncertainty Expression, Confidence, Metacognition},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713475,
author = {Bogon, Johanna and H\"{o}\ss{}l, Sabrina and Wolff, Christian and Henze, Niels and Halbhuber, David},
title = {Cognitive Integration of Delays: Anticipated System Delays Slow Down User Actions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713475},
doi = {10.1145/3706598.3713475},
abstract = {There are inevitably delays between user actions and system responses, which can increase task completion times. However, it remains unclear whether this is solely due to waiting times and compensation strategies, or whether users further slow down their actions because these delays become integrated into their cognitive action structures, as suggested by cognitive psychological theories. To explore this, we examined the effects of repeated exposure to delays during point-and-click tasks. Our findings demonstrate that longer system response delays significantly slow down users’ actions, even before they experience the delayed feedback from the current input. This suggests that the user’s cognitive system anticipates delays based on previous interactions and adjusts actions accordingly. These results emphasize the importance of minimizing systematic delays to maintain optimal user performance and highlight the potential for system properties to become embedded in users’ cognitive action structures.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1112},
numpages = {14},
keywords = {System Delays, Latency, Anticipatory Action Planning, Behavioral Adaptation, Ideomotor Theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713444,
author = {Wallinger, Markus and Akbulut, Osman and Rufai, Kabir Ahmed and Purchase, Helen C. and Archambault, Daniel},
title = {How Do People Perceive Bundling? An Experiment},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713444},
doi = {10.1145/3706598.3713444},
abstract = {We present an exploratory study on how people perceive visualizations of spatial social networks generated by edge bundling algorithms. Although these algorithms successfully minimize clutter in node-link diagrams, they do so through various methods that can sometimes create false connections between nodes. We conducted a qualitative experiment involving participants with technical expertise but no prior knowledge of edge bundling algorithms. Participants described their perceptions of both bundled and straight-line visualizations in open-ended tasks. Analysis of their annotations and transcripts revealed a general preference for bundled visualizations. However, when it came to false connections, participants tended to follow them in tightly bundled diagrams while also vocalizing that these drawings were more ambiguous. The routing of bundles influenced the perception of clusters and participants assigned more or fewer nodes to the clusters, depending on the routing of bundles. Participants’ unfamiliarity with the dataset led them to use analogies to describe the bundled drawings, potentially adding perceived semantic meaning to the data.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1113},
numpages = {14},
keywords = {Network Visualization, Edge Bundling, Qualitative Experiment, Empirical Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713536,
author = {Lima, Gabriel and Grgi\'{c}-Hla\v{c}a, Nina and Langer, Markus and Zou, Yixin},
title = {Lay Perceptions of Algorithmic Discrimination in the Context of Systemic Injustice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713536},
doi = {10.1145/3706598.3713536},
abstract = {Algorithmic fairness research often disregards concerns related to systemic injustice. We study how contextualizing algorithms within systemic injustice impacts lay perceptions of algorithmic discrimination. Using the hiring domain as a case-study, we conduct a 2x3 between-participants experiment (N = 716), studying how people’s views of algorithmic fairness are influenced by information about (i) systemic injustice in historical hiring decisions and (ii) algorithms’ propensity to perpetuate biases learned from past human decisions. We find that shedding light on systemic injustice has heterogeneous effects: participants from historically advantaged groups became more negative about discriminatory algorithms, while those from disadvantaged groups reported more positive attitudes. Explaining that algorithms learn from past human decisions had null effects on people’s views, adding nuances to calls for improving public understanding of algorithms. Our findings reveal that contextualizing algorithms in systemic injustice can have unintended consequences and show how different ways of framing existing inequalities influence perceptions of injustice.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1114},
numpages = {30},
keywords = {Artificial Intelligence, Algorithms, Algorithmic Decision-Making, Injustice, Discrimination, Systemic Injustice},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713279,
author = {Xiao, Qing and Zheng, Yuhang and Fan, Xianzhe and Zhang, Bingbing and Lu, Zhicong},
title = {Let's Influence Algorithms Together: How Millions of Fans Build Collective Understanding of Algorithms and Organize Coordinated Algorithmic Actions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713279},
doi = {10.1145/3706598.3713279},
abstract = {Previous research pays attention to how users strategically understand and consciously interact with algorithms but mainly focuses on an individual level, making it difficult to explore how users within communities could develop a collective understanding of algorithms and organize collective algorithmic actions. Through a two-year ethnography of online fan activities, this study investigates 43 core fans who always organize large-scale fans collective actions and their corresponding general fan groups. This study aims to reveal how these core fans mobilize millions of general fans through collective algorithmic actions. These core fans reported the rhetorical strategies used to persuade general fans, the steps taken to build a collective understanding of algorithms, and the collaborative processes that adapt collective actions across platforms and cultures. Our findings highlight the key factors that enable computer-supported collective algorithmic actions and extend collective action research into the large-scale domain targeting algorithms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1115},
numpages = {19},
keywords = {Algorithm; Folk Theory of Algorithm; Collective Understanding of Algorithm; Collective Algorithmic Action; Fandom Studies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714300,
author = {Li, Duan and Guo, Xinyuan and Shu, Xinhuan and Xiao, Lanxi and Yu, Lingyun and Liu, Shixia},
title = {RouteFlow: Trajectory-Aware Animated Transitions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714300},
doi = {10.1145/3706598.3714300},
abstract = {Animating objects’ movements is widely used to facilitate tracking changes and observing both the global trend and local hotspots where objects converge or diverge. Existing methods, however, often obscure critical local hotspots by only considering the start and end positions of objects’ trajectories. To address this gap, we propose RouteFlow, a trajectory-aware animated transition method that effectively balances the global trend and local hotspots while minimizing occlusion. RouteFlow is inspired by a real-world bus route analogy: objects are regarded as passengers traveling together, with local hotspots representing bus stops where these passengers get on and off. Based on this analogy, animation paths are generated like bus routes, with the object layout generated similarly to seat allocation according to their destinations. Compared with state-of-the-art methods, RouteFlow better facilitates identifying the global trend and locating local hotspots while performing comparably in tracking objects’ movements.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1116},
numpages = {17},
keywords = {trajectory data, animation, edge bundling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713564,
author = {Agarwal, Dhruv and Naaman, Mor and Vashistha, Aditya},
title = {AI Suggestions Homogenize Writing Toward Western Styles and Diminish Cultural Nuances},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713564},
doi = {10.1145/3706598.3713564},
abstract = {Large language models (LLMs) are being increasingly integrated into everyday products and services, such as coding tools and writing assistants. As these embedded AI applications are deployed globally, there is a growing concern that the AI models underlying these applications prioritize Western values. This paper investigates what happens when a Western-centric AI model provides writing suggestions to users from a different cultural background. We conducted a cross-cultural controlled experiment with 118 participants from India and the United States who completed culturally grounded writing tasks with and without AI suggestions. Our analysis reveals that AI provided greater efficiency gains for Americans compared to Indians. Moreover, AI suggestions led Indian participants to adopt Western writing styles, altering not just what is written but also how it is written. These findings show that Western-centric AI models homogenize writing toward Western norms, diminishing nuances that differentiate cultural expression.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1117},
numpages = {21},
keywords = {AI, NLP, culture, homogenization, bias, human-AI interaction, cross-cultural AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713287,
author = {Gero, Katy Ilonka and Desai, Meera and Schnitzler, Carly and Eom, Nayun and Cushman, Jack and Glassman, Elena L.},
title = {Creative Writers' Attitudes on Writing as Training Data for Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713287},
doi = {10.1145/3706598.3713287},
abstract = {The use of creative writing as training data for large language models (LLMs) is highly contentious and many writers have expressed outrage at the use of their work without consent or compensation. In this paper, we seek to understand how creative writers reason about the real or hypothetical use of their writing as training data. We interviewed 33 writers with variation across genre, method of publishing, degree of professionalization, and attitudes toward and engagement with LLMs. We report on core principles that writers express (support of the creative chain, respect for writers and writing, and the human element of creativity) and how these principles can be at odds with their realistic expectations of the world (a lack of control, industry-scale impacts, and interpretation of scale). Collectively these findings demonstrate that writers have a nuanced understanding of LLMs and are more concerned with power imbalances than the technology itself.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1118},
numpages = {16},
keywords = {Large language models, natural language generation, creative writers, creative writing, writing assistants, data collection, training data, archival practices, grounded theory.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713497,
author = {Bhattacharya, Aditya and Stumpf, Simone and De Croon, Robin and Verbert, Katrien},
title = {Explanatory Debiasing: Involving Domain Experts in the Data Generation Process to Mitigate Representation Bias in AI Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713497},
doi = {10.1145/3706598.3713497},
abstract = {Representation bias is one of the most common types of biases in artificial intelligence (AI) systems, causing AI models to perform poorly on underrepresented data segments. Although AI practitioners use various methods to reduce representation bias, their effectiveness is often constrained by insufficient domain knowledge in the debiasing process. To address this gap, this paper introduces a set of generic design guidelines for effectively involving domain experts in representation debiasing. We instantiated our proposed guidelines in a healthcare-focused application and evaluated them through a comprehensive mixed-methods user study with 35 healthcare experts. Our findings show that involving domain experts can reduce representation bias without compromising model accuracy. Based on our findings, we also offer recommendations for developers to build robust debiasing systems guided by our generic design guidelines, ensuring more effective inclusion of domain experts in the debiasing process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1119},
numpages = {20},
keywords = {Representation Bias, Bias detection, Debiasing, Explainable AI, XAI, Generative AI, GenAI, Responsible AI, Fair AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713338,
author = {Lima, Gabriel and Grgi\'{c}-Hla\v{c}a, Nina and Redmiles, Elissa M.},
title = {Public Opinions About Copyright for AI-Generated Art: The Role of Egocentricity, Competition, and Experience},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713338},
doi = {10.1145/3706598.3713338},
abstract = {Breakthroughs in generative AI (GenAI) have fueled debates concerning the artistic and legal status of AI-generated creations. We investigate laypeople’s perceptions (N = 432) of AI-generated art through the lens of copyright law. We study lay judgments of GenAI images concerning several copyright-related factors and capture people’s opinions of who should be the authors and rights-holders of AI-generated images. To do so, we held an incentivized AI art competition in which some participants used a GenAI model to create art while others evaluated these images. We find that participants believe creativity and effort, but not skills, are needed to create AI-generated art. Participants were most likely to attribute authorship and copyright to the AI model’s users and to the artists whose creations were used for training. We find evidence of egocentric effects: participants favored their own art with respect to quality, creativity, and effort—particularly when these assessments determined real monetary awards.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1120},
numpages = {32},
keywords = {Generative AI, Large Language Models, GenAI, LLM, Copyright, Egocentric Effects, Competition, Exhibition, Art, AI-Generated Art, Intellectual Property, IP},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713778,
author = {Lee, Hao-Ping (Hank) and Sarkar, Advait and Tankelevitch, Lev and Drosos, Ian and Rintel, Sean and Banks, Richard and Wilson, Nicholas},
title = {The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713778},
doi = {10.1145/3706598.3713778},
abstract = {The rise of Generative AI (GenAI) in knowledge workflows raises questions about its impact on critical thinking skills and practices. We survey 319 knowledge workers to investigate 1) when and how they perceive the enaction of critical thinking when using GenAI, and 2) when and why GenAI affects their effort to do so. Participants shared 936 first-hand examples of using GenAI in work tasks. Quantitatively, when considering both task- and user-specific factors, a user’s task-specific self-confidence and confidence in GenAI are predictive of whether critical thinking is enacted and the effort of doing so in GenAI-assisted tasks. Specifically, higher confidence in GenAI is associated with less critical thinking, while higher self-confidence is associated with more critical thinking. Qualitatively, GenAI shifts the nature of critical thinking toward information verification, response integration, and task stewardship. Our insights reveal new design challenges and opportunities for developing GenAI tools for knowledge work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1121},
numpages = {22},
keywords = {Critical thinking, Generative AI tools, Knowledge worker, Bloom’s taxonomy, Survey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714103,
author = {Qiao, Han and Vermeulen, Jo and Fitzmaurice, George and Matejka, Justin},
title = {To Use or Not to Use: Impatience and Overreliance When Using Generative AI Productivity Support Tools},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714103},
doi = {10.1145/3706598.3714103},
abstract = {Generative AI has the potential to assist people with completing various tasks, but increased productivity is not guaranteed due to challenges such as uncertainty in output quality and unclear processing time. Through an online crowdsourced experiment (N=508), leveraging a “paint by numbers” task to simulate properties of GenAI assistance, we explore how, and how well, users make decisions on whether to use or not use automation to maximize their productivity given varying waiting times and output quality. We observed gaps between user’s actual choices and their optimal choices and characterized these gaps as the “gulf of impatience” and the “gulf of overreliance”. We also distilled strategies that participants adopted when making their decisions. We discuss design considerations in supporting users to make more informed decisions when interacting with GenAI tools and make these tools more useful for improving users’ task performance, productivity and satisfaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1122},
numpages = {18},
keywords = {generative AI, decision-making, productivity, reliance, AI, automation, controlled experiment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714286,
author = {Wang, Yimeng and Wang, Yinzhou and Crace, Kelly and Zhang, Yixuan},
title = {Understanding Attitudes and Trust of Generative AI Chatbots for Social Anxiety Support},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714286},
doi = {10.1145/3706598.3714286},
abstract = {Social anxiety (SA) has become increasingly prevalent. Traditional coping strategies often face accessibility challenges. Generative AI (GenAI), known for their knowledgeable and conversational capabilities, are emerging as alternative tools for mental well-being. With the increased integration of GenAI, it is important to examine individuals’ attitudes and trust in GenAI chatbots’ support for SA. Through a mixed-method approach that involved surveys (n = 159) and interviews (n = 17), we found that individuals with severe symptoms tended to trust and embrace GenAI chatbots more readily, valuing their non-judgmental support and perceived emotional comprehension. However, those with milder symptoms prioritized technical reliability. We identified factors influencing trust, such as GenAI chatbots’ ability to generate empathetic responses and its context-sensitive limitations, which were particularly important among individuals with SA. We also discuss the design implications and use of GenAI chatbots in fostering cognitive and emotional trust, with practical and design considerations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1123},
numpages = {21},
keywords = {social anxiety, generative AI, trust, mixed methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714127,
author = {Fernandez-Espinosa, Mariana and Clouse, Kara and Sellars, Dylan and Tong, Danny and Bsales, Michael and Alcindor, Sophonie and Hubbard, Timothy D and Villano, Michael and G\'{o}mez-Zar\'{a}, Diego},
title = {Breaking the Familiarity Bias: Employing Virtual Reality Environments to Enhance Team Formation and Inclusion},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714127},
doi = {10.1145/3706598.3714127},
abstract = {Team closeness provides the foundations of trust and communication, contributing to teams’ success and viability. However, newcomers often struggle to be included in a team since incumbents tend to interact more with other existing members. Previous research suggests that online communication technologies can help team inclusion by mitigating members’ perceived differences. In this study, we test how virtual reality (VR) can promote team closeness when forming teams. We conducted a between-subject experiment with teams working in-person and VR, where two members interacted first, and then a third member was added later to conduct a hidden-profile task. Participants evaluated how close they felt with their teammates after the task was completed. Our results show that VR newcomers felt closer to the incumbents than in-person newcomers. However, incumbents’ closeness to newcomers did not vary across conditions. We discuss the implications of these findings and offer suggestions for how VR can promote inclusion.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1124},
numpages = {16},
keywords = {Familiarity Bias, Newcomers, Team Formation, Team Inclusion, Virtual Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714041,
author = {Schott, Ephraim and L\'{o}pez Garc\'{\i}a, Irene and Semple, Lauren August and Froehlich, Bernd},
title = {Estimating Detection Thresholds of Being Looked at in Virtual Reality for Avatar Redirection},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714041},
doi = {10.1145/3706598.3714041},
abstract = {The human face and eyes provide crucial conversational cues about a person’s focus of attention. In virtual reality applications, avatar faces are typically simplified, and eye movements often neglected. This paper explores how VR users perceive the look-at direction of other avatars and estimates the range within which an avatar’s averted gaze goes unnoticed. Through two-alternative forced choice experiments, we investigate different gaze offsets to quantify thresholds for perceived gaze aversion across three conditions: gaze side (left/right), stimulus duration, and avatar distance. Additionally, we assess the impact of averted gaze on social presence during interactions with an embodied conversational agent in a social game. A user study (N=40) revealed that social presence is significantly affected by averted gaze when noticed, and that detection thresholds are particularly impacted by stimuli duration and interactions between side and distance. Our findings provide a foundation for understanding gaze perception in social virtual reality.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1125},
numpages = {14},
keywords = {virtual reality, gaze direction, gaze perception, averted gaze, threshold detection, embodied conversational agents, avatar redirection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713409,
author = {Wang, Yingna and Liu, Qingqin and Wei, Xiaoying and Fan, Mingming},
title = {Facilitating Daily Practice in Intangible Cultural Heritage through Virtual Reality: A Case Study of Traditional Chinese Flower Arrangement},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713409},
doi = {10.1145/3706598.3713409},
abstract = {The essence of intangible cultural heritage (ICH) lies in the living knowledge and skills passed down through generations. Daily practice plays a vital role in revitalizing ICH by fostering continuous learning and improvement. However, limited resources and accessibility pose significant challenges to sustaining such practice. Virtual reality (VR) has shown promise in supporting extensive skill training. Unlike technical skill training, ICH daily practice prioritizes cultivating a deeper understanding of cultural meanings and values. This study explores VR’s potential in facilitating ICH daily practice through a case study of Traditional Chinese Flower Arrangement (TCFA). By investigating TCFA learners’ challenges and expectations, we designed and evaluated FloraJing, a VR system enriched with cultural elements to support sustained TCFA practice. Findings reveal that FloraJing promotes progressive reflection, and continuous enhances technical improvement and cultural understanding. We further propose design implications for VR applications aimed at fostering ICH daily practice in both knowledge and skills.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1126},
numpages = {17},
keywords = {Virtual Reality, Intangible Cultural Heritage, Daily Practice, Traditional Chinese Flower Arrangement},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714099,
author = {Chen, Qiyu and Mishra, Richa and Purnamasari, Lia Sparingga and EL-Zanfaly, Dina and Kitani, Kris},
title = {Origami Sensei: A Mixed Reality AI-Assistant},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714099},
doi = {10.1145/3706598.3714099},
abstract = {Learning creative hands-on skills, like origami, can be difficult for beginners. Conventional instructional methods often fail to support the experiential aspect of learning with timely and personalized feedback. Despite recent advancement of AI and Extended Reality in many fields, there is a lack of research on supporting learning in creative hands-on tasks. We investigate an AI-augmented Mixed Reality approach for learning hands-on creative tasks by introducing Origami Sensei as an approach for learning origami. Origami Sensei identifies the current step and relative locations of the paper using origami detection models, and projects real-time, personalized instructions directly onto the paper. We conducted a user study (n=18) comparing it with traditional video tutorials. Our findings show that participants prefer Origami Sensei, and it increases task efficiency and learner engagement. We introduce design insights for developing AI-augmented MR systems and highlight the potential for extending this approach to other creative hands-on tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1127},
numpages = {18},
keywords = {Mixed Reality, Origami, Hands-on learning, Convolutional neural networks},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714236,
author = {Wei, Qianjie and Wei, Xiaoying and Liang, Yiqi and Lin, Fan and Si, Nuonan and Fan, Mingming},
title = {RemoteChess: Enhancing Older Adults' Social Connectedness via Designing a Virtual Reality Chinese Chess (Xiangqi) Community},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714236},
doi = {10.1145/3706598.3714236},
abstract = {The decline of social connectedness caused by distance and physical limitations severely affects older adults’ well-being and mental health. While virtual reality (VR) is promising for older adults to socialize remotely, existing social VR designs primarily focus on verbal communication (e.g., reminiscent, chat). Actively engaging in shared activities is also an important aspect of social connection. We designed RemoteChess, which constructs a social community and a culturally relevant activity (i.e., Chinese chess) for older adults to play while engaging in social interaction. We conducted a user study with groups of older adults interacting with each other through RemoteChess. Our findings indicate that RemoteChess enhanced participants’ social connectedness by offering familiar environments, culturally relevant social catalysts, and asymmetric interactions. We further discussed design guidelines for designing culturally relevant social activities in VR to promote social connectedness for older adults.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1128},
numpages = {16},
keywords = {Older Adults, Social Connectedness, Virtual Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713700,
author = {Robert, Florent and Wu, Hui-Yin and Sassatelli, Lucile and Winckler, Marco},
title = {The Triangle of Misunderstanding in Interactive Virtual Narratives: Gulfs Between System, Designers and Players},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713700},
doi = {10.1145/3706598.3713700},
abstract = {Designers of storytelling experiences in virtual reality (VR) can take advantage of the medium’s realism and immersion to communicate their intentions. However, interaction freedom comes with unpredictability, raising the risk of miscommunication between the experience sought by the designer and the player’s interpretation. To better understand such miscommunications, we revisit Don Norman’s work on stages of action to propose a model of designer-player gulfs in VR that incorporates eight classes of communication gulfs. We designed a two-phase study where 10 participants designed VR scenarios and then played scenarios created by previous participants. Through coupled structured interviews, we identified 127 issues in VR-mediated communication that were mapped to our model to understand their impact on the player’s interpretation of the narrative experience. Our work provides a roadmap to identifying sources of miscommunication in VR, a first step to conceiving principles and guidelines for achieving effective communication in storytelling experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1129},
numpages = {16},
keywords = {Usability, Computer mediated communication, Qualitative method, Structured interviews, Virtual narratives},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713642,
author = {Wagener, Nadine and Albensoeder, Daniel Christian and Reicherts, Leon and Wo\'{z}niak, Pawe\l{} W. and Rogers, Yvonne and Niess, Jasmin},
title = {TogetherReflect: Supporting Emotional Expression in Couples Through a Collaborative Virtual Reality Experience},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713642},
doi = {10.1145/3706598.3713642},
abstract = {Navigating emotional conflicts within relationships can be challenging. People often struggle to express their emotions during a conflict, which can lead to misunderstandings and unresolved feelings. To facilitate deeper emotional expression, we developed TogetherReflect, a multi-user Virtual Reality (VR) experience designed for couples. Partners first draw their emotions related to a shared conflict in VR, allowing for individual expression and self-reflection. They then invite each other into their drawings to discuss their feelings, before drawing together on a shared canvas to reaffirm their love and commitment. Throughout this process, TogetherReflect provides prompts and guidance, aiming to foster self-reflection and communication skills. We exploratory evaluated the experience with 10 couples (n=20). Our findings indicate that TogetherReflect deepens personal emotional insights, fosters mutual understanding, and strengthens relational bonds. We highlight the potential of guided VR experiences to transform conflict resolution in intimate relationships and offer design considerations for future development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1130},
numpages = {16},
keywords = {Virtual Reality, couples, relationship, conflict resolution, emotional expression, multi-user},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713441,
author = {Lim, Chungman and John, Kevin and Jin, Gyungmin and Seifi, Hasti and Park, Gunhyuk},
title = {ChatHAP: A Chat-Based Haptic System for Designing Vibrations through Conversation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713441},
doi = {10.1145/3706598.3713441},
abstract = {In contrast to design tools for graphics and audio generation from text prompts, haptic design tools lag behind due to challenges in constructing large-scale, high-quality datasets including vibrations and text descriptions. To address this gap, we propose ChatHAP, a conversational haptic system for designing vibrations. ChatHAP integrates various haptic design approaches using a large language model, including generating vibrations using signal parameters, navigating through libraries, and modifying existing vibrations. To further improve vibration navigation, we present an algorithm that adaptively learns user preferences for vibration features. A user study with novices (n=20) demonstrated that ChatHAP can serve as a practical design tool, and the proposed algorithm significantly reduced task completion time (38\%), prompt quantity (25\%), and verbosity (36\%). The study found ChatHAP easy-to-use and identified requirements for chat-based haptic design as well as features for further improvement. Finally, we present key findings with ChatHAP and discuss implications for future work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1131},
numpages = {18},
keywords = {Design Tool, Vibration, Text-Based System, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713469,
author = {Wittchen, Dennis and Ramian, Alexander and Sabnis, Nihar and B\"{o}hme, Richard and Chlebowski, Christopher and Freitag, Georg and Fruchard, Bruno and Degraen, Donald},
title = {CollabJam: Studying Collaborative Haptic Experience Design for On-Body Vibrotactile Patterns},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713469},
doi = {10.1145/3706598.3713469},
abstract = {Designing vibrotactile experiences collaboratively requires communicating using multiple senses. This is challenging in remote scenarios as designers need to effectively express and communicate their intention while iteratively building and refining experiences, ideally in real-time. We formulate design considerations for collaborative haptic design tools, and propose CollabJam, a collaborative prototyping suite enabling remote synchronous design of vibrotactile experiences for on-body applications. We first outline CollabJam’s features and present a technical evaluation. Second, we use CollabJam to understand communication and design patterns used during haptic experience design. We performed an in-depth design evaluation spanning four sessions in which four pairs of participants designed and reviewed vibrotactile experiences remotely. A qualitative content analysis revealed how multi-sensory communication is essential to convey ideas, how stimulating the tactile sense can interfere with personal boundaries, and how freely placing actuators on the skin can provide both benefits and challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1132},
numpages = {20},
keywords = {vibrotactile design, vibrotactile patterns, tacton, collaborative design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714310,
author = {Rajaram, Shwetha and Surale, Hemant Bhaskar and McConkey, Codie and Rognon, Carine and Mehta, Hrim and Glueck, Michael and Collins, Christopher},
title = {Gesture and Audio-Haptic Guidance Techniques to Direct Conversations with Intelligent Voice Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714310},
doi = {10.1145/3706598.3714310},
abstract = {Advances in large language models (LLMs) empower new interactive capabilities for wearable voice interfaces, yet traditional voice-and-audio I/O techniques limit users’ ability to flexibly navigate information and manage timing for complex conversational tasks. We developed a suite of gesture and audio-haptic guidance techniques that enable users to control conversation flows and maintain awareness of possible future actions, while simultaneously contributing and receiving conversation content through voice and audio. A 14-participant exploratory study compared our parallelized I/O techniques to a baseline of voice-only interaction. The results demonstrate the efficiency of gestures and haptics for information access, while allowing system speech to be redirected and interrupted in a socially acceptable manner. The techniques also raised user awareness of how to leverage intelligent capabilities. Our findings inform design recommendations to facilitate role-based collaboration between multimodal I/O techniques and reduce users’ perception of time pressure when interleaving interactions with system speech.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1133},
numpages = {20},
keywords = {multimodal interaction, voice interfaces},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713358,
author = {Sabnis, Nihar and Roche, Ma\"{e}lle and Wittchen, Dennis and Degraen, Donald and Strohmeier, Paul},
title = {Motion-Coupled Asymmetric Vibration for Pseudo Force Rendering in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713358},
doi = {10.1145/3706598.3713358},
abstract = {In Virtual Reality (VR), rendering realistic forces is crucial for immersion, but traditional vibrotactile feedback fails to convey force sensations effectively. Studies of asymmetric vibrations that elicit pseudo forces show promise but are inherently tied to unwanted vibrations, reducing realism. Leveraging sensory attenuation to reduce the perceived intensity of self-generated vibrations during user movement, we present a novel algorithm that couples asymmetric vibrations with user motion, which mimics self-generated sensations. Our psychophysics study with 12 participants shows that motion-coupled asymmetric vibration attenuates the experience of vibration (equivalent to a ~30\% reduction in vibration-amplitude) while preserving the experience of force, compared to continuous asymmetric vibrations (state-of-the-art). We demonstrate the effectiveness of our approach in VR through three scenarios: shooting arrows, lifting weights, and simulating haptic magnets. Results revealed that participants preferred forces elicited by motion-coupled asymmetric vibration for tasks like shooting arrows and lifting weights. This research highlights the potential of motion-coupled asymmetric vibrations, offers new insights into sensory attenuation, and advances force rendering in VR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1134},
numpages = {22},
keywords = {virtual reality, haptic feedback, asymmetric vibration, pseudo forces, sensory attenuation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713629,
author = {Shi, Han and Luo, Hanzhong and Yi, HyeonBeom and Je, Seungwoo},
title = {ReachPad: Interacting with Multiple Virtual Screens using a Single Physical Pad through Haptic Retargeting},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713629},
doi = {10.1145/3706598.3713629},
abstract = {The advancement of Virtual Reality (VR) has expanded 2D user interfaces into 3D space. This change has introduced richer interaction modalities but also brought challenges, especially the lack of haptic feedback in mid-air interactions. Previous research has explored various methods to provide feedback for interface interactions, but most approaches require specialized haptic devices. We introduce haptic retargeting to enable users to control multiple virtual screens in VR using a simple flat pad, which serves as a single physical proxy to support seamless interaction across multiple virtual screens. We conducted user studies to explore the appropriate virtual screen size and positioning under our retargeting method and then compared various drag-and-drop methods for cross-screen interaction. Finally, we compared our method with controller-based interaction in application scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1135},
numpages = {17},
keywords = {Virtual reality, 3D user interfaces, haptic retargeting, passive haptics, interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714003,
author = {Cibulskis, Mantas and Yu, Difeng and Mortensen, Erik Skjoldan and Hassan, Waseem and Christensen, Mark Schram and Bergstr\"{o}m, Joanna},
title = {Tendon Vibration for Creating Movement Illusions in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714003},
doi = {10.1145/3706598.3714003},
abstract = {Tendon vibration can create movement illusions: vibrating the biceps tendon induces an illusion of extending the arm, while vibrating the triceps tendon induces an illusion of flexing the arm. However, it is unclear how to create and integrate such illusions shown in neuroscience to interaction techniques in virtual reality (VR). We first design a motor setup for tendon vibration. Study 1 validates that the setup induces movement illusions which on average create a 5.26 cm offset in active arm movements. Study 2 shows that tendon vibration improves the detection thresholds of visual motion gains often used in VR interaction techniques by 0.22. A model we developed in Study 2 predicts the effects of tendon vibration and is used in a biomechanical simulation to demonstrate the detection thresholds across typical reaching tasks in VR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1136},
numpages = {16},
keywords = {Virtual Reality, Hand Redirection, Tendon Vibration, Movement Illusions, Detection Thresholds},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714273,
author = {Huang, Bingjian and Ren, Siyi and Luo, Yuewen and Cheng, Qilong and Cai, Hanfeng and Sang, Yeqi and Sousa, Mauricio and Dietz, Paul H and Wigdor, Daniel},
title = {VibraForge: A Scalable Prototyping Toolkit For Creating Spatialized Vibrotactile Feedback Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714273},
doi = {10.1145/3706598.3714273},
abstract = {Spatialized vibrotactile feedback systems deliver tactile information by placing multiple vibrotactile actuators on the body. As increasing numbers of actuators are required to adequately convey information in complicated applications, haptic designers find it difficult to create such systems due to limited scalability of existing toolkits. We propose VibraForge, an open-source vibrotactile toolkit that supports up to 128 vibrotactile actuators. Each actuator is encapsulated within a self-contained vibration unit and driven by its own microcontroller. By leveraging a chain-connection method, each unit receives independent vibration commands from a control unit, with fine-grained control over intensity and frequency. We also designed a GUI Editor to expedite the authoring of spatial vibrotactile patterns. Technical evaluation showed that vibration units reliably reproduced audio waveforms with low-latency and high-bandwidth data communication. Case studies of a phonemic tactile display, virtual reality fitness training, and drone teleoperation demonstrated the potential usage of VibraForge within different domains. A usability study with non-expert users highlighted the low technical barrier and customizability of the toolkit.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1137},
numpages = {18},
keywords = {Haptics, Vibrotactile Feedback, Haptic Toolkit, Multi-Actuator Devices, Wearable Devices},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713880,
author = {Kim, Minsun and Lee, Dawon and Noh, Junyong},
title = {Generating Highlight Videos of a User-Specified Length using Most Replayed Data},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713880},
doi = {10.1145/3706598.3713880},
abstract = {A highlight is a short edit of the original video that includes the most engaging moments. Given the rigid timing of TV commercial slots and length limits of social media uploads, generating highlights of specific lengths is crucial. Previous research on automatic highlight generation often overlooked the control over the duration of the final video, producing highlights of arbitrary lengths. We propose a novel system that automatically generates highlights of any user-specified length. Our system leverages Most Replayed Data (MRD), which identifies how frequently a video has been watched over time, to gauge the most engaging parts. It then optimizes the final editing path by adjusting internal segment durations. We evaluated the quality of our system’s outputs through two user studies, including a comparison with highlights created by human editors. Results show that our system can automatically produce highlights that are indistinguishable from those created by humans in viewing experience.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1138},
numpages = {13},
keywords = {Highlight Generation, Video Summarization, Video Editing, Image Processing, Most Replayed Data},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713206,
author = {Bartindale, Tom and Cleever, Cassandra and Moran, Claire and Angelucci, Margherita and Varghese, Delvin and Olivier, Patrick},
title = {More Than 'ticking-a-box': The Affordances of Short-form Video for Community Reporting to Government},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713206},
doi = {10.1145/3706598.3713206},
abstract = {Communication between government agencies and not-for-profits (NFPs) within the local funding sector typically require the writing and submitting of long-form text-based reports. These processes are time and resource intensive and require skill in written communication, placing a significant administrative burden on the small, already under-resourced organisations who interact with programs. NFP’s now have the technical literacy to create rich video content, but little is understood about how video could be used instead of, or alongside traditional written reports. We present findings from a novel funding acquittal (final report) process that we designed for a government grant programme to explore the affordances of video from the perspective of the grantee. We discuss the affordances of structured short-form video to overcome the barriers faced by organisations during these reporting processes. We present design considerations for digitally mediated processes that could support the media augmentation of these established workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1139},
numpages = {15},
keywords = {granting, acquittal, participatory video, automatic production},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713741,
author = {He, Yuchen and Lv, Jianbing and Cheng, Liqi and Meng, Lingyu and Deng, Dazhen and Wu, Yingcai},
title = {ProTAL: A Drag-and-Link Video Programming Framework for Temporal Action Localization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713741},
doi = {10.1145/3706598.3713741},
abstract = {Temporal Action Localization (TAL) aims to detect the start and end timestamps of actions in a video. However, the training of TAL models requires a substantial amount of manually annotated data. Data programming is an efficient method to create training labels with a series of human-defined labeling functions. However, its application in TAL faces difficulties of defining complex actions in the context of temporal video frames. In this paper, we propose ProTAL, a drag-and-link video programming framework for TAL. ProTAL enables users to define key events by dragging nodes representing body parts and objects and linking them to constrain the relations (direction, distance, etc.). These definitions are used to generate action labels for large-scale unlabelled videos. A semi-supervised method is then employed to train TAL models with such labels. We demonstrate the effectiveness of ProTAL through a usage scenario and a user study, providing insights into designing video programming framework.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1140},
numpages = {18},
keywords = {Interactive Data Programming, Data Annotation, Temporal Action Localization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713342,
author = {Halperin, Brett A. and Ru\'{\i}z, Diana Flores and Rosner, Daniela K.},
title = {Underground AI? Critical Approaches to Generative Cinema through Amateur Filmmaking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713342},
doi = {10.1145/3706598.3713342},
abstract = {Amateurism (e.g., hobbyist and do-it-yourself making) has long helped human-computer interaction (HCI) scholars map alternatives to status quo technology developments, cultures, and practices. Following the 2023 Hollywood film worker strikes, many scholars, artists, and activists alike have called for alternative approaches to AI that reclaim the apparatus for co-creative and resistant means. Towards this end, we conduct an 11-week diary study with 20 amateur filmmakers of 15 AI-infused films, investigating the emerging space of generative cinema as a critical technical practice. Our close reading of the films and filmmakers’ reflections on their processes reveal four critical approaches to negotiating AI use in filmmaking: minimization, maximization, compartmentalization, and revitalization. We discuss how these approaches suggest the potential for underground filmmaking cultures to form around AI with critical amateurs reclaiming social control over the creative possibilities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1141},
numpages = {18},
keywords = {AI, AI Art, Amateurism, Bias, Creativity, Critical Humanistic Inquiry, Cinema, Cinematography, Critical Technical Practice, Film, Filmmaking, Generative AI, Non-Use, Storytelling, Underground Film, Video, Visual Storytelling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713857,
author = {Yang, Joshua Kong and Leake, Mackenzie and Huang, Jeff and DiVerdi, Stephen},
title = {VidSTR: Automatic Spatiotemporal Retargeting of Speech-Driven Video Compositions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713857},
doi = {10.1145/3706598.3713857},
abstract = {Video editors often record multiple versions of a performance with minor differences. When they add graphics atop one video, they may wish to transfer those assets to another recording, but differences in performance, wordings, and timings can cause assets to no longer be aligned with the video content. Fixing this is a time-consuming, manual task. We present a technique which preserves the temporal and spatial alignment of the original composition when automatically retargeting speech-driven video compositions. It can transfer graphics between both similar and dissimilar performances, including those varying in speech and gesture. We use a large language model for transcript-based temporal alignment and integer programming for spatial alignment. Results from retargeting between 51 pairs of performances show that we achieve a temporal alignment success rate of 90\% compared to hand-generated ground truth compositions. We demonstrate challenging scenarios, retargeting video compositions across different people, aspect ratios, and languages.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1142},
numpages = {17},
keywords = {video, composition, motion graphics, temporal alignment, spatial alignment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713417,
author = {Huh, Mina and Li, Ding and Pimmel, Kim and Shin, Hijung Valentina and Pavel, Amy and Dontcheva, Mira},
title = {VideoDiff: Human-AI Video Co-Creation with Alternatives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713417},
doi = {10.1145/3706598.3713417},
abstract = {To make an engaging video, people sequence interesting moments and add visuals such as B-rolls or text. While video editing requires time and effort, AI has recently shown strong potential to make editing easier through suggestions and automation. A key strength of generative models is their ability to quickly generate multiple variations, but when provided with many alternatives, creators struggle to compare them to find the best fit. We propose VideoDiff, an AI video editing tool designed for editing with alternatives. With VideoDiff, creators can generate and review multiple AI recommendations for each editing process: creating a rough cut, inserting B-rolls, and adding text effects. VideoDiff simplifies comparisons by aligning videos and highlighting differences through timelines, transcripts, and video previews. Creators have the flexibility to regenerate and refine AI suggestions as they compare alternatives. Our study participants (N=12) could easily compare and customize alternatives, creating more satisfying results.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1143},
numpages = {19},
keywords = {Video Editing, Authoring Tools, Generative AI, Human-AI Co-Creation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714061,
author = {Wang, Ke and Lin, Lehao and Abdallah, Maha and Cai, Wei},
title = {Where is the Boundary? Understanding How People Recognize and Evaluate Generative AI-extended Videos},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714061},
doi = {10.1145/3706598.3714061},
abstract = {The rise of video generative models that produce high-quality content has made it increasingly difficult to discern video authenticity. AI-extended videos, which mix real-world footage with generative content, pose new challenges in distinguishing real from manipulated segments. AI-extended videos might be utilized to deceive humans, but they also have the capacity to assist video creators and offer people novel video experiences. Despite these concerns, research on how people recognize and evaluate AI-extended videos remains limited. To address this, we conducted a user study where participants interacted with AI-extended videos on a web-based system, identifying boundaries between raw and generated content, followed by a survey and one-on-one interviews. Our quantitative and qualitative analyses revealed how individuals perceive these videos, the factors influencing their perception, evaluations and attitudes. We believe that these insights will aid the future development of AI-extended video technologies and ecosystems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1144},
numpages = {19},
keywords = {Human Perception, AI-generated Videos, AI-extended Videos, Video Extension, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714279,
author = {Xiao, Cleo and Yu, Difeng and Hornb\ae{}k, Kasper and Bergstr\"{o}m, Joanna},
title = {A Concept at Work: A Review of Motivations, Operationalizations, and Conclusions in VR Research about Presence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714279},
doi = {10.1145/3706598.3714279},
abstract = {Presence appears an important concept for virtual reality (VR): It is frequently measured with questionnaires, and theory and methods about it have been discussed in numerous works. Yet, it is unclear how to actually work with this concept: Why is presence important to measure, how to choose an appropriate questionnaire, and what to conclude about it based on findings? To answer these questions, we review how the concept is put to work in 288 VR papers from 2023 measuring presence with questionnaires. Our findings include that measuring presence is often motivated by another construct, such as user experience; the reasons for choosing a specific questionnaire are often weak or not reported at all; and high presence values are frequently used simply to validate an interaction technique. We propose recommendations for working with presence and formulate questions to direct future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1145},
numpages = {21},
keywords = {Virtual reality, presence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713610,
author = {Rocha, Filipa and Sim\~{a}o, Hugo and Nogueira, Jo\~{a}o and Neto, Isabel and Guerreiro, Tiago and Nicolau, Hugo},
title = {Awareness in Collaborative Mixed-Visual Ability Tangible Programming Activities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713610},
doi = {10.1145/3706598.3713610},
abstract = {In the context of computational thinking tasks, which often require problem-solving and critical thinking skills, awareness of a partner’s actions can play a significant role in fostering a balanced collaboration. Understanding how awareness influences mixed-visual ability group collaboration in a tangible environment can provide insights into inclusive design for learning environments. To address this issue, we ran a user study where 6 mixed-visual ability pairs engaged in a tangible programming activity. The study had three experimental conditions, representing 3 different levels of awareness. Our findings reveal that while pre-existing power dynamics heavily influenced collaboration, workspace awareness feedback was essential in fostering engagement and improving communication for both children. This paper highlights the need for designing inclusive collaborative programming systems that account for workspace awareness and individual abilities, offering insights into more effective and balanced collaborative environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1146},
numpages = {15},
keywords = {Accessibility, Mixed-Visual Ability, Collaboration, Computational Thinking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714162,
author = {Zhang, Jian and Johal, Wafa and Knibbe, Jarrod},
title = {Illusion Spaces in VR: The Interplay Between Size and Taper Angle Perception in Grasping},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714162},
doi = {10.1145/3706598.3714162},
abstract = {Leveraging the integration of visual and proprioceptive cues, research has uncovered various perception thresholds in VR that can be exploited to support haptic feedback for grasping. While previous studies have explored individual dimensions, such as size, the combined effect of multiple geometric properties on perceptual illusions remains poorly understood. We present a two-alternative forced choice study investigating the perceptual interplay between object size and taper angle. We introduce an illusion space model, providing detailed insights into how physical and virtual object configurations affect human perception. Our insights reveal how, for example, as virtual sizes increase, users perceive that taper angles increase, and as virtual angles decrease, users overestimate sizes. We provide a mathematical model of the illusion space, and an associated tool, which can be used as a guide for the design of future VR haptic devices and for proxy object selections.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1147},
numpages = {17},
keywords = {Virtual Reality, Grasping, Haptics, Perception},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714303,
author = {Zhao, Ke and Chen, Ruiqi and Zhang, Xiaziyu and Wang, Chenxi and Chen, Siling and Wang, Xiaoguang and Wang, Yujue and Tong, Xin},
title = {Immersive Biography: Supporting Intercultural Empathy and Understanding for Displaced Cultural Objects in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714303},
doi = {10.1145/3706598.3714303},
abstract = {Displaced cultural objects often act as mediators of intercultural understanding due to their connection between the original and host communities. This study explores how immersive embodied VR biography enhances intercultural empathy and understanding of displaced cultural objects. We took the famous Chinese painting, the Admonitions Scroll, housed at the British Museum as an example to design an Immersive Biography in VR. We conducted an empirical study with 24 participants from source and non-source communities. Findings suggested that interacting with biographical narratives of displaced cultural objects in a personified embodied way can effectively promote intercultural empathy and understanding. Additionally, simulated intercultural scenarios and dialogues with personified cultural objects fostered intercultural empathy in both groups, with a stronger effect observed in non-source communities due to differences in cultural identity and personal connections. Our study provided the potential and practical insights of immersive technologies to inspire intercultural communication for displaced cultural objects.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1148},
numpages = {17},
keywords = {Intercultural empathy, Displaced cultural objects, Embodied narratives, Object biography, Virtual Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713328,
author = {Xiao, Xiao and Noh, Hayoun and Lefevre, Adrien and Li, Lucy and McKee, Holly and Algargoosh, Alaa and Ishii, Hiroshi},
title = {ReMirrorFugue: Examining the Emotional Experience of Presence and (Illusory) Communications Across Time},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713328},
doi = {10.1145/3706598.3713328},
abstract = {This paper examines how strategies for simulating social presence across distance can evoke a sense of presence and facilitate illusory interactions across time. We conducted a mixed-methods study with 28 participants, exploring their emotional experience of interacting with decade-old recorded piano performances on MirrorFugue—a player piano enhanced with life-sized projections of the pianist’s hands and body, creating the illusion of a virtual reflection playing the instrument. Data were collected via wearable sensors, questionnaires, and interviews.Results showed that participants felt a strong presence of past pianists, with some experiencing the illusion of two-way communication and an overall increase in connection. The emotional experience was significantly influenced by the participant’s relationship with the recorded pianist and the pianist’s vital status. These findings suggest that telepresence technologies can foster connections with the past, offering spaces for memory recall, self-reflection, and a sense of “time travel.”},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1149},
numpages = {26},
keywords = {Mixed-methods, telepresence, technology for reflection, social presence, musical experience, piano, affective computing, physiological signals, emotions, interviews, quantitative methods, qualitative methods, augmented reality, ongoingness},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713566,
author = {Belga, Jacob and Skarbez, Richard and Hmaiti, Yahya and Chen, Eric J and McMahan, Ryan P. and LaViola, Joseph J.},
title = {The Fidelity-based Presence Scale (FPS): Modeling the Effects of Fidelity on Sense of Presence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713566},
doi = {10.1145/3706598.3713566},
abstract = {Within the virtual reality (VR) research community, there have been several efforts to develop questionnaires with the aim of better understanding the sense of presence. Despite having numerous surveys, the community does not have a questionnaire that informs which components of a VR application contributed to the sense of presence. Furthermore, previous literature notes the absence of consensus on which questionnaire or questions should be used. Therefore, we conducted a Delphi study, engaging presence experts to establish a consensus on the most important presence questions and their respective verbiage. We then conducted a validation study with an exploratory factor analysis (EFA). The efforts between our two studies led to the creation of the Fidelity-based Presence Scale (FPS). With our consensus-driven approach and fidelity-based factoring, we hope the FPS will enable better communication within the research community and yield important future results regarding the relationship between VR system fidelity and presence.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1150},
numpages = {15},
keywords = {Virtual reality, presence, fidelity, Delphi method},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714204,
author = {Degenhard, Annalisa and Askari, Ali and Rietzler, Michael and Rukzio, Enrico},
title = {When Do We Feel Present in a Virtual Reality? Towards Sensitivity and User Acceptance of Presence Questionnaires},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714204},
doi = {10.1145/3706598.3714204},
abstract = {Presence is an important and widely used metric to measure the quality of virtual reality (VR) applications. Given the multifaceted and subjective nature of presence, the most common measures for presence are questionnaires. But there is little research on their validity regarding specific presence dimensions and their responsiveness to differences in perception among users. We investigated four presence questionnaires (SUS, PQ, IPQ, Bouchard) on their responsiveness to intensity variations of known presence dimensions and asked users about their consistency with their experience. Therefore, we created five VR scenarios that were designed to emphasize a specific presence dimension. Our findings showed heterogeneous sensitivity of the questionnaires dependent on the different dimensions of presence. This highlights a context-specific suitability of presence questionnaires. The questionnaires’ sensitivity was further stated as lower than actually perceived. Based on our findings, we offer guidance on selecting these questionnaires based on their suitability for particular use cases.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1151},
numpages = {29},
keywords = {virtual reality, presence, plausibility, place illusion, embodiment, social presence, involvement, questionnaires},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713777,
author = {Sendhilnathan, Naveen and Zhang, Ting and Bethge, David and Nebeling, Michael and Grossman, Tovi and Jonker, Tanya R.},
title = {A Multimodal Approach for Targeting Error Detection in Virtual Reality Using Implicit User Behavior},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713777},
doi = {10.1145/3706598.3713777},
abstract = {Although the point-and-select interaction method has been shown to lead to user and system-initiated errors, it is still prevalent in VR scenarios. Current solutions to facilitate selection interactions exist, however they do not address the challenges caused by targeting inaccuracy. To reduce the effort required to target objects, we developed a model that quickly detected targeting errors after they occurred. The model used implicit multimodal user behavioral data to identify possible targeting outcomes. Using a dataset composed of 23 participants engaged in VR targeting tasks, we then trained a deep learning model to differentiate between correct and incorrect targeting events within 0.5 seconds of a selection, resulting in an AUC-ROC of 0.9. The utility of this model was then evaluated in a user study with 25 participants that identified that participants recovered from more errors and faster when assisted by the model. These results advance our understanding of targeting errors in VR and facilitate the design of future intelligent error-aware systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1152},
numpages = {14},
keywords = {Gaze behavior, eye tracking, multimodal input, error detection, virtual reality, point-and-select},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713492,
author = {Li, Tinghui and Velloso, Eduardo and Withana, Anusha and Sarsenbayeva, Zhanna},
title = {Estimating the Effects of Encumbrance and Walking on Mixed Reality Interaction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713492},
doi = {10.1145/3706598.3713492},
abstract = {This paper investigates the effects of two situational impairments—encumbrance (i.e., carrying a heavy object) and walking—on interaction performance in canonical mixed reality tasks. We built Bayesian regression models of movement time, pointing offset, error rate, and throughput for target acquisition task, and throughput, UER, and CER for text entry task to estimate these effects. Our results indicate that 1.0 kg encumbrance increases selection movement time by 28\%, decreases text entry throughput by 17\%, and increase UER by 50\%, but does not affect pointing offset. Walking led to a 63\% increase in ray-cast movement time and a 51\% reduction in text entry throughput. It also increased selection pointing offset by 16\%, ray-cast pointing offset by 17\%, and error rate by 8.4\%. The interaction effect on 1.0 kg encumbrance and walking resulted in a 112\% increase in ray-cast movement time. Our findings enhance the understanding of the effects of encumbrance and walking on mixed reality interaction, and contribute towards accumulating knowledge of situational impairments research in mixed reality.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1153},
numpages = {24},
keywords = {Situational Impairments, Encumbrance, Walking, Fitts’s Law, Text Entry},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713766,
author = {Niu, Ruowen and Zheng, Ruishen and Liang, Chen and Liu, Minghui},
title = {Exploring Joint Effects of Locomotion Continuity and Wayfinding Assistance in Non-Embodied VR Game Navigation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713766},
doi = {10.1145/3706598.3713766},
abstract = {Navigation is a crucial part of the VR game experience. However, discrete and continuous optic flow from locomotion techniques (DL and CL) and wayfinding assistance in VR games may impact players’ navigation differently. Limited research has explored how DL and CL’s influence on navigation changes across different wayfinding assistance conditions. This study employed a 2\texttimes{}3 factorial between-subjects experiment with 78 participants to investigate their joint effects. The study explores explanations for observed differences among conditions from the mixed-method analysis of quantitative data (game performance, spatial learning performance, pressure level, usability, and sickness) and thematic analysis of post-hoc interviews. Therefore, the study identifies three key factors—exploration strategy, attention, and spatial knowledge as explanations. Designers can leverage these insights to improve navigation support in VR games, with broader potential applications in fields such as healthcare and training.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1154},
numpages = {21},
keywords = {Virtual reality; locomotion technique; game navigation; navigation aids},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714214,
author = {Wu, En-Huei and Cheng, Po-Yun and Hsu, Che-Wei and Han, Cheng Hsin and Lee, Pei Chen and Fan, Chia-An and Kuo, Yu Chia and Hu, Kai-Jing and Chen, Yu and Chen, Mike Y.},
title = {HeadTurner: Enhancing Viewing Range and Comfort of using Virtual and Mixed-Reality Headsets while Lying Down via Assisted Shoulder and Head Actuation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714214},
doi = {10.1145/3706598.3714214},
abstract = {Virtual and mixed reality headsets, such as the Apple Vision Pro and Meta Quest, began supporting use in reclined postures in 2024, accommodating users who prefer or require this position. However, the surfaces on which users rest restrict shoulder and head rotation, reducing viewing range and comfort. A formative study (n=16) comparing usage while standing vs. lying down showed that head rotation range decreased from 261º to 130º horizontally and from 172º to 94.9º vertically. To improve viewing range and comfort, we present HeadTurner, a novel approach that assists user-initiated head rotations by actuating the resting surface to yield in pitch and yaw axes. In a user study (n=16), HeadTurner significantly expanded the field of view and improved comfort compared to a fixed surface. Although VR sickness was slightly reduced with HeadTurner, the difference was not statistically significant. Overall, HeadTurner was preferred by 75\% of participants. Although our proof-of-concept device was prototyped as a bed, the approach can be extended to more compact and affordable device form factors, such as motorized reclining chairs, offering the potential for comfortable use of VR and MR headsets over extended periods , and was shown to inspire users with interested applications in back-rested scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1155},
numpages = {16},
keywords = {Head-mounted Display, Back-rest, Supine, Bed, Lying down, Ergonomic Movement, Upper Body Actuation, User Experience, Extended Viewing Range},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713647,
author = {Zhou, Hongyu and Kip, Tom and Dong, Yihao and Bianchi, Andrea and Sarsenbayeva, Zhanna and Withana, Anusha},
title = {Juggling Extra Limbs: Identifying Control Strategies for Supernumerary Multi-Arms in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713647},
doi = {10.1145/3706598.3713647},
abstract = {Using supernumerary multi-limbs for complex tasks is a growing research focus in Virtual Reality (VR) and robotics. Understanding how users integrate extra limbs to achieve shared goals is crucial for developing efficient supernumeraries. This paper presents an exploratory study (N=14) investigating strategies for controlling virtual supernumerary limbs with varying autonomy in VR object manipulation tasks. Using a Wizard-of-Oz approach to simulate semi-autonomous limbs, we collected qualitative and quantitative data. Results show participants adapted control strategies based on task complexity and autonomy, affecting task delegation, coordination, and body ownership. Based on these findings, we propose guidelines—commands, demonstration, delegation, and labeling—to improve multi-limb interaction design by adapting autonomy to user needs and fostering context-aware experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1156},
numpages = {16},
keywords = {Embodied Interaction, Virtual/Augmented Reality, Empirical study that tells us about how people use a system, Interaction Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714180,
author = {Jung, Ju Yeon and Steinberger, Tom},
title = {Modes of Interaction with Navigation Apps},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714180},
doi = {10.1145/3706598.3714180},
abstract = {Despite many HCI studies of diverse factors shaping users’ navigation experiences, how to design navigation systems to be adaptable to all of these factors remains a challenge. To address this challenge, we study general variations in users’ intended navigation experiences. Based on 30 interviews, we find that interactions with navigation apps can be subsumed under three “modes”: follow, modify, and background. For each mode of interaction, we highlight users’ key motivations, interactions with apps, and challenges. We propose these modes as higher-level concepts for exploring how to enable the details of navigation support to be adaptable to users’ generally intended navigation experiences. We discuss broader implications for issues of efficiency and overreliance in our experience of the physical environments through navigation apps.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1157},
numpages = {15},
keywords = {Navigation, adaptive systems, efficiency, modes of interaction, navigation apps, navigation experience, reliance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714289,
author = {Kim, You-Jin and Kumaran, Radha and Luo, Jingjing and Bullock, Tom and Giesbrecht, Barry and H\"{o}llerer, Tobias},
title = {On the Go with AR: Attention to Virtual and Physical Targets while Varying Augmentation Density},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714289},
doi = {10.1145/3706598.3714289},
abstract = {Augmented reality is projected to be a primary mode of information consumption on the go, seamlessly integrating virtual content into the physical world. However, the potential perceptual demands of viewing virtual annotations while navigating a physical environment could impact user efficacy and safety, and the implications of these demands are not well understood. Here, we investigate the impact of virtual path guidance and augmentation density (visual clutter) on search performance and memory. Participants walked along a predefined path, searching for physical or virtual items. They experienced two levels of augmentation density, and either walked freely or with enforced speed and path guidance. Augmentation density impacted behavior and reduced awareness of uncommon objects in the environment. Analysis of search task performance and post-experiment item recall revealed differing attention to physical and virtual objects. On the basis of these findings we outline considerations for AR apps designed for use on the go.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1158},
numpages = {16},
keywords = {Mobile Augmented Reality, Extended Reality, Mixed Reality, Perception, Behavior},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714173,
author = {Clepper, Gina and McDonnell, Emma J. and Findlater, Leah and Peek, Nadya},
title = {"What Would I Want to Make? Probably Everything": Practices and Speculations of Blind and Low Vision Tactile Graphics Creators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714173},
doi = {10.1145/3706598.3714173},
abstract = {Tactile graphics communicate images and spatial information to blind and low vision (BLV) audiences via touch. However, designing and producing tactile graphics is laborious and often inaccessible to BLV people themselves. We interviewed 14 BLV adults with experience both using and creating tactile graphics to understand their current and desired practices. We found that tactile graphics are intensely valued by many, but that access to and fluency with tactile graphics are compounding challenges. To produce tactile graphics, BLV makers constantly navigate tradeoffs between accessible, low-fidelity craft materials and less accessible, high-fidelity equipment. Going forward, we argue that tactile graphics design and production should be made widely accessible and that tactile graphics themselves should be designed to be expressive and ubiquitous. Drawing from these design goals, we propose specific future tools with features for inclusive designing, sharing, and (re)production of tactile graphics.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1159},
numpages = {16},
keywords = {Tactile Graphics, Blind, Low vision},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714205,
author = {Ran, Zihe and Li, Xiyu and Xiao, Qing and Fan, Xianzhe and Li, Franklin Mingzhe and Wang, Yanyun and Lu, Zhicong},
title = {How Users Who are Blind or Low Vision Play Mobile Games: Perceptions, Challenges, and Strategies},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714205},
doi = {10.1145/3706598.3714205},
abstract = {As blind and low-vision (BLV) players engage more deeply with games, accessibility features have become essential. While some research has explored tools and strategies to enhance game accessibility, the specific experiences of these players with mobile games remain underexamined. This study addresses this gap by investigating how BLV users experience mobile games with varying accessibility levels. Through interviews with 32 experienced BLV mobile players, we explore their perceptions, challenges, and strategies for engaging with mobile games. Our findings reveal that BLV players turn to mobile games to alleviate boredom, achieve a sense of accomplishment, and build social connections, but face barriers depending on the game’s accessibility level. We also compare mobile games to other forms of gaming, highlighting the relative advantages of mobile games, such as the inherent accessibility of smartphones. This study contributes to understanding BLV mobile gaming experiences and provides insights for enhancing accessible mobile game design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1160},
numpages = {18},
keywords = {Game Accessibility, Mobile Accessibility, Mobile Game, Blind and Low-Vision (BLV) Users; Global South},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713553,
author = {Kim, Gyeongdeok and Lim, Chungman and Park, Gunhyuk},
title = {I-Scratch: Independent Slide Creation With Auditory Comment and Haptic Interface for the Blind and Visually Impaired},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713553},
doi = {10.1145/3706598.3713553},
abstract = {Presentation software still holds barriers to independent creation for blind and visually impaired users (BVIs) due to its visual-centric interface. To address this gap, we introduce I-Scratch, a multimodal system which empowers BVIs to independently create, explore, and edit PowerPoint slides. We initially designed I-Scratch to tackle the practical challenges faced by BVIs and refined I-Scratch to improve its usability and accessibility through iterative participatory sessions involving a blind user. I-Scratch integrates a graphical tactile display with auditory guidance for multimodal feedback, simplifies the user interface, and leverages AI technologies for visual assistance in image generation and content interpretation. A user study with ten BVIs demonstrated that I-Scratch enables them to produce visually coherent and aesthetically pleasing slides independently, achieving 91.25\% of full and partial successes with a CSI score of 85.07. We present five guidelines and future directions to support the creative work of BVIs using presentation software.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1161},
numpages = {23},
keywords = {The Blind and Visually Impaired, Accessibility, Slide Editing, Graphical Tactile Display, Multimodal Interfaces, AI Assistance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713454,
author = {Meinhardt, Luca-Maxim and Weilke, Lina Madlin and Elhaidary, Maryam and von Abel, Julia and Fink, Paul D. S. and Rietzler, Michael and Colley, Mark and Rukzio, Enrico},
title = {Light My Way: Developing and Exploring a Multimodal Interface to Assist People With Visual Impairments to Exit Highly Automated Vehicles},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713454},
doi = {10.1145/3706598.3713454},
abstract = {The introduction of Highly Automated Vehicles (HAVs) has the potential to increase the independence of blind and visually impaired people (BVIPs). However, ensuring safety and situation awareness when exiting these vehicles in unfamiliar environments remains challenging. To address this, we conducted an interactive workshop with N=5 BVIPs to identify their information needs when exiting an HAV and evaluated three prior-developed low-fidelity prototypes. The insights from this workshop guided the development of PathFinder, a multimodal interface combining visual, auditory, and tactile modalities tailored to BVIP’s unique needs. In a three-factorial within-between-subject study with N=16 BVIPs, we evaluated PathFinder against an auditory-only baseline in urban and rural scenarios. PathFinder significantly reduced mental demand and maintained high perceived safety in both scenarios, while the auditory baseline led to lower perceived safety in the urban scenario compared to the rural one. Qualitative feedback further supported PathFinder’s effectiveness in providing spatial orientation during exiting.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1162},
numpages = {20},
keywords = {people with visual impairments, multimodal interfaces, situation awareness, highly automated vehicles},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713797,
author = {Zhong, Mingyuan and Chen, Ruolin and Chen, Xia and Fogarty, James and Wobbrock, Jacob O.},
title = {ScreenAudit: Detecting Screen Reader Accessibility Errors in Mobile Apps Using Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713797},
doi = {10.1145/3706598.3713797},
abstract = {Many mobile apps are inaccessible, thereby excluding people from their potential benefits. Existing rule-based accessibility checkers aim to mitigate these failures by identifying errors early during development but are constrained in the types of errors they can detect. We present ScreenAudit, an LLM-powered system designed to traverse mobile app screens, extract metadata and transcripts, and identify screen reader accessibility errors overlooked by existing checkers. We recruited six accessibility experts including one screen reader user to evaluate ScreenAudit’s reports across 14 unique app screens. Our findings indicate that ScreenAudit achieves an average coverage of 69.2\%, compared to only 31.3\% with a widely-used accessibility checker. Expert feedback indicated that ScreenAudit delivered higher-quality feedback and addressed more aspects of screen reader accessibility compared to existing checkers, and that ScreenAudit would benefit app developers in real-world settings.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1163},
numpages = {19},
keywords = {Mobile accessibility, large language models, accessibility audit.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714008,
author = {Flores-Saviaga, Claudia and Hanrahan, Benjamin V. and Imteyaz, Kashif and Clarke, Steven and Savage*, Saiph},
title = {The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714008},
doi = {10.1145/3706598.3714008},
abstract = {The rapid adoption of generative AI in software development has impacted the industry, yet its effects on developers with visual impairments remain largely unexplored. To address this gap, we used an Activity Theory framework to examine how developers with visual impairments interact with AI coding assistants. For this purpose, we conducted a study where developers who are visually impaired completed a series of programming tasks using a generative AI coding assistant. We uncovered that, while participants found the AI assistant beneficial and reported significant advantages, they also highlighted accessibility challenges. Specifically, the AI coding assistant often exacerbated existing accessibility barriers and introduced new challenges. For example, it overwhelmed users with an excessive number of suggestions, leading developers who are visually impaired to express a desire for “AI timeouts.” Additionally, the generative AI coding assistant made it more difficult for developers to switch contexts between the AI-generated content and their own code. Despite these challenges, participants were optimistic about the potential of AI coding assistants to transform the coding experience for developers with visual impairments. Our findings emphasize the need to apply activity-centered design principles to generative AI assistants, ensuring they better align with user behaviors and address specific accessibility needs. This approach can enable the assistants to provide more intuitive, inclusive, and effective experiences, while also contributing to the broader goal of enhancing accessibility in software development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1164},
numpages = {17},
keywords = {generative ai, accessibility, ai coding assistants, assistive technology},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713634,
author = {Perera, Minoli and Ananthanarayan, Swamy and Goncu, Cagatay and Marriott, Kim},
title = {The Sky is the Limit: Understanding How Generative AI can Enhance Screen Reader Users' Experience with Productivity Applications},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713634},
doi = {10.1145/3706598.3713634},
abstract = {Productivity applications including word processors, spreadsheets, and presentation tools are crucial in work, education, and personal settings. Blind users typically access these tools via screen readers (SRs) and face significant accessibility and usability challenges. Recent advancements in Generative AI (GenAI) may address these challenges by enabling natural language interactions and contextual task understanding. However, there is limited understanding of SR users’ needs and attitudes toward GenAI assistance in these applications. We surveyed 99 SR users to gain a holistic understanding of the challenges they face when using productivity applications, the impact of these challenges on their productivity and independence, and their initial perceptions of AI assistance. Driven by their enthusiasm, we conducted interviews with 16 SR users to explore their attitudes toward GenAI and its potential usefulness in productivity applications. Our findings highlight its need to support existing SR workflows and the importance of enabling customization and task verification.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1165},
numpages = {17},
keywords = {blind, accessibility, productivity applications, assistive technology, screen readers, AI assistants, Generative AI, virtual assistants},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713364,
author = {Ge, Lily W. and Cui, Yuan and Kay, Matthew},
title = {AVEC: An Assessment of Visual Encoding Ability in Visualization Construction},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713364},
doi = {10.1145/3706598.3713364},
abstract = {Visualization literacy is the ability to both interpret and construct visualizations. Yet existing assessments focus solely on visualization interpretation. A lack of construction-related measurements hinders efforts in understanding and improving literacy in visualizations. We design and develop avec, an assessment of a person’s visual encoding ability—a core component of the larger process of visualization construction—by: (1) creating an initial item bank using a design space of visualization tasks and chart types, (2) designing an assessment tool to support the combinatorial nature of selecting appropriate visual encodings, (3) building an autograder from expert scores of answers to our items, and (4) refining and validating the item bank and autograder through an analysis of test tryout data with 95 participants and feedback from the expert panel. We discuss recommendations for using avec, potential alternative scoring strategies, and the challenges in assessing higher-level visualization skills using constructed-response tests. Supplemental materials are available at: https://osf.io/hg7kx/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1166},
numpages = {16},
keywords = {Visualization literacy, Visualization construction, Measurement},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713128,
author = {Shi, Danqing and Wang, Yao and Bai, Yunpeng and Bulling, Andreas and Oulasvirta, Antti},
title = {Chartist: Task-driven Eye Movement Control for Chart Reading},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713128},
doi = {10.1145/3706598.3713128},
abstract = {To design data visualizations that are easy to comprehend, we need to understand how people with different interests read them. Computational models of predicting scanpaths on charts could complement empirical studies by offering estimates of user performance inexpensively; however, previous models have been limited to gaze patterns and overlooked the effects of tasks. Here, we contribute Chartist, a computational model that simulates how users move their eyes to extract information from the chart in order to perform analysis tasks, including value retrieval, filtering, and finding extremes. The novel contribution lies in a two-level hierarchical control architecture. At the high level, the model uses LLMs to comprehend the information gained so far and applies this representation to select a goal for the lower-level controllers, which, in turn, move the eyes in accordance with a sampling policy learned via reinforcement learning. The model is capable of predicting human-like task-driven scanpaths across various tasks. It can be applied in fields such as explainable AI, visualization design evaluation, and optimization. While it displays limitations in terms of generalizability and accuracy, it takes modeling in a promising direction, toward understanding human behaviors in interacting with charts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1167},
numpages = {14},
keywords = {User model; Simulation; Scanpath; Reinforcement learning; LLMs},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714191,
author = {Baigelenov, Ali and Shukla, Prakash and Parsons, Paul},
title = {How Visualization Designers Perceive and Use Inspiration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714191},
doi = {10.1145/3706598.3714191},
abstract = {Inspiration plays an important role in design, yet its specific impact on data visualization design practice remains underexplored. This study investigates how professional visualization designers perceive and use inspiration in their practice. Through semi-structured interviews, we examine their sources of inspiration, the value they place on them, and how they navigate the balance between inspiration and imitation. Our findings reveal that designers draw from a diverse array of sources, including existing visualizations, real-world phenomena, and personal experiences. Participants describe a mix of active and passive inspiration practices, often iterating on sources to create original designs. This research offers insights into the role of inspiration in visualization practice, the need to expand visualization design theory, and the implications for the development of visualization tools that support inspiration and for training future visualization designers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1168},
numpages = {13},
keywords = {Information Visualization, Inspiration, Design Fixation, Design Cognition, Design Practice, Design Process},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713769,
author = {Zhao, Yue and Wang, Yunhai and Luo, Xu and Wang, Yanyan and Fekete, Jean-Daniel},
title = {Libra: An Interaction Model for Data Visualization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713769},
doi = {10.1145/3706598.3713769},
abstract = {While existing visualization libraries enable the reuse, extension, and combination of static visualizations, achieving the same for interactions remains nearly impossible. Therefore, we contribute an interaction model and its implementation to achieve this goal. Our model enables the creation of interactions that support direct manipulation, enforce software modularity by clearly separating visualizations from interactions, and ensure compatibility with existing visualization systems. Interaction management is achieved through an instrument that receives events from the view, dispatches these events to graphical layers containing objects, and then triggers actions. We present a JavaScript prototype implementation of our model called Libra.js, enabling the specification of interactions for visualizations created by different libraries. We demonstrate the effectiveness of Libra by describing and generating a wide range of existing interaction techniques. We evaluate Libra.js through diverse examples, a metric-based notation comparison, and a performance benchmark analysis.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1169},
numpages = {17},
keywords = {Information visualization, interaction, software modularity, direct manipulation, undo/redo},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713487,
author = {Batziakoudi, Katerina and Cabric, Florent and Rey, St\'{e}phanie and Fekete, Jean-Daniel},
title = {Lost in Magnitudes: Exploring Visualization Designs for Large Value Ranges},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713487},
doi = {10.1145/3706598.3713487},
abstract = {We explore the design of visualizations for values spanning multiple orders of magnitude; we call them Orders of Magnitude Values (OMVs). Visualization researchers have shown that separating OMVs into two components, the mantissa and the exponent, and encoding them separately overcomes limitations of linear and logarithmic scales. However, only a small number of such visualizations have been tested, and the design guidelines for visualizing the mantissa and exponent separately remain under-explored. To initiate this exploration, better understand the factors influencing the effectiveness of these visualizations, and create guidelines, we adopt a multi-stage workflow. We introduce a design space for visualizing mantissa and exponent, systematically generating and qualitatively evaluating all possible visualizations within it. From this evaluation, we derive guidelines. We select two visualizations that align with our guidelines and test them using a crowdsourcing experiment, showing they facilitate quantitative comparisons and increase confidence in interpretation compared to the state-of-the-art.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1170},
numpages = {18},
keywords = {design space, visualization, static, overview, orders of magnitude, mantissa, exponent},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713955,
author = {Long, Sheng and Chatzimparmpas, Angelos and Alexander, Emma and Kay, Matthew and Hullman, Jessica},
title = {Seeing Eye to AI? Applying Deep-Feature-Based Similarity Metrics to Information Visualization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713955},
doi = {10.1145/3706598.3713955},
abstract = {Judging the similarity of visualizations is crucial to various applications, such as visualization-based search and visualization recommendation systems. Recent studies show deep-feature-based similarity metrics correlate well with perceptual judgments of image similarity and serve as effective loss functions for tasks like image super-resolution and style transfer. We explore the application of such metrics to judgments of visualization similarity. We extend a similarity metric using five ML architectures and three pre-trained weight sets. We replicate results from previous crowdsourced studies on scatterplot and visual channel similarity perception. Notably, our metric using pre-trained ImageNet weights outperformed gradient-descent tuned MS-SSIM, a multi-scale similarity metric based on luminance, contrast, and structure. Our work contributes to understanding how deep-feature-based metrics can enhance similarity assessments in visualization, potentially improving visual analysis tools and techniques. Supplementary materials are available at https://osf.io/dj2ms/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1171},
numpages = {20},
keywords = {evaluation, similarity perception, replication studies, deep-feature-based similarity metrics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714070,
author = {Meng, Zhiyuan and Yang, Yunpeng and Zeng, Qiong and Lu, Kecheng and Lu, Lin and Tu, Changhe and Yang, Fumeng and Wang, Yunhai},
title = {Seeing Through the Overlap: The Impact of Color and Opacity on Depth Order Perception in Visualization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714070},
doi = {10.1145/3706598.3714070},
abstract = {Semi-transparent visualizations are commonly used to reveal information in overlapped regions by applying colors and opacity. While a few studies made recommendations on how to choose colors and opacity levels to maintain depth perception, they often conflict and overlook the interaction effect between these factors. In this paper, we systematically explore the impact of color and opacity on depth order perception across eight colors, three opacity levels, and various layer orders and arrangements. Our inferential analysis shows that both color hue and opacity significantly influence depth order perception, with the effectiveness depending on their interaction. We also derived 12 features for predictive analysis, achieving the best mean accuracy of 80.72\% and mean F1 score of 87.75\%, with opacity assigned to the front layer as the top feature for most models. Finally, we provide a small design tool and four guidelines to better align the design rules of colors and opacity in semi-transparent visualizations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1172},
numpages = {14},
keywords = {Color Design, Opacity, Depth Order Perception, Semi-Transparent Visualization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714400,
author = {Chen, Mengyu and Yang, Andrew and Min, Seungchan and Hamilton, Kristy A and Wall, Emily},
title = {A Novel Lens on Metacognition in Visualization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714400},
doi = {10.1145/3706598.3714400},
abstract = {Metacognition, or the awareness and regulation of one’s own cognitive processes, allows individuals to take command of their learning and decision making in various contexts. In tasks that require problem-solving and adaptive learning, individuals with heightened metacognitive awareness tend to outperform others, as they are better equipped to regulate cognition, leading to more effective processes. On the other hand, visualization research facilitates exploration and decision making with data. We posit that metacognitive frameworks that examine how individuals think about their own thinking processes can likewise enhance visualization processes. In this paper, we review metacognition literature from the cognitive and learning science to identify opportunities in visualization to improve people’s ability to reason with data. We propose the use of a metacognitive framework, serving as a starting point to inspire future research to improve visualization practices and outcomes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1173},
numpages = {16},
keywords = {Visualization, Metacognition},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713693,
author = {Chen, Yuexi and Xiao, Yimin and Zinat, Kazi Tasnim and Yamashita, Naomi and Gao, Ge and Liu, Zhicheng},
title = {Comparing Native and Non-native English Speakers' Behaviors in Collaborative Writing through Visual Analytics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713693},
doi = {10.1145/3706598.3713693},
abstract = {Understanding collaborative writing dynamics between native speakers (NS) and non-native speakers (NNS) is critical for enhancing collaboration quality and team inclusivity. In this paper, we partnered with communication researchers to develop visual analytics solutions for comparing NS and NNS behaviors in 162 writing sessions across 27 teams. The primary challenges in analyzing writing behaviors are data complexity and the uncertainties introduced by automated methods. In response, we present COALA, a novel visual analytics tool that improves model interpretability by displaying uncertainties in author clusters, generating behavior summaries using large language models, and visualizing writing-related actions at multiple granularities. We validated the effectiveness of COALA through user studies with domain experts (N=2+2) and researchers with relevant experience (N=8). We present the insights discovered by participants using COALA, suggest features for future AI-assisted collaborative writing tools, and discuss the broader implications for analyzing collaborative processes beyond writing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1174},
numpages = {16},
keywords = {Collaborative writing, non-native speakers, event sequence analysis, human-AI interaction, collaboration, large language models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713831,
author = {Li, Shiyao and Davidson, Thomas James and Xiong Bearfield, Cindy and Wall, Emily},
title = {Confirmation Bias: The Double-Edged Sword of Data Facts in Visual Data Communication},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713831},
doi = {10.1145/3706598.3713831},
abstract = {Incorporating data facts, which are natural language descriptions of data patterns, alongside visualizations can guide readers and enhance the visibility of data patterns. However, data facts might also induce confirmation bias in visual analysis. We conducted a series of crowdsourced experiments to explore the biasing effects of data facts. Our findings show that the presentation style, strength, and alignment of data facts with pre-existing beliefs significantly impact confirmation bias. Data facts that support prior beliefs can exacerbate confirmation bias, whereas those that refute an individual’s beliefs can mitigate it. This effect is amplified when data facts are used in combination with visual annotations. Data facts describing variable correlations are perceived to be more compelling than ones describing average values and are associated with higher levels of confirmation bias. We underscore the persuasive influence of data facts in visualizations and caution against their indiscriminate use in efforts to mitigate bias.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1175},
numpages = {16},
keywords = {confirmation bias, data visualization, data facts, annotation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713212,
author = {Offenhuber, Dietmar and Perovich, Laura J and Rogowitz, Bernice},
title = {Data at Hand: Exploring the Tactile Perception of Data Physicalizations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713212},
doi = {10.1145/3706598.3713212},
abstract = {Data physicalizations are tangible objects, and touching them may improve their interpretation. However, little is known about how people actually touch physicalizations. We recorded verbal and tactile responses to data physicalizations in three consecutive conditions: as an unspecified object, as a representation of unknown data, and with full information about data and encoding. Our two stimulus objects present data for nine countries in a 3x3 grid. We varied vertical axis polarity, with positive data values either above (convex) or below (concave) baseline. Using an analog tracer method, we examine whether some components of the physicalization are touched more than others, whether touch varies by task and the impact of axis polarity. We found large differences in the degree to which different components were touched and that the effect of vertical axis polarity depended on task. We describe additional tactile and verbal behaviors that can inform the design of data physicalizations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1176},
numpages = {15},
keywords = {data physicalization, tactile behavior, touch},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713096,
author = {Bancilhon, Melanie and Ottley, Alvitta and Jordan, Andrew},
title = {The Anatomy of a Plea: How Uncertainty, Visualizations \&amp; Individual Differences Shape Plea Bargain Decisions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713096},
doi = {10.1145/3706598.3713096},
abstract = {Plea bargains are commonly used in the criminal justice system, where they can offer potential benefits to both the prosecution and the defendant. However, research has shown that defendants often engage in poor decision-making, such as accepting the plea even when the trial sentence is likely to be less severe. While previous studies have shown some evidence that uncertainty visualizations can improve decision-making, there is a lack of research on their effectiveness in domain-specific tasks like plea bargain decision-making. In this work, we conduct a series of experiments to explore whether the presence and format of uncertainty impact plea bargain decisions, taking into account time pressure and individual differences. Our findings reveal that these factors can have a significant impact on plea bargain decisions. We also show evidence that communicating uncertainty in the form of text can elicit more optimal decisions under time-pressure conditions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1177},
numpages = {18},
keywords = {Plea Bargain, Uncertainty Visualizations, Decision-Making, Criminal Justice, Individual Differences, Time Pressure},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713425,
author = {Chen, Shanshan and Hu, Jun and van Iterson, Hannah Christina and Fang, Ning and Markopoulos, Panos},
title = {"Did you sleep well?": A Multimodal Sleep Diary for Sustained Self-Reporting by Children},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713425},
doi = {10.1145/3706598.3713425},
abstract = {Sleep diaries are essential self-reporting tools for understanding children’s sleep patterns, but maintaining sustained engagement and high-quality self-reporting remains challenging. While voice input has been explored in child-computer interaction research as a method to improve engagement, limited evidence exists regarding its effectiveness in supporting sustained self-reporting over time. To address this gap, we conducted a five-day field study with 20 children aged seven to twelve, using a multimodal sleep diary that integrated both voice and text input modalities. Our findings reveal that voice input significantly supports younger children in maintaining engagement over five days, though their response quality remains lower than that of older children. Two distinct response quality patterns over time also emphasize the importance of accounting for individual differences in task performance. Furthermore, input modality preferences varied by age: older children consistently favored text input, while younger children generally preferred voice input over time. These results highlight the potential of incorporating voice input into text-based sleep diaries to better accommodate the diverse needs of children, enhancing both sustained engagement and response quality. Future studies with longer observation periods are needed to validate and extend these findings.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1178},
numpages = {17},
keywords = {Multimodal interface, Children, Sleep diary, Engagement, Response quality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713844,
author = {Davis, Katie and Landesman, Rotem and Yoon, Jina and Kim, JaeWon and Munoz Lopez, Daniela E and Magis-Weinberg, Lucia and Hiniker, Alexis},
title = {"You Go Through So Many Emotions Scrolling Through Instagram": How Teens Use Instagram To Regulate Their Emotions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713844},
doi = {10.1145/3706598.3713844},
abstract = {Prior work has documented various ways that teens use social media to regulate their emotions. However, little is known about what these processes look like on a moment-by-moment basis. We conducted a diary study to investigate how teens (N=57, Mage= 16.3 years) used Instagram to regulate their emotions. We identified three kinds of emotionally-salient drivers that brought teens to Instagram and two types of behaviors that impacted their emotional experiences on the platform. Teens described going to Instagram to escape, to engage, and to manage the demands of the platform. Once on Instagram, their primary behaviors consisted of mindless diversions and deliberate acts. Although teens reported many positive emotional responses, the variety, unpredictability, and habitual nature of their experiences revealed Instagram to be an unreliable tool for emotion regulation (ER). We present a model of teens’ ER processes on Instagram and offer design considerations for supporting adolescent emotion regulation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1179},
numpages = {16},
keywords = {Adolescents, Social Media, Digital Emotion Regulation, Design For Well-Being},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713868,
author = {Chung, Ji Won and Yuan, Robin and Zitting, Kirsi-Marja and Chen, Jiahua and Xu, Neil and Daskalova, Nediyana and Huang, Jeff},
title = {Beyond the Circadian Rhythm: Variable Cycles of Regularity Found in Long-Term Sleep Tracking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713868},
doi = {10.1145/3706598.3713868},
abstract = {Sleep is more than resting eight hours a day—it contextualizes and shapes the routines during the day. Using a large-scale naturalistic dataset of 180,083 people from a popular sleep app, made possible by the widespread adoption of passive tracking, we find that people’s lives have distinct natural rhythms that can be automatically inferred from sleep routines. We discover heterogeneous behaviors: the rhythm of sleep is different for each person, as there is a different cadence for each person to achieve consistency. Some are most consistent week-to-week, while others weeks-to-weeks. We investigate changes in overall daily routines and find the interval for each person at which they show the most consistency. Through a series of comparative case analyses, we investigate the implications of designing for the weekly ‘norm’. Our tripartite analyses triangulate to one conclusion: we should design for people’s natural routines to account for variable cycles of regularity.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1180},
numpages = {18},
keywords = {routine management, longitudinal study, behavioral regularity, sleep regularity, naturalistic study, personal informatics, design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713888,
author = {Kim, Minseo and Kim, Taemin and Vo, Thu Hoang Anh and Jung, Yugyeong and Lee, Uichin},
title = {Exploring Modular Prompt Design for Emotion and Mental Health Recognition},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713888},
doi = {10.1145/3706598.3713888},
abstract = {Recent advances in large language models (LLM) offered human-like capabilities for comprehending emotion and mental states. Prior studies explored diverse prompt engineering techniques for improving classification performance, but there is a lack of analysis of prompt design space and the impact of each component. To bridge this gap, we conduct a qualitative thematic analysis of existing prompts for emotion and mental health classification tasks to define the key components for prompt design space. We then evaluate the impact of major prompt components, such as persona and task instruction, on classification performance by using four LLM models and five datasets. Modular prompt design offers new insights into examining performance variability as well as promoting transparency and reproducibility in LLM-based tasks within health and well-being intervention systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1181},
numpages = {18},
keywords = {Large language model, prompt engineering, emotion, mental health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714086,
author = {Le, Ha and Potter, Veronika and Lakshminarayanan, Rithika and Mishra, Varun and Intille, Stephen},
title = {Feasibility and Utility of Multimodal Micro Ecological Momentary Assessment on a Smartwatch},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714086},
doi = {10.1145/3706598.3714086},
abstract = {μ EMAs allow participants to answer a short survey quickly with a tap on a smartwatch screen or a brief speech input. The short interaction time and low cognitive burden enable researchers to collect self-reports at high frequency (once every 5-15 minutes) while maintaining participant engagement. Systems with single input modality, however, may carry different contextual biases that could affect compliance. We combined two input modalities to create a multimodal-μ EMA system, allowing participants to choose between speech or touch input to self-report. To investigate system usability, we conducted a seven-day field study where we asked 20 participants to label their posture and/or physical activity once every five minutes throughout their waking day. Despite the intense prompting interval, participants responded to 72.4\% of the prompts. We found participants gravitated towards different modalities based on personal preferences and contextual states, highlighting the need to consider these factors when designing context-aware multimodal μ EMA systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1182},
numpages = {22},
keywords = {Ecological momentary assessment, Experience sampling, Ubiquitous computing; Wearable computing; Speech input; Touch input; Multimodal input},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713875,
author = {Silva, Lucas M. and Lu, Xi and Liang, Emily X. and Epstein, Daniel A.},
title = {Foody Talk: Exploring Opportunities for Conversational Food Journaling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713875},
doi = {10.1145/3706598.3713875},
abstract = {Digital food journaling can help support reflection and improvement of wellbeing relating to eating habits. However, it is often viewed as burdensome, and abandoned before gaining benefits. Advances in conversational user interfaces (CUIs) have the potential to support people journaling in a natural and interactive manner, but we lack understanding of how people would ideally prefer to use CUIs when journaling. We conducted 33 co-design sessions with 18 participants to ideate CUI interactions supportive of their health goals and in everyday situations. Our findings reveal that participants expect CUIs to be adaptive by learning goals and personal references, and support depth in detail and goal alignment while respecting situational constraints and intent. While participants expressed concern around navigating long-term data solely through conversations, they envisioned that CUIs could provide empathetic, non-judgmental feedback. We discuss opportunities for CUIs to support empathetic food journaling and accountability while following guardrails for delegated tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1183},
numpages = {19},
keywords = {Conversational User Interfaces, Personal Informatics, Food Tracking, Co-Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714089,
author = {Hudig, Anna Ida and Singh, Jatinder},
title = {Intimate Data Sharing: Enhancing Transparency and Control in Fertility Tracking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714089},
doi = {10.1145/3706598.3714089},
abstract = {Fertility trackers are popular for self-monitoring menstrual cycles and managing other aspects of reproductive or sexual health. However, the intimate nature of fertility tracking raises particular concerns about potential data (mis)use. Our study deepens understandings of fertility tracker data sharing and presents co-created mechanisms to enhance user agency over their data in intimate contexts. To achieve this, we first analysed the network transmissions from eight fertility tracker products, observing that many data transmissions appear to be tied to particular uses of the tracker and that the products communicate with endpoints associated with various organisations across different countries. This raises concerns about how intimate data is governed, used, and shared. To understand user attitudes towards data sharing in intimate contexts, we then conducted a survey exploring factors influencing user data sharing preferences. Our findings reveal that users desire transparency and control mechanisms and that their willingness to share data is influenced by contextual factors, including the third parties involved, the purposes of data collection, and the sensitivity of the data. Building on these findings, we worked with users to co-design ten concrete mechanisms for enhancing data transparency and control throughout fertility tracker product usage lifecycles. In all, our mixed-method study provides an in-depth understanding of fertility tracker data flows and preferences and proposes actionable mechanisms designers can utilise to support and protect data rights in intimate data ecosystems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1184},
numpages = {24},
keywords = {fertility trackers, intimate data, data sharing, transparency, control, design interventions, privacy, data governance, wearables, connected devices, participatory design, mobile apps},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713732,
author = {Jin, Seungwan and Kim, Bogoan and Han, Kyungsik},
title = {"I Don't Know Why I Should Use This App": Holistic Analysis on User Engagement Challenges in Mobile Mental Health},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713732},
doi = {10.1145/3706598.3713732},
abstract = {Over the past decade, mobile apps have been widely adopted as a digital intervention method for mental health support, offering scalable and accessible solutions to address the growing global mental health challenges. However, sustaining user engagement in real-world settings remains a major challenge in the development of these applications. This study systematically examines factors that hinder user engagement in existing mobile mental health support systems through a scoping review of the literature. After an initial identification of 1,267 papers, we conducted a final analysis of 111 empirical studies using mobile app-based mental health support systems. The study investigates the main factors that negatively affect user engagement from user and system perspectives. Based on these findings, we propose guidelines for sustaining and enhancing user engagement and for structuring personalized emotional interaction design along three dimensions: adaptive, continuous, and multimodal interactions. Furthermore, we discuss the potential for integration with advanced AI methods (e.g., LLM-based generative AI agents) as a way to achieve these design implications and suggestions. Our results provide critical insights for enhancing long-term user engagement in the development of future mental health support systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1185},
numpages = {23},
keywords = {mental health apps, user engagement, scoping review, large language model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713481,
author = {Adler, Daniel A. and Yang, Yuewen and Viranda, Thalia and Van Meter, Anna R. and McGinty, Emma Elizabeth and Choudhury, Tanzeem},
title = {Designing Technologies for Value-based Mental Healthcare: Centering Clinicians' Perspectives on Outcomes Data Specification, Collection, and Use},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713481},
doi = {10.1145/3706598.3713481},
abstract = {Health information technologies are transforming how mental healthcare is paid for through value-based care programs, which tie payment to data quantifying care outcomes. But, it is unclear what outcomes data these technologies should store, how to engage users in data collection, and how outcomes data can improve care. Given these challenges, we conducted interviews with 30 U.S.-based mental health clinicians to explore the design space of health information technologies that support outcomes data specification, collection, and use in value-based mental healthcare. Our findings center clinicians’ perspectives on aligning outcomes data for payment programs and care; opportunities for health technologies and personal devices to improve data collection; and considerations for using outcomes data to hold stakeholders including clinicians, health insurers, and social services financially accountable in value-based mental healthcare. We conclude with implications for future research designing and developing technologies supporting value-based care across stakeholders involved with mental health service delivery.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1186},
numpages = {21},
keywords = {health information technology; mental health; user-centered design; health services; implementation science; value-based care; qualitative research; passive sensing; digital phenotyping; digital biomarkers; digital mental health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713537,
author = {Claisse, Caroline and Osborne, Alison K and Sillence, Elizabeth and Glascott, Angela and Cameron, Alisdair S and Durrant, Abigail C},
title = {Exploring Alternative Socio-Technical Systems for Careful Data Work in Recovery Contexts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713537},
doi = {10.1145/3706598.3713537},
abstract = {Non-profits such as voluntary and community-based (VC) organisations are facing increasing pressures to engage in data work to sustain themselves. They face challenges with practices, information systems and tools associated with capturing data for supporting service provision. Most recently, researchers working with VC organisations have turned to Feminist and Care discourses to envision alternatives to current socio-technical systems whereby their values and purposes do not match with those of non-profits, consequently pulling the latter away from their socially driven mission. We report on a longitudinal, collaborative study with a UK-based mental health peer support organisation that created innovative tools as a means of navigating current pressures to practice data work for the quantification of mental health service provision. We present findings from interviews conducted with our community partner and share how recovery work has informed careful data practices, offering recommendations for supporting data work in mental health recovery.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1187},
numpages = {17},
keywords = {Community, Data, Data work, Mental health, Voluntary organisations, care},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714208,
author = {Jang, Sueun and Seo, Youngseok and Choi, Woohyeok and Lee, Uichin},
title = {Like Adding a Small Weight to a Scale About to Tip: Personalizing Micro-Financial Incentives for Digital Wellbeing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714208},
doi = {10.1145/3706598.3714208},
abstract = {Personalized behavior change interventions can be effective as they dynamically adapt to an individual’s context. Financial incentives, a commonly used intervention in commercial applications and policy-making, offer a mechanism for creating personalized micro-interventions that are both quantifiable and amenable to systematic evaluation. However, the effectiveness of such personalized micro-financial incentives in real-world settings remains largely unexplored. In this study, we propose a personalization strategy that dynamically adjusts the amount of micro-financial incentives to promote smartphone use regulation and explore its efficacy and user experience through a four-week, in-the-wild user study. The results demonstrate that the proposed method is highly cost-effective without compromising intervention effectiveness. Based on these findings, we discuss the role of micro-financial incentives in enhancing awareness, design considerations for personalized micro-financial incentive systems, and their potential benefits and limitations concerning motivation change.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1188},
numpages = {19},
keywords = {digital wellbeing, micro-intervention, micro-financial incentive, behavior change, personalization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713650,
author = {Loerakker, Meagan B. and Jarsve, Tora and Niess, Jasmin and Wo\'{z}niak, Pawe\l{} W.},
title = {The Framework of the Lived Experience of Metrics: Understanding the Purposes and Activities of Self-Tracking Metrics},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713650},
doi = {10.1145/3706598.3713650},
abstract = {Most studies of Personal Informatics (PI) focus on the holistic experience of self-tracking or how users relate to self-tracking goals. Recently, new tracker metrics became available in commercial systems, e.g. stress scores or body battery. Hence, more attention should be devoted to what users track and how they understand metrics produced by their trackers. Charting the evolution of metrics in PI can enable building systems that better support well-being. To this end, we interviewed n = 25 fitness tracker users to discover what metrics are most important to them, how they understand the metrics, and how they formulate their goals with respect to the metrics. We found that users created a metric ecology which they adjusted to their life circumstances, reformulating their goals. We identified key issues in understanding metrics which bear the risk of misuse. We contribute recommendations for future PI systems as self-tracking metrics increase in complexity.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1189},
numpages = {20},
keywords = {Personal informatics, lived experience of metrics framework, fitness trackers, self-tracking purposes, self-tracking activities, PI journey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713143,
author = {Cheng, Nai-Yu and Wong, Novia and Reddy, Madhu},
title = {Understanding Mental Wellbeing and Tools for Support with Taiwanese Emerging Adults: An Eastern Cultural Perspective},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713143},
doi = {10.1145/3706598.3713143},
abstract = {Mental wellbeing has become a crucial aspect of overall health and has drawn increased attention to mental health concerns. Research in human-computer interaction (HCI) has explored how technologies can support mental wellbeing and address mental health issues. However, current research predominantly reflects Western cultural perspectives, leaving gaps in our understanding of mental wellbeing, coping strategies, and digital tools for mental wellbeing support from Eastern cultural viewpoints. To start to address this disparity, we interviewed 19 Taiwanese emerging adults aged between 18 and 29—a demographic uniquely susceptible to mental health challenges due to the transitional nature of this life phase. We explored their conceptualization of mental wellbeing, the challenges they encounter, the strategies they employ for managing mental wellbeing, and the role of digital tools in this process. The results highlight the intricate influence of cultural, political, social, and individual factors, and their interactions on mental wellbeing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1190},
numpages = {18},
keywords = {Digital Mental Health, Eastern Cultures, Health-Wellbeing, Interviews},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713197,
author = {Louie, Julianne and Mukund, Tara and Vu, Chau and Epstein, Daniel A. and Papoutsaki, Alexandra},
title = {Understanding Temporality of Reflection in Personal Informatics through Baby Tracking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713197},
doi = {10.1145/3706598.3713197},
abstract = {Personal informatics literature has examined reflection in tracking, but there are gaps in our understanding of how self-initiated reflection that one engages in shortly after data collection has taken place occurs in everyday life and how technology can best support it. We use baby tracking as a case study to explore ‘temporality,’ the time over which reflection occurs relative to data collection, as caregivers track their baby’s well-being over both short-term and long-term. We interviewed 20 parents in the U.S. who used baby-tracking technology. We find that parents ask different questions based on the time elapsed since data collection, such as checking alignment with medical guidance and prior patterns immediately after tracking or augmenting memory when reflecting hours later. We summarize these findings into a framework for short-term reflection in baby tracking that includes three windows: the immediate, in-between, and cumulative. We use these windows to identify helpful design patterns in baby-tracking technologies toward supporting temporally meaningful reflection and opportunities for further study in other self-tracking domains.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1191},
numpages = {18},
keywords = {personal informatics, reflection, tracking, temporality, baby tracking},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714219,
author = {Zheng, Qingxiao and Chen, Minrui and Park, Hyanghee and Xu, Zhongwei and Huang, Yun},
title = {Evaluating Non-AI Experts' Interaction with AI: A Case Study In Library Context},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714219},
doi = {10.1145/3706598.3714219},
abstract = {Public libraries in the U.S. are increasingly facing labor shortages, tight budgets, and overworked staff, creating a pressing need for conversational agents to assist patrons. The democratization of generative AI has empowered public service professionals to develop AI agents by leveraging large language models. To understand the needs of non-AI library professionals in creating their own conversational agents, we conducted semi-structured interviews with library professionals (n=11) across the U.S. Insights from these interviews informed the design of AgentBuilder, a prototype tool that enables non-AI experts to create conversational agents without coding skills. We then conducted think-aloud sessions and follow-up interviews to evaluate the prototype experience and identify the key evaluation criteria emphasized by library professionals (n=12) when developing conversational agents. Our findings highlight how these professionals perceive the prototype experience and reveal five essential evaluation criteria: interpreting user intent, faithful paraphrasing, proper alignment with authoritative sources, tailoring the tone of voice, and handling unknown answers effectively. These insights provide valuable guidance for designing AI-supported "end-user creation tools" in public service domains beyond libraries.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1192},
numpages = {20},
keywords = {End-User AI Creation Tool, User Experience, Large language models, Generative AI, Public Service},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713133,
author = {Li, Zhuoyan and Zhu, Hangxiao and Lu, Zhuoran and Xiao, Ziang and Yin, Ming},
title = {From Text to Trust: Empowering AI-assisted Decision Making with Adaptive LLM-powered Analysis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713133},
doi = {10.1145/3706598.3713133},
abstract = {AI-assisted decision making becomes increasingly prevalent, yet individuals often fail to utilize AI-based decision aids appropriately especially when the AI explanations are absent, potentially as they do not reflect on AI’s decision recommendations critically. Large language models (LLMs), with their exceptional conversational and analytical capabilities, present great opportunities to enhance AI-assisted decision making in the absence of AI explanations by providing natural-language-based analysis of AI’s decision recommendation, e.g., how each feature of a decision making task might contribute to the AI recommendation. In this paper, via a randomized experiment, we first show that presenting LLM-powered analysis of each task feature, either sequentially or concurrently, does not significantly improve people’s AI-assisted decision performance. To enable decision makers to better leverage LLM-powered analysis, we then propose an algorithmic framework to characterize the effects of LLM-powered analysis on human decisions and dynamically decide which analysis to present. Our evaluation with human subjects shows that this approach effectively improves decision makers’ appropriate reliance on AI in AI-assisted decision making.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1193},
numpages = {18},
keywords = {AI-assisted decision making, Explainable AI, Large language model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713814,
author = {Winecoff, Amy and Bogen, Miranda},
title = {Improving Governance Outcomes Through AI Documentation: Bridging Theory and Practice},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713814},
doi = {10.1145/3706598.3713814},
abstract = {Documentation plays a crucial role in both external accountability and internal governance of AI systems. Although there are many proposals for documenting AI data, models, systems, and methods, the ways these practices enhance governance as well as the challenges practitioners and organizations face with documentation remain underexplored. In this paper, we analyze 37 proposed documentation frameworks and 22 empirical studies evaluating their use. We identify several pathways or "theories of change" through which documentation can enhance governance, including informing stakeholders about AI risks and applications, facilitating collaboration, encouraging ethical deliberation, and supporting best practices. However, empirical findings reveal significant challenges for practitioners, such as insufficient incentives and resources, structural and organizational communication barriers, interpersonal and organizational constraints to ethical action, and poor integration with existing workflows. These challenges often hinder the realization of the possible benefits of documentation. We also highlight key considerations for organizations when designing documentation, such as determining the appropriate level of detail and balancing automation in the process. We conclude by discussing how future research can expand on our findings such as by exploring documentation approaches that support governance of general-purpose models and how multiple transparency and documentation methods can collectively improve governance outcomes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1194},
numpages = {18},
keywords = {Artificial intelligence, documentation, AI governance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714319,
author = {He, Zeyu and Naphade, Saniya and Huang, Ting-Hao Kenneth},
title = {Prompting in the Dark: Assessing Human Performance in Prompt Engineering for Data Labeling When Gold Labels Are Absent},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714319},
doi = {10.1145/3706598.3714319},
abstract = {Millions of users prompt large language models (LLMs) for various tasks, but how good are people at prompt engineering? Do users actually get closer to their desired outcome over multiple iterations of their prompts? These questions are crucial when no gold-standard labels are available to measure progress. This paper investigates a scenario in LLM-powered data labeling, “prompting in the dark,” where users iteratively prompt LLMs to label data without using manually-labeled benchmarks. We developed PromptingSheet, a Google Sheets add-on that enables users to compose, revise, and iteratively label data through spreadsheets. Through a study with 20 participants, we found that prompting in the dark was highly unreliable—only 9 participants improved labeling accuracy after four or more iterations. Automated prompt optimization tools like DSPy also struggled when few gold labels were available. Our findings highlight the importance of gold labels and the needs, as well as the risks, of automated support in human prompt engineering, providing insights for future tool design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1195},
numpages = {33},
keywords = {Data Annotation; Data Labeling; Large Language Model; Iterative labeling; End-User Programming},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713443,
author = {Jia, Kaiyue and Yu, Junnan},
title = {Technologies for Children's AI Learning: Design Features and Future Opportunities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713443},
doi = {10.1145/3706598.3713443},
abstract = {With the growing integration of AI into daily life, various technologies have been developed to teach children about AI. However, differences in their designs highlight the need for a thorough understanding of these tools to make the most of current technological resources and guide the effective development of future learning tools. Through a systematic search, we identified 64 different AI learning tools for children and analyzed their design features, including both static design features (i.e., presentation formats and learning content) and interactive design features (i.e., learning activity types and design features that potentially enhance the effectiveness of the activities). Our findings reveal the current trends and gaps in the design of children’s AI learning technologies. Based on these insights, we reflect on future design opportunities and provide recommendations for creating new, effective learning technologies to advance AI education for the next generations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1196},
numpages = {22},
keywords = {AI literacy, AI learning tool, Learning technology, Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714090,
author = {Xiao, Qing and Fan, Xianzhe and Simon, Felix Marvin and Zhang, Bingbing and Eslami, Motahhare},
title = {"It Might be Technically Impressive, But It's Practically Useless to us": Motivations, Practices, Challenges, and Opportunities for Cross-Functional Collaboration around AI within the News Industry},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714090},
doi = {10.1145/3706598.3714090},
abstract = {Recently, an increasing number of news organizations have integrated artificial intelligence (AI) into their workflows, leading to a further influx of AI technologists and data workers into the news industry. This has initiated cross-functional collaborations between these professionals and journalists. Although prior research has explored the impact of AI-related roles entering the news industry, there is a lack of studies on how internal cross-functional collaboration around AI unfolds between AI professionals and journalists within the news industry. Through interviews with 17 journalists, six AI technologists, and three AI workers with cross-functional experience from leading Chinese news organizations, we investigate the practices, challenges, and opportunities for internal cross-functional collaboration around AI in news industry. We first study how these journalists and AI professionals perceive existing internal cross-collaboration strategies. We explore the challenges of cross-functional collaboration and provide recommendations for enhancing future cross-functional collaboration around AI in the news industry.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1197},
numpages = {19},
keywords = {Cross-functional Collaboration, Artificial Intelligence (AI), Journalism Studies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714035,
author = {Varanasi, Rama Adithya and Wiesenfeld, Batia Mishan and Nov, Oded},
title = {AI Rivalry as a Craft: How Resisting and Embracing Generative AI Are Reshaping the Writing Profession},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714035},
doi = {10.1145/3706598.3714035},
abstract = {Generative AI (GAI) technologies are disrupting professional writing, challenging traditional practices. Recent studies explore GAI adoption experiences of creative practitioners, but we know little about how these experiences evolve into established practices and how GAI resistance alters these practices. To address this gap, we conducted 25 semi-structured interviews with writing professionals who adopted and/or resisted GAI. Using the theoretical lens of Job Crafting, we identify four strategies professionals employ to reshape their roles. Writing professionals employed GAI resisting strategies to maximize human potential, reinforce professional identity, carve out a professional niche, and preserve credibility within their networks. In contrast, GAI-enabled strategies allowed writers who embraced GAI to enhance desirable workflows, minimize mundane tasks, and engage in new AI-managerial labor. These strategies amplified their collaborations with GAI while reducing their reliance on other people. We conclude by discussing implications of GAI practices on writers’ identity and practices as well as crafting theory.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1198},
numpages = {19},
keywords = {Generative AI, genAI, writer, writing professional, author, chatGPT, job, job crafting, labor, work transformation, productivity, invisible work, rivalry},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713827,
author = {Wagman, Kelly B. and Dearing, Matthew T. and Chetty, Marshini},
title = {Generative AI Uses and Risks for Knowledge Workers in a Science Organization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713827},
doi = {10.1145/3706598.3713827},
abstract = {Generative AI could enhance scientific discovery by supporting knowledge workers in science organizations. However, the real-world applications and perceived concerns of generative AI use in these organizations are uncertain. In this paper, we report on a collaborative study with a US national laboratory with employees spanning Science and Operations about their use of generative AI tools. We surveyed 66 employees, interviewed a subset (N=22), and measured early adoption of an internal generative AI interface called Argo lab-wide. We have four findings: (1) Argo usage data shows small but increasing use by Science and Operations employees; Common current and envisioned use cases for generative AI in this context conceptually fall into either a (2) copilot or (3) workflow agent modality; and (4) Concerns include sensitive data security, academic publishing, and job impacts. Based on our findings, we make recommendations for generative AI use in science and other organizations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1199},
numpages = {17},
keywords = {generative AI, genAI, artificial intelligence, large language models, LLMs, copilot, workflow agent, agents, future of work, enterprise AI, AI for science, knowledge work, responsible AI, security},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714267,
author = {Saka, Tarini and Vakali, Kalliopi and Jenkins, Adam D G and Kokciyan, Nadin and Vaniea, Kami},
title = {Judging Phishing Under Uncertainty: How Do Users Handle Inaccurate Automated Advice?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714267},
doi = {10.1145/3706598.3714267},
abstract = {Providing accurate and actionable advice about phishing emails is challenging. The majority of advice is generic and hard to implement. Phishing emails that pass through filters and land in user inboxes are usually sophisticated and exploit differences between how humans and computers interpret emails. Therefore, users need accurate and relevant guidance to take the right action. This study investigates the effectiveness of guidance based on features extracted from emails, which even in AI-driven systems can sometimes be inaccurate, leading to poor advice. We examined three conditions: control (generic advice), perfect advice, and realistic advice, through an online survey of 489 participants on Prolific, and measured user accuracy and confidence in phishing detection with and without guidance. Our findings indicate that having advice specific to the email is more effective than generic guidance (control). Inaccuracies in the guidance can also impact user decisions and reduce detection accuracy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1200},
numpages = {18},
keywords = {Phishing; User Guidance; Security, Attack Detection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713470,
author = {Schneiders, Eike and Seabrooke, Tina and Krook, Joshua and Hyde, Richard and Leesakul, Natalie and Clos, Jeremie and Fischer, Joel E},
title = {Objection Overruled! Lay People can Distinguish Large Language Models from Lawyers, but still Favour Advice from an LLM},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713470},
doi = {10.1145/3706598.3713470},
abstract = {Large Language Models (LLMs) are seemingly infiltrating every domain, and the legal context is no exception. In this paper, we present the results of three experiments (total N&nbsp;=&nbsp;288) that investigated lay people’s willingness to act upon, and their ability to discriminate between, LLM- and lawyer-generated legal advice. In Experiment 1, participants judged their willingness to act on legal advice when the source of the advice was either known or unknown. When the advice source was unknown, participants indicated that they were significantly more willing to act on the LLM-generated advice. The result of the source unknown condition was replicated in Experiment 2. Intriguingly, despite participants indicating higher willingness to act on LLM-generated advice in Experiments 1 and 2, participants discriminated between the LLM- and lawyer-generated texts significantly above chance-level in Experiment 3. Lastly, we discuss potential explanations and risks of our findings, limitations and future work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1201},
numpages = {14},
keywords = {Large language model, LLM, legal advice, generative AI, ChatGPT},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3715019,
author = {Ankrah, Elizabeth A and Awori, Kagonya and Nyairo, Stephanie and Muchai, Mercy and Ochieng, Millicent and Kariuki, Mark and Hayes, Gillian R and O'Neill, Jacki},
title = {Social by Nature: How Socio-tecture Shapes the Work of SMBs and Considerations for Reimagining Collaborative Human-AI Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3715019},
doi = {10.1145/3706598.3715019},
abstract = {Globally, small and medium-sized businesses (SMBs) have had to adapt to rapid digital changes, a shift accelerated by the COVID-19 pandemic. In Kenya, this transition has involved a significant move towards digital management tools. While many had already experienced marked digitalization over the last few decades, they completed this work differently from their European and North American counterparts. This study explores how Kenyan SMBs continue to navigate these changes and considers the potential of Generative AI in this context. Applying the concept of socio-tecture—which emphasizes social networks, relational business practices, and employees as knowledge producers—we analyze how these elements influence SMB operations in Nairobi. We highlight how socio-tecture affects business performance and growth, and discuss how an Afro-centric strengths-based approach might offer unique opportunities and challenges with the influx of new technologies like Generative AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1202},
numpages = {19},
keywords = {SMB, Africa, Future of work, Productivity, Data Management, Data Work, Global South, Digital Transformation, Socio-tecture, Workplaces, Distributed Knowledge, Afro-Centric Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713112,
author = {Zhang, Ben Zefeng and Yang, Tianling and Miceli, Milagros and Haimson, Oliver L. and Thomas, Michaelanne},
title = {The Making of Performative Accuracy in AI Training: Precision Labor and Its Consequences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713112},
doi = {10.1145/3706598.3713112},
abstract = {Accuracy and precision are central values in the AI communities and the technology sector. This paper provides empirical evidence on the construction and organizational management of technical accuracy, demonstrating how technology companies’ preoccupation with such values leads to harm. Drawing on nine months of multi-sited ethnographic fieldwork in China, we document how AI trainers’ everyday work practices, challenges, and harms stem from clients’ demands for high levels of technical accuracy. We introduce the concept of precision labor to unpack the labor dimension of constructing and performing accuracy in AI training. This concept highlights the hidden and excessive labor required to reconcile the ambiguity and uncertainty involved in this process. We argue that precision labor offers a new lens to illuminate three critical aspects of AI training: 1) the negative health and financial impacts of hidden and excessive labor on AI workers; 2) emerging harms, including workers’ subordinate roles to machines and financial precarity; and 3) a conceptual contribution to contexts beyond AI training. This contribution re-centers arbitrariness in technical production, highlights the excessive demands of precision labor, and examines the legitimization of labor and harm. Our study also contributes to existing scholarship on the prevailing values and invisible labor in AI production, underscoring accuracy as performative rather than self-evident and unambiguous. A precision labor lens challenges the legitimacy and sustainability of relentlessly pursuing technical accuracy, raising new questions about its consequences and ethical implications. We conclude by proposing recommendations and alternative approaches to enhance worker agency and well-being.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1203},
numpages = {19},
keywords = {data work, AI training, digital labor, microwork, precision labor, ethnography, China},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713550,
author = {Chow, Kevin and McGrenere, Joanna and Fritz, Thomas and Puente, Lucas L and Massimi, Michael},
title = {Beyond the Watercooler: Designing for Computer-Mediated Self-Disclosure among Work Colleagues},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713550},
doi = {10.1145/3706598.3713550},
abstract = {Self-disclosure, the sharing of personal and professional information about yourself, can help foster and maintain working relationships. But how do computers mediate the way we self-disclose at work? We look "beyond the watercooler" to investigate computer-mediated self-disclosure (CMSD) at work. We conducted two studies: (1) a survey (n=455 knowledge workers) to understand perceptions towards disclosing various information types among colleagues, and (2) an interview study (n=12 knowledge workers) with five speculative design concepts to characterize attitudes and needs around CMSD. Study 1 indicated sharing about well-being was valuable, but that it was less familiar among remote workers compared to those in-person or hybrid. Study 1 informed the design concepts for Study 2, whose findings revealed that CMSD is a key part of workers’ socialization and should evolve alongside relationship stages. We discuss design opportunities for adaptive, intentional, and personal CMSD, along with policy implications for organizations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1204},
numpages = {21},
keywords = {self-disclosure, computer-mediated self-disclosure, remote work, online self-disclosure, colleagues, computer-mediated communication, knowledge work},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713651,
author = {Bunwaree, Teshan S. and Stawarz, Katarzyna and Collins, Philippa and Gould, Sandy J. J.},
title = {Boss is aWare—Are you? Employee Comprehension and Legal Awareness of Workplace Monitoring},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713651},
doi = {10.1145/3706598.3713651},
abstract = {Bossware, software that monitors worker activity, is a common feature of workplaces. What do workers know about these tools and how they relate to their rights at work? We explored this question through two studies. Study 1 surveyed 100 workers to assess their understanding of work monitoring terminology. Participants were confident in their knowledge of key terms but struggled to accurately define them. Study 2 explored awareness of legal protection in relation to work monitoring through 19 semi-structured online interviews. We found that awareness varied with industry and work role, but was generally low and lacked certainty. Participants were largely skeptical of the use of bossware, questioning its necessity. Limited knowledge of monitoring terminology and legal protection at work further weakens workers’ ability to notice and challenge the use of monitoring tools in their workplaces. We finish by speculating on whether educating workers about bossware and workplace rights would help.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1205},
numpages = {19},
keywords = {bossware, work monitoring, surveillance, tracking, privacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713625,
author = {Han, Dongjun and Chen, Pingting and Sun, Yutong and Zhang, Xiaoyu and Ren, Xipei},
title = {DistKey: Incorporating Physical Activities into Daily Workflow through Spatially Distributed Hotkeys},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713625},
doi = {10.1145/3706598.3713625},
abstract = {It is important to motivate healthy behaviors, especially in office environments. However, there are few systems which integrate physical engagement mechanisms in such environments. This paper presents the design and evaluation of DistKey, a set of hotkeys allocated in different spatial interfaces of the workspace, enabling users to engage in some office tasks through intentional body movements. Through a within-subject experiment with 20 office workers, we compared DistKey with a traditional keyboard to assess the health benefits and effectiveness of integrating exercise into the workflow. Our results confirmed the benefits of DistKey-led healthful interactions in enhancing physical health and reducing mental stress during different tasks at work. Based on our follow-up qualitative research, a range of design insights are discussed to enlighten the design and development of future healthful spatial interfaces for increased office vitality.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1206},
numpages = {17},
keywords = {Proactive health behaviors, exergame-based human-spatial interaction, integration of physical activity into daily workflow, spatially distributed work method},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714100,
author = {Zhang, Angie and Lee, Min Kyung},
title = {Knowledge Workers' Perspectives on AI Training for Responsible AI Use},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714100},
doi = {10.1145/3706598.3714100},
abstract = {AI expansion has accelerated workplace adoption of new technologies. Yet, it is unclear whether and how knowledge workers are supported and trained to safely use AI. Inadequate training may lead to unrealized benefits if workers abandon tools, or perpetuate biases if workers misinterpret AI-based outcomes. In a workshop with 39 workers from 26 countries specializing in human resources, labor law, standards creation, and worker training, we explored questions and ideas they had about safely adopting AI. We held 17 follow-up interviews to further investigate what skills and training knowledge workers need to achieve safe and effective AI in practice. We synthesize nine training topics participants surfaced for knowledge workers related to challenges around understanding what AI is, misinterpreting outcomes, exacerbating biases, and worker rights. We reflect how these training topics might be addressed under different contexts, imagine HCI research prototypes as potential training tools, and consider ways to ensure training does not perpetuate harmful values.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1207},
numpages = {18},
keywords = {Workplace AI, AI Training, AI Literacy, Artificial Intelligence, Future of Work, Responsible AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713885,
author = {Ma, Shuhao and Liu, Zhiming and Nisi, Valentina and Fox, Sarah E and Nunes, Nuno Jardim},
title = {Speculative Job Design: Probing Alternative Opportunities for Gig Workers in an Automated Future},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713885},
doi = {10.1145/3706598.3713885},
abstract = {Automation is reshaping the gig economy, raising urgent concerns about worker displacement. With the global rise in gig workers, there is an increasing urgency for HCI and design research to focus on the impact of designing automation technologies on labor dynamics. This study introduces speculative job design research to probe alternative opportunities for gig workers in an automated future, engaging 20 workers in the process. Guided by Feminist HCI, we performed reflexive thematic analysis to uncover gig workers’ views on automation technology, human labor, speculative jobs, and their concerns about the future of work. We highlighted how workers see labor exploitation as a competitive asset over machines, urging that future platform designs must not perpetuate this. Notably, through speculative job design and conversation with workers, we proposed labor design, suggesting labor as a designable material to help address unfair labor dynamics in technology design. Our research offers potential insights and directions for addressing labor tensions in the evolving sociotechnical landscape.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1208},
numpages = {18},
keywords = {Futur of Work, Gig Work, Gig Economy, Automation Technologies, Design Futuring, Speculative Design, Job Design, Labor Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713915,
author = {Zhao, Linqi and Knierim, Michael Thomas and Wilson, Max L and Dickinson, Patrick and Maior, Horia A.},
title = {Work Hard, Play Harder: Intense Games Enable Recovery from High Mental Workload Tasks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713915},
doi = {10.1145/3706598.3713915},
abstract = {Playing games has been shown to be an effective method of post-work recovery. Previous research has shown that gameplay with high cognitive involvement is effective for recovery. This finding conflicts with models of mental workload (MWL), which suggest that people feel best when cycling between high and low MWL. To unpack the relationship between recovery and mental workload, we designed a lab experiment where 40 participants experienced different combinations of high and low MWL while undertaking both work tasks and recovery gameplay, and we collected both self-report and physiological (fNIRS) data. Results showed that high and low MWL games created different impacts on recovery, depending on the MWL of the prior work task. While fNIRS measurements of MWL varied as expected during work tasks, experience of MWL when playing games was not evident in the prefrontal cortex. We conclude by discussing the relationship between mental workload and theories of recovery.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1209},
numpages = {21},
keywords = {Gameplay, Mental Workload, Work Recovery, fNIRS},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713559,
author = {Chakrabarty, Tuhin and Laban, Philippe and Wu, Chien-Sheng},
title = {Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving Human-AI Alignment in the Writing Process through Edits},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713559},
doi = {10.1145/3706598.3713559},
abstract = {LLM-based applications are helping people write, and LLM-generated text is making its way into social media, journalism, and our classrooms. However, the differences between LLM-generated and human-written text remain unclear. To explore this, we hired professional writers to edit paragraphs in several creative domains. We first found these writers agree on undesirable idiosyncrasies in LLM-generated text, formalizing it into a seven-category taxonomy (e.g. clich\'{e}s, unnecessary exposition). Second, we curated the LAMP corpus: 1,057 LLM-generated paragraphs edited by professional writers according to our taxonomy. Analysis of LAMP reveals that none of the LLMs used in our study (GPT4o, Claude-3.5-Sonnet, Llama-3.1-70b) outperform each other in terms of writing quality, revealing common limitations across model families. Third, building on existing work in automatic editing we evaluated methods to improve LLM-generated text. A large-scale preference annotation confirms that although experts largely prefer text edited by other experts, automatic editing methods show promise in improving alignment between LLM-generated and human-written text.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1210},
numpages = {33},
keywords = {Human-AI collaboration, Large Language Models, Design Methods, Text Editing, Natural Language Generation, Evaluation, Writing Assistance, Generative AI, Homogenization, Alignment, Behavioral Science},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713974,
author = {Dang, Hai and Swoopes, Chelse and Buschek, Daniel and Glassman, Elena L.},
title = {CorpusStudio: Surfacing Emergent Patterns In A Corpus Of Prior Work While Writing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713974},
doi = {10.1145/3706598.3713974},
abstract = {Many communities, including the scientific community, develop implicit writing norms. Understanding them is crucial for effective communication with that community. Writers gradually develop an implicit understanding of norms by reading papers and receiving feedback on their writing. However, it is difficult to both externalize this knowledge and apply it to one’s own writing. We propose two new writing support concepts that reify document and sentence-level patterns in a given text corpus: (1) an ordered distribution over section titles and (2) given the user’s draft and cursor location, many retrieved contextually relevant sentences. Recurring words in the latter are algorithmically highlighted to help users see any emergent norms. Study results (N=16) show that participants revised the structure and content using these concepts, gaining confidence in aligning with or breaking norms after reviewing many examples. These results demonstrate the value of reifying distributions over other authors’ writing choices during the writing process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1211},
numpages = {19},
keywords = {writing assistance, natural language processing, text visualization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713521,
author = {Choi, Frederick and Lambert, Charlotte and Koshy, Vinay and Pratipati, Sowmya and Do, Tue and Chandrasekharan, Eshwar},
title = {Creator Hearts: Investigating the Impact Positive Signals from YouTube Creators in Shaping Comment Section Behavior},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713521},
doi = {10.1145/3706598.3713521},
abstract = {Much of the research in online moderation focuses on punitive actions. However, emerging research has shown that positive reinforcement is effective at encouraging desirable behavior on online platforms. We extend this research by studying the “creator heart” feature on YouTube, quantifying their primary effects on comments that receive hearts and on videos where hearts have been given out by creators. Overall, creator hearts increased creator agency over feed presentation in YouTube comments sections, and also served as an incentive mechanism to drive user engagement. We find that creator hearts increased the visibility of comments, and increased the amount of positive engagement they received from other users. We also find that the presence of a creator-hearted comment soon after a video is published can incentivize viewers to comment, increasing the total engagement with the video over time. We discuss how creators can use hearts to shape behavior in their communities by highlighting, rewarding, and incentivizing desired behaviors from users. We discuss avenues for extending our study to understanding positive signals from moderators and curators on other platforms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1212},
numpages = {18},
keywords = {positive reinforcement, incentives, desirable behavior, moderation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713830,
author = {Lambert, Charlotte and Saha, Koustuv and Chandrasekharan, Eshwar},
title = {Does Positive Reinforcement Work?: A Quasi-Experimental Study of the Effects of Positive Feedback on Reddit},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713830},
doi = {10.1145/3706598.3713830},
abstract = {Social media platform design often incorporates explicit signals of positive feedback. Some moderators provide positive feedback with the goal of positive reinforcement, but are often unsure of their ability to actually influence user behavior. Despite its widespread use and theory touting positive feedback as crucial for user motivation, its effect on recipients is relatively unknown. This paper examines how positive feedback impacts Reddit users and evaluates its differential effects to understand who benefits most from receiving positive feedback. Through a causal inference study of 11M posts across 4 months, we find that users who received positive feedback made more frequent (2\% per day) and higher quality (57\% higher score; 2\% fewer removals per day) posts compared to a set of matched control users. Our findings highlight the need for platforms, communities, and moderators to expand their perspective on moderation and complement punitive approaches with positive reinforcement strategies to foster desirable behavior online.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1213},
numpages = {16},
keywords = {Online Communities; Online Moderation; Feedback Mechanisms; Causal Inference},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713691,
author = {Wang, Leijie and Yurechko, Kathryn and Dani, Pranati and Chen, Quan Ze and Zhang, Amy X.},
title = {End User Authoring of Personalized Content Classifiers: Comparing Example Labeling, Rule Writing, and LLM Prompting},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713691},
doi = {10.1145/3706598.3713691},
abstract = {Existing tools for laypeople to create personal classifiers often assume a motivated user working uninterrupted in a single, lengthy session. However, users tend to engage with social media casually, with many short sessions on an ongoing, daily basis. To make creating personal classifiers for content curation easier for such users, tools should support rapid initialization and iterative refinement. In this work, we compare three strategies—(1) example labeling, (2) rule writing, and (3) large language model (LLM) prompting—for end users to build personal content classifiers. From an experiment with 37 non-programmers tasked with creating personalized moderation filters, we found that participants preferred different initializing strategies in different contexts, despite LLM prompting’s better performance. However, all strategies faced challenges with iterative refinement. To overcome challenges in iterating on their prompts, participants even adopted hybrid approaches such as providing examples as in-context examples or writing rule-like prompts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1214},
numpages = {21},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713205,
author = {Monge Roffarello, Alberto and Cal\`{o}, Tommaso and Scibetta, Luca and De Russis, Luigi},
title = {Investigating How Computer Science Researchers Design Their Co-Writing Experiences With AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713205},
doi = {10.1145/3706598.3713205},
abstract = {Recent advancements in AI have significantly enhanced collaboration between humans and writing assistants. However, empirical evidence is still lacking on how this collaboration unfolds in scientific writing, especially considering the variety of tools researchers can use nowadays. We conducted observations and retrospective interviews to investigate how 19 computer science researchers collaborated with intelligent writing assistants while working on their ongoing projects. We adopted a design-in-use lens to analyze the collected data, exploring how researchers adapt writing assistants during their use to overcome challenges and meet their specific needs and preferences. Our findings identify issues such as workflow disruptions and over-reliance on AI, and reveal five distinct design-in-use styles—teaching, resisting, repurposing, orchestrating, and complying—each consisting of different practices used by researchers. This study contributes to understanding the evolving landscape of human-AI co-writing in scientific research and offers insights for designing more effective writing assistants.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1215},
numpages = {17},
keywords = {Generative AI, scientific writing, writing assistants, design-in-use},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713161,
author = {Zhao, Zixin and Masson, Damien and Kim, Young-Ho and Penn, Gerald and Chevalier, Fanny},
title = {Making the Write Connections: Linking Writing Support Tools with Writer Needs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713161},
doi = {10.1145/3706598.3713161},
abstract = {This work sheds light on whether and how creative writers’ needs are met by existing research and commercial writing support tools (WST). We conducted a need finding study to gain insight into the writers’ process during creative writing through a qualitative analysis of the response from an online questionnaire and Reddit discussions on r/Writing. Using a systematic analysis of 115 tools and 67 research papers, we map out the landscape of how digital tools facilitate the writing process. Our triangulation of data reveals that research predominantly focuses on the writing activity and overlooks pre-writing activities and the importance of visualization. We distill 10 key takeaways to inform future research on WST and point to opportunities surrounding underexplored areas. Our work offers a holistic and up-to-date account of how tools have transformed the writing process, guiding the design of future tools that address writers’ evolving and unmet needs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1216},
numpages = {21},
keywords = {Creative writing, meta-analysis, literature review, data triangulation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714258,
author = {Rasch, Julian and Wilhalm, Matthias and M\"{u}ller, Florian and Chiossi, Francesco},
title = {AR You on Track? Investigating Effects of Augmented Reality Anchoring on Dual-Task Performance While Walking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714258},
doi = {10.1145/3706598.3714258},
abstract = {With the increasing spread of AR head-mounted displays suitable for everyday use, interaction with information becomes ubiquitous, even while walking. However, this requires constant shifts of our attention between walking and interacting with virtual information to fulfill both tasks adequately. Accordingly, we as a community need a thorough understanding of the mutual influences of walking and interacting with digital information to design safe yet effective interactions. Thus, we systematically investigate the effects of different AR anchors (hand, head, torso) and task difficulties on user experience and performance. We engage participants (n = 26) in a dual-task paradigm involving a visual working memory task while walking. We assess the impact of dual-tasking on both virtual and walking performance, and subjective evaluations of mental and physical load. Our results show that head-anchored AR content least affected walking while allowing for fast and accurate virtual task interaction, while hand-anchored content increased reaction times and workload.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1217},
numpages = {21},
keywords = {Augmented Reality, Dual-Tasking, Cognitive-Motor Interference},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713518,
author = {Luo, Weizhou and Ellenberg, Mats Ole and Satkowski, Marc and Dachselt, Raimund},
title = {Documents in Your Hands: Exploring Interaction Techniques for Spatial Arrangement of Augmented Reality Documents},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713518},
doi = {10.1145/3706598.3713518},
abstract = {Augmented Reality (AR) promises to enhance daily office activities involving numerous textual documents, slides, and spreadsheets by expanding workspaces and enabling more direct interaction. However, there is a lack of systematic understanding of how knowledge workers can manage multiple documents and organize, explore, and compare them in AR environments. Therefore, we conducted a user-centered design study (N&nbsp;=&nbsp;21) using predefined spatial document layouts in AR to elicit interaction techniques, resulting in 790 observation notes. Thematic analysis identified various interaction methods for aggregating, distributing, transforming, inspecting, and navigating document collections. Based on these findings, we propose a design space and distill design implications for AR document arrangement systems, such as enabling body-anchored storage, facilitating layout spreading and compressing, and designing interactions for layout transformation. To demonstrate their usage, we developed a rapid prototyping system and exemplify three envisioned scenarios. With this, we aim to inspire the design of future immersive offices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1218},
numpages = {22},
keywords = {spatial layout, content organization, interaction design, user-centered design, Mixed Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713377,
author = {Galindo Esparza, Rosella P. and Dudley, John J. and Garaj, Vanja and Kristensson, Per Ola},
title = {Exclusion Rates among Disabled and Older Users of Virtual and Augmented Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713377},
doi = {10.1145/3706598.3713377},
abstract = {This paper examines the levels of exclusion encountered by disabled and older users of consumer-level VR and AR technology and identifies methods formed by people with diverse access needs to circumvent encountered barriers to use. First, we estimate exclusion rates for a selection of nine immersive experiences of VR and AR, computed using population statistics data for the United Kingdom (UK). We then present an empirical lab-based study evaluating the usability of the same VR and AR experiences. The study involved 60 UK-based participants with varying access needs and the study results were used to calculate the empirical exclusion rates. Both the estimated and empirical exclusion rates display high levels of exclusion, which for the more complex experiences in the study reached 100&nbsp;\%. However, multiple participants overcame usability barriers and completed experiences through provided assistance and self-initiated adaptations, suggesting that future VR and AR can become more inclusive if designed to counter these barriers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1219},
numpages = {15},
keywords = {Accessibility, Virtual Reality, Augmented Reality, Disabilities, Ageing},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713288,
author = {Meinhardt, Luca-Maxim and Schramm, Clara and Jansen, Pascal and Colley, Mark and Rukzio, Enrico},
title = {Fly Away: Evaluating the Impact of Motion Fidelity on Optimized User Interface Design via Bayesian Optimization in Automated Urban Air Mobility Simulations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713288},
doi = {10.1145/3706598.3713288},
abstract = {Automated Urban Air Mobility (UAM) can improve passenger transportation and reduce congestion, but its success depends on passenger trust. While initial research addresses passengers’ information needs, questions remain about how to simulate air taxi flights and how these simulations impact users and interface requirements. We conducted a between-subjects study (N=40), examining the influence of motion fidelity in Virtual-Reality-simulated air taxi flights on user effects and interface design. Our study compared simulations with and without motion cues using a 3-Degrees-of-Freedom motion chair. Optimizing the interface design across six objectives, such as trust and mental demand, we used multi-objective Bayesian optimization to determine the most effective design trade-offs. Our results indicate that motion fidelity decreases users’ trust, understanding, and acceptance, highlighting the need to consider motion fidelity in future UAM studies to approach realism. However, minimal evidence was found for differences or equality in the optimized interface designs, suggesting personalized interface designs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1220},
numpages = {16},
keywords = {urban air mobility, virtual reality, motion chair, Bayesian optimization, mobility},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713203,
author = {Kocur, Martin and Kloss, Melanie and Schaufler, Christoph and Schwind, Valentin and Henze, Niels},
title = {Investigating the Impact of Customized Avatars and the Proteus Effect during Physical Exercise in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713203},
doi = {10.1145/3706598.3713203},
abstract = {Virtual reality (VR) allows to embody avatars. Coined the Proteus effect, an avatar’s visual appearance can influence users’ behavior and perception. Recent work suggests that athletic avatars decrease perceptual and physiological responses during VR exercise. However, such effects can fail to occur when users do not experience avatar ownership and identification. While customized avatars increase body ownership and identification, it is unclear whether they improve the Proteus effect. We conducted a study with 24 participants to determine the effects of athletic and non-athletic avatars that were either customized or randomly assigned. We developed a customization editor to allow creating customized avatars. We found that customized avatars reduced perceived exertion. We also found that athletic avatars decreased heart rate while holding weights, however, only when being customized. Results indicate that customized avatars can positively influence users during physical exertion. We discuss the utilization of avatar customization in VR exercise systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1221},
numpages = {18},
keywords = {virtual reality, body ownership, Proteus effect, virtual embodiment, avatars, customization},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713743,
author = {Hu, Jinghui and Dudley, John J and Kristensson, Per Ola},
title = {Seeing and Touching the Air: Unraveling Eye-Hand Coordination in Mid-Air Gesture Typing for Mixed Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713743},
doi = {10.1145/3706598.3713743},
abstract = {Mid-air text entry in mixed reality (MR) headsets has shown promise but remains less efficient than traditional input methods. While research has focused on improving typing performance, the mechanics of mid-air gesture typing, especially eye-hand coordination, are less understood. This paper investigates visuomotor coordination of mid-air gesture keyboards through a user study (n = 16) comparing gesture typing on a tablet and in mid-air. Through an expert task we demonstrate that users were able to achieve a comparable text input performance. Our in-depth analysis of eye-hand coordination reveals significant differences in the eye-hand coordination patterns between gesture typing on a tablet and in-air. The mid-air gesture typing necessitates almost all of the visual attention on the keyboard area and a more consistent synchronization in eye-hand coordination to compensate for the increased motor and cognitive demands without physical boundaries. These insights provide important implications for the design of more efficient text input methods.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1222},
numpages = {15},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713382,
author = {Bhatia, Arpit and Mughrabi, Moaaz Hudhud and Abdlkarim, Diar and Di Luca, Massimiliano and Gonzalez-Franco, Mar and Ahuja, Karan and Seifi, Hasti},
title = {Text Entry for XR Trove (TEXT): Collecting and Analyzing Techniques for Text Input in XR},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713382},
doi = {10.1145/3706598.3713382},
abstract = {Text entry for extended reality (XR) is far from perfect, and a variety of text entry techniques (TETs) have been proposed to fit various contexts of use. However, comparing between TETs remains challenging due to the lack of a consolidated collection of techniques, and limited understanding of how interaction attributes of a technique (e.g., presence of visual feedback) impact user performance. To address these gaps, this paper examines the current landscape of XR TETs by creating a database of 176 different techniques. We analyze this database to highlight trends in the design of these techniques, the metrics used to evaluate them, and how various interaction attributes impact these metrics. We discuss implications for future techniques and present TEXT: Text Entry for XR Trove, an interactive online tool to navigate our database.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1223},
numpages = {18},
keywords = {Text Entry, Extended Reality, Dataset},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713685,
author = {Bahnsen, Kilian L and Dischinger, Emma and Grundgeiger, Tobias},
title = {AR Cue Reliability for Interrupted Task Resumption Affects Users' Resumption Strategies and Performance},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713685},
doi = {10.1145/3706598.3713685},
abstract = {Reliable augmented reality (AR) cues can support the resumption of interrupted tasks. We investigated how sub-optimal AR cue reliability (100\%, 86\%, 64\%, or no cue) affected users’ resumption performance and strategies. In a between-subjects experiment, 120 participants conducted a physical sorting task including interruptions, and we manipulated AR cue reliability (i.e., the AR cue was present or absent at the end of interruptions). In trials with AR cue, performance with 86\% and 64\% reliable AR cues was as well as with 100\% reliable cues. In trials without AR cue, performance with sub-optimal AR cue reliability declined but was still better than with no cue. Cue reliability affected task resumption strategies of the 86\% (slow but no increase in errors) and the 64\% (fast but increase in errors) reliability groups differently. Our results extend reliability research to interruptions and the observed efficiency-thoroughness trade-offs in resumption strategies provide insight for design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1224},
numpages = {12},
keywords = {Task Resumption, Interruption, Augmented Reality, Resumption Lag, Reliability, Automation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713519,
author = {Windl, Maximiliane and Laboda, Petra Zsofia and Mayer, Sven},
title = {Designing Effective Consent Mechanisms for Spontaneous Interactions in Augmented Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713519},
doi = {10.1145/3706598.3713519},
abstract = {Ubiquitous computing devices like Augmented Reality (AR) glasses allow countless spontaneous interactions – all serving different goals. AR devices rely on data transfer to personalize recommendations and adapt to the user. Today’s consent mechanisms, such as privacy policies, are suitable for long-lasting interactions; however, how users can consent to fast, spontaneous interactions is unclear. We first conducted two focus groups (N=17) to identify privacy-relevant scenarios in AR. We then conducted expert interviews (N=11) with co-design activities to establish effective consent mechanisms. Based on that, we contribute (1) a validated scenario taxonomy to define privacy-relevant AR interaction scenarios, (2) a flowchart to decide on the type of mechanisms considering contextual factors, (3) a design continuum and design aspects chart to create the mechanisms, and (4) a trade-off and prediction chart to evaluate the mechanism. Thus, we contribute a conceptual framework fostering a privacy-preserving future with AR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1225},
numpages = {18},
keywords = {human-computer interaction, privacy, consent, augmented reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713320,
author = {Rajaram, Shwetha and Peralta, Macarena and Johnson, Janet G. and Nebeling, Michael},
title = {Exploring the Design Space of Privacy-Driven Adaptation Techniques for Future Augmented Reality Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713320},
doi = {10.1145/3706598.3713320},
abstract = {Modern augmented reality (AR) devices with advanced display and sensing capabilities pose significant privacy risks to users and bystanders. While previous context-aware adaptations focused on usability and ergonomics, we explore the design space of privacy-driven adaptations that allow users to meet their dynamic needs. These techniques offer granular control over AR sensing capabilities across various AR input, output, and interaction modalities, aiming to minimize degradations to the user experience. Through an elicitation study with 10 AR researchers, we derive 62 privacy-focused adaptation techniques that preserve key AR functionalities and classify them into system-driven, user-driven, and mixed-initiative approaches to create an adaptation catalog. We also contribute a visualization tool that helps AR developers navigate the design space, validating its effectiveness in design workshops with six AR developers. Our findings indicate that the tool allowed developers to discover new techniques, evaluate tradeoffs, and make informed decisions that balance usability and privacy concerns in AR design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1226},
numpages = {19},
keywords = {elicitation studies, threat modeling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713293,
author = {Zhang, Nandi and Yan, Yukang and Suzuki, Ryo},
title = {From Following to Understanding: Investigating the Role of Reflective Prompts in AR-Guided Tasks to Promote User Understanding},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713293},
doi = {10.1145/3706598.3713293},
abstract = {Augmented Reality (AR) is a promising medium for guiding users through tasks, yet its impact on fostering deeper task understanding remains underexplored. This paper investigates the impact of reflective prompts—strategic questions that encourage users to challenge assumptions, connect actions to outcomes, and consider hypothetical scenarios—on task comprehension and performance. We conducted a two-phase study: a formative survey and co-design sessions (N=9) to develop reflective prompts, followed by a within-subject evaluation (N=16) comparing AR instructions with and without these prompts in coffee-making and circuit assembly tasks. Our results show that reflective prompts significantly improved objective task understanding and resulted in more proactive information acquisition behaviors during task completion. These findings highlight the potential of incorporating reflective elements into AR instructions to foster deeper engagement and learning. Based on data from both studies, we synthesized design guidelines for integrating reflective elements into AR systems to enhance user understanding without compromising task performance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1227},
numpages = {18},
keywords = {Augmented Reality; Task Guidance; Instruction Following; Reflective Prompts},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713970,
author = {Ring, Patrizia and Masuch, Maic},
title = {Long-Term Effects of User Expertise and Application Design on Collision Anxiety in VR Games},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713970},
doi = {10.1145/3706598.3713970},
abstract = {Virtual reality (VR) applications achieve their high immersive potential by detaching the user from the real world, replacing it through a virtual environment. This detachment also blocks real-world orientation cues, which might cause fear of colliding with the real environment and negatively impact the player experience. However, since collision anxiety (CA) is a relatively young concept, it is unclear how factors like users’ VR expertise or specific game design choices may affect it. We defined expected CA profiles for five commercial VR games and conducted a longitudinal study examining how growing VR expertise and VR game design influence the users’ CA. After six weeks and a total of 154 VR sessions, results indicate that CA differs between applications and generally decreases as VR expertise increases. Based on our results, we propose design implications, providing researchers and designers with guidelines on when to expect and how to avoid fear of colliding.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1228},
numpages = {15},
keywords = {virtual reality, user experience, user expertise, collision anxiety, discomfort, assessment, questionnaire, spatial orientation, VR orientation, VR games},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714188,
author = {Li, Chenyi and Wu, Guande and Chan, Gromit Yeuk-Yin and Turakhia, Dishita Gdi and Castelo Quispe, Sonia and Li, Dong and Welch, Leslie and Silva, Claudio and Qian, Jing},
title = {Satori 悟り: Towards Proactive AR Assistant with Belief-Desire-Intention User Modeling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714188},
doi = {10.1145/3706598.3714188},
abstract = {Augmented Reality (AR) assistance is increasingly used for supporting users with physical tasks like assembly and cooking. However, most systems rely on reactive responses triggered by user input, overlooking rich contextual and user-specific information. To address this, we present Satori, a novel AR system that proactively guides users by modeling both – their mental states and environmental contexts. Satori integrates the Belief-Desire-Intention (BDI) framework with the state-of-the-art multi-modal large language model (LLM) to deliver contextually appropriate guidance. Our system is designed based on two formative studies involving twelve experts. We evaluated the system with a sixteen within-subject study and found that Satori matches the performance of designer-created Wizard-of-Oz (WoZ) systems, without manual configurations or heuristics, thereby improving generalizability, reusability, and expanding the potential of AR assistance. Code is available at https://github.com/VIDA-NYU/satori-assistance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1229},
numpages = {24},
keywords = {Augmented reality assistant, proactive virtual assistant, user modeling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713765,
author = {Yang, Xiliu and Sasikumar, Prasanth and Amtsberg, Felix and Menges, Achim and Sedlmair, Michael and Nanayakkara, Suranga},
title = {Who is in Control? Understanding User Agency in AR-assisted Construction Assembly},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713765},
doi = {10.1145/3706598.3713765},
abstract = {Adaptive AR assistance can automatically trigger content to support users based on their context. Such intelligent automation offers many benefits but also alters users’ degree of control, which is seldom explored in existing research. In this paper, we compare high- and low-agency control in AR-assisted construction assembly to understand the role of user agency. We designed cognitive and physical assembly scenarios and conducted a lab study (N=24), showing that low-agency control reduced mental workloads and perceived autonomy in several tasks. A follow-up domain expert study with trained carpenters (N=8) contextualised these results in an ecologically valid setting. Through semi-structured interviews, we examined the carpenters’ perspectives on AR support in their daily work and the trade-offs of automating interactions. Based on these findings, we summarise key design considerations to inform future adaptive AR designs in the context of timber construction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1230},
numpages = {15},
keywords = {Augmented Reality, Worker Assistance, User Agency, Construction Industry},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713879,
author = {Bang, Sunyoung and Lee, Hyunjin and Oh, Seo Young and Woo, Woontack},
title = {AReading with Smartphones: Understanding the Trade-offs between Enhanced Legibility and Display Switching Costs in Hybrid AR Interfaces},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713879},
doi = {10.1145/3706598.3713879},
abstract = {This research investigates the use of hybrid user interfaces to enhance text readability in augmented reality (AR) by combining optical see-through head-mounted displays with smartphones. While this integration can improve information legibility, it may also introduce display switching side effects. The extent to which these side effects hinder user experience and when the benefits outweigh drawbacks remain unclear. To address this gap, we conducted an empirical study (N=24) to evaluate how hybrid user interfaces affect AR reading tasks across different content distances, which induce varying levels of display switching. Our findings show that hybrid user interfaces offer significant readability benefits compared to using the HMD only, reducing mental and physical demands when reading text linked to content at closer distances. However, as the distance between displays increases, the compensatory behaviors users adopt to manage increased switching costs negate these benefits, making hybrid user interfaces less effective. Based on these findings, we suggest (1) using smartphones as supplementary displays for text in reading-intensive tasks, (2) implementing adaptive display positioning to minimize switching overhead in such scenarios, and (3) adjusting the smartphone’s role based on content distance for less intensive reading tasks. These insights provide guidance for optimizing smartphone integration in hybrid interfaces and enhancing AR systems for reading applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1231},
numpages = {20},
keywords = {hybrid user interfaces, OST HMD, readability, attention switching, augmented reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714274,
author = {Numan, Nels and Brostow, Gabriel and Park, Suhyun and Julier, Simon and Steed, Anthony and Van Brummelen, Jessica},
title = {CoCreatAR: Enhancing Authoring of Outdoor Augmented Reality Experiences Through Asymmetric Collaboration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714274},
doi = {10.1145/3706598.3714274},
abstract = {Authoring site-specific outdoor augmented reality (AR) experiences requires a nuanced understanding of real-world context to create immersive and relevant content. Existing ex-situ authoring tools typically rely on static 3D models to represent spatial information. However, in our formative study (n=25), we identified key limitations of this approach: models are often outdated, incomplete, or insufficient for capturing critical factors such as safety considerations, user flow, and dynamic environmental changes. These issues necessitate frequent on-site visits and additional iterations, making the authoring process more time-consuming and resource-intensive. To mitigate these challenges, we introduce CoCreatAR, an asymmetric collaborative mixed reality authoring system that integrates the flexibility of ex-situ workflows with the immediate contextual awareness of in-situ authoring. We conducted an exploratory study (n=32) comparing CoCreatAR to an asynchronous workflow baseline, finding that it enhances engagement, creativity, and confidence in the authored output while also providing preliminary insights into its impact on task load. We conclude by discussing the implications of our findings for integrating real-world context into site-specific AR authoring systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1232},
numpages = {22},
keywords = {collaborative mixed reality, augmented reality, co-creation, site-specific, authoring tools, reconstruction, context-aware systems},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713095,
author = {Mhaidli, Abraham and Fidan, Selin Erin and Schaub, Florian},
title = {Intriguing, Concerning, and Questioning the Impact on Immersion: An Exploration of VR Users' Advertising Experiences and Attitudes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713095},
doi = {10.1145/3706598.3713095},
abstract = {Many companies are experimenting with, and developing, advertisements for virtual reality (VR) consumer applications. So far, the development of VR advertising has not accounted for the voices of VR users. Since VR users will be the ones impacted by VR advertising, it is both a requirement and a moral imperative to center their voices in the discussion. We interviewed 22 VR users (14 of which had experienced VR ads, 8 of which had not) to understand their experiences with, and attitudes towards, VR advertising. Many participants had already encountered VR advertisements, ranging from static billboards in virtual worlds to virtual markets. While some participants acknowledged that VR advertising could provide benefits (including monetizing the VR ecosystem and more informative advertising), many were concerned about in-app VR advertisements ruining the immersion of VR experiences, unavoidable ads that were forced on users, privacy risks, physical harms, and manipulation. We conclude by discussing avenues for designing VR advertisements that align with users’ needs and wants.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1233},
numpages = {19},
keywords = {VR, VR Advertising, Manipulation, Immersion},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713597,
author = {Sarbach, Adrian and Weber, Thierry Robin},
title = {Next-Generation Navigation: Evaluating the Impact of Augmented Reality on Situation Awareness in General Aviation Cockpits},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713597},
doi = {10.1145/3706598.3713597},
abstract = {Flights in general aviation require pilots to navigate using 2D maps, which splits their attention between the cockpit and the outside environment, reducing situation awareness. Augmented reality (AR) can bridge the gap between the inside and outside world, and thus can resolve the issue of attention switches. In a mixed methods simulator study with 19 pilots, we tested an AR application that integrated invisible and hard-to-see aeronautical data and navigation features with the visible world. Results show that the AR tool enhances and accelerates orientation, and can result in flight trajectories being more accurate with AR than without AR. Situation awareness, measured with a subjective self-rating, was not increased with AR support. Participants voiced concerns about AR content occluding outside features, while positive feedback included use cases in unfamiliar areas and in low visibility, as well as highlighting of hazards.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1234},
numpages = {18},
keywords = {Orientation, Airspace Structure, Approach, Aeronautical Chart, 3D, Extended Reality, HoloLens},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713922,
author = {Petiot, Leana and Sauzeon, H\'{e}l\`{e}ne and Dragicevic, Pierre},
title = {The Effect of Augmented Reality on Involuntary Autobiographical Memory},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713922},
doi = {10.1145/3706598.3713922},
abstract = {We know little about the impact of augmented reality (AR) on human cognition, particularly regarding involuntary autobiographical memory (IAM). IAMs are spontaneous recollections of personal events, ubiquitous in daily life but under-researched in both psychology and human-computer interaction. We first discuss the potential opportunities and risks of replacing conventional displays with AR to increase the likelihood of IAMs. We then report on a study investigating whether stimuli displayed on the same mobile device using video-see-through AR are more likely to resurface than those shown with a simple 3D viewer. We found that AR elicits approximately twice as many IAMs in controlled settings with immediate re-exposure to contextual cues, but no measurable effect was found in everyday settings with delayed re-exposure. Therefore, AR can enhance IAMs, but its effects may be modest and short-lived in most cases. Nevertheless, future studies could reveal stronger effects of AR in other settings. Supplementary material is available at osf.io/gscpv/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1235},
numpages = {20},
keywords = {Involuntary Autobiographical Memory, Augmented Reality},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713949,
author = {Rau, Tobias and Isenberg, Tobias and Koehn, Andreas and Sedlmair, Michael and Lee, Benjamin},
title = {Traversing Dual Realities: Investigating Techniques for Transitioning 3D Objects between Desktop and Augmented Reality Environments},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713949},
doi = {10.1145/3706598.3713949},
abstract = {Desktop environments can integrate augmented reality (AR) head-worn devices to support 3D representations, visualizations, and interactions in a novel yet familiar setting. As users navigate across the dual realities—desktop and AR—a way to move 3D objects between them is needed. We devise three baseline transition techniques based on common approaches in the literature and evaluate their usability and practicality in an initial user study (N=18). After refining both our transition techniques and the surrounding technical setup, we validate the applicability of the overall concept for real-world activities in an expert user study (N=6). In it, computational chemists followed their usual desktop workflows to build, manipulate, and analyze 3D molecular structures, but now aided with the addition of AR and our transition techniques. Based on our findings from both user studies, we provide lessons learned and takeaways for the design of 3D object transition techniques in desktop + AR environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1236},
numpages = {16},
keywords = {Augmented reality, Cross-reality, Hybrid user interfaces, Usability study, Expert study, Computational Chemistry, Gestural input},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714216,
author = {Lee, Ken Jen and Wang, PiaoHong and Lu, Zhicong},
title = {"Can't believe I'm crying over an anime girl": Public Parasocial Grieving and Coping Towards VTuber Graduation and Termination},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714216},
doi = {10.1145/3706598.3714216},
abstract = {Despite the significant increase in popularity of Virtual YouTubers (VTubers), research on the unique dynamics of viewer-VTuber parasocial relationships is nascent. This work investigates how English-speaking viewers grieved VTubers whose identities are no longer used, an interesting context as the nakanohito (i.e., the person behind the VTuber identity) is usually alive post-retirement and might “reincarnate” as another VTuber. We propose a typology for VTuber retirements and analyzed 13,655 Reddit posts and comments spanning nearly three years using mixed-methods. Findings include how viewers coped using methods similar to when losing loved ones, alongside novel coping methods reflecting different attachment styles. Although emotions like sadness, shock, concern, disapproval, confusion, and love decreased with time, regret and loyalty showed opposite trends. Furthermore, viewers’ reactions situated a VTuber identity within a community of content creators and viewers. We also discuss design implications alongside implications on the VTuber ecosystem and future research directions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1237},
numpages = {23},
keywords = {Virtual YouTubers, VTubers, Parasocial Relationship, Parasocial Relationship Dissolution, Parasocial Grieving, Mixed-Methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713577,
author = {Chen, Qijia and Wu, Qunfang and Jacucci, Giulio},
title = {Democratic Moderation: Exploring the Use and Perception of Votekicking in Social Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713577},
doi = {10.1145/3706598.3713577},
abstract = {Extensive research has focused on community-based moderation involving selected or volunteer moderators. The “votekick” system represents a democratized approach allowing all users to participate in moderation. Despite its widespread use in online gaming and social VR platforms, votekicking remains underexplored. This research studies how users use and perceive votekicking in VRChat, a leading social VR platform. Through thematic analysis of discussions from the Reddit community r/VRChat, our findings reveal that votekicking serves to cope with misconduct and enforce group-specific rules, but it also perpetuates toxicity such as materializing community-level biases. While praised for its immediacy and clear messaging against unacceptable behavior, votekicking’s effectiveness is hindered by its reactive nature, consensus challenges, and decision-making complexities. This research contributes to broader discussions on the limitations and advantages of direct community involvement in moderation and suggests practical design improvements to address the challenges associated with votekicking.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1238},
numpages = {18},
keywords = {social VR, virtual reality, community moderation, votekick},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714218,
author = {Ahn, Dakyeom and Park, Seora and Lee, Seolhee and Cho, Jieun and Lim, Hajin},
title = {I Stan Alien Idols and Also the People Behind Them: Understanding How Seams Between Virtual and Real Identities Engage VTuber Fans – A Case Study of PLAVE},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714218},
doi = {10.1145/3706598.3714218},
abstract = {Virtual YouTubers (VTubers) have recently gained popularity as streamers using computer-generated avatars and real-time motion capture to create distinct virtual identities. While prior research has explored how VTubers construct virtual personas and engage audiences, little attention has been given to viewers’ reactions when virtual and real identities blur—what we refer to as “seams.” To address this gap, we conducted a case study on PLAVE, a popular Korean VTuber Kpop idol group, interviewing 24 of their fans. Our findings identified two main sources of seams: technical glitches and identity collapses, where VTubers act inconsistently with their virtual personas, revealing aspects of their real selves. These seams played a pivotal role in shaping diverse fan engagements, with some valuing authenticity linked to real identities, while others prioritized the coherence of virtual personas. Overall, our findings underscore the importance of seams in shaping viewer experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1239},
numpages = {13},
keywords = {VTuber, VTubing, virtual idol, live streaming, virtual identity, seam},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714253,
author = {Oh, Jeongseok and Kim, SeungJun},
title = {MoWa: An Authoring Tool for Refining AI-Generated Human Avatar Motions Through Latent Waveform Manipulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714253},
doi = {10.1145/3706598.3714253},
abstract = {Creating expressive and realistic motion animations is a challenging task. Generative artificial intelligence (AI) models have emerged to address this challenge, offering the capability to synthesize human motion animations from text prompts. However, the effective integration of AI-generated motion into professional designer workflows remains uncertain. This study proposes MoWa, an authoring tool designed to refine AI-generated human motions to meet professional standards. A formative study with six professional motion designers identified the strengths and weaknesses of AI-generated motions. To address these weaknesses, MoWa utilizes latent space to enhance the expressiveness of motions, making them suitable for use in professional workflows. A user study involving twelve professional motion designers was conducted to evaluate MoWa’s effectiveness in refining AI-generated motions. The results indicated that MoWa streamlines the motion design process and improves the quality of the outcomes. These findings suggest that incorporating latent space into motion design tasks can improve efficiency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1240},
numpages = {21},
keywords = {creativity support tool, graphics design, artificial intelligence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713688,
author = {Wang, Xueyang and Zhao, Sheng and Wang, Yihe and Han, Howard Ziyu and Liu, Xinge and Yi, Xin and Tong, Xin and Li, Hewu},
title = {Raise Your Eyebrows Higher: Facilitating Emotional Communication in Social Virtual Reality Through Region-Specific Facial Expression Exaggeration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713688},
doi = {10.1145/3706598.3713688},
abstract = {While exaggerated facial expressions in cartoon avatars can enhance emotional communication in social virtual reality (VR), they risk triggering the uncanny valley effect. Our research reveals that this effect varies significantly across different emotions. In Study 1 (N=30), participants evaluated scaled facial expressions during simulated VR conversations. We found that expression exaggeration had opposing effects: it decreased facial realism for joy, surprise, and disgust due to overly dramatic mouth movements, while enhancing realism for fear, sadness, and anger—emotions that rely on upper facial expressions typically constrained by HMD pressure. Based on these findings, we developed a region-specific facial expression exaggeration strategy that enhances under-expressed upper facial features while maintaining natural lower facial movements. Study 2 (N=20) validated this approach, demonstrating enhanced emotional intensity and contagion for negative emotions while mitigating the uncanny valley effect. Our research provides practical guidelines for optimizing avatar-mediated emotional communication in social VR environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1241},
numpages = {22},
keywords = {Social Virtual Reality, Facial Expression Exaggeration, Cartoon Avatars, User Empathy, Uncanny Valley Effect},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714107,
author = {Kim, Daye and Lee, Sebin and Jun, Yoonseo and Shin, Yujin and Lee, Jungjin},
title = {VTuber's Atelier: The Design Space, Challenges, and Opportunities for VTubing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714107},
doi = {10.1145/3706598.3714107},
abstract = {VTubing, the practice of live streaming using virtual avatars, has gained worldwide popularity among streamers seeking to maintain anonymity. While previous research has primarily focused on the social and cultural aspects of VTubing, there is a noticeable lack of studies examining the practical challenges VTubers face in creating and operating their avatars. To address this gap, we surveyed VTubers’ equipment and expanded the live-streaming design space by introducing six new dimensions related to avatar creation and control. Additionally, we conducted interviews with 16 professional VTubers to comprehensively explore their practices, strategies, and challenges throughout the VTubing process. Our findings reveal that VTubers face significant burdens compared to real-person streamers due to fragmented tools and the multi-tasking nature of VTubing, leading to unique workarounds. Finally, we summarize these challenges and propose design opportunities to improve the effectiveness and efficiency of VTubing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1242},
numpages = {23},
keywords = {VTuber, VTubing equipment, live streaming, design space, virtual avatar},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713572,
author = {Tran, Tram Thi Minh and Brown, Shane and Weidlich, Oliver and Yoo, Soojeong and Parker, Callum},
title = {Wearable AR in Everyday Contexts: Insights from a Digital Ethnography of YouTube Videos},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713572},
doi = {10.1145/3706598.3713572},
abstract = {With growing investment in consumer augmented reality (AR) headsets and glasses, wearable AR is moving from niche applications to everyday use. However, current research primarily examines AR in controlled settings, offering limited insights into its use in real-world daily life. To address this gap, we adopt a digital ethnographic approach, analysing 27 hours of 112 YouTube videos featuring early adopters. These videos capture usage ranging from continuous periods of hours to intermittent use over weeks and months. Our analysis shows that currently, wearable AR is primarily used for media consumption and gaming. While productivity is a desired use case, frequent use is constrained by current hardware limitations and the nascent application ecosystem. Users seek continuity in their digital experience, desiring functionalities similar to those on smartphones, tablets, or computers. We propose implications for everyday AR development that promote adoption while ensuring safe, ethical, and socially-aware integration into daily life.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1243},
numpages = {18},
keywords = {augmented reality, mixed reality, spatial computing, everyday AR, pervasive AR, video analysis, digital ethnography},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714284,
author = {Abe, Yuki and Matsushima, Keisuke and Hara, Kotaro and Sakamoto, Daisuke and Ono, Tetsuo},
title = {“I can run at night!": Using Augmented Reality to Support Nighttime Guided Running for Low-vision Runners},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714284},
doi = {10.1145/3706598.3714284},
abstract = {Dark environment challenges low-vision (LV) individuals to engage in running by following sighted guide—a Caller-style guided running—due to insufficient illumination, because it prevents them from using their residual vision to follow the guide and be aware about their environment. We design, develop, and evaluate RunSight, an augmented reality (AR)-based assistive tool to support LV individuals to run at night. RunSight combines see-through HMD and image processing to enhance one’s visual awareness of the surrounding environment (e.g., potential hazard) and visualize the guide’s position with AR-based visualization. To demonstrate RunSight’s efficacy, we conducted a user study with 8 LV runners. The results showed that all participants could run at least 1km (mean = 3.44 km) using RunSight, while none could engage in Caller-style guided running without it. Our participants could run safely because they effectively synthesized RunSight-provided cues and information gained from runner-guide communication.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1244},
numpages = {20},
keywords = {accessibility, augmented reality, low-vision individuals, guided running, nighttime outdoor exercise},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713558,
author = {Anderton, Craig and Creed, Chris and Sarcar, Sayan and Theil, Arthur},
title = {Asleep at the Virtual Wheel: The Increasing Inaccessibility of Virtual Reality Applications},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713558},
doi = {10.1145/3706598.3713558},
abstract = {Prior research has highlighted numerous accessibility barriers within virtual reality software, with guidelines emerging to address the requirements of diverse audiences. However, an empirical understanding of industry practitioner implementation of accessible guidelines within mainstream commercial applications is currently lacking. This review addresses this gap by categorising all accessibility features presented at a software-level in 330 of the most used virtual reality applications released between 2016 to 2023 on the Steam, Meta, Oculus, Viveport, and SideQuest platforms. Results suggest a growing lack of interaction customisation, with the number of applications allowing for alternative inputs and physical posture flexibility decreasing. Meanwhile, display output settings, such as text font resizing and colourblind alterations, are almost completely absent. Our findings highlight the evolution in the implementation of accessible features in virtual reality software, contributing to a representative overview of practitioner decisions, and acting as a catalyst towards the establishment of industry-wide guidelines.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1245},
numpages = {20},
keywords = {VR, Accessibility, Software review, Input, Output, Locomotion},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713374,
author = {Furtado, Diogo and Ribeiro, Renato Alexandre and Pi\c{c}arra, Manuel and Seixas Pereira, Let\'{\i}cia and Duarte, Carlos and Rodrigues, Andr\'{e} and Guerreiro, Jo\~{a}o},
title = {Designing and Evaluating a VR Boxing Experience with Blind People},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713374},
doi = {10.1145/3706598.3713374},
abstract = {Virtual Reality (VR) offers immersive experiences through advanced interaction mechanisms and rich sensory stimuli but is often inaccessible to blind people due to its over-reliance on visual feedback. While prior work has investigated specific aspects of VR accessibility, there is little knowledge on how to design full, feature-rich VR experiences accessible to blind people. This paper presents the design and evaluation of a VR Boxing experience, developed through participatory design with an ex-professional boxer who is now blind. A user study with 15 blind participants explored their perceptions of the three-mode experience developed – Heavy Bag Training, Coach Training, and Combat – to inform the design of accessible VR experiences. Our findings highlight the importance of combining natural movement, rich auditory feedback, and well-timed guidance that also fosters user independence. Furthermore, they demonstrate the value of structured progression in complexity, while also opening opportunities for engaging spatial awareness and coordination training.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1246},
numpages = {17},
keywords = {Accessible VR, Nonvisual Interaction, Participatory Design, Sports},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713346,
author = {Gottsacker, Matt and Chen, Mengyu and Saffo, David and Lu, Feiyu and Lee, Benjamin and MacIntyre, Blair},
title = {Examining the Effects of Immersive and Non-Immersive Presenter Modalities on Engagement and Social Interaction in Co-located Augmented Presentations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713346},
doi = {10.1145/3706598.3713346},
abstract = {Head-worn augmented reality (AR) allows audiences to be immersed and engaged in stories told by live presenters. While presenters may also be in AR to have the same level of immersion and awareness as their audience, this symmetric presentation style may diminish important social cues such as eye contact. In this work, we examine the effects this (a)symmetry has on engagement, group awareness, and social interaction in co-located one-on-one augmented presentations. We developed a presentation system incorporating 2D/3D content that audiences can view and interact with in AR, with presenters controlling and delivering the presentation in either a symmetric style in AR, or an asymmetric style with a handheld tablet. We conducted a within- and between-subjects evaluation with 12 participant pairs to examine the differences between these symmetric and asymmetric presentation modalities. From our findings, we extracted four themes and derived strategies and guidelines for designers interested in augmented presentations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1247},
numpages = {19},
keywords = {Augmented Reality, Augmented Presentation, Social Interaction, Engagement},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713541,
author = {Kaiser, Jonah-No\"{e}l and Kimmel, Simon and Licht, Eva and Landwehr, Eric and Hemmert, Fabian and Heuten, Wilko},
title = {Get Real With Me: Effects of Avatar Realism on Social Presence and Comfort in Augmented Reality Remote Collaboration and Self-Disclosure},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713541},
doi = {10.1145/3706598.3713541},
abstract = {Augmented reality (AR) is poised to transform remote communication with realistic user representations authentically simulating in-person interactions in one’s own environment. While increased avatar realism is beneficial in various social contexts, as it generally fosters social presence, its impact in intimate interactions is less clear, possibly creating discomfort. We explored how varying avatar realism affects social presence and comfort in AR across different social interactions. Realism preferences were established in an online survey (N=157), informing our subsequent experiment (N=42). Participants engaged in remote AR collaboration and self-disclosure tasks with avatars ranging from abstract to realistic point-cloud. Quantitative and qualitative feedback revealed that higher avatar realism generally enhances social presence and comfort, though preferences can vary. The self-disclosure task increased social presence but reduced comfort compared to the collaboration task. This research provides an empirical analysis of avatar realism, highlighting the benefits of realistic avatars in various scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1248},
numpages = {18},
keywords = {augmented reality, social presence, user-representation, avatar realism, collaboration, self-disclosure},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713927,
author = {Wang, Yi and Liu, Xiao and Arora, Chetan and Grundy, John and Hoang, Thuong},
title = {Understanding VR Accessibility Practices of VR Professionals},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713927},
doi = {10.1145/3706598.3713927},
abstract = {Accessibility is a crucial concept in Virtual Reality (VR), pivotal for meeting the needs of users, including those with disabilities. In recent years, there has been an increasing focus of VR products on enhancing the accessibility of a diverse range of digital content. Despite this growing attention from the VR community, there is a serious lack of empirical research on how VR practitioners consider VR accessibility. This includes their understanding of and insights into VR accessibility challenges and practices in the VR software development life cycle. In this paper, we aim to address these gaps using a mixed-methods approach. Specifically, we conducted interviews with 21 VR practitioners (incl. 3D modelers, developers, technical directors, and product managers) and surveyed 202 VR practitioner respondents from VR-related industries. Our findings outline the insights and challenges they face concerning VR accessibility practices in the software development life cycle. Furthermore, our findings shed light on the challenges faced by practitioners concerning VR accessibility and the reasons why it often goes unconsidered. As far as we know, this is the first comprehensive report about the understanding of accessibility in the VR software development life cycle from practitioners’ perspectives. We hope this paper will help VR practitioners better understand the practices, challenges, and potential solutions related to VR accessibility.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1249},
numpages = {17},
keywords = {Virtual Reality, Accessibility Requirements, Survey, Interview, Empirical Research.},
location = {
},
series = {CHI '25}
}

