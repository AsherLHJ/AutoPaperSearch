@inproceedings{10.1145/3359996.3364243,
author = {Griffin, Nathan Navarro and Folmer, Eelke},
title = {Out-of-body Locomotion: Vectionless Navigation with a Continuous Avatar Representation},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364243},
doi = {10.1145/3359996.3364243},
abstract = {Teleportation is a popular and low risk means of navigating in VR. Because teleportation discontinuously translates the user’s viewpoint, no optical flow is generated that could lead to vection-induced VR sickness. However, instant viewpoint translations and resulting discontinuous avatar representation is not only detrimental to presence and spatial awareness but also presents a challenge for gameplay design–particularly for multiplayer games. We compare out-of-body locomotion, a hybrid viewpoint technique that lets users seamlessly switch between a first-person and third-person avatar view, to traditional pointer-based teleportation. While in third-person, if the user doesn’t move, the camera remains stationary to avoid any optical flow generation. Third-person also lets users precisely and continuously navigate their avatar without risk of getting VR sick. The viewpoint automatically switches back to first-person as soon the users breaks line of sight with their avatar or the user requests to rejoin the avatar with a button press. A user study compares out-of-body locomotion to teleportation with participants (n=22) traversing an obstacle course. Results show that out-of-body locomotion requires significantly fewer (67\%) viewpoint transitions than teleportation while there was no significant difference in performance. In addition to being able to offer a continuous avatar representation, participants also deemed out-of-body locomotion to be faster.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {1},
numpages = {8},
keywords = {Locomotion, Teleportation., VR sickness, Virtual Reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364256,
author = {Kang, HyeongYeop and Lee, Geonsun and Han, JungHyun},
title = {Obstacle Detection and Alert System for Smartphone AR Users},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364256},
doi = {10.1145/3359996.3364256},
abstract = {This paper presents an obstacle detection and alert system for the pedestrians who use smartphone AR applications. The system analyzes the input camera image to extract feature points and determines whether the feature points come from obstacles ahead in the path. With the obstacle detector, two experiments were made. The first investigated the obstacle alert interfaces, and the second investigated the orientation guide interfaces that instruct users to hold their smartphones with some angles/orientations appropriate to capture the environment. Then, the best interfaces identified from the experiments were integrated and tested to examine their usability and user experiences.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {2},
numpages = {11},
keywords = {alert interface, augmented reality, pedestrian safety},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364277,
author = {Congdon, Ben J and Steed, Anthony},
title = {Sensitivity to Rate of Change in Gains Applied by Redirected Walking},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364277},
doi = {10.1145/3359996.3364277},
abstract = {Redirected walking allows for natural locomotion in virtual environments that are larger than a user’s physical environment. The mapping between real and virtual motion is modified by scaling some aspect of motion. As a user traverses the virtual environment these modifications (or gains) must be dynamically adjusted to prevent collision with physical obstacles. A significant body of work has established perceptual thresholds on rates of absolute gain, but the effect of changing gain is little understood. We present the results of a user study on the effects of rate of gain change. A psychophysical experiment was conducted with 21 participants. Each participant completed a series of two-alternative forced choice tasks in which they determined whether their virtual motion differed from their physical motion while experiencing one of three different methods of gain change: sudden gain change, slow gain change and constant gain. Gain thresholds were determined by 3 interleaved 2-up 1-down staircases, one per condition. Our results indicate that slow gain change is significantly harder to detect than sudden gain change.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {3},
numpages = {9},
keywords = {head-mounted display, redirected walking, virtual reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364240,
author = {Thomasset, Vincent and Caron, St\'{e}phane and Weistroffer, Vincent},
title = {Lower body control of a semi-autonomous avatar in Virtual Reality: Balance and Locomotion of a 3D Bipedal Model},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364240},
doi = {10.1145/3359996.3364240},
abstract = {Animated virtual humans may rely on full-body tracking system to reproduce user motions. In this paper, we reduce tracking to the upper-body and reconstruct the lower body to follow autonomously its upper counterpart. Doing so reduces the number of sensors required, making the application of virtual humans simpler and cheaper. It also enable deployment in cluttered scenes where the lower body is often hidden. The contribution here is the inversion of the well-known capture problem for bipedal walking. It determines footsteps rather than center-of-mass motions and yet can be solved with an off-the-shelf capture problem solver. The quality of our method is assessed in real-time tracking experiments on a wide variety of movements.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {4},
numpages = {11},
keywords = {Humanoid Locomotion, Motion Capture, Virtual Reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364269,
author = {Roth, Daniel and Bente, Gary and Kullmann, Peter and Mal, David and Purps, Chris Felix and Vogeley, Kai and Latoschik, Marc Erich},
title = {Technologies for Social Augmentations in User-Embodied Virtual Reality},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364269},
doi = {10.1145/3359996.3364269},
abstract = {Technologies for Virtual, Mixed, and Augmented Reality (VR, MR, and AR) allow to artificially augment social interactions and thus to go beyond what is possible in real life. Motivations for the use of social augmentations are manifold, for example, to synthesize behavior when sensory input is missing, to provide additional affordances in shared environments, or to support inclusion and training of individuals with social communication disorders. We review and categorize augmentation approaches and propose a software architecture based on four data layers. Three components further handle the status analysis, the modification, and the blending of behaviors. We present a prototype (injectX) that supports behavior tracking (body motion, eye gaze, and facial expressions from the lower face), status analysis, decision-making, augmentation, and behavior blending in immersive interactions. Along with a critical reflection, we consider further technical and ethical aspects.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {5},
numpages = {12},
keywords = {artificial intelligence, augmented social interaction, virtual reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364270,
author = {Pan, Ye and Steed, Anthony},
title = {Avatar Type Affects Performance of Cognitive Tasks in Virtual Reality},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364270},
doi = {10.1145/3359996.3364270},
abstract = {Current consumer virtual reality applications typically represent the user by an avatar comprising a simple head/torso and decoupled hands. In the prior work of Steed et al. it was shown that the presence or absence of an avatar could have a significant impact on the cognitive load of the user. We extend that work in two ways. First they only used a full-body avatar with articulated arms, so we add a condition with hands-only representation similar to the majority of current consumer applications. Second we provide a real-world benchmark so as to start to get at the impact of using any immersive system. We validate the prior results: real and full body avatar performance on a memory task is significantly better than no avatar. However the hands only condition is not significantly different than either these two extremes. We discuss why this might be, in particular we discuss the potential for a individual variation in response to the embodiment level.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {6},
numpages = {4},
keywords = {Avatar, Cognitive Tasks, Embodiment, Virtual Reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364268,
author = {Jeon, Seung-Gon and Han, Jaeho and Jo, Yonggeol and Han, Kyungsik},
title = {Being More Focused and Engaged in Firefighting Training: Applying User-Centered Design to VR System Development},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364268},
doi = {10.1145/3359996.3364268},
abstract = {Although virtual reality (VR) programs to provide firefighting training continue to be developed and adopted, our investigation with 15 firefighters indicates that a current VR training system tends to convey behavioral tips and does not sufficiently reflect actual firefighters’ needs and realities in the field. It often provides somewhat simplified fire simulations and actually lowers the effectiveness of the training. In this paper, we employ Human-Computer Interaction (HCI) methods to examine and identify core elements in firefighting scenarios and develop a VR system that incorporates such elements. We evaluate our system with respect to presence and three design components of the VR simulation (i.e., reality, meaning, play) through a user study with 22 participants. Our study results demonstrate greater user experience and perception toward the four elements in firefighting training with our VR system compared to the existing one. We discuss design implications (e.g., move control, degree of freedom, sight hindrance by smoke, unexpected events) of our study that are expected to help implement and provide an effective VR training system for firefighters.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {7},
numpages = {11},
keywords = {Firefighting training system, Presence, Triadic game design, User study, User-centered design, Virtual reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364273,
author = {George, Ceenu and Schwuchow, Julia and Hussmann, Heinrich},
title = {Fearing Disengagement from the Real World},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364273},
doi = {10.1145/3359996.3364273},
abstract = {With the adoption of mobile head mounted displays (HMDs) amongst non-experts outside of lab settings, it becomes increasingly important to understand what factors influence a holistic mobile virtual reality (MVR) user experience. We present the results of a field study (N=34), in which we used three methods - a drawing task, a storytelling exercise, and the technology acceptance questionnaire (TAM) - to explore factors, beyond technical capability, that influence the user experience of HMDs. Our analysis (1) highlights factors that designers and researchers can adopt to create and evaluate socially acceptable MVR systems for non-expert users outside a lab context, and (2) puts these factors in context with existing research from industry and academia.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {8},
numpages = {5},
keywords = {Field study, Mobile Virtual Reality, Qualitative study},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364242,
author = {Cavallo, Marco and Dolakia, Mishal and Havlena, Matous and Ocheltree, Kenneth and Podlaseck, Mark},
title = {Immersive Insights: A Hybrid Analytics System forCollaborative Exploratory Data Analysis},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364242},
doi = {10.1145/3359996.3364242},
abstract = {In the past few years, augmented reality (AR) and virtual reality (VR) technologies have experienced terrific improvements in both accessibility and hardware capabilities, encouraging the application of these devices across various domains. While researchers have demonstrated the possible advantages of AR and VR for certain data science tasks, it is still unclear how these technologies would perform in the context of exploratory data analysis (EDA) at large. In particular, we believe it is important to better understand which level of immersion EDA would concretely benefit from, and to quantify the contribution of AR and VR with respect to standard analysis workflows. In this work, we leverage a Dataspace reconfigurable hybrid reality environment to study how data scientists might perform EDA in a co-located, collaborative context. Specifically, we propose the design and implementation of Immersive Insights, a hybrid analytics system combining high-resolution displays, table projections, and augmented reality (AR) visualizations of the data. We conducted a two-part user study with twelve data scientists, in which we evaluated how different levels of data immersion affect the EDA process and compared the performance of Immersive Insights with a state-of-the-art, non-immersive data analysis system.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {9},
numpages = {12},
keywords = {Augmented Reality, Clustering, Data Visualization, Dataspace, Exploratory Data Analysis, Hybrid Reality, Virtuality Continuum},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364244,
author = {Anjos, Rafael Kuffner dos and Sousa, Maur\'{\i}cio and Mendes, Daniel and Medeiros, Daniel and Billinghurst, Mark and Anslow, Craig and Jorge, Joaquim},
title = {Adventures in Hologram Space: Exploring the Design Space of Eye-to-eye Volumetric Telepresence},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364244},
doi = {10.1145/3359996.3364244},
abstract = {Modern volumetric projection-based telepresence approaches are capable of providing realistic full-size virtual representations of remote people. Interacting with full-size people may not be desirable due to the spatial constraints of the physical environment, application context, or display technology. However, the miniaturization of remote people is known to create an eye gaze matching problem. Eye-contact is essential to communication as it allows for people to use natural nonverbal cues and improves the sense of “being there”. In this paper we discuss the design space for interacting with volumetric representations of people and present an approach for dynamically manipulating scale, orientation and the position of holograms which guarantees eye-contact. We created a working augmented reality-based prototype and validated it with 14 participants.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {10},
numpages = {5},
keywords = {Augmented Reality, Eye-to-eye, Holograms, Volumetric Projection},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364267,
author = {Wu, Yuanjie and Wang, Yu and Jung, Sungchul and Hoermann, Simon and Lindeman, Robert W.},
title = {Exploring the Use of a Robust Depth-sensor-based Avatar Control System and its Effects on Communication Behaviors},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364267},
doi = {10.1145/3359996.3364267},
abstract = {To interact as fully-tracked avatars with rich hand gestures in Virtual Reality (VR), we often need to wear a tracking suit or attach extra sensors on our bodies. User experience and performance may be impacted by the cumbersome devices and low fidelity behavior representations, especially in social scenarios where good communication is required. In this paper, we use multiple depth sensors and focus on increasing the behavioral fidelity of a participant’s virtual body representation. To investigate the impact of the depth-sensor-based avatar system (full-body tracking with hand gestures), we compared it against a controller-based avatar system (partial-body tracking with limited hand gestures). We designed a VR interview simulation for a single user to measure the effects on presence, virtual body ownership, workload, usability, and perceived self-performance. Specifically, the interview process was recorded in VR, together with all the verbal and non-verbal cues. Subjects then took a third-person view to evaluate their previous performance. Our results show that the depth-sensor-based avatar control system increased virtual body ownership and also improved the user experience. In addition, users rated their non-verbal behavior performance higher in the full-body depth-sensor-based avatar system.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {11},
numpages = {9},
keywords = {avatar control, communication behavior, depth sensor, motion capture, tracking, virtual reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364248,
author = {Gonzalez, Eric J. and Follmer, Sean},
title = {Investigating the Detection of Bimanual Haptic Retargeting in Virtual Reality},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364248},
doi = {10.1145/3359996.3364248},
abstract = {Haptic retargeting is a virtual reality (VR) interaction technique enabling virtual objects to be ”remapped” to different haptic proxies by offsetting the user’s virtual hand from their physical hand. While researchers have investigated single-hand retargeting, the effects of bimanual interaction in the context of haptic retargeting have been less explored. In this study, we present an evaluation of perceptual detection rates for bimanual haptic retargeting in VR. We tested 64 combinations of simultaneous left- and right-hand retargeting ranging from − 24° to + 24° offsets and found that bimanual retargeting can be more noticeable to users when the hands are redirected in different directions as opposed to the same direction.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {12},
numpages = {5},
keywords = {Haptic retargeting, bimanual, virtual reality., visuo-haptic illusion},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364250,
author = {Khamis, Mohamed and Schuster, Nora and George, Ceenu and Pfeiffer, Max},
title = {ElectroCutscenes: Realistic Haptic Feedback in Cutscenes of Virtual Reality Games Using Electric Muscle Stimulation},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364250},
doi = {10.1145/3359996.3364250},
abstract = {Cutscenes in Virtual Reality (VR) games enhance story telling by delivering output in the form of visual, auditory, or haptic feedback (e.g., using vibrating handheld controllers). Since they lack interaction in the form of user input, cutscenes would significantly benefit from improved feedback. We introduce the concept and implementation of ElectroCutscenes, where Electric Muscle Stimulation (EMS) is leveraged to elicit physical user movements to different body parts to correspond to those of personal avatars in cutscenes of VR games while the user stays passive. Through a user study (N=22) in which users passively received kinesthetic feedback resulting in involuntarily movements, we show that ElectroCutscenes significantly increases perceived presence and realism compared to controller-based vibrotactile and no haptic feedback. Furthermore, we found preliminary evidence that combining visual and EMS feedback can evoke movements that are not actuated by either of them alone. We discuss how to enhance realism and presence of cutscenes in VR games even when EMS can partially rather than completely actuate the desired body movements.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {13},
numpages = {10},
keywords = {EMS, Haptic Feedback, Haptics, Head-mounted Displays},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364266,
author = {Gao, Yang and Xu, Yinghao and Li, Shuai and Hao, Aimin and Qin, Hong},
title = {A Hybrid Method for Powdered Materials Modeling},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364266},
doi = {10.1145/3359996.3364266},
abstract = {Powdered materials, such as sand and flour, are quite common in nature, whose properties always range from granular particles to smog materials under the air friction while throwing. This paper presents a hybrid method that tightly couples APIC solver with density field to accomplish the transformation of continuous powdered materials varying among granular particles, smog, powders and their natural mixtures. In our method, a part of the granular particles will be transformed to dust smog while interacting with air and represented by density field, then, as velocity decreases the density-based dust will deposit to powder particles. We construct a unified framework to imitate the mutual transformation process for the powdered materials of different scales, which greatly enhance the details of particle-based materials modeling. We have conducted extensive experiments to verify the performance of our model, and get satisfactory results in terms of stability, efficiency and visual authenticity as expected.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {14},
numpages = {10},
keywords = {APIC, Density Field based Smog, Granular Material, Two-Way Transformation},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364275,
author = {Abdulali, Arsen and Atadjanov, Ibragim and Lee, Seungkyu and Jeon, Seokhee},
title = {Measurement-based Hyper-elastic Material Identification and Real-time FEM Simulation for Haptic Rendering},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364275},
doi = {10.1145/3359996.3364275},
abstract = {In this paper, we propose a measurement-based modeling framework for hyper-elastic material identification and real-time haptic rendering. We build a custom data collection setup that captures shape deformation and response forces during compressive deformation of cylindrical material samples. We collected training and testing sets of data from four silicone objects having various material profiles. We design an objective function for material parameter identification by incorporating both shape deformation and reactive forces and utilize a genetic algorithm. We adopted an optimization-based Finite Element Method (FEM) for object deformation rendering. The numerical error of simulated forces was found to be perceptually negligible.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {15},
numpages = {10},
keywords = {Haptic Rendering, Hyper-elasticity, Measurement-based identification},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364239,
author = {Dissanayake, Vipula and Elvitigala, Don Samitha and Zhang, Haimo and Weerasinghe, Chamod and Nanayakkara, Suranga},
title = {CompRate: Power Efficient Heart Rate and Heart Rate Variability Monitoring on Smart Wearables},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364239},
doi = {10.1145/3359996.3364239},
abstract = {Currently, smartwatches are equipped with Photoplethysmography (PPG) sensors to measure Heart Rate (HR) and Heart Rate Variability (HRV). However, PPG sensors consume considerably high energy, making it impractical to monitor HR \&amp; HRV continuously for an extended period. Utilising low power accelerometers to estimate HR has been broadly discussed in previous decades. Inspired by prior work, we introduce CompRate, an alternative method to measure HR continuously for an extended period in low-intensity physical activities. CompRate model calibrated for individual users only has an average performance of Root Mean Squared Error (RMSE) 1.58 Beats Per Minute (BPM). Further, CompRate used 3.75 times less energy compared to the built-in PPG sensor. We also demonstrate that CompRate model can be extended to predict HRV. We will demonstrate CompRate in several application scenarios: self-awareness of fatigue and just-in-time interruption while driving; enabling teachers to be aware of students’ mental effort during a learning activity; and the broadcasting of the location of live victims in a disaster situation.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {16},
numpages = {8},
keywords = {Accelerometer, Heart Rate, Heart Rate Variability, Inferring Stress, Low Power, Photoplethysmography},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364241,
author = {Ikeda, Haruka and Hayakawa, Tomohiko and Ishikawa, Masatoshi},
title = {Bilateral Motion Display: Strategy to Provide Multiple Visual Perception Using Afterimage Effects for Specific Motion},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364241},
doi = {10.1145/3359996.3364241},
abstract = {We propose a novel displaying method that provides completely different visual perception to multiple observers simultaneously using afterimage effects for specific motion. Initially, the displayed patterns do not reveal any information; however, when seen by a user moving his or her gaze in a certain direction and speed, they are spatially integrated and appear as 2D afterimages. Our method only requires a high-speed display system to produce the user-oriented perception, which expands the range of applications in various situations such as in road signs.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {17},
numpages = {5},
keywords = {afterimage effect, high-speed projection, motion-based perception, saccade-based perception},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364257,
author = {B\ae{}rentzen, Andreas and Frisvad, Jeppe Revall and Singh, Karan},
title = {Signifier-Based Immersive and Interactive 3D Modeling},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364257},
doi = {10.1145/3359996.3364257},
abstract = {Interactive 3D modeling in VR is both aided by immersive 3D input and hampered by model disjunct, tool-based or selection-action user interfaces. We propose a direct, signifier-based approach to the popular interactive technique of creating 3D models through a sequence of extrusion operations. Motivated by handles and signifiers that communicate the affordances of everyday objects, we define a set of design principles for an immersive, signifier-based modeling interface. We then present an interactive 3D modeling system where all modeling affordances are modelessly reachable and signified on the model itself.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {18},
numpages = {5},
keywords = {3D Modeling, affordances, signifiers},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364261,
author = {Horst, Robin and D\"{o}rner, Ralf},
title = {Virtual Reality Forge: Pattern-Oriented Authoring of Virtual Reality Nuggets},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364261},
doi = {10.1145/3359996.3364261},
abstract = {A current educational trend is to divide learning content in relatively small and independent learning units, referred to as learning nuggets. These “bite-sized” nuggets often rely on patterns in order to reuse these patterns within highly diverse curricular structures like lessons, presentations or demos. In this paper, we explore how virtual reality (VR) can be utilized as a medium for learning purposes similar to learning nuggets. We present a nugget-inspired VR system design and dovetail the pattern-oriented nugget concept in relatively small VR systems. We call this authoring approach with VR nuggets forging. Furthermore, we propose a VR authoring system for these VR nuggets – the VR forge. The system design for realizing VR nuggets and the authoring system are presented and implemented in Unity. For an example we utilize a set of basic patterns from the educational domain. In an expert user study, we use the resulting bite-sized VR applications to evaluate four critical aspects concerning VR and nugget-like usage and show that the educational experts accepted the VR nuggets. Within an additional study, we indicate that our authoring system which reflects the simplistic pattern-oriented content creation paradigm of learning nuggets has potential for general laymen authoring of VR application.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {19},
numpages = {12},
keywords = {Laymen Authoring, Microlearning, Pattern-Based Virtual Reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364262,
author = {JANG, Hyouk and CHOI, Juheon and Kim, Gunhee},
title = {POL360: A Universal Mobile VR Motion Controller using Polarized Light},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364262},
doi = {10.1145/3359996.3364262},
abstract = {We introduce POL360: the first universal VR motion controller that leverages the principle of light polarization. POL360 enables a user who holds it and wears a VR headset to see their hand motion in a virtual world via its accurate 6-DOF position tracking. Compared to other techniques for VR positioning, POL360 has several advantages as follows. (1) Mobile compatibility: Neither additional computing resource like a PC/console nor any complicated pre-installation is required in the environment. Only necessary device is a VR headset with an IR LED module as a light source to which a thin-film linear polarizer is attached. (2) On-device computing: Our POL360’s computation for positioning is completed on the microprocessor in the device. Thus, it does not require additional computing resource of a VR headset. (3) Competitive accuracy and update rate: In spite of POL360’s superior mobile compatibility and affordability, POL360 attains competitive performance of accuracy and fast update rates. That is, it achieves the subcentimeter accuracy of positioning and the tracking rate higher than 60 Hz. In this paper, we derive the mathematical formulation of 6-DOF positioning using light polarization for the first time and implement a POL360 prototype that can directly operate with any commercial VR headset systems. In order to demonstrate POL360’s performance and usability, we carry out thorough quantitative evaluation and a user study and develop three game demos as use cases.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {20},
numpages = {10},
keywords = {Virtual reality, light polarization, spatial interaction},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364265,
author = {Pham, Duc-Minh and Stuerzlinger, Wolfgang},
title = {HawKEY: Efficient and Versatile Text Entry for Virtual Reality},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364265},
doi = {10.1145/3359996.3364265},
abstract = {Text entry is still a challenging task in modern Virtual Reality (VR) systems. The lack of efficient text entry methods limits the applications that can be used productively in VR. Previous work has addressed this issue through virtual keyboards or showing the physical keyboard in VR. While physical keyboards afford faster text entry, they usually require a seated user and an instrumented environment. We introduce a new keyboard, worn on a hawker’s tray in front of the user, which affords a compact, simple, flexible, and efficient text entry solution for VR, without restricting physical movement. In our new video condition, we also show the keyboard only when the user is looking down at it. To evaluate our novel solution and to identify good keyboard visualizations, we ran a user study where we asked participants to enter both lowercase sentences as well as complex text while standing. The results show that text entry rates are affected negatively by simplistic keyboard visualization conditions and that our solution affords desktop text entry rates, even when standing.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {21},
numpages = {11},
keywords = {Text Entry, Virtual Reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364263,
author = {Yi, HyeonBeom and Hong, Jiwoo and Kim, Hwan and Lee, Woohun},
title = {DexController : Designing a VR Controller with Grasp-Recognition for Enriching Natural Game Experience},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364263},
doi = {10.1145/3359996.3364263},
abstract = {We present DexController, which is a hand-held controller leveraging grasp as an additional modality for virtual reality (VR) game. The pressure-sensitive surface of DexController was designed to recognize two different grasp-poses (i.e. precision grip and power grip) and detect grasp-force. Based on the results of two feasibility tests, a VR defense game was designed in which players could attack each enemy using the proper weapon with a proper level of force. A within-subject comparative study is conducted with a button-based controller which has the same physical form of DexController. The results indicated that DexController enhanced the perceived naturalness of the controller and game enjoyment, with having acceptable physical demand. This study clarifies the empirical effect of utilizing grasp-recognition on VR game controller to enhance interactivity. Also, we provide insight for the integration of VR game elements with the grasping modality of a controller.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {22},
numpages = {11},
keywords = {Virtual reality, controller, game experience, gaming, natural interaction},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364238,
author = {Teo, Theophilus and F. Hayati, Ashkan and A. Lee, Gun and Billinghurst, Mark and Adcock, Matt},
title = {A Technique for Mixed Reality Remote Collaboration using 360 Panoramas in 3D Reconstructed Scenes},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364238},
doi = {10.1145/3359996.3364238},
abstract = {Mixed Reality (MR) remote collaboration provides an enhanced immersive experience where a remote user can provide verbal and nonverbal assistance to a local user to increase the efficiency and performance of the collaboration. This is usually achieved by sharing the local user's environment through live 360 video or a 3D scene, and using visual cues to gesture or point at real objects allowing for better understanding and collaborative task performance. While most of prior work used one of the methods to capture the surrounding environment, there may be situations where users have to choose between using 360 panoramas or 3D scene reconstruction to collaborate, as each have unique benefits and limitations. In this paper we designed a prototype system that combines 360 panoramas into a 3D scene to introduce a novel way for users to interact and collaborate with each other. We evaluated the prototype through a user study which compared the usability and performance of our proposed approach to live 360 video collaborative system, and we found that participants enjoyed using different ways to access the local user's environment although it took them longer time to learn to use our system. We also collected subjective feedback for future improvements and provide directions for future research.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {23},
numpages = {11},
keywords = {360 Panorama, 3D Scene Reconstruction, Interaction Methods, Mixed Reality, Remote Collaboration, Virtual Reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364252,
author = {Fang, Xianyong and Yang, Jikui and Rao, Jie and Wang, Linbo and Deng, Zhigang},
title = {Single RGB-D Fitting: Total Human Modeling with an RGB-D Shot},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364252},
doi = {10.1145/3359996.3364252},
abstract = {Existing single shot based human modeling methods generally cannot model the complete pose details (e.g., head and hand positions) without non-trivial interactions. We explore the merits of both RGB and depth images and propose a new method called Single RGB-D Fitting (SRDF) to generate a realistic 3D human model with a single RGB-D shot from a consumer-grade depth camera. Specifically, the state-of-the-art deep learning techniques for RGB images are incorporated into SRDF, so that: 1) A compound skeleton detection method is introduced to obtain accurate 3D skeletons with refined hands based on the combination of depth and RGB images; and 2) an RGB image segmentation assisted point cloud pre-processing method is presented to obtain smooth foreground point clouds. In addition, several novel constraints are also introduced into the energy minimization model, including the shape continuity constraint, the keypoint-guided head pose prior constraint, and the penalty-enforced point cloud prior constraint. The energy model is optimized in a two-pass way so that a realistic shape can be estimated from coarse to fine. Through extensive experiments and comparisons with the state of the art methods, we demonstrate the effectiveness and efficiency of the proposed method.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {24},
numpages = {11},
keywords = {3D reconstruction, Shape modeling, deep learning, depth camera, single RGB-D image},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364260,
author = {Morton, Jacob and Lee, Seungyong},
title = {Floating-point Precision and Deformation Awareness for Scalable and Robust 3D Face Alignment},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364260},
doi = {10.1145/3359996.3364260},
abstract = {This paper improves the accuracy of heatmap-based 3D face alignment neural networks. Many current approaches in face alignment are limited by two major problems, quantization and the lack of regularization of heatmaps. The first limitation is caused by the non-differentiable argmax function, which extracts landmark coordinates from heatmaps as integer indices. Heatmaps are generated at low-resolution to reduce the memory and computational costs, which results in heatmaps far lower than the input image’s resolution. We propose a heatmap generator network producing floating-point precision heatmaps that are scalable to higher-resolutions. To resolve the second limitation, we propose a novel deformation constraint on heatmaps. The constraint is based on graph-Laplacian and enables a heatmap generator to regularize overall shape of the output face landmarks using the global face structure. By eliminating quantization and including regularization, our method can vastly improve landmark localization accuracy, and achieves the state-of-the-art performance without adding complex network structures.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {25},
numpages = {10},
keywords = {face alignment, graph Laplacian, heatmap, neural networks, soft-argmax},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364245,
author = {Heinrich, Florian and Bornemann, Kai and Lawonn, Kai and Hansen, Christian},
title = {Depth Perception in Projective Augmented Reality: An Evaluation of Advanced Visualization Techniques},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364245},
doi = {10.1145/3359996.3364245},
abstract = {Augmented reality (AR) is a promising tool to convey useful information at the place where it is needed. However, perceptual issues with augmented reality visualizations affect the estimation of distances and depth and thus can lead to critically wrong assumptions. These issues have been successfully investigated for video see-through modalities. Moreover, advanced visualization methods encoding depth information by displaying additional depth cues were developed. In this work, state-of-the-art visualization concepts were adopted for a projective AR setup. We conducted a user study to assess the concepts’ suitability to convey depth information. Participants were asked to sort virtual cubes by using the provided depth cues. The investigated visualization concepts consisted of conventional Phong shading, a virtual mirror, depth-encoding silhouettes, pseudo-chromadepth rendering and an illustrative visualization using supporting line depth cues. Besides different concepts, we altered between a monoscopic and a stereoscopic display mode to examine the effects of stereopsis. Consistent results across variables show a clear ranking of examined concepts. The supporting lines approach and the pseudo-chromadepth rendering performed best. Stereopsis was shown to provide significant advantages for depth perception, while the current visualization technique had only little effect on investigated measures in this condition. However, similar results were achieved using the supporting lines and the pseudo-chromadepth concepts in a monoscopic setup. Our study showed the suitability of advanced visualization concepts for the rendering of virtual content in projective AR. Specific depth estimation results contribute to the future design and development of applications for these systems.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {26},
numpages = {11},
keywords = {Depth Perception, Distance Estimation, Projective Augmented Reality, Visualization},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364255,
author = {Sano, Ayaka and Koizumi, Naoya},
title = {Portable Mid-air Imaging Optical System on Glossy Surface},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364255},
doi = {10.1145/3359996.3364255},
abstract = {We propose a portable optical system, PortOn, that displays an upright mid-air image when simply placed on a flat and glossy surface such as a desk or floor. Mid-air imaging is promising for glasses-free mixed reality because the user can see images without wearing a special device. However, there is a limitation in terms of where the conventional mid-air imaging optical systems can be installed. Therefore, we propose a mid-air optical system that solves this limitation. Our contribution is a practical optical design that enables the system to be easily installed. The advantage of our method is that it erases unnecessary light that is produced when mid-air images are displayed and shows beautiful mid-air images clearly when view-angle control and polarization are added to the system. We evaluate whether undesired light is erased by measuring luminance. As a result, the luminance of the undesired light is much lower than that of mid-air images.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {27},
numpages = {5},
keywords = {Muller matrix, glass-free mixed reality, polarizer},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364247,
author = {Gradl, Stefan and Wirth, Markus and M\"{a}chtlinger, Nico and Poguntke, Romina and Wonner, Andrea and Rohleder, Nicolas and Eskofier, Bjoern M.},
title = {The Stroop Room: A Virtual Reality-Enhanced Stroop Test},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364247},
doi = {10.1145/3359996.3364247},
abstract = {The Stroop Test is a well known and regularly employed stressor in laboratory research. In contrast to other methods, it is not based on fear of physical harm or social shame. Consequently, it is more likely accepted by a wide population. In our always-on, technology-driven, social-media centered world, large-scale in-field stress research will need adequate experimental tools to explore the increasing prevalence of stress-related diseases without bringing subjects into laboratories. This is why we designed the Stroop Room: A virtual reality-based adaptation of the Stroop Test using elements of the virtual world to extend the demands of the original test and at the same time make it easily accessible. It is open source and can be used and improved by anyone as an in-the-wild, repeatable, laboratory-quality stressor. In this work, the method is presented and an evaluation study described, to demonstrate its effectiveness in provoking cognitive stress. 16 male and 16 female subjects were tested in the Stroop Room while recording the electrocardiogram, electrodermal activity, saliva based cortisol and alpha-amylase, performance metrics and an array of questionnaire-based assessments regarding psychological confounders, stress state and likability of the simulation. Our results show that the Stroop Room increases heart rate on average by 19\%, other heart rate variability time-domain parameters (RMSSD, pNN50) decrease by 24\%-47\%, and its most stress-correlated frequency-parameter (LF/HF) increases by 107\%. Skin conductance (SC) level increases by 63\% and non-specific SC responses by 135\% on average. Salivary cortisol and alpha-amylase concentrations increase significantly in some specific conditions. Compared to related work using the Stroop Test, this is an improvement for some metrics by around 30\%-40\%. Questionnaire evaluation show a strong engagement of users with the simulation and some aspects of a flow-induction. These findings support the effectiveness of a Stroop Test involving 3-dimensional interactivity and thus the Stroop Room demonstrates how this can be applied in a playful interaction that could be used pervasively.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {28},
numpages = {12},
keywords = {EDA, HRV, amylase, cortisol, heart rate, psychological stress, stroop test, virtual reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364272,
author = {Sinnott, Christian and Liu, James and Matera, Courtney and Halow, Savannah and Jones, Ann and Moroz, Matthew and Mulligan, Jeffrey and Crognale, Michael and Folmer, Eelke and MacNeilage, Paul},
title = {Underwater Virtual Reality System for Neutral Buoyancy Training: Development and Evaluation},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364272},
doi = {10.1145/3359996.3364272},
abstract = {During terrestrial activities, sensation of pressure on the skin and tension in muscles and joints provides information about how the body is oriented relative to gravity and how the body is moving relative to the surrounding environment. In contrast, in aquatic environments when suspended in a state of neutral buoyancy, the weight of the body and limbs is offloaded, rendering these cues uninformative. It is not yet known how this altered sensory environment impacts virtual reality experiences. To investigate this question, we converted a full-face SCUBA mask into an underwater head-mounted display and developed software to simulate jetpack locomotion outside the International Space Station. Our goal was to emulate conditions experienced by astronauts during training at NASA's Neutral Buoyancy Lab. A user study was conducted to evaluate both sickness and presence when using virtual reality in this altered sensory environment. We observed an increase in nausea related symptoms underwater, but we cannot conclude that this is due to VR use. Other measures of sickness and presence underwater were comparable to measures taken above water. We conclude with suggestions for improved underwater VR systems and improved methods for evaluation of these systems based on our experience.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {29},
numpages = {9},
keywords = {Head-mounted Display, Presence, Sickness, Simulation, Space, Spacewalk, Training, Underwater, Virtual Reality, Waterproof},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364249,
author = {Batmaz, Anil Ufuk and Sun, Xintian and Taskiran, Dogu and Stuerzlinger, Wolfgang},
title = {Hitting the Wall: Mid-Air Interaction for Eye-Hand Coordination},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364249},
doi = {10.1145/3359996.3364249},
abstract = {Reaction time training systems are used to improve user performance. Until now, such setups use physical 2D flat surfaces, e.g., a 2D touch screen or buttons mounted on a wall. We designed and investigated a mid-air reaction time training system with an immersive virtual reality (VR) headset. 12 participants performed an eye-hand coordination reaction test in three conditions: both in mid-air with or without VR controller as well as with passive haptic feedback through hitting a soft-surface wall. We also altered target and cursor sizes and used a Fitts’ law task to analyze user performance. According to the results, subjects were slower and their throughput was lower when they hit a solid surface to interact with virtual targets. Our results show that Fitts’s model can be applied to these systems to measure and assess participant training.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {30},
numpages = {5},
keywords = {Fitts’ task, Virtual Reality, mid-air interaction, performance assessment, reaction test},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364246,
author = {Adolf, Jind\v{r}ich and K\'{a}n, Peter and Outram, Benjamin and Kaufmann, Hannes and Dole\v{z}al, Jarom\'{\i}r and Lhotsk\'{a}, Lenka},
title = {Juggling in VR: Advantages of Immersive Virtual Reality in Juggling Learning},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364246},
doi = {10.1145/3359996.3364246},
abstract = {In this paper, we follow up on research dealing with motion learning in Virtual Reality (VR). We investigate the impact of VR motion learning on motion performance, motivation for motion learning and willingness to continue with the motion learning. In our research, we used three ball juggling as a subject of learning. We performed a user study with 30 participants. A VR application was used in our study which allows setting up lower gravity and thus slowing down the motion for learning purposes. The results were statistically evaluated and we comment on the positive influence of virtual reality on motivation and possibilities of using VR in the motion learning process.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {31},
numpages = {5},
keywords = {Virtual Reality, juggling, motion learning, motor learning},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364259,
author = {McHugh, Natalie and Jung, Sungchul and Hoermann, Simon and Lindeman, Robert W.},
title = {Investigating a Physical Dial as a Measurement Tool for Cybersickness in Virtual Reality},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364259},
doi = {10.1145/3359996.3364259},
abstract = {This study explores ways to increase comfort in Virtual Reality by minimizing cybersickness. Cybersickness is related to classical motion sickness and causes unwanted symptoms when using immersive technologies. We developed a dial interface to accurately capture momentary user cybersickness and feed this information back to the user. Using a seated VR roller coaster environment, we found that the dial is significantly positively correlated with post-immersion questionnaires and is a valid tool compared to verbal rating approaches.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {32},
numpages = {5},
keywords = {cybersickness, human-computer interaction, physical dial, virtual reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364276,
author = {Gupta, Kunal and Hajika, Ryo and Pai, Yun Suen and Duenser, Andreas and Lochner, Martin and Billinghurst, Mark},
title = {In AI We Trust: Investigating the Relationship between Biosignals, Trust and Cognitive Load in VR},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364276},
doi = {10.1145/3359996.3364276},
abstract = {Human trust is a psycho-physiological state that is difficult to measure, yet is becoming increasingly important for the design of human-computer interactions. This paper explores if human trust can be measured using physiological measures when interacting with a computer interface, and how it correlates with cognitive load. In this work, we present a pilot study in Virtual Reality (VR) that uses a multi-sensory approach of Electroencephalography (EEG), galvanic skin response (GSR), and Heart Rate Variability (HRV) to measure trust with a virtual agent and explore the correlation between trust and cognitive load. The goal of this study is twofold; 1) to determine the relationship between biosignals, or physiological signals with trust and cognitive load, and 2) to introduce a pilot study in VR based on cognitive load level to evaluate trust. Even though we could not report any significant main effect or interaction of cognitive load and trust from the physiological signal, we found that in low cognitive load tasks, EEG alpha band power reflects trustworthiness on the agent. Moreover, cognitive load of the user decreases when the agent is accurate regardless of task’s cognitive load. This could be possible because of small sample size, tasks not stressful enough to induce high cognitive load due to lab study and comfortable environment or timestamp synchronisation error due to fusing data from various physiological sensors with different sample rate.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {33},
numpages = {10},
keywords = {Cognitive Load, Physiological signals, Trust, Virtual Assistant, Virtual Reality},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364258,
author = {Jackson, Bret and Beckham, Kayla and Cohen, Anael Kuperwajs and Heggeseth, Brianna C.},
title = {Comparing Convex Region-of-Interest Selection Techniques for Surface Geometry},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364258},
doi = {10.1145/3359996.3364258},
abstract = {Selecting 3D regions-of-interest (ROI) in surface geometry is essential for 3D modeling, but few 3D user interfaces using fully manual input for ROI selection exist. Furthermore, their relative performance is not well studied. We present an evaluation comparing three ROI techniques: Volume Cube [Ulinski et al. 2007], Slice-n- Swipe [Bacim et al. 2014], and Yea Big Yea High Selection [Jackson et al. 2018]. Results show that Yea Big Yea High is best for tasks requiring high accuracy and speed, but modifications may be needed for use in dense geometry or with non-convex ROI.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {34},
numpages = {5},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364264,
author = {Pham, Duc-Minh and Stuerzlinger, Wolfgang},
title = {Is the Pen Mightier than the Controller? A Comparison of Input Devices for Selection in Virtual and Augmented Reality},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364264},
doi = {10.1145/3359996.3364264},
abstract = {Controllers are currently the typical input device for commercial Virtual Reality (VR) systems. Yet, such controllers are not as efficient as other devices, including the mouse. This motivates us to investigate devices that substantially exceed the controller’s performance, for both VR and Augmented Reality (AR) systems. We performed a user study to compare several input devices, including a mouse, controller, and a 3D pen-like device on a VR and AR pointing task. Our results show that the 3D pen significantly outperforms modern VR controllers in all evaluated measures and that it is comparable to the mouse. Participants also liked the 3D pen more than the controller. Finally, we show how 3D pen devices could be integrated into today’s VR and AR systems.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {35},
numpages = {11},
keywords = {3D pointing, Virtual and Augmented Reality, input devices},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364274,
author = {Munsinger, Brita and Quarles, John},
title = {Augmented Reality for Children in a Confirmation Task: Time, Fatigue, and Usability},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364274},
doi = {10.1145/3359996.3364274},
abstract = {The objective of this paper is to explore three different interaction methods in a confirmation task on a head-mounted Augmented Reality (AR) device with a population of children aged 9-11 years. The three interaction methods we look at are voice recognition, gesture recognition, and controller. We conducted a within-subjects study using a Fitts’ Law confirmation task performed by children with a Microsoft HoloLens. We measured elapsed time during the completion of the tasks. Also, we collected usability and fatigue measures using the System Usability Scale and the OMNI RPE (Ratings of Perceived Exertion) scale. We found significant differences between voice and controller for time, fatigue and usability. We also found significant differences between gesture and controller for time, fatigue and usability. We hope to apply the results of this study to improve augmented reality educational tools for children in the future.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {36},
numpages = {5},
keywords = {Augmented Reality, Children, Fitts’ Law, Usability Studies},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364254,
author = {Machuca, Mayra D. Barrera and Stuerzlinger, Wolfgang and Asente, Paul},
title = {Smart3DGuides: Making Unconstrained Immersive 3D Drawing More Accurate},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364254},
doi = {10.1145/3359996.3364254},
abstract = {Most current commercial Virtual Reality (VR) drawing applications for creativity rely on freehand 3D drawing as their main interaction paradigm. However, the presence of the additional third dimension makes accurate freehand drawing challenging. Some systems address this problem by constraining or beautifying user strokes, which can be intrusive and can limit the expressivity of freehand drawing. In this paper, we evaluate the effectiveness of relying solely on visual guidance to increase overall drawing shape-likeness. We identified a set of common mistakes that users make while creating freehand strokes in VR and then designed a set of visual guides, the Smart3DGuides, which help users avoid these mistakes. We evaluated Smart3DGuides in two user studies, and our results show that non-constraining visual guides help users draw more accurately.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {37},
numpages = {13},
keywords = {3D User Interfaces, Drawing, Virtual Reality Drawing},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364251,
author = {Sun, Junwei and Stuerzlinger, Wolfgang},
title = {Extended Sliding in Virtual Reality},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364251},
doi = {10.1145/3359996.3364251},
abstract = {Although precise 3D positioning is not always necessary in virtual environments, it is still an important task for current and future applications of Virtual Reality (VR), including 3D modelling, engineering, and scientific applications. We focus on 3D positioning techniques in immersive environments that use a 6DOF controller as input device and present a new technique that improves 3D positioning performance in VR, in both speed and accuracy. Towards this goal, we adapted an extended sliding technique to VR systems with a controller as input device and compared it with previously presented 3DOF positioning techniques. The results showed that our new Extended VR Sliding technique significantly improved the accuracy for 3D positioning tasks, especially for targets in contact with the scene.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {38},
numpages = {5},
keywords = {3D positioning, object sliding},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@inproceedings{10.1145/3359996.3364271,
author = {Tsykunov, Evgeny and Ibrahimov, Roman and Vasquez, Derek and Tsetserukou, Dzmitry},
title = {SlingDrone: Mixed Reality System for Pointing and Interaction Using a Single Drone},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359996.3364271},
doi = {10.1145/3359996.3364271},
abstract = {We propose SlingDrone, a novel Mixed Reality interaction paradigm that utilizes a micro-quadrotor as both pointing controller and interactive robot with a slingshot motion type. The drone attempts to hover at a given position while the human pulls it in desired direction using a hand grip and a leash. Based on the displacement, a virtual trajectory is defined. To allow for intuitive and simple control, we use virtual reality (VR) technology to trace the path of the drone based on the displacement input. The user receives force feedback propagated through the leash. Force feedback from SlingDrone coupled with visualized trajectory in VR creates an intuitive and user friendly pointing device. When the drone is released, it follows the trajectory that was shown in VR. Onboard payload (e.g. magnetic gripper) can perform various scenarios for real interaction with the surroundings, e.g. manipulation or sensing. Unlike HTC Vive controller, SlingDrone does not require handheld devices, thus it can be used as a standalone pointing technology in VR.},
booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {39},
numpages = {5},
keywords = {haptics, human-robot interaction, mixed reality, quadrotor},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

