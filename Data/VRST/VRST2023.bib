@inproceedings{10.1145/3611659.3615711,
author = {Moore, Cameron and Lages, Wallace S},
title = {Planning Locomotion Techniques for Virtual Reality Games},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615711},
doi = {10.1145/3611659.3615711},
abstract = {Locomotion is a fundamental component in many virtual reality (VR) games. However, few techniques have been designed with gameâ€™s demands in mind. In this paper, we propose two locomotion techniques for fast-paced VR games: Repeated Short-Range Teleports and Continuous Movement Pads. We conducted a user study with 27 participants using these techniques against Smooth Locomotion and Teleport in a game-like scenario. We found that Movement Pads can be a suitable alternative for games, with competitive performance on various criteria such as time, damage taken, usability, workload, and user preference. On the other hand, Repeated Short-Range Teleport displayed lower usability and higher mental workload.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {1},
numpages = {10},
keywords = {Games, Human-Computer Interaction, Locomotion, Movement, Virtual Reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615701,
author = {Franzluebbers, Anton and Johnsen, Kyle},
title = {Versatile Mixed-method Locomotion under Free-hand and Controller-based Virtual Reality Interfaces},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615701},
doi = {10.1145/3611659.3615701},
abstract = {Locomotion systems that allow the user to interact with large virtual spaces require precise input, competing with the same inputs available for performing a task in the virtual world. Despite extensive research on hand tracking input modalities, there is a lack of a widely adopted mechanism that offers general-purpose, high-precision locomotion across various applications. This research aims to address this gap by proposing a design that combines teleportation with a grab-pull locomotion scheme to bridge the divide between long-distance and high-precision locomotion in both a tracked-controller and free-hand environment. The implementation details for both tracked controller and tracked hand environments are presented and evaluated through a user study. The study findings indicate that each locomotion mechanism holds value for different tasks, with grab-pull providing more benefit in scenarios where smaller, more precise positioning is required. As found in prior research, controller tracking was found to be faster than hand tracking, but all participants were able to successfully use the locomotion system with both interfaces.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {2},
numpages = {10},
keywords = {controller, free-hand, hand tracking, interaction, locomotion, virtual reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615687,
author = {Somarathna, Rukshani and Elvitigala, Don Samitha and Yan, Yijun and Quigley, Aaron J and Mohammadi, Gelareh},
title = {Exploring User Engagement in Immersive Virtual Reality Games through Multimodal Body Movements},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615687},
doi = {10.1145/3611659.3615687},
abstract = {User engagement in Virtual Reality (VR) games is crucial for creating immersive and captivating gaming experiences that meet the expectations of players. However, understanding and measuring these levels in VR games presents a challenge for game designers, as current methods, such as self-reports, may be limited in capturing the full extent of user engagement. Additionally, approaches based on biological signals to measure engagement in VR games present complications and challenges, including signal complexity, interpretation difficulties, and ethical concerns. This study explores body movements, as a novel approach to measure user engagement in VR gaming. We employ E4, emteqPRO, and off-the-shelf IMUs to measure the body movements from diverse participants engaged in multiple VR games. Further, we examine the simultaneous occurrence of player motivation and physiological responses to explore potential associations with body movements. Our findings suggest that body movements hold promise as a reliable and objective indicator of user engagement, offering game designers valuable insights on generating more engaging and immersive experiences.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {3},
numpages = {8},
keywords = {Body Movements, Data-driven methods, Emotions, Engagement, Virtual Reality Games},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615698,
author = {Jung, Sungchul and Wu, Yuanjie and Lukosch, Stephan and Lukosch, Heide and Mckee, Ryan Douglas and Lindeman, Robert W.},
title = {Cross-Reality Gaming: Comparing Competition and Collaboration in an Asymmetric Gaming Experience},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615698},
doi = {10.1145/3611659.3615698},
abstract = {Due to the level of immersion and differences in the user interface, there can be a very large discrepancy in the user experience between users in immersive systems and non-immersive systems when playing games together. To investigate the impact of the cross-reality experience, which refers to the asymmetric use of eXtended Reality, we aim to understand the different affordances and experiences in an asymmetric setup, where one participant uses a desktop setup with a mouse and keyboard, and one uses a virtual reality (VR) headset and controller in two different task modes, Competition or Collaboration. In our research, a pair of participants played a game in real-time, using either the VR setup or the desktop setup. In Competition mode, the two participants were asked to defeat each other. In Collaboration mode, the pair of participants played as a team and were asked to defeat a pair of AI enemies. Our results show the VR group reported a better gaming experience and perceptual responses compared to the desktop group regardless of game mode, but that the desktop group showed superior gaming performance compared to the VR group in Competition mode.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {4},
numpages = {10},
keywords = {asymmetric platform, collaboration, competition, cross-platform, cross-reality, gaming experience, shared experience, virtual reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615692,
author = {Schenkluhn, Marius and Peukert, Christian and Greif-Winzrieth, Anke and Weinhardt, Christof},
title = {Does One Keyboard Fit All? Comparison and Evaluation of Device-Free Augmented Reality Keyboard Designs},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615692},
doi = {10.1145/3611659.3615692},
abstract = {Virtual keyboard designs are widely discussed with the increasing prevalence of head-mounted and lightweight Mixed Reality devices. However, isolated design suggestions with distinct implementations may lack comparability in terms of performance, learnability, and user preference. We compare three promising device-free text-entry solutions for Augmented Reality (AR) on the Microsoft HoloLens 2. The virtual keyboards comprise dwell-based eye-gaze input, eye-gaze with pinch-gesture-commit input, and mid-air tap typing on virtual QWERTY-keyboards. We conducted a controlled within-subjects lab experiment with 27 subjects measuring typing performance, task load, usability, and preference across the three keyboards. Users state distinct preferences for the respective keyboards and weight the advantages and disadvantages differently. Considering diverse usage scenarios, subjects would even prefer these input modes over speech or physical keyboard input. The results indicate that virtual keyboard design shall be tailored to individual user preferences. Therefore, this study provides essential insights into designing AR keyboards for heterogeneous user groups.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {5},
numpages = {11},
keywords = {augmented reality, eye tracking, laboratory experiment, text entry},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615700,
author = {Calepso, Aimee Sousa and Fleck, Philipp and Schmalstieg, Dieter and Sedlmair, Michael},
title = {Exploring Augmented Reality for Situated Analytics with Many Movable Physical Referents},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615700},
doi = {10.1145/3611659.3615700},
abstract = {Situated analytics (SitA) uses visualization in the context of physical referents, typically by using augmented reality (AR). We want to pave the way toward studying SitA in more suitable and realistic settings. Toward this goal, we contribute a testbed to evaluate SitA based on a scenario in which participants play the role of a museum curator and need to organize an exhibition of music artifacts. We conducted two experiments: First, we evaluated an AR headset interface and the testbed itself in an exploratory manner. Second, we compared the AR headset to a tablet interface. We summarize the lessons learned as guidance for designing and evaluating SitA.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {6},
numpages = {12},
keywords = {Augmented Reality, Immersive analytics, Situated analytics},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615710,
author = {Ullah, A K M Amanat and Delamare, William and Hasan, Khalad},
title = {Exploring Users' Pointing Performance on Virtual and Physical Large Curved Displays},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615710},
doi = {10.1145/3611659.3615710},
abstract = {Large curved displays have emerged as a powerful platform for collaboration, data visualization, and entertainment. These displays provide highly immersive experiences, a wider field of view, and higher satisfaction levels. Yet, large curved displays are not commonly available due to their high costs. With the recent advancement of Head Mounted Displays (HMDs), large curved displays can be simulated in Virtual Reality (VR) with minimal cost and space requirements. However, to consider the virtual display as an alternative to the physical display, it is necessary to uncover user performance differences (e.g., pointing speed and accuracy) between these two platforms. In this paper, we explored usersâ€™ pointing performance on both physical and virtual large curved displays. Specifically, with two studies, we investigate usersâ€™ performance between the two platforms for standard pointing factors such as target width, target amplitude as well as usersâ€™ position relative to the screen. Results from user studies reveal no significant difference in pointing performance between the two platforms when users are located at the same position relative to the screen. In addition, we observe usersâ€™ pointing performance improves when they are located at the center of a semi-circular display compared to off-centered positions. We conclude by outlining design implications for pointing on large curved virtual displays. These findings show that large curved virtual displays are a viable alternative to physical displays for pointing tasks.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {7},
numpages = {11},
keywords = {Curved Display, Display Curvatures, Fitts Law, Large Physical Display, Large Virtual Display, Pointing Performance},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615686,
author = {Batmaz, Anil Ufuk and Turkmen, Rumeysa and Sarac, Mine and Barrera Machuca, Mayra Donaji and Stuerzlinger, Wolfgang},
title = {Re-investigating the Effect of the Vergence-Accommodation Conflict on 3D Pointing},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615686},
doi = {10.1145/3611659.3615686},
abstract = {The vergence-accommodation conflict (VAC) limits user performance in current Virtual Reality (VR) systems. In this paper, we investigate the effects of the VAC in a single-focal VR system using three experimental conditions: with no VAC, with a constant VAC, and with a varying VAC. Previous work in this area had yielded conflicting results, so we decided to re-investigate this issue. Eighteen participants performed an ISO 9241:411 task in a study that closely replicates previous work, except that the angle of the task space was rotated 20 degrees downward, to make the task less fatiguing to perform, which addresses a potential confound in previous work. We found that the varying VAC condition had worse performance than the other conditions, which indicates that the contrasting results in previous work were very likely due to biomechanical factors. We hope that our work contributes to the understanding of the influence of the VAC in VR systems and potential strategies for improving user experience and performance in immersive virtual environments.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {8},
numpages = {10},
keywords = {3D pointing, Fittsâ€™ Law, VR, vergence-accommodation conflict},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615695,
author = {Brandst\"{a}tter, Klara and Steed, Anthony},
title = {Dialogues For One: Single-User Content Creation Using Immersive Record and Replay},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615695},
doi = {10.1145/3611659.3615695},
abstract = {Non-player characters are an essential element of many 3D and virtual reality experiences. They can make the experiences feel more lively and populated. Animation for non-player characters is often motion-captured using expensive hardware and the post-processing steps are time-consuming, especially when capturing multiple people at once. Using record and replay techniques in virtual reality can offer cheaper and easier ways of motion capture since the user is already tracked. We use immersive record and replay to enable a single user to create stacked recordings of themselves. We provide tools to help the user interact with their previous recorded self and in doing so allow them to create believable interactive scenarios with multiple characters that can be used to populate virtual environments. We create a small dialogue dataset with two amateur actors who used our tool to record dialogues alone and together in virtual reality. To evaluate whether stacked recordings are qualitatively comparable to conventional multi-user recordings and whether people could tell the difference between the two, we conducted two user studies, one online and one in virtual reality with 89 participants in total. We found that participants could not tell the difference and even slightly preferred stacked recordings.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {9},
numpages = {11},
keywords = {content creation, record and replay, virtual reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615718,
author = {Yu, Zhongyuan and Zeidler, Daniel and Victor, Victor and Mcginity, Matthew},
title = {Dynascapeâ€¯: Immersive Authoring of Real-World Dynamic Scenes with Spatially Tracked RGB-D Videos},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615718},
doi = {10.1145/3611659.3615718},
abstract = {In this paper, we present Dynascape, an immersive approach to the composition and playback of dynamic real-world scenes in mixed and virtual reality. We use spatially tracked RGB-D cameras to capture point cloud representations of arbitrary dynamic real-world scenes. Dynascape provides a suite of tools for spatial and temporal editing and composition of such scenes, as well as fine control over their visual appearance. We also explore strategies for spatiotemporal navigation and different tools for the in situ authoring and viewing of mixed and virtual reality scenes. Dynascape is intended as a research platform for exploring the creative potential of dynamic point clouds captured with mobile, tracked RGB-D cameras. We believe our work represents a first attempt to author and playback spatially tracked RGB-D video in an immersive environment, and opens up new possibilities for involving dynamic 3D scenes in virtual space.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {10},
numpages = {12},
keywords = {Data Visualization, Human Computer Interaction, Immersive Authoring},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615683,
author = {Plabst, Lucas and Raikwar, Aditya and Oberd\"{o}rfer, Sebastian and Ortega, Francisco Raul and Niebling, Florian},
title = {Exploring Unimodal Notification Interaction and Display Methods in Augmented Reality},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615683},
doi = {10.1145/3611659.3615683},
abstract = {As we develop computing platforms for augmented reality (AR) head-mounted display (HMDs) technologies for social or workplace environments, understanding how users interact with notifications in immersive environments has become crucial. We researched effectiveness and user preferences of different interaction modalities for notifications, along with two types of notification display methods. In our study, participants were immersed in a simulated cooking environment using an AR-HMD, where they had to fulfill customer orders. During the cooking process, participants received notifications related to customer orders and ingredient updates. They were given three interaction modes for those notifications: voice commands, eye gaze and dwell, and hand gestures. To manage multiple notifications at once, we also researched two different notification list displays, one attached to the userâ€™s hand and one in the world. Results indicate that participants preferred using their hands to interact with notifications and having the list of notifications attached to their hands. Voice and gaze interaction was perceived as having lower usability than touch.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {11},
numpages = {11},
keywords = {augmented reality, display methods, eye gaze, interaction, notifications, voice commands},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615694,
author = {Schubert, Ryan and Bruder, Gerd and Welch, Greg},
title = {Intuitive User Interfaces for Real-Time Magnification in Augmented Reality},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615694},
doi = {10.1145/3611659.3615694},
abstract = {Various reasons exist why humans desire to magnify portions of our visually perceived surroundings, e.g., because they are too far away or too small to see with the naked eye. Different technologies are used to facilitate magnification, from telescopes to microscopes using monocular or binocular designs. In particular, modern digital cameras capable of optical and/or digital zoom are very flexible as their high-resolution imagery can be presented to users in real-time with displays and interfaces allowing control over the magnification. In this paper, we present a novel design space of intuitive augmented reality (AR) magnifications where an AR head-mounted display is used for the presentation of real-time magnified camera imagery. We present a user study evaluating and comparing different visual presentation methods and AR interaction techniques. Our results show different advantages for unimanual, bimanual, and situated AR magnification window interfaces, near versus far vergence distances for the image presentation, and five different user interfaces for specifying the scaling factor of the imagery.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {12},
numpages = {10},
keywords = {3D User Interfaces, Augmented Reality, Magnification},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615715,
author = {Aoki, Hiroto and Hiroi, Yuichi and Itoh, Yuta and Rekimoto, Jun},
title = {Retinal Homing Display: Head-Tracking Auto-stereoscopic Retinal Projection Display},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615715},
doi = {10.1145/3611659.3615715},
abstract = {This paper introduces Retinal Homing Display, which presents focus-free stereoscopic images via retinal projection, thus eliminating the need for the user to wear additional equipment. Traditional 3D displays, typically classified as either naked-eye stereoscopic or wearable, present inherent challenges: the former involves a compromise between resolution and accurate depth perception, while the latter imposes an additional burden on the user. Our proposed display employs optical and mechanical mechanisms to converge projector light at the userâ€™s pupil center, simultaneously tracking eye movements. This lets the user perceive focus-free, high-resolution stereoscopic images without wearable equipment. We implemented a proof-of-concept system utilizing a robotic arm and a Dihedral Corner Reflector Array (DCRA), subsequently evaluating image quality and its eyebox. Finally, we discuss the limitations of the current prototype and outline potential directions for future research.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {13},
numpages = {10},
keywords = {autostereoscopic display, motion-following display, retinal projection},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615707,
author = {Bonner, Jolie and Mathis, Florian and O'Hagan, Joseph and Mcgill, Mark},
title = {When Filters Escape the Smartphone: Exploring Acceptance and Concerns Regarding Augmented Expression of Social Identity for Everyday AR},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615707},
doi = {10.1145/3611659.3615707},
abstract = {Mass adoption of Everyday Augmented Reality (AR) glasses will enable pervasive augmentation of our expression of social identity through AR filters, transforming our perception of self and others. However, despite filtersâ€™ prominent and often problematic usage in social media, research has yet to reflect on the potential impact AR filters might have when brought into everyday life. Informed by our survey of 300 existing popular AR filters used on Snapchat, Instagram and Tiktok, we conducted an AR-in-VR user study where participants (N=24) were exposed to 18 filters across six categories. We evaluated the social acceptability of these augmentations around others and attitudes towards an individualâ€™s augmented self.Our findings highlight 1) how users broadly respected another individualâ€™s augmented self; 2) positive use cases, such as supporting the presentation of gender identity; and 3) tensions around applying AR filters to others (e.g. censorship, changing protected characteristics) and their impact on self-perception (e.g. perpetuating unrealistic beauty standards). We raise questions regarding the rights of individuals to augment and be augmented that provoke the need for further consideration of AR augmentations in society.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {14},
numpages = {14},
keywords = {AR Filters, Augmented Identity, Augmented Reality, Identity, Mediated Perception, Self-Presentation, Social Identity},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615703,
author = {Landeck, Maximilian and Unruh, Fabian and Lugrin, Jean-Luc and Latoschik, Marc Erich},
title = {From Clocks to Pendulums: A Study on the Influence of External Moving Objects on Time Perception in Virtual Environments},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615703},
doi = {10.1145/3611659.3615703},
abstract = {This paper investigates the relationship between perceived object motion and the experience of time in virtual environments. We developed an application to measure how the motion properties of virtual objects and the degree of immersion and embodiment may affect the time experience. A first study (n = 145) was conducted remotely using an online video survey, while a second study (n = 60) was conducted under laboratory conditions in virtual reality (VR). Participants in both studies experienced seven different virtual objects in a randomized order and then answered questions about time experience. The VR study added an "embodiment" condition in which participants were either represented by a virtual full body or lacked any form of virtual body representation. In both studies, time was judged to pass faster when viewing oscillating motion in immersive and non-immersive settings and independently of the presence or absence of a virtual body. This trend was strongest when virtual pendulums were displayed. Both studies also found a significant inverse correlation between the passage of time and boredom. Our results support the development of applications that manipulate the perception of time in virtual environments for therapeutic use, for instance, for disorders such as depression, autism, and schizophrenia. Disturbances in the perception of time are known to be associated with these disorders.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {15},
numpages = {11},
keywords = {embodiment, extended reality, mixed reality, time perception, virtual reality, virtual time, virtual zeitgeber},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615682,
author = {Choudhary, Zubin and Bruder, Gerd and Welch, Greg},
title = {Visual Hearing Aids: Artificial Visual Speech Stimuli for Audiovisual Speech Perception in Noise},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615682},
doi = {10.1145/3611659.3615682},
abstract = {Speech perception is optimal in quiet environments, but noise can impair comprehension and increase errors. In these situations, lip reading can help, but it is not always possible, such as during an audio call or when wearing a face mask. One approach to improve speech perception in these situations is to use an artificial visual lip reading aid. In this paper, we present a user study (N = 17) in which we compared three levels of audio stimuli visualizations and two levels of modulating the appearance of the visualization based on the speech signal, and we compared them against two control conditions: an audio-only condition, and a real human speaking. We measured participantsâ€™ speech reception thresholds (SRTs) to understand the effects of these visualizations on speech perception in noise. These thresholds indicate the decibel levels of the speech signal that are necessary for a listener to receive the speech correctly 50\% of the time. Additionally, we measured the usability of the approaches and the user experience. We found that the different artificial visualizations improved participantsâ€™ speech reception compared to the audio-only baseline condition, but they were significantly poorer than the real human condition. This suggests that different visualizations can improve speech perception when the speakerâ€™s face is not available. However, we also discuss limitations of current plug-and-play lip sync software and abstract representations of the speaker in the context of speech perception.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {16},
numpages = {10},
keywords = {Speech perception, background noise, hearing, speechreading, user study, virtual humans, visualizations},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615713,
author = {Bauer, Valentin and Adjorlu, Ali and Pedersen, Linnea Bjerregaard and Bouchara, Tifanie and Serafin, Stefania},
title = {Music Therapy in Virtual Reality for Autistic Children with Severe Learning Disabilities},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615713},
doi = {10.1145/3611659.3615713},
abstract = {Music Therapy (MT) has shown many benefits in helping autistic children, but some challenges remain due to childrenâ€™s social anxiety and sensory issues. Yet, very few studies have investigated how Virtual Reality (VR) could help to increase the accessibility of MT approaches. This paper presents an exploratory study investigating the use of VR to perform MT sessions for autistic children with severe learning disabilities and complex needs. The study is performed in terms of acceptability, usability, and social communication. A collaborative MT approach was designed in close collaboration with music therapists from Denmark and psychologists from France, using head-mounted display-based VR. Testing were conducted with thirteen children with various neurodevelopmental conditions and intellectual disabilities at a childrenâ€™s day hospital in Paris. The results indicate positive acceptability and usability for these children, and suggest a positive effect of MT in VR regarding communication.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {17},
numpages = {9},
keywords = {autism, intellectual disabilities, music therapy, virtual reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615706,
author = {Rings, Sebastian and Schmidt, Susanne and Schmelter, Thereza and Brosius, Maximilian and Steinicke, Frank},
title = {Gaze Assistance for Older Adults during Throwing in Virtual Reality and its Effects on Performance and Motivation},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615706},
doi = {10.1145/3611659.3615706},
abstract = {Initial motivation when starting exergaming is a key factor towards enabling long-term engagement and adherence, especially among older adults. To increase, in particular, the initial motivation of older adults, we introduce the concept of diminishing gaze assistance (GA), assess its feasibility for virtual reality (VR) exergames, and investigate the effects on motor learning, performance, and motivation in older adult users. First, we conducted a focus group followed by a pre-study on the development of VR exergames for older adults and VR gaze assistance. The results informed the design and implementation of our gaze-assisted throwing exergame, which was then evaluated in a follow-up main study. Participants of the main study were randomly assigned to the GA and Motor (control) group, and had to complete a VR throwing task, in which participants had to aim and throw at three targets at varying angles. The GA group received declining gaze assistance, in which the ball trajectory was initially guided by their gaze (rather than their physical (motor) throwing) before guidance was gradually reduced until their physical (motor) throwing ability was solely responsible for hitting the target. Motivation and user experience were assessed using the Questionnaire on Current Motivation before and during, and the short scale of intrinsic motivation questionnaire after the task. The results show that the GA was generally perceived positively. In particular, the initial confidence of the GA group was rated higher, and we observed evidence suggesting increased confidence throughout the trial.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {18},
numpages = {11},
keywords = {errorless learning, eyetracking, gaze assistance, motivation},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615693,
author = {Chen, Di Laura and Giordano, Marcello and Benko, Hrvoje and Grossman, Tovi and Santosa, Stephanie},
title = {GazeRayCursor: Facilitating Virtual Reality Target Selection by Blending Gaze and Controller Raycasting},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615693},
doi = {10.1145/3611659.3615693},
abstract = {Raycasting is a common method for target selection in virtual reality (VR). However, it results in selection ambiguity whenever a ray intersects multiple targets that are located at different depths. To resolve these ambiguities, we estimate object depth by projecting the closest intersection between the gaze and controller rays onto the controller ray. An evaluation of this method found that it significantly outperformed a previous eye convergence depth estimation technique. Based on these results, we developed GazeRayCursor, a novel selection technique that enhances Raycasting, by leveraging gaze for object depth estimation. In a second study, we compared two variations of GazeRayCursor with RayCursor, a recent technique developed for a similar purpose, in a dense target environment. The results indicated that GazeRayCursor decreased selection time by 45.0\% and reduced manual depth adjustments by a factor of 10 in a dense target environment. Our findings showed that GazeRayCursor is an effective method for target disambiguation in VR selection without incurring extra effort.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {19},
numpages = {11},
keywords = {VR, controller, disambiguation, gaze, object selection, raycasting},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615685,
author = {Rebol, Manuel and Pietroszek, Krzysztof and Sikka, Neal and Ranniger, Claudia and Hood, Colton and Rutenberg, Adam and Sasankan, Puja and G\"{u}tl, Christian},
title = {Evaluating Augmented Reality Communication: How Can We Teach Procedural Skill in AR?},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615685},
doi = {10.1145/3611659.3615685},
abstract = {Augmented reality (AR) has great potential for use in healthcare applications, especially remote medical training and supervision. In this paper, we analyze the usage of an AR communication system to teach a medical procedure, the placement of a central venous catheter (CVC) under ultrasound guidance. We examine various AR communication and collaboration components, including gestural communication, volumetric information, annotations, augmented objects, and augmented screens. We compare how teaching in AR differs from teaching through videoconferencing-based communication. Our results include a detailed medical training steps analysis in which we compare how verbal and visual communication differs between video and AR training. We identify procedural steps in which medical experts give visual instructions utilizing AR components. We examine the change in AR usage and interaction over time and recognize patterns between users. Moreover, AR design recommendations are given based on post-training interviews.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {20},
numpages = {11},
keywords = {Augmented Reality, Remote Collaboration, Telehealth, Volumetric Communication},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615684,
author = {Dunn, Sebastian and W\"{u}nsche, Burkhard C. and Allison, Jane R. and Thompson, Samuel E. R. and Lange-Nawka, Dominik},
title = {Hands-on DNA: Exploring the Impact of Virtual Reality on Teaching DNA Structure and Function},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615684},
doi = {10.1145/3611659.3615684},
abstract = {Molecular biology is a demanding subject, requiring students to master abstract, three-dimensional (3D) concepts across a range of spatial scales. Virtual reality (VR) is a medium that excels at portraying scale and 3D concepts, and allows people to have tangible experiences of otherwise intangible subjects. This paper describes Hands-on DNA, a virtual reality learning experience for teaching undergraduate university students about the scale and structure of deoxyribose nucleic acid (DNA), a central molecule in molecular biology. The intention of Hands-on DNA is to leverage the advantages of virtual reality against specific challenges faced in teaching molecular biology. We derive design requirements motivated by pedagogy, provide guidelines, and discuss lessons learned during development. Our user study shows that students perceive Hands-on DNA as a fun, engaging, effective learning tool, and that it addresses some of the weaknesses in molecular biology education. Our results also suggest that new interaction techniques to support learning in VR need to be developed (e.g., for note taking) and that the increasing penetration of recreational VR increases studentsâ€™ expectations and hence the risk of students being disappointed of VR learning tools.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {21},
numpages = {11},
keywords = {DNA, Virtual reality, constructivism, education, gamification, molecular biology, multimedia education},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615691,
author = {Kintscher, Michael and Huang, Jinbin and Arunkumar, Anjana and Amresh, Ashish and Bryan, Chris},
title = {Measuring and Comparing Collaborative Visualization Behaviors in Desktop and Augmented Reality Environments},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615691},
doi = {10.1145/3611659.3615691},
abstract = {Augmented reality (AR) provides a significant opportunity to improve collaboration between co-located team members jointly analyzing data visualizations, but existing rigorous studies are lacking. We present a novel method for qualitatively encoding the positions of co-located users collaborating with head-mounted displays (HMDs) to assist in reliably analyzing collaboration styles and behaviors. We then perform a user study on the collaborative behaviors of multiple, co-located synchronously collaborating users in AR to demonstrate this method in practice and contribute to the shortfall of such studies in the existing literature. Pairs of users performed analysis tasks on several data visualizations using both AR and traditional desktop displays. To provide a robust evaluation, we collected several types of data, including software logging of participant positioning, qualitative analysis of video recordings of participant sessions, and pre- and post-study questionnaires including the NASA TLX survey. Our results suggest that the independent viewports of AR headsets reduce the need to verbally communicate about navigating around the visualization and encourage face-to-face and non-verbal communication. Our novel positional encoding method also revealed the overlap of task and communication spaces vary based on the needs of the collaborators.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {22},
numpages = {11},
keywords = {Augmented reality, Co-located collaboration, Visualization},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615709,
author = {Zaman, Faisal and Anslow, Craig and Rhee, Taehyun James},
title = {Vicarious: Context-aware Viewpoints Selection for Mixed Reality Collaboration},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615709},
doi = {10.1145/3611659.3615709},
abstract = {Mixed-perspective, combining egocentric (first-person) and exocentric (third-person) viewpoints, have been shown to improve the collaborative experience in remote settings. Such experiences allow remote users to switch between different viewpoints to gain alternative perspectives of the remote space. However, existing systems lack seamless selection and transition between multiple perspectives that better fit the task at hand. To address this, we present a new approach called Vicarious, which simplifies and automates the selection between egocentric and exocentric viewpoints. Vicarious employs a context-aware method for dynamically switching or highlighting the optimal viewpoint based on user actions and the current context. To evaluate the effectiveness of the viewpoint selection method, we conducted a user study (n = 27) using an asymmetric AR-VR setup where users performed remote collaboration tasks under four distinct conditions: No-view, Manual, Guided, and Automatic selection. The results showed that Guided and Automatic viewpoint selection improved usersâ€™ understanding of the task space and task performance, and reduced cognitive load compared to Manual or No-view selection. The results also suggest that the asymmetric setup had minimal impact on spatial and social presence, except for differences in task load and preference. Based on these findings, we provide design implications for future research in mixed reality collaboration.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {23},
numpages = {11},
keywords = {360-degree Panoramic Video, Mixed Reality, Perspective Sharing., Remote Collaboration, Telepresence, Viewpoint Sharing},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615680,
author = {Ruvimova, Anastasia and Fronchetti, Felipe and Kahn, Boden A and Susin, Luiz Henrique and Hurley, Zekeya and Fritz, Thomas and Hancock, Mark and Shepherd, David},
title = {Ready Worker One? High-Res VR for the Home Office},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615680},
doi = {10.1145/3611659.3615680},
abstract = {Many employees prefer to work from home, yet struggle to squeeze their office into an already fully-utilized space. Virtual Reality (VR) seemingly offered a solution with its ability to transform even modest physical spaces into spacious, productive virtual offices, but hardware challengesâ€”such as low resolutionâ€”have prevented this from becoming a reality. Now that hardware issues are being overcome, we are able to investigate the suitability of VR for daily work. To do so, we (1) studied the physical space that users typically dedicate to home offices and (2) conducted an exploratory study of users working in VR for one week. For (1) we used digital ethnography to study 430 self-published images of software developer workstations in the home, confirming that developers faced myriad space challenges. We used speculative design to re-envision these as VR workstations, eliminating many challenges. For (2) we asked 10 developers to work in their own home using VR for about two hours each day for four workdays, and then interviewed them. We found that working in VR improved focus and made mundane tasks more enjoyable. While some subjects reported issuesâ€”annoyances with the fit, weight, and umbilical cord of the headsetâ€”the vast majority of these issues seem to be addressable. Together, these studies show VR technology has the potential to address many key problems with home workstations, and, with continued improvements, may become an integral part of creating an effective workstation in the home.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {24},
numpages = {12},
keywords = {Field Study, Remote Work, Virtual Reality, Workstations},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615708,
author = {Schott, Ephraim and Makled, Elhassan Belal and Zoeppig, Tony Jan and Muehlhaus, Sebastian and Weidner, Florian and Broll, Wolfgang and Froehlich, Bernd},
title = {UniteXR: Joint Exploration of a Real-World Museum and its Digital Twin},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615708},
doi = {10.1145/3611659.3615708},
abstract = {The combination of smartphone Augmented Reality (AR) and Virtual Reality (VR) makes it possible for on-site and remote users to simultaneously explore a physical space and its digital twin through an asymmetric Collaborative Virtual Environment (CVE). In this paper, we investigate two spatial awareness visualizations to enable joint exploration of a space for dyads consisting of a smartphone AR user and a head-mounted display VR user. Our study revealed that both, a mini-map-based method and an egocentric compass method with a path visualization, enabled the on-site visitors to locate and follow a virtual companion reliably and quickly. Furthermore, the embodiment of the AR user by an inverse kinematics avatar allowed the use of natural gestures such as pointing and waving which was preferred over text messages by the participants of our study. In an expert review in a museum and its digital twin we observed an overall high social presence for on-site AR and remote VR visitors and found that the visualizations and the avatar embodiment successfully facilitated their communication and collaboration.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {25},
numpages = {10},
keywords = {asymmetric exploration, cross-device collaboration, digital twin, mixed reality, smartphone augmented reality, virtual reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615719,
author = {Congdon, Ben J. and Park, Gun Woo (Warren) and Zhang, Jingyi and Steed, Anthony},
title = {Comparing Mixed Reality Agent Representations: Studies in the Lab and in the Wild},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615719},
doi = {10.1145/3611659.3615719},
abstract = {Mixed-reality systems provide a number of different ways of representing users to each other in collaborative scenarios. There is an obvious tension between using media such as video for remote users compared to representations as avatars. This paper includes two experiments (total n = 80) on user trust when exposed to two of three different user representations in an immersive virtual reality environment that also acts as a simulation of typical augmented reality simulations: full body video, head and shoulder video and an animated 3D model. These representations acted as advisors in a trivia quiz. By evaluating trust through advisor selection and self-report, we found only minor differences between representations, but a strong effect of perceived advisor expertise. Unlike prior work, we did not find the 3D model scored poorly on trust, perhaps as a result of greater congruence within an immersive context.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {26},
numpages = {11},
keywords = {Virtual reality, avatars, collaboration, mixed reality, trust},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615705,
author = {Kim, You-Jin and Lu, Joshua and H\"{o}llerer, Tobias},
title = {Dynamic Theater: Location-Based Immersive Dance Theater, Investigating User Guidance and Experience},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615705},
doi = {10.1145/3611659.3615705},
abstract = {Dynamic Theater explores the use of augmented reality (AR) in immersive theater as a platform for digital dance performances. The project presents a locomotion-based experience that allows for full spatial exploration. A large indoor AR theater space was designed to allow users to freely explore the augmented environment. The curated wide-area experience employs various guidance mechanisms to direct users to the main content zones. Results from our 20-person user study show how users experience the performance piece while using a guidance system. The importance of stage layout, guidance system, and dancer placement in immersive theater experiences are highlighted as they cater to user preferences while enhancing the overall reception of digital content in wide-area AR. Observations after working with dancers and choreographers, as well as their experience and feedback are also discussed.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {27},
numpages = {11},
keywords = {Immersive Theater, Mobile Augmented Reality, User Study, Wide-Area},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615702,
author = {Li, Yi and Crowther, Robert and Smiley, Jim and Dwyer, Tim and Tag, Benjamin and Irani, Pourang and Ens, Barrett},
title = {Revisiting Consumed Endurance: A NICE Way to Quantify Shoulder Fatigue in Virtual Reality},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615702},
doi = {10.1145/3611659.3615702},
abstract = {Virtual Reality (VR) is increasingly being adopted in fitness, gaming, and workplace productivity applications for its natural interaction with body movement. A widely accepted method for quantifying the physical fatigue caused by VR interactions is through metrics such as Consumed Endurance (CE). Proposed in 2014, CE calculates the shoulder torque to infer endurance time (ET)â€”i.e. the maximum amount of time a pose can be maintainedâ€”during mid-air interactions. This model remains widely cited but has not been closely examined beyond its initial evaluation, leaving untested assumptions about exertion from low-intensity interactions and its basis on torque. In this paper, we present two VR studies where we (1) collect a baseline dataset that replicates the foundation of CE and (2) extend the initial evaluation in a pointing task from a two-dimensional (2D) screen to a three-dimensional (3D) immersive environment. Our baseline dataset collected from a high-precision tracking system found that the CE model overestimates ET for low-exertion interactions. Further, our studies reveal that a biomechanical model based on only torque cannot account for additional exertion measured when the shoulder angle exceeds 90Â° elevation. Based on these findings, we propose a revised formulation of CE to highlight the need for a hybrid approach in future fatigue modelling.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {28},
numpages = {10},
keywords = {Consumed Endurance, Endurance, Ergonomics, Interaction design, VR interactions},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615704,
author = {Ahmadi, Mohammad and Michalka, Samantha W. and Lenzoni, Sabrina and Ahmadi Najafabadi, Marzieh and Bai, Huidong and Sumich, Alexander and Wuensche, Burkhard and Billinghurst, Mark},
title = {Cognitive Load Measurement with Physiological Sensors in Virtual Reality during Physical Activity},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615704},
doi = {10.1145/3611659.3615704},
abstract = {Many Virtual Reality (VR) experiences, such as learning tools, would benefit from utilising mental states such as cognitive load. Increases in cognitive load (CL) are often reflected in the alteration of physiological responses, such as pupil dilation (PD), electrodermal cctivity (EDA), heart rate (HR), and electroencephalography (EEG). However, the relationship between these physiological responses and cognitive load are usually measured while participants sit in front of a computer screen, whereas VR environments often require a high degree of physical movement. This physical activity can affect the measured signals, making it unclear how suitable these measures are for use in interactive Virtual Reality (VR). We investigate the suitability of four physiological measures as correlates of cognitive load in interactive VR. Suitable measures must be robust enough to allow the learner to move within VR and be temporally responsive enough to be a useful metric for adaptation. We recorded PD, EDA, HR, and EEG data from nineteen participants during a sequence memory task at varying levels of cognitive load using VR, while in the standing position and using their dominant arm to play a game. We observed significant linear relationships between cognitive load and PD, EDA, and EEG frequency band power, but not HR. PD showed the most reliable relationship but has a slower response rate than EEG. Our results suggest the potential for use of PD, EDA, and EEG in this type of interactive VR environment, but additional studies will be needed to assess feasibility under conditions of greater movement.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {29},
numpages = {11},
keywords = {EEG, cognitive load, galvanic skin response, heart rate, physical activity, pupil dilation, virtual reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615696,
author = {Liebers, Jonathan and Burschik, Christian and Gruenefeld, Uwe and Schneegass, Stefan},
title = {Exploring the Stability of Behavioral Biometrics in Virtual Reality in a Remote Field Study: Towards Implicit and Continuous User Identification through Body Movements},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615696},
doi = {10.1145/3611659.3615696},
abstract = {Behavioral biometrics has recently become a viable alternative method for user identification in Virtual Reality (VR). Its ability to identify users based solely on their implicit interaction allows for high usability and removes the burden commonly associated with security mechanisms. However, little is known about the temporal stability of behavior (i.e., how behavior changes over time), as most previous works were evaluated in highly controlled lab environments over short periods. In this work, we present findings obtained from a remote field study (N = 15) that elicited data over a period of eight weeks from a popular VR game. We found that there are changes in peopleâ€™s behavior over time, but that two-session identification still is possible with a mean F1-score of up to 71\%, while an initial training yields 86\%. However, we also see that performance can drop by up to over 50 percentage points when testing with later sessions, compared to the first session, particularly for smaller groups. Thus, our findings indicate that the use of behavioral biometrics in VR is convenient for the user and practical with regard to changing behavior and also reliable regarding behavioral variation.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {30},
numpages = {12},
keywords = {Continuous Identification., Field Study, Implicit User Identification, Virtual Reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615690,
author = {Hu, Yong-Hao and Hatada, Yuji and Narumi, Takuji},
title = {Beyond Mirrors: Exploring Behavioral Changes through Comparative Avatar Design in VR Taiko Drumming},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615690},
doi = {10.1145/3611659.3615690},
abstract = {Most studies on the Proteus Effect, which examines how avatars can influence usersâ€™ behavior through evoked stereotypes, have primarily manipulated only participantsâ€™ own avatars as the independent variable. However, in reality, there are numerous scenarios where individuals recognize their uniqueness by comparing themselves to others. Therefore, this study aimed to explore the impact of recognizing oneâ€™s distinctiveness by comparing oneâ€™s own avatarâ€™s appearance with others on behavioral changes. In our experiment, participants and non-player characters engaged in playing the Japanese drum â€˜Taikoâ€™ together within a virtual environment. They utilized avatars dressed in suits or â€˜Happi,â€™ which is a traditional Japanese festival costume. The results demonstrated that both the uniformity/distinctiveness and the type of avatar appearance played a joint role in influencing the speed and amplitude of arm swings during the taiko performance. This finding provides valuable insights into comprehending the mechanisms of behavior change in settings where multiple avatars interact, such as social virtual reality, and aids in designing virtual spaces that foster appropriate interactions among individuals.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {31},
numpages = {11},
keywords = {avatar, behavioral changes, comparative avatar design, identification, proteus effect, social comparison, virtual reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615689,
author = {Morimoto, Kosuke and Hashiura, Kenta and Watanabe, Keita},
title = {Effect of Virtual Hand's Fingertip Deformation on the Stiffness Perceived Using Pseudo-Haptics},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615689},
doi = {10.1145/3611659.3615689},
abstract = {In this study, using a novel method for haptic presentation based on pseudo-haptics, the perceived stiffness was visually altered by changing the fingertips shape of a virtual hand, as users engaged with objects in a VR environment. While past approaches have primarily focused on instigating such sensations through object deformation, we focused on how an individualâ€™s fingertips deform upon making contact with an object. In this study, we investigated pseudo-haptics based on the deformation of the fingertips of a virtual hand. In Experiment 1, we determined how the shape deformation of a virtual handâ€™s fingertip affected the sense of body ownership. The experiment determined that the maximum change in the fingertip width should be 2.25 times. In Experiment 2, subjects touched a virtual object in the VR space and evaluated the perception of the stiffness of the virtual object. The results confirmed that when the deformation of the fingertip shape of the virtual hand was small, the object was perceived as hard, whereas when it was large, the object was perceived as soft. These results indicated that a haptic presentation is possible without using a haptic device that restricts user movement, which will users could broaden the range of natural interactions in VR spaces.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {32},
numpages = {10},
keywords = {haptics illusions, pseudo-haptics, virtual reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615714,
author = {Awan, Mudassir Ibrahim and Hassan, Waseem and Jeon, Seokhee},
title = {Predicting Perceptual Haptic Attributes of Textured Surface from Tactile Data Based on Deep CNN-LSTM Network},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615714},
doi = {10.1145/3611659.3615714},
abstract = {This paper introduces a framework to predict multi-dimensional haptic attribute values that humans use to recognize the material by using the physical tactile signals (acceleration) generated when a textured surface is stroked. To this end, two spaces are established: a haptic attribute space and a physical signal space. A five-dimensional haptic attribute space is established through human adjective rating experiments with the 25 real texture samples. The physical space is constructed using tool-based interaction data from the same 25 samples. A mapping is modeled between the aforementioned spaces using a newly designed CNN-LSTM deep learning network. Finally, a prediction algorithm is implemented that takes acceleration data and returns coordinates in the haptic attribute space. A quantitative evaluation was conducted to inspect the reliability of the algorithm on unseen textures, showing that the model outperformed other similar models.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {33},
numpages = {9},
keywords = {Haptic texture classification, neural network, psychophysics},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615712,
author = {Tang, Xingyue and Chang, Zhuang and He, Weiping and Billinghurst, Mark and Zhang, Xiaotian},
title = {Exploring Real-time Precision Feedback for AR-assisted Manual Adjustment in Mechanical Assembly},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615712},
doi = {10.1145/3611659.3615712},
abstract = {Augmented Reality (AR) based manual assembly nowadays enables to guide the process of physical tasks, providing intuitive instructions and detailed information in real-time. However, very limited studies have explored AR manual adjustment tasks with precision requirements. In this paper, we develop an AR-assisted guidance system for manual adjustments with relatively high-precision requirements. We first assessed the accuracy of the special-set OptiTrack system to determine the threshold of precision requirements for our user study. We further evaluated the performance of Number-based and Bar-based precision feedback by comparing orienting assembly errors and task completion time, as well as the usability in the user study. We found that the assembly errors of orientation in the Number-based and Bar-based interfaces were significantly lower than the baseline condition, while there was no significant difference between the Number-based and Bar-based interfaces. Furthermore, the Number-based showed faster task completion time, lower workload, and higher usability than the Bar-based condition.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {34},
numpages = {11},
keywords = {Augmented Reality, OptiTrack, manual adjustment, precision feedback},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615681,
author = {Otsuki, Mai and Ichikari, Ryosuke and Ohyama, Junji and Watanabe, Hiroshi and Endo, Hiroshi and Takamatsu, Nobumasa and Okuda, Koji and Matsumura, Yukinori},
title = {Exploring Visual Augmentations for Improving the Operation of a Hydraulic Excavator using Expert Operation Replay},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615681},
doi = {10.1145/3611659.3615681},
abstract = {Hydraulic excavators are widely used in construction work owing to their versatility. However, the general operation of these excavators is complex and novice operators require extensive training to operate them. In this study, we propose a virtual reality (VR)-based training system with three types of visual augmentations using pre-recorded expert operations to support the skill acquirement for handling a hydraulic excavator. To evaluate the effectiveness of the proposed visual augmentations in terms of skill improvement, we compared the scores of the trainees before and after training including combinations of visual augmentations. The results indicated that the display of the lever movement significantly improved the trajectory of the bucket tip, while ghost animation and slow motion did not show significant effects. Furthermore, by showing the lever input and excavator movement of the expert in slow motion, the task completion time increased because of the aftereffect. Our findings not only provide a design guideline for VR-based excavator operation training but can also be applied to augmented reality (AR)/mixed reality (MR) support systems for supporting practical excavator operations.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {35},
numpages = {8},
keywords = {Augmentations, Excavator, Training, Virtual Reality, Visualization},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615688,
author = {Yang, Xuanhui and Zhang, Yan and Yang, Xubo},
title = {Redirected Placement: Evaluating the Redirection of Passive Props during Reach-to-Place in Virtual Reality},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615688},
doi = {10.1145/3611659.3615688},
abstract = {Hand redirection is an effective technique that can provide users with haptic feedback in virtual reality (VR) when a disparity exists between virtual objects and their physical counterparts. Psychophysiological research has revealed the distinct motion profiles of different kinematic phases when people operate hand-object interaction. In this paper, we proposed the Redirected Placement (RP), which determines the new placement of a physical prop using a constrained optimization problem. The visual illusion is used during the "reach-to-place" kinematic phase in the proposed RP method rather than the "reach-to-grasp" phase in the typical Redirected Reach (RR) method. We conducted two experiments based on the proposed RP method. Our first experiment showed that detection thresholds are generally higher with the proposed method compared to the RR method. The second experiment evaluated the embodiment experience with hand redirection using RR-only, RP-only, and RR&amp;RP methods. The results report an enhanced sense of embodiment with the combined use of both RR and RP techniques. Our study further indicates that a 1:1 combination ratio of RR&amp;RP resulted in the closest subjective experience to the baseline.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {36},
numpages = {11},
keywords = {Virtual Reality, hand interaction, hand redirection, passive haptic feedback},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615717,
author = {Groth, Colin and Scholz, Timon and Castillo, Susana and Tauscher, Jan-Philipp and Magnor, Marcus},
title = {Instant Hand Redirection in Virtual Reality Through Electrical Muscle Stimulation-Triggered Eye Blinks},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615717},
doi = {10.1145/3611659.3615717},
abstract = {In this paper we investigate the use of electrical muscle stimulation (EMS) to trigger eye blinks for instant hand redirection in virtual reality (VR). With the rapid development of VR technology and increasing user expectations for realistic experiences, maintaining a seamless match between real and virtual objects becomes crucial for immersive interactions. However, hand movements are fast and sometimes unpredictable, increasing the need for instantaneous redirection. We introduce EMS to the field of hand redirection in VR through precise stimulation of the eyelid muscles. By exploiting the phenomenon of change blindness through natural eye blinks, our novel stimulation model achieves instantaneous, imperceptible hand redirection without the need for eye tracking. We first empirically validate the efficiency of our EMS model in eliciting full eye closure. In a second experiment, we demonstrate the feasibility of using such a technique for seamless instantaneous displacement in VR and its particular impact for hand redirection. Among other factors, our analysis also delves into the under-explored domain of gender influence on hand redirection techniques, revealing significant gender-based performance disparities.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {37},
numpages = {11},
keywords = {EMS, Hand redirection, VR, eye blinks, redirection, virtual reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615716,
author = {Gabel, Jenny and Schmidt, Susanne and Ariza, Oscar and Steinicke, Frank},
title = {Redirecting Rays: Evaluation of Assistive Raycasting Techniques in Virtual Reality},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615716},
doi = {10.1145/3611659.3615716},
abstract = {Raycasting-based interaction techniques are widely used for object selection in immersive environments. Despite their intuitive use, they come with challenges due to small or far away objects, hand tremor, and tracking inaccuracies. Previous adaptations for raycasting, such as directly snapping the ray to the closest target, extruding the ray to a cone, or multi-step selection techniques, require additional time for users to become familiar with them. To address these issues, we propose three assistive techniques in which the visible selection ray is subtly redirected towards a target, with a proximity and gain based increase in the redirection amount. In a user study (N = 26), we compared these redirection techniques with a baseline condition based on a Fittsâ€™ law task and collected performance measures as well as comprehensive subjective feedback. The results indicate that the three redirection techniques are significantly faster and have higher effective throughput than the baseline condition. Participants retained a high sense of agency with all redirection techniques and reported significantly lower total workload compared to the baseline. The majority of participants preferred selection with assistive ray redirection and perceived it as not distracting or intrusive. Our findings support that assistive redirected raycasting techniques can improve object selection performance and user experience in virtual environments.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {38},
numpages = {11},
keywords = {interaction techniques, raycast redirection, selection, virtual reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@inproceedings{10.1145/3611659.3615697,
author = {Zielasko, Daniel and Weissker, Tim},
title = {Stay Vigilant: The Threat of a Replication Crisis in VR Locomotion Research},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3615697},
doi = {10.1145/3611659.3615697},
abstract = {The ability to reproduce previously published research findings is an important cornerstone of the scientific knowledge acquisition process. However, the exact details required to reproduce empirical experiments vary depending on the discipline. In this paper, we summarize key replication challenges as well as their specific consequences for VR locomotion research. We then present the results of a literature review on artificial locomotion techniques, in which we analyzed 61 papers published in the last five years with respect to their report of essential details required for reproduction. Our results indicate several issues in terms of the description of the experimental setup, the scientific rigor of the research process, and the generalizability of results, which altogether points towards a potential replication crisis in VR locomotion research. As a countermeasure, we provide guidelines to assist researchers with reporting future artificial locomotion experiments in a reproducible form.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {39},
numpages = {10},
keywords = {Locomotion, Replication Crisis, Reproducibility, Steering, Teleportation, Virtual Reality},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

